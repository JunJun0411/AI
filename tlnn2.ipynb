{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from functions import sigmoid, softmax\n",
    "from gradient import cross_entropy_error, numerical_gradient\n",
    "\n",
    "class TwoLayerNeuralNetwork2:\n",
    "    \"\"\" a neural network with one hidden layer \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\" initialize parameters \"\"\"\n",
    "        self.params = {}\n",
    "        # input --> hidden layer\n",
    "        self.params['W1'] = np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.random.randn(hidden_size)\n",
    "        # hidden layer --> output layer\n",
    "        self.params['W2'] = np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.random.randn(output_size)\n",
    "        self.input_size, self.output_size = input_size, output_size # input, output size 저장\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"calculate output given input and current parameters: W1, b1, W2, b2 \"\"\"\n",
    "        W1, W2, b1, b2 = self.params['W1'], self.params['W2'], self.params['b1'], self.params['b2']\n",
    "        \n",
    "        # input --> hidden layer : sigmoid\n",
    "        z2 = np.dot(x, W1) + b1\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        # hidden layer --> output : softmax\n",
    "        z3 = np.dot(a2, W2) + b2\n",
    "        y = softmax(z3)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "        \n",
    "    def accuracy(self, x, t):\n",
    "        \"\"\" testData로 실제 target과 계산된 y를 비교해서 맞춘 갯수 리턴\"\"\"\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        accuracy = np.sum(t[np.arange(t.shape[0]), y]) / t.shape[0]\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\" 가중치 매개변수의 기울기를 구한다. \"\"\"\n",
    "        f = lambda W: self.loss(x, t)\n",
    "\n",
    "        grad = {}\n",
    "        grad['W1'] = numerical_gradient(f, self.params['W1'])\n",
    "        grad['b1'] = numerical_gradient(f, self.params['b1'])\n",
    "        grad['W2'] = numerical_gradient(f, self.params['W2'])\n",
    "        grad['b2'] = numerical_gradient(f, self.params['b2'])\n",
    "        \n",
    "        return grad\n",
    "        \n",
    "        \n",
    "    def learn(self, lr, epoch):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2545915712281754\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8e068075c019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-8e068075c019>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#         grad[i] = (f(x+h) - f(x-h)) / (2*h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mtmp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtmp_val\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mfxh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "## import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def one_hot(y_train):\n",
    "        return np.eye(np.unique(y_train).shape[0])[y_train]\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data # iris data input\n",
    "y = iris.target # iris target (label)\n",
    "\n",
    "# 데이터 Split Use training : testing = 8 : 2\n",
    "l = int(X.shape[0] * 8 / 10)\n",
    "suffle = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "for_train = suffle[:l]\n",
    "for_test = suffle[l:]\n",
    "\n",
    "# for training data (X, y)\n",
    "X_train = X[for_train]\n",
    "y_train = y[for_train]\n",
    "y_train = one_hot(y_train)\n",
    "# for testing data (X, y)\n",
    "X_test = X[for_test]\n",
    "y_test = y[for_test]\n",
    "y_test = one_hot(y_test) \n",
    "\n",
    "tn2 = TwoLayerNeuralNetwork2(input_size = 4, hidden_size = 5, output_size = 3)\n",
    "\n",
    "print(tn2.params)\n",
    "# print(tn2.predict(X_train))\n",
    "# print(tn2.loss(X_train, y_train))\n",
    "# print(tn2.accuracy(X_test, y_test))\n",
    "print(tn2.numerical_gradient(X_train, y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
