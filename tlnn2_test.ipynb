{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 loss, accuracy:  1.615286482622568 0.30833333333333335\n",
      "1 번째 loss, accuracy:  1.6047675988235872 0.30833333333333335\n",
      "2 번째 loss, accuracy:  1.5944671341093837 0.30833333333333335\n",
      "3 번째 loss, accuracy:  1.5843806150982582 0.30833333333333335\n",
      "4 번째 loss, accuracy:  1.5745035816063222 0.30833333333333335\n",
      "5 번째 loss, accuracy:  1.5648315971059463 0.30833333333333335\n",
      "6 번째 loss, accuracy:  1.555360258042114 0.30833333333333335\n",
      "7 번째 loss, accuracy:  1.5460852020789957 0.30833333333333335\n",
      "8 번째 loss, accuracy:  1.537002115349939 0.30833333333333335\n",
      "9 번째 loss, accuracy:  1.5281067387819571 0.30833333333333335\n",
      "10 번째 loss, accuracy:  1.5193948735651488 0.30833333333333335\n",
      "11 번째 loss, accuracy:  1.5108623858336723 0.30833333333333335\n",
      "12 번째 loss, accuracy:  1.5025052106235046 0.30833333333333335\n",
      "13 번째 loss, accuracy:  1.4943193551680072 0.30833333333333335\n",
      "14 번째 loss, accuracy:  1.4863009015898716 0.30833333333333335\n",
      "15 번째 loss, accuracy:  1.47844600904412 0.30833333333333335\n",
      "16 번째 loss, accuracy:  1.4707509153641734 0.30833333333333335\n",
      "17 번째 loss, accuracy:  1.4632119382588016 0.30833333333333335\n",
      "18 번째 loss, accuracy:  1.4558254761056468 0.30833333333333335\n",
      "19 번째 loss, accuracy:  1.4485880083828373 0.30833333333333335\n",
      "20 번째 loss, accuracy:  1.4414960957777745 0.30833333333333335\n",
      "21 번째 loss, accuracy:  1.4345463800093365 0.30833333333333335\n",
      "22 번째 loss, accuracy:  1.427735583396378 0.30833333333333335\n",
      "23 번째 loss, accuracy:  1.4210605082034842 0.30833333333333335\n",
      "24 번째 loss, accuracy:  1.4145180357919398 0.30833333333333335\n",
      "25 번째 loss, accuracy:  1.4081051256018298 0.30833333333333335\n",
      "26 번째 loss, accuracy:  1.401818813988633 0.30833333333333335\n",
      "27 번째 loss, accuracy:  1.39565621293599 0.30833333333333335\n",
      "28 번째 loss, accuracy:  1.3896145086641203 0.30833333333333335\n",
      "29 번째 loss, accuracy:  1.3836909601514995 0.30833333333333335\n",
      "30 번째 loss, accuracy:  1.3778828975860293 0.30833333333333335\n",
      "31 번째 loss, accuracy:  1.3721877207599245 0.30833333333333335\n",
      "32 번째 loss, accuracy:  1.3666028974215363 0.30833333333333335\n",
      "33 번째 loss, accuracy:  1.3611259615955322 0.30833333333333335\n",
      "34 번째 loss, accuracy:  1.3557545118820082 0.30833333333333335\n",
      "35 번째 loss, accuracy:  1.3504862097437165 0.30833333333333335\n",
      "36 번째 loss, accuracy:  1.3453187777895637 0.30833333333333335\n",
      "37 번째 loss, accuracy:  1.340249998061642 0.30833333333333335\n",
      "38 번째 loss, accuracy:  1.3352777103322153 0.30833333333333335\n",
      "39 번째 loss, accuracy:  1.3303998104160153 0.30833333333333335\n",
      "40 번째 loss, accuracy:  1.3256142485028222 0.30833333333333335\n",
      "41 번째 loss, accuracy:  1.320919027514313 0.30833333333333335\n",
      "42 번째 loss, accuracy:  1.3163122014888584 0.30833333333333335\n",
      "43 번째 loss, accuracy:  1.3117918739970522 0.30833333333333335\n",
      "44 번째 loss, accuracy:  1.3073561965905838 0.30833333333333335\n",
      "45 번째 loss, accuracy:  1.3030033672864385 0.30833333333333335\n",
      "46 번째 loss, accuracy:  1.2987316290880007 0.30833333333333335\n",
      "47 번째 loss, accuracy:  1.294539268544415 0.30833333333333335\n",
      "48 번째 loss, accuracy:  1.2904246143491211 0.30833333333333335\n",
      "49 번째 loss, accuracy:  1.2863860359781394 0.30833333333333335\n",
      "50 번째 loss, accuracy:  1.2824219423686742 0.30833333333333335\n",
      "51 번째 loss, accuracy:  1.2785307806380182 0.30833333333333335\n",
      "52 번째 loss, accuracy:  1.274711034842953 0.30833333333333335\n",
      "53 번째 loss, accuracy:  1.2709612247793203 0.30833333333333335\n",
      "54 번째 loss, accuracy:  1.267279904821453 0.30833333333333335\n",
      "55 번째 loss, accuracy:  1.263665662801039 0.30833333333333335\n",
      "56 번째 loss, accuracy:  1.2601171189248426 0.30833333333333335\n",
      "57 번째 loss, accuracy:  1.2566329247305916 0.30833333333333335\n",
      "58 번째 loss, accuracy:  1.2532117620802075 0.30833333333333335\n",
      "59 번째 loss, accuracy:  1.2498523421897656 0.30833333333333335\n",
      "60 번째 loss, accuracy:  1.2465534046951208 0.30833333333333335\n",
      "61 번째 loss, accuracy:  1.2433137167523243 0.30833333333333335\n",
      "62 번째 loss, accuracy:  1.2401320721719744 0.30833333333333335\n",
      "63 번째 loss, accuracy:  1.2370072905864617 0.30833333333333335\n",
      "64 번째 loss, accuracy:  1.2339382166490651 0.30833333333333335\n",
      "65 번째 loss, accuracy:  1.2309237192640254 0.30833333333333335\n",
      "66 번째 loss, accuracy:  1.2279626908464942 0.30833333333333335\n",
      "67 번째 loss, accuracy:  1.2250540466113118 0.30833333333333335\n",
      "68 번째 loss, accuracy:  1.2221967238897946 0.30833333333333335\n",
      "69 번째 loss, accuracy:  1.219389681473316 0.30833333333333335\n",
      "70 번째 loss, accuracy:  1.216631898982829 0.30833333333333335\n",
      "71 번째 loss, accuracy:  1.213922376263343 0.30833333333333335\n",
      "72 번째 loss, accuracy:  1.2112601328023656 0.30833333333333335\n",
      "73 번째 loss, accuracy:  1.2086442071714247 0.30833333333333335\n",
      "74 번째 loss, accuracy:  1.2060736564897516 0.30833333333333335\n",
      "75 번째 loss, accuracy:  1.203547555909178 0.30833333333333335\n",
      "76 번째 loss, accuracy:  1.2010649981194477 0.30833333333333335\n",
      "77 번째 loss, accuracy:  1.1986250928731508 0.30833333333333335\n",
      "78 번째 loss, accuracy:  1.1962269665293244 0.30833333333333335\n",
      "79 번째 loss, accuracy:  1.1938697616150298 0.30833333333333335\n",
      "80 번째 loss, accuracy:  1.191552636404176 0.30833333333333335\n",
      "81 번째 loss, accuracy:  1.1892747645127477 0.3\n",
      "82 번째 loss, accuracy:  1.1870353345098055 0.2916666666666667\n",
      "83 번째 loss, accuracy:  1.1848335495436142 0.2916666666666667\n",
      "84 번째 loss, accuracy:  1.182668626982136 0.2916666666666667\n",
      "85 번째 loss, accuracy:  1.1805397980673384 0.2916666666666667\n",
      "86 번째 loss, accuracy:  1.1784463075826934 0.2916666666666667\n",
      "87 번째 loss, accuracy:  1.1763874135333325 0.3\n",
      "88 번째 loss, accuracy:  1.1743623868382145 0.2833333333333333\n",
      "89 번째 loss, accuracy:  1.1723705110338756 0.25\n",
      "90 번째 loss, accuracy:  1.1704110819892188 0.25\n",
      "91 번째 loss, accuracy:  1.168483407630812 0.21666666666666667\n",
      "92 번째 loss, accuracy:  1.1665868076783676 0.19166666666666668\n",
      "93 번째 loss, accuracy:  1.164720613389871 0.15833333333333333\n",
      "94 번째 loss, accuracy:  1.1628841673159536 0.13333333333333333\n",
      "95 번째 loss, accuracy:  1.1610768230631345 0.11666666666666667\n",
      "96 번째 loss, accuracy:  1.1592979450655772 0.1\n",
      "97 번째 loss, accuracy:  1.1575469083650176 0.11666666666666667\n",
      "98 번째 loss, accuracy:  1.1558230983984727 0.11666666666666667\n",
      "99 번째 loss, accuracy:  1.154125910793462 0.11666666666666667\n",
      "100 번째 loss, accuracy:  1.15245475117048 0.11666666666666667\n",
      "101 번째 loss, accuracy:  1.1508090349523443 0.125\n",
      "102 번째 loss, accuracy:  1.1491881871802676 0.125\n",
      "103 번째 loss, accuracy:  1.1475916423362866 0.13333333333333333\n",
      "104 번째 loss, accuracy:  1.1460188441719492 0.175\n",
      "105 번째 loss, accuracy:  1.144469245542924 0.19166666666666668\n",
      "106 번째 loss, accuracy:  1.1429423082494004 0.24166666666666667\n",
      "107 번째 loss, accuracy:  1.1414375028820796 0.25\n",
      "108 번째 loss, accuracy:  1.1399543086735227 0.3\n",
      "109 번째 loss, accuracy:  1.1384922133547668 0.31666666666666665\n",
      "110 번째 loss, accuracy:  1.1370507130169711 0.31666666666666665\n",
      "111 번째 loss, accuracy:  1.1356293119780576 0.325\n",
      "112 번째 loss, accuracy:  1.1342275226540726 0.3416666666666667\n",
      "113 번째 loss, accuracy:  1.132844865435235 0.35\n",
      "114 번째 loss, accuracy:  1.131480868566535 0.35\n",
      "115 번째 loss, accuracy:  1.1301350680327564 0.35\n",
      "116 번째 loss, accuracy:  1.12880700744781 0.35\n",
      "117 번째 loss, accuracy:  1.127496237948318 0.35\n",
      "118 번째 loss, accuracy:  1.1262023180913237 0.35\n",
      "119 번째 loss, accuracy:  1.124924813755998 0.35\n",
      "120 번째 loss, accuracy:  1.1236632980494141 0.35\n",
      "121 번째 loss, accuracy:  1.1224173512161149 0.35\n",
      "122 번째 loss, accuracy:  1.1211865605515057 0.35\n",
      "123 번째 loss, accuracy:  1.1199705203190298 0.35\n",
      "124 번째 loss, accuracy:  1.1187688316709574 0.35\n",
      "125 번째 loss, accuracy:  1.1175811025728009 0.35\n",
      "126 번째 loss, accuracy:  1.1164069477312457 0.35\n",
      "127 번째 loss, accuracy:  1.1152459885255426 0.35\n",
      "128 번째 loss, accuracy:  1.1140978529423171 0.35\n",
      "129 번째 loss, accuracy:  1.1129621755136583 0.35\n",
      "130 번째 loss, accuracy:  1.1118385972585214 0.35\n",
      "131 번째 loss, accuracy:  1.11072676562726 0.35\n",
      "132 번째 loss, accuracy:  1.1096263344492991 0.35\n",
      "133 번째 loss, accuracy:  1.1085369638838207 0.35\n",
      "134 번째 loss, accuracy:  1.1074583203734227 0.35\n",
      "135 번째 loss, accuracy:  1.1063900766006385 0.35\n",
      "136 번째 loss, accuracy:  1.1053319114472169 0.35\n",
      "137 번째 loss, accuracy:  1.1042835099560997 0.35\n",
      "138 번째 loss, accuracy:  1.103244563295983 0.35\n",
      "139 번째 loss, accuracy:  1.1022147687283412 0.35\n",
      "140 번째 loss, accuracy:  1.1011938295768693 0.35\n",
      "141 번째 loss, accuracy:  1.1001814551991027 0.35\n",
      "142 번째 loss, accuracy:  1.0991773609602187 0.35\n",
      "143 번째 loss, accuracy:  1.0981812682088135 0.35\n",
      "144 번째 loss, accuracy:  1.0971929042545223 0.35\n",
      "145 번째 loss, accuracy:  1.096212002347375 0.35\n",
      "146 번째 loss, accuracy:  1.0952383016587328 0.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 번째 loss, accuracy:  1.094271547263531 0.35\n",
      "148 번째 loss, accuracy:  1.0933114901238834 0.35\n",
      "149 번째 loss, accuracy:  1.0923578870736368 0.35\n",
      "150 번째 loss, accuracy:  1.0914105008038806 0.35\n",
      "151 번째 loss, accuracy:  1.0904690998490871 0.35\n",
      "152 번째 loss, accuracy:  1.0895334585738077 0.35\n",
      "153 번째 loss, accuracy:  1.088603357159623 0.35\n",
      "154 번째 loss, accuracy:  1.0876785815922143 0.35\n",
      "155 번째 loss, accuracy:  1.0867589236483128 0.35\n",
      "156 번째 loss, accuracy:  1.0858441808823187 0.35\n",
      "157 번째 loss, accuracy:  1.0849341566123907 0.35\n",
      "158 번째 loss, accuracy:  1.084028659905773 0.35\n",
      "159 번째 loss, accuracy:  1.0831275055631158 0.35\n",
      "160 번째 loss, accuracy:  1.0822305141016473 0.35\n",
      "161 번째 loss, accuracy:  1.0813375117368653 0.35\n",
      "162 번째 loss, accuracy:  1.0804483303626413 0.35\n",
      "163 번째 loss, accuracy:  1.079562807529455 0.35\n",
      "164 번째 loss, accuracy:  1.0786807864205448 0.35\n",
      "165 번째 loss, accuracy:  1.077802115825809 0.35\n",
      "166 번째 loss, accuracy:  1.0769266501132306 0.35\n",
      "167 번째 loss, accuracy:  1.0760542491976415 0.35\n",
      "168 번째 loss, accuracy:  1.0751847785066369 0.35\n",
      "169 번째 loss, accuracy:  1.0743181089434577 0.35\n",
      "170 번째 loss, accuracy:  1.0734541168467453 0.35\n",
      "171 번째 loss, accuracy:  1.072592683946892 0.35\n",
      "172 번째 loss, accuracy:  1.071733697318982 0.35\n",
      "173 번째 loss, accuracy:  1.0708770493321267 0.35\n",
      "174 번째 loss, accuracy:  1.0700226375951194 0.35\n",
      "175 번째 loss, accuracy:  1.069170364898326 0.35\n",
      "176 번째 loss, accuracy:  1.0683201391516903 0.35\n",
      "177 번째 loss, accuracy:  1.0674718733189072 0.35\n",
      "178 번째 loss, accuracy:  1.066625485347615 0.35\n",
      "179 번째 loss, accuracy:  1.0657808980956782 0.35\n",
      "180 번째 loss, accuracy:  1.0649380392535335 0.35\n",
      "181 번째 loss, accuracy:  1.0640968412626417 0.35\n",
      "182 번째 loss, accuracy:  1.0632572412300794 0.35\n",
      "183 번째 loss, accuracy:  1.0624191808393537 0.35\n",
      "184 번째 loss, accuracy:  1.0615826062575133 0.35\n",
      "185 번째 loss, accuracy:  1.0607474680387134 0.35\n",
      "186 번째 loss, accuracy:  1.0599137210242657 0.35\n",
      "187 번째 loss, accuracy:  1.0590813242394432 0.35\n",
      "188 번째 loss, accuracy:  1.0582502407870984 0.35\n",
      "189 번째 loss, accuracy:  1.0574204377383332 0.35\n",
      "190 번째 loss, accuracy:  1.0565918860204149 0.35\n",
      "191 번째 loss, accuracy:  1.0557645603021242 0.35\n",
      "192 번째 loss, accuracy:  1.0549384388767844 0.35\n",
      "193 번째 loss, accuracy:  1.0541135035431883 0.35\n",
      "194 번째 loss, accuracy:  1.0532897394846907 0.35\n",
      "195 번째 loss, accuracy:  1.0524671351466923 0.35\n",
      "196 번째 loss, accuracy:  1.0516456821128253 0.35\n",
      "197 번째 loss, accuracy:  1.0508253749800243 0.35\n",
      "198 번째 loss, accuracy:  1.0500062112328503 0.35\n",
      "199 번째 loss, accuracy:  1.0491881911172802 0.35\n",
      "200 번째 loss, accuracy:  1.0483713175142302 0.35\n",
      "201 번째 loss, accuracy:  1.0475555958131337 0.35\n",
      "202 번째 loss, accuracy:  1.04674103378578 0.35\n",
      "203 번째 loss, accuracy:  1.0459276414607184 0.35\n",
      "204 번째 loss, accuracy:  1.0451154309984836 0.35\n",
      "205 번째 loss, accuracy:  1.0443044165678725 0.35\n",
      "206 번째 loss, accuracy:  1.0434946142235024 0.35833333333333334\n",
      "207 번째 loss, accuracy:  1.042686041784956 0.35833333333333334\n",
      "208 번째 loss, accuracy:  1.0418787187176288 0.35833333333333334\n",
      "209 번째 loss, accuracy:  1.0410726660155578 0.35833333333333334\n",
      "210 번째 loss, accuracy:  1.0402679060864164 0.35833333333333334\n",
      "211 번째 loss, accuracy:  1.039464462638852 0.35833333333333334\n",
      "212 번째 loss, accuracy:  1.038662360572306 0.35833333333333334\n",
      "213 번째 loss, accuracy:  1.0378616258695301 0.35833333333333334\n",
      "214 번째 loss, accuracy:  1.0370622854918905 0.36666666666666664\n",
      "215 번째 loss, accuracy:  1.0362643672776006 0.36666666666666664\n",
      "216 번째 loss, accuracy:  1.0354678998429914 0.36666666666666664\n",
      "217 번째 loss, accuracy:  1.0346729124869187 0.375\n",
      "218 번째 loss, accuracy:  1.0338794350983815 0.375\n",
      "219 번째 loss, accuracy:  1.0330874980674054 0.375\n",
      "220 번째 loss, accuracy:  1.0322971321992866 0.375\n",
      "221 번째 loss, accuracy:  1.0315083686321769 0.375\n",
      "222 번째 loss, accuracy:  1.03072123875806 0.375\n",
      "223 번째 loss, accuracy:  1.0299357741471542 0.375\n",
      "224 번째 loss, accuracy:  1.0291520064757036 0.38333333333333336\n",
      "225 번째 loss, accuracy:  1.0283699674571658 0.38333333333333336\n",
      "226 번째 loss, accuracy:  1.0275896887767695 0.38333333333333336\n",
      "227 번째 loss, accuracy:  1.0268112020294242 0.4083333333333333\n",
      "228 번째 loss, accuracy:  1.0260345386609102 0.4083333333333333\n",
      "229 번째 loss, accuracy:  1.0252597299123323 0.4083333333333333\n",
      "230 번째 loss, accuracy:  1.0244868067677628 0.4166666666666667\n",
      "231 번째 loss, accuracy:  1.0237157999050208 0.4166666666666667\n",
      "232 번째 loss, accuracy:  1.0229467396494907 0.4166666666666667\n",
      "233 번째 loss, accuracy:  1.0221796559309648 0.4166666666666667\n",
      "234 번째 loss, accuracy:  1.0214145782433481 0.425\n",
      "235 번째 loss, accuracy:  1.0206515356072208 0.425\n",
      "236 번째 loss, accuracy:  1.0198905565351175 0.425\n",
      "237 번째 loss, accuracy:  1.0191316689994523 0.425\n",
      "238 번째 loss, accuracy:  1.0183749004030187 0.425\n",
      "239 번째 loss, accuracy:  1.0176202775519285 0.43333333333333335\n",
      "240 번째 loss, accuracy:  1.0168678266309426 0.43333333333333335\n",
      "241 번째 loss, accuracy:  1.0161175731810543 0.43333333333333335\n",
      "242 번째 loss, accuracy:  1.015369542079272 0.45\n",
      "243 번째 loss, accuracy:  1.0146237575204937 0.4583333333333333\n",
      "244 번째 loss, accuracy:  1.0138802430013418 0.4666666666666667\n",
      "245 번째 loss, accuracy:  1.0131390213059415 0.48333333333333334\n",
      "246 번째 loss, accuracy:  1.0124001144934955 0.48333333333333334\n",
      "247 번째 loss, accuracy:  1.0116635438875867 0.49166666666666664\n",
      "248 번째 loss, accuracy:  1.0109293300671125 0.49166666666666664\n",
      "249 번째 loss, accuracy:  1.0101974928587647 0.49166666666666664\n",
      "250 번째 loss, accuracy:  1.0094680513310044 0.5\n",
      "251 번째 loss, accuracy:  1.0087410237894099 0.5\n",
      "252 번째 loss, accuracy:  1.0080164277733281 0.5\n",
      "253 번째 loss, accuracy:  1.0072942800537943 0.5\n",
      "254 번째 loss, accuracy:  1.0065745966325843 0.5083333333333333\n",
      "255 번째 loss, accuracy:  1.0058573927423824 0.5166666666666667\n",
      "256 번째 loss, accuracy:  1.005142682847967 0.5166666666666667\n",
      "257 번째 loss, accuracy:  1.0044304806483624 0.525\n",
      "258 번째 loss, accuracy:  1.0037207990798953 0.5416666666666666\n",
      "259 번째 loss, accuracy:  1.0030136503200888 0.5416666666666666\n",
      "260 번째 loss, accuracy:  1.002309045792347 0.55\n",
      "261 번째 loss, accuracy:  1.0016069961713654 0.55\n",
      "262 번째 loss, accuracy:  1.0009075113892338 0.55\n",
      "263 번째 loss, accuracy:  1.0002106006421423 0.55\n",
      "264 번째 loss, accuracy:  0.9995162723977086 0.55\n",
      "265 번째 loss, accuracy:  0.9988245344028105 0.55\n",
      "266 번째 loss, accuracy:  0.9981353936919407 0.5583333333333333\n",
      "267 번째 loss, accuracy:  0.9974488565960123 0.5666666666666667\n",
      "268 번째 loss, accuracy:  0.9967649287515588 0.575\n",
      "269 번째 loss, accuracy:  0.9960836151103583 0.575\n",
      "270 번째 loss, accuracy:  0.9954049199493794 0.575\n",
      "271 번째 loss, accuracy:  0.9947288468810406 0.575\n",
      "272 번째 loss, accuracy:  0.9940553988637709 0.575\n",
      "273 번째 loss, accuracy:  0.9933845782128204 0.575\n",
      "274 번째 loss, accuracy:  0.9927163866112972 0.575\n",
      "275 번째 loss, accuracy:  0.9920508251214007 0.5916666666666667\n",
      "276 번째 loss, accuracy:  0.9913878941958588 0.5916666666666667\n",
      "277 번째 loss, accuracy:  0.9907275936894844 0.6\n",
      "278 번째 loss, accuracy:  0.9900699228709047 0.6083333333333333\n",
      "279 번째 loss, accuracy:  0.9894148804343793 0.6166666666666667\n",
      "280 번째 loss, accuracy:  0.9887624645117065 0.6166666666666667\n",
      "281 번째 loss, accuracy:  0.9881126726842265 0.6166666666666667\n",
      "282 번째 loss, accuracy:  0.9874655019948816 0.625\n",
      "283 번째 loss, accuracy:  0.9868209489603016 0.625\n",
      "284 번째 loss, accuracy:  0.9861790095829192 0.6333333333333333\n",
      "285 번째 loss, accuracy:  0.9855396793631274 0.6333333333333333\n",
      "286 번째 loss, accuracy:  0.9849029533113972 0.6333333333333333\n",
      "287 번째 loss, accuracy:  0.9842688259604135 0.6333333333333333\n",
      "288 번째 loss, accuracy:  0.983637291377164 0.6416666666666667\n",
      "289 번째 loss, accuracy:  0.9830083431750107 0.6416666666666667\n",
      "290 번째 loss, accuracy:  0.9823819745257049 0.6416666666666667\n",
      "291 번째 loss, accuracy:  0.9817581781713448 0.65\n",
      "292 번째 loss, accuracy:  0.9811369464362788 0.65\n",
      "293 번째 loss, accuracy:  0.9805182712389289 0.65\n",
      "294 번째 loss, accuracy:  0.9799021441035263 0.6583333333333333\n",
      "295 번째 loss, accuracy:  0.9792885561717746 0.6583333333333333\n",
      "296 번째 loss, accuracy:  0.9786774982143972 0.6666666666666666\n",
      "297 번째 loss, accuracy:  0.9780689606426088 0.6666666666666666\n",
      "298 번째 loss, accuracy:  0.9774629335194469 0.6666666666666666\n",
      "299 번째 loss, accuracy:  0.9768594065710184 0.675\n",
      "300 번째 loss, accuracy:  0.9762583691976118 0.675\n",
      "301 번째 loss, accuracy:  0.9756598104846899 0.675\n",
      "302 번째 loss, accuracy:  0.9750637192137581 0.6833333333333333\n",
      "303 번째 loss, accuracy:  0.9744700838730893 0.6833333333333333\n",
      "304 번째 loss, accuracy:  0.9738788926683264 0.6833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 번째 loss, accuracy:  0.9732901335329507 0.6833333333333333\n",
      "306 번째 loss, accuracy:  0.972703794138581 0.6833333333333333\n",
      "307 번째 loss, accuracy:  0.9721198619051618 0.6833333333333333\n",
      "308 번째 loss, accuracy:  0.9715383240109788 0.6833333333333333\n",
      "309 번째 loss, accuracy:  0.9709591674025417 0.6833333333333333\n",
      "310 번째 loss, accuracy:  0.9703823788042968 0.6833333333333333\n",
      "311 번째 loss, accuracy:  0.9698079447282143 0.6833333333333333\n",
      "312 번째 loss, accuracy:  0.9692358514831938 0.6833333333333333\n",
      "313 번째 loss, accuracy:  0.9686660851843264 0.6833333333333333\n",
      "314 번째 loss, accuracy:  0.9680986317620018 0.6833333333333333\n",
      "315 번째 loss, accuracy:  0.967533476970852 0.6833333333333333\n",
      "316 번째 loss, accuracy:  0.9669706063985344 0.6833333333333333\n",
      "317 번째 loss, accuracy:  0.9664100054743631 0.6833333333333333\n",
      "318 번째 loss, accuracy:  0.9658516594777781 0.6833333333333333\n",
      "319 번째 loss, accuracy:  0.9652955535466455 0.6833333333333333\n",
      "320 번째 loss, accuracy:  0.9647416726854068 0.6833333333333333\n",
      "321 번째 loss, accuracy:  0.9641900017730732 0.6833333333333333\n",
      "322 번째 loss, accuracy:  0.9636405255710433 0.6833333333333333\n",
      "323 번째 loss, accuracy:  0.9630932287307801 0.6833333333333333\n",
      "324 번째 loss, accuracy:  0.9625480958013017 0.6833333333333333\n",
      "325 번째 loss, accuracy:  0.9620051112365547 0.6833333333333333\n",
      "326 번째 loss, accuracy:  0.961464259402591 0.6833333333333333\n",
      "327 번째 loss, accuracy:  0.9609255245846046 0.6833333333333333\n",
      "328 번째 loss, accuracy:  0.9603888909938064 0.6833333333333333\n",
      "329 번째 loss, accuracy:  0.9598543427741556 0.6833333333333333\n",
      "330 번째 loss, accuracy:  0.9593218640089192 0.6833333333333333\n",
      "331 번째 loss, accuracy:  0.9587914387270937 0.6833333333333333\n",
      "332 번째 loss, accuracy:  0.9582630509096591 0.6833333333333333\n",
      "333 번째 loss, accuracy:  0.9577366844956928 0.6833333333333333\n",
      "334 번째 loss, accuracy:  0.9572123233883355 0.6833333333333333\n",
      "335 번째 loss, accuracy:  0.9566899514606031 0.6833333333333333\n",
      "336 번째 loss, accuracy:  0.956169552561049 0.6833333333333333\n",
      "337 번째 loss, accuracy:  0.9556511105192887 0.6833333333333333\n",
      "338 번째 loss, accuracy:  0.9551346091513788 0.6833333333333333\n",
      "339 번째 loss, accuracy:  0.95462003226504 0.6833333333333333\n",
      "340 번째 loss, accuracy:  0.9541073636647709 0.6833333333333333\n",
      "341 번째 loss, accuracy:  0.9535965871567901 0.6833333333333333\n",
      "342 번째 loss, accuracy:  0.9530876865538522 0.6833333333333333\n",
      "343 번째 loss, accuracy:  0.9525806456799427 0.6833333333333333\n",
      "344 번째 loss, accuracy:  0.9520754483748134 0.6833333333333333\n",
      "345 번째 loss, accuracy:  0.9515720784983998 0.6833333333333333\n",
      "346 번째 loss, accuracy:  0.9510705199351237 0.6833333333333333\n",
      "347 번째 loss, accuracy:  0.9505707565980354 0.6833333333333333\n",
      "348 번째 loss, accuracy:  0.9500727724328447 0.6833333333333333\n",
      "349 번째 loss, accuracy:  0.9495765514218383 0.6833333333333333\n",
      "350 번째 loss, accuracy:  0.9490820775876568 0.6833333333333333\n",
      "351 번째 loss, accuracy:  0.9485893349969626 0.6833333333333333\n",
      "352 번째 loss, accuracy:  0.9480983077639761 0.6833333333333333\n",
      "353 번째 loss, accuracy:  0.9476089800539176 0.6833333333333333\n",
      "354 번째 loss, accuracy:  0.9471213360863047 0.6833333333333333\n",
      "355 번째 loss, accuracy:  0.9466353601381604 0.6833333333333333\n",
      "356 번째 loss, accuracy:  0.946151036547104 0.6833333333333333\n",
      "357 번째 loss, accuracy:  0.9456683497143243 0.6833333333333333\n",
      "358 번째 loss, accuracy:  0.9451872841074501 0.6833333333333333\n",
      "359 번째 loss, accuracy:  0.9447078242633257 0.6833333333333333\n",
      "360 번째 loss, accuracy:  0.944229954790663 0.6833333333333333\n",
      "361 번째 loss, accuracy:  0.943753660372614 0.6833333333333333\n",
      "362 번째 loss, accuracy:  0.9432789257692279 0.6833333333333333\n",
      "363 번째 loss, accuracy:  0.9428057358198116 0.6833333333333333\n",
      "364 번째 loss, accuracy:  0.9423340754452059 0.6833333333333333\n",
      "365 번째 loss, accuracy:  0.9418639296499618 0.6833333333333333\n",
      "366 번째 loss, accuracy:  0.9413952835244129 0.6833333333333333\n",
      "367 번째 loss, accuracy:  0.940928122246681 0.6833333333333333\n",
      "368 번째 loss, accuracy:  0.9404624310845734 0.6833333333333333\n",
      "369 번째 loss, accuracy:  0.939998195397413 0.6833333333333333\n",
      "370 번째 loss, accuracy:  0.9395354006377533 0.6833333333333333\n",
      "371 번째 loss, accuracy:  0.9390740323530486 0.6833333333333333\n",
      "372 번째 loss, accuracy:  0.9386140761872203 0.6833333333333333\n",
      "373 번째 loss, accuracy:  0.9381555178821431 0.6833333333333333\n",
      "374 번째 loss, accuracy:  0.9376983432790692 0.6833333333333333\n",
      "375 번째 loss, accuracy:  0.9372425383199601 0.6833333333333333\n",
      "376 번째 loss, accuracy:  0.9367880890487581 0.6833333333333333\n",
      "377 번째 loss, accuracy:  0.9363349816125797 0.6833333333333333\n",
      "378 번째 loss, accuracy:  0.9358832022628351 0.6833333333333333\n",
      "379 번째 loss, accuracy:  0.9354327373562868 0.6833333333333333\n",
      "380 번째 loss, accuracy:  0.9349835733560402 0.6833333333333333\n",
      "381 번째 loss, accuracy:  0.9345356968324623 0.6833333333333333\n",
      "382 번째 loss, accuracy:  0.9340890944640436 0.6833333333333333\n",
      "383 번째 loss, accuracy:  0.9336437530381979 0.6833333333333333\n",
      "384 번째 loss, accuracy:  0.9331996594519951 0.6833333333333333\n",
      "385 번째 loss, accuracy:  0.9327568007128407 0.6833333333333333\n",
      "386 번째 loss, accuracy:  0.9323151639391016 0.6833333333333333\n",
      "387 번째 loss, accuracy:  0.9318747363606635 0.6833333333333333\n",
      "388 번째 loss, accuracy:  0.9314355053194469 0.6833333333333333\n",
      "389 번째 loss, accuracy:  0.9309974582698625 0.6833333333333333\n",
      "390 번째 loss, accuracy:  0.9305605827792255 0.6833333333333333\n",
      "391 번째 loss, accuracy:  0.930124866528102 0.6833333333333333\n",
      "392 번째 loss, accuracy:  0.9296902973106266 0.6833333333333333\n",
      "393 번째 loss, accuracy:  0.9292568630347507 0.6833333333333333\n",
      "394 번째 loss, accuracy:  0.9288245517224776 0.6833333333333333\n",
      "395 번째 loss, accuracy:  0.9283933515100126 0.6833333333333333\n",
      "396 번째 loss, accuracy:  0.9279632506479117 0.6833333333333333\n",
      "397 번째 loss, accuracy:  0.9275342375011458 0.6833333333333333\n",
      "398 번째 loss, accuracy:  0.9271063005491668 0.6833333333333333\n",
      "399 번째 loss, accuracy:  0.9266794283858998 0.6833333333333333\n",
      "400 번째 loss, accuracy:  0.9262536097197175 0.6833333333333333\n",
      "401 번째 loss, accuracy:  0.92582883337337 0.6833333333333333\n",
      "402 번째 loss, accuracy:  0.9254050882838792 0.6833333333333333\n",
      "403 번째 loss, accuracy:  0.9249823635024049 0.6833333333333333\n",
      "404 번째 loss, accuracy:  0.9245606481940669 0.6833333333333333\n",
      "405 번째 loss, accuracy:  0.924139931637747 0.6833333333333333\n",
      "406 번째 loss, accuracy:  0.9237202032258456 0.6833333333333333\n",
      "407 번째 loss, accuracy:  0.9233014524640208 0.6833333333333333\n",
      "408 번째 loss, accuracy:  0.9228836689708922 0.6833333333333333\n",
      "409 번째 loss, accuracy:  0.9224668424777176 0.6833333333333333\n",
      "410 번째 loss, accuracy:  0.9220509628280463 0.6833333333333333\n",
      "411 번째 loss, accuracy:  0.9216360199773401 0.6833333333333333\n",
      "412 번째 loss, accuracy:  0.9212220039925736 0.6833333333333333\n",
      "413 번째 loss, accuracy:  0.9208089050518062 0.6833333333333333\n",
      "414 번째 loss, accuracy:  0.9203967134437373 0.6833333333333333\n",
      "415 번째 loss, accuracy:  0.919985419567237 0.6833333333333333\n",
      "416 번째 loss, accuracy:  0.9195750139308468 0.6833333333333333\n",
      "417 번째 loss, accuracy:  0.9191654871522758 0.6833333333333333\n",
      "418 번째 loss, accuracy:  0.9187568299578618 0.6833333333333333\n",
      "419 번째 loss, accuracy:  0.9183490331820264 0.6833333333333333\n",
      "420 번째 loss, accuracy:  0.9179420877666983 0.6833333333333333\n",
      "421 번째 loss, accuracy:  0.9175359847607304 0.6833333333333333\n",
      "422 번째 loss, accuracy:  0.917130715319301 0.6833333333333333\n",
      "423 번째 loss, accuracy:  0.9167262707032852 0.6833333333333333\n",
      "424 번째 loss, accuracy:  0.9163226422786303 0.6833333333333333\n",
      "425 번째 loss, accuracy:  0.9159198215157017 0.6833333333333333\n",
      "426 번째 loss, accuracy:  0.9155177999886235 0.6916666666666667\n",
      "427 번째 loss, accuracy:  0.9151165693746006 0.6916666666666667\n",
      "428 번째 loss, accuracy:  0.9147161214532347 0.6916666666666667\n",
      "429 번째 loss, accuracy:  0.9143164481058311 0.6916666666666667\n",
      "430 번째 loss, accuracy:  0.9139175413146726 0.6916666666666667\n",
      "431 번째 loss, accuracy:  0.9135193931623152 0.6916666666666667\n",
      "432 번째 loss, accuracy:  0.9131219958308475 0.6916666666666667\n",
      "433 번째 loss, accuracy:  0.9127253416011577 0.6916666666666667\n",
      "434 번째 loss, accuracy:  0.9123294228521835 0.6916666666666667\n",
      "435 번째 loss, accuracy:  0.9119342320601528 0.6916666666666667\n",
      "436 번째 loss, accuracy:  0.9115397617978248 0.6916666666666667\n",
      "437 번째 loss, accuracy:  0.9111460047337201 0.6916666666666667\n",
      "438 번째 loss, accuracy:  0.910752953631331 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 번째 loss, accuracy:  0.9103606013483574 0.6916666666666667\n",
      "440 번째 loss, accuracy:  0.9099689408359009 0.6916666666666667\n",
      "441 번째 loss, accuracy:  0.90957796513768 0.6916666666666667\n",
      "442 번째 loss, accuracy:  0.9091876673892233 0.6916666666666667\n",
      "443 번째 loss, accuracy:  0.908798040817077 0.6916666666666667\n",
      "444 번째 loss, accuracy:  0.9084090787379882 0.6916666666666667\n",
      "445 번째 loss, accuracy:  0.9080207745580999 0.6916666666666667\n",
      "446 번째 loss, accuracy:  0.9076331217721321 0.6916666666666667\n",
      "447 번째 loss, accuracy:  0.9072461139625696 0.6916666666666667\n",
      "448 번째 loss, accuracy:  0.906859744798849 0.6916666666666667\n",
      "449 번째 loss, accuracy:  0.9064740080365233 0.6916666666666667\n",
      "450 번째 loss, accuracy:  0.9060888975164559 0.6916666666666667\n",
      "451 번째 loss, accuracy:  0.9057044071639858 0.6916666666666667\n",
      "452 번째 loss, accuracy:  0.9053205309881119 0.6916666666666667\n",
      "453 번째 loss, accuracy:  0.9049372630806606 0.6916666666666667\n",
      "454 번째 loss, accuracy:  0.9045545976154699 0.6916666666666667\n",
      "455 번째 loss, accuracy:  0.9041725288475566 0.6916666666666667\n",
      "456 번째 loss, accuracy:  0.9037910511122942 0.6916666666666667\n",
      "457 번째 loss, accuracy:  0.9034101588245927 0.6916666666666667\n",
      "458 번째 loss, accuracy:  0.9030298464780713 0.6916666666666667\n",
      "459 번째 loss, accuracy:  0.9026501086442368 0.6916666666666667\n",
      "460 번째 loss, accuracy:  0.9022709399716663 0.6916666666666667\n",
      "461 번째 loss, accuracy:  0.9018923351851842 0.6916666666666667\n",
      "462 번째 loss, accuracy:  0.9015142890850513 0.6916666666666667\n",
      "463 번째 loss, accuracy:  0.9011367965461408 0.6916666666666667\n",
      "464 번째 loss, accuracy:  0.9007598525171313 0.6916666666666667\n",
      "465 번째 loss, accuracy:  0.9003834520196992 0.6916666666666667\n",
      "466 번째 loss, accuracy:  0.9000075901477044 0.6916666666666667\n",
      "467 번째 loss, accuracy:  0.8996322620663904 0.6916666666666667\n",
      "468 번째 loss, accuracy:  0.8992574630115805 0.6916666666666667\n",
      "469 번째 loss, accuracy:  0.8988831882888823 0.6916666666666667\n",
      "470 번째 loss, accuracy:  0.8985094332728912 0.6916666666666667\n",
      "471 번째 loss, accuracy:  0.898136193406397 0.6916666666666667\n",
      "472 번째 loss, accuracy:  0.8977634641995976 0.6916666666666667\n",
      "473 번째 loss, accuracy:  0.8973912412293223 0.6916666666666667\n",
      "474 번째 loss, accuracy:  0.8970195201382357 0.6916666666666667\n",
      "475 번째 loss, accuracy:  0.8966482966340793 0.6916666666666667\n",
      "476 번째 loss, accuracy:  0.8962775664888909 0.6916666666666667\n",
      "477 번째 loss, accuracy:  0.8959073255382389 0.6916666666666667\n",
      "478 번째 loss, accuracy:  0.8955375696804619 0.6916666666666667\n",
      "479 번째 loss, accuracy:  0.8951682948759093 0.6916666666666667\n",
      "480 번째 loss, accuracy:  0.8947994971461932 0.6916666666666667\n",
      "481 번째 loss, accuracy:  0.8944311725734285 0.6916666666666667\n",
      "482 번째 loss, accuracy:  0.8940633172995013 0.6916666666666667\n",
      "483 번째 loss, accuracy:  0.893695927525328 0.6916666666666667\n",
      "484 번째 loss, accuracy:  0.8933289995101181 0.6916666666666667\n",
      "485 번째 loss, accuracy:  0.8929625295706519 0.6916666666666667\n",
      "486 번째 loss, accuracy:  0.8925965140805512 0.6916666666666667\n",
      "487 번째 loss, accuracy:  0.89223094946957 0.6916666666666667\n",
      "488 번째 loss, accuracy:  0.8918658322228766 0.6916666666666667\n",
      "489 번째 loss, accuracy:  0.8915011588803476 0.6916666666666667\n",
      "490 번째 loss, accuracy:  0.8911369260358681 0.6916666666666667\n",
      "491 번째 loss, accuracy:  0.890773130336639 0.6916666666666667\n",
      "492 번째 loss, accuracy:  0.8904097684824835 0.6916666666666667\n",
      "493 번째 loss, accuracy:  0.8900468372251623 0.6916666666666667\n",
      "494 번째 loss, accuracy:  0.889684333367703 0.6916666666666667\n",
      "495 번째 loss, accuracy:  0.889322253763716 0.6916666666666667\n",
      "496 번째 loss, accuracy:  0.8889605953167372 0.6916666666666667\n",
      "497 번째 loss, accuracy:  0.8885993549795629 0.6916666666666667\n",
      "498 번째 loss, accuracy:  0.8882385297535916 0.6916666666666667\n",
      "499 번째 loss, accuracy:  0.8878781166881825 0.6916666666666667\n",
      "500 번째 loss, accuracy:  0.8875181128800056 0.6916666666666667\n",
      "501 번째 loss, accuracy:  0.8871585154724071 0.6916666666666667\n",
      "502 번째 loss, accuracy:  0.8867993216547801 0.6916666666666667\n",
      "503 번째 loss, accuracy:  0.8864405286619312 0.6916666666666667\n",
      "504 번째 loss, accuracy:  0.8860821337734712 0.6916666666666667\n",
      "505 번째 loss, accuracy:  0.8857241343131932 0.6916666666666667\n",
      "506 번째 loss, accuracy:  0.8853665276484678 0.6916666666666667\n",
      "507 번째 loss, accuracy:  0.885009311189642 0.6916666666666667\n",
      "508 번째 loss, accuracy:  0.8846524823894464 0.6916666666666667\n",
      "509 번째 loss, accuracy:  0.8842960387423968 0.6916666666666667\n",
      "510 번째 loss, accuracy:  0.8839399777842206 0.6916666666666667\n",
      "511 번째 loss, accuracy:  0.8835842970912725 0.6916666666666667\n",
      "512 번째 loss, accuracy:  0.8832289942799657 0.6916666666666667\n",
      "513 번째 loss, accuracy:  0.8828740670062046 0.6916666666666667\n",
      "514 번째 loss, accuracy:  0.8825195129648241 0.6916666666666667\n",
      "515 번째 loss, accuracy:  0.8821653298890377 0.6916666666666667\n",
      "516 번째 loss, accuracy:  0.8818115155498897 0.6916666666666667\n",
      "517 번째 loss, accuracy:  0.881458067755712 0.6916666666666667\n",
      "518 번째 loss, accuracy:  0.8811049843515885 0.6916666666666667\n",
      "519 번째 loss, accuracy:  0.8807522632188213 0.6916666666666667\n",
      "520 번째 loss, accuracy:  0.880399902274411 0.6916666666666667\n",
      "521 번째 loss, accuracy:  0.8800478994705372 0.6916666666666667\n",
      "522 번째 loss, accuracy:  0.8796962527940415 0.6916666666666667\n",
      "523 번째 loss, accuracy:  0.8793449602659289 0.6916666666666667\n",
      "524 번째 loss, accuracy:  0.8789940199408576 0.6916666666666667\n",
      "525 번째 loss, accuracy:  0.8786434299066453 0.6916666666666667\n",
      "526 번째 loss, accuracy:  0.8782931882837857 0.6916666666666667\n",
      "527 번째 loss, accuracy:  0.8779432932249551 0.6916666666666667\n",
      "528 번째 loss, accuracy:  0.8775937429145398 0.6916666666666667\n",
      "529 번째 loss, accuracy:  0.8772445355681621 0.6916666666666667\n",
      "530 번째 loss, accuracy:  0.8768956694322114 0.6916666666666667\n",
      "531 번째 loss, accuracy:  0.8765471427833835 0.6916666666666667\n",
      "532 번째 loss, accuracy:  0.8761989539282236 0.6916666666666667\n",
      "533 번째 loss, accuracy:  0.8758511012026796 0.6916666666666667\n",
      "534 번째 loss, accuracy:  0.875503582971647 0.6916666666666667\n",
      "535 번째 loss, accuracy:  0.8751563976285388 0.6916666666666667\n",
      "536 번째 loss, accuracy:  0.8748095435948472 0.6916666666666667\n",
      "537 번째 loss, accuracy:  0.8744630193197146 0.6916666666666667\n",
      "538 번째 loss, accuracy:  0.874116823279505 0.6916666666666667\n",
      "539 번째 loss, accuracy:  0.8737709539773929 0.6916666666666667\n",
      "540 번째 loss, accuracy:  0.8734254099429468 0.6916666666666667\n",
      "541 번째 loss, accuracy:  0.8730801897317165 0.6916666666666667\n",
      "542 번째 loss, accuracy:  0.8727352919248387 0.6916666666666667\n",
      "543 번째 loss, accuracy:  0.872390715128629 0.6916666666666667\n",
      "544 번째 loss, accuracy:  0.8720464579741971 0.6916666666666667\n",
      "545 번째 loss, accuracy:  0.8717025191170549 0.6916666666666667\n",
      "546 번째 loss, accuracy:  0.8713588972367338 0.6916666666666667\n",
      "547 번째 loss, accuracy:  0.871015591036407 0.6916666666666667\n",
      "548 번째 loss, accuracy:  0.8706725992425134 0.6916666666666667\n",
      "549 번째 loss, accuracy:  0.870329920604397 0.6916666666666667\n",
      "550 번째 loss, accuracy:  0.8699875538939341 0.6916666666666667\n",
      "551 번째 loss, accuracy:  0.8696454979051822 0.6916666666666667\n",
      "552 번째 loss, accuracy:  0.8693037514540161 0.6916666666666667\n",
      "553 번째 loss, accuracy:  0.8689623133777915 0.6916666666666667\n",
      "554 번째 loss, accuracy:  0.8686211825349885 0.6916666666666667\n",
      "555 번째 loss, accuracy:  0.8682803578048814 0.6916666666666667\n",
      "556 번째 loss, accuracy:  0.8679398380871954 0.6916666666666667\n",
      "557 번째 loss, accuracy:  0.8675996223017783 0.6916666666666667\n",
      "558 번째 loss, accuracy:  0.8672597093882743 0.6916666666666667\n",
      "559 번째 loss, accuracy:  0.8669200983058002 0.6916666666666667\n",
      "560 번째 loss, accuracy:  0.8665807880326296 0.6916666666666667\n",
      "561 번째 loss, accuracy:  0.8662417775658778 0.6916666666666667\n",
      "562 번째 loss, accuracy:  0.8659030659211935 0.6916666666666667\n",
      "563 번째 loss, accuracy:  0.8655646521324541 0.6916666666666667\n",
      "564 번째 loss, accuracy:  0.865226535251463 0.6916666666666667\n",
      "565 번째 loss, accuracy:  0.8648887143476552 0.6916666666666667\n",
      "566 번째 loss, accuracy:  0.8645511885078034 0.6916666666666667\n",
      "567 번째 loss, accuracy:  0.8642139568357324 0.6916666666666667\n",
      "568 번째 loss, accuracy:  0.8638770184520278 0.6916666666666667\n",
      "569 번째 loss, accuracy:  0.863540372493764 0.6916666666666667\n",
      "570 번째 loss, accuracy:  0.8632040181142208 0.6916666666666667\n",
      "571 번째 loss, accuracy:  0.862867954482617 0.6916666666666667\n",
      "572 번째 loss, accuracy:  0.8625321807838346 0.6916666666666667\n",
      "573 번째 loss, accuracy:  0.8621966962181602 0.6916666666666667\n",
      "574 번째 loss, accuracy:  0.8618615000010205 0.6916666666666667\n",
      "575 번째 loss, accuracy:  0.8615265913627261 0.6916666666666667\n",
      "576 번째 loss, accuracy:  0.8611919695482195 0.6916666666666667\n",
      "577 번째 loss, accuracy:  0.860857633816816 0.6916666666666667\n",
      "578 번째 loss, accuracy:  0.8605235834419728 0.6916666666666667\n",
      "579 번째 loss, accuracy:  0.8601898177110329 0.6916666666666667\n",
      "580 번째 loss, accuracy:  0.8598563359249876 0.6916666666666667\n",
      "581 번째 loss, accuracy:  0.8595231373982469 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582 번째 loss, accuracy:  0.8591902214584032 0.6916666666666667\n",
      "583 번째 loss, accuracy:  0.8588575874459982 0.6916666666666667\n",
      "584 번째 loss, accuracy:  0.8585252347143049 0.6916666666666667\n",
      "585 번째 loss, accuracy:  0.8581931626290998 0.6916666666666667\n",
      "586 번째 loss, accuracy:  0.8578613705684455 0.6916666666666667\n",
      "587 번째 loss, accuracy:  0.8575298579224772 0.6916666666666667\n",
      "588 번째 loss, accuracy:  0.8571986240931827 0.6916666666666667\n",
      "589 번째 loss, accuracy:  0.8568676684941982 0.6916666666666667\n",
      "590 번째 loss, accuracy:  0.856536990550606 0.6916666666666667\n",
      "591 번째 loss, accuracy:  0.856206589698721 0.6916666666666667\n",
      "592 번째 loss, accuracy:  0.8558764653858966 0.6916666666666667\n",
      "593 번째 loss, accuracy:  0.8555466170703256 0.6916666666666667\n",
      "594 번째 loss, accuracy:  0.8552170442208513 0.6916666666666667\n",
      "595 번째 loss, accuracy:  0.8548877463167659 0.6916666666666667\n",
      "596 번째 loss, accuracy:  0.854558722847631 0.6916666666666667\n",
      "597 번째 loss, accuracy:  0.854229973313086 0.6916666666666667\n",
      "598 번째 loss, accuracy:  0.8539014972226705 0.6916666666666667\n",
      "599 번째 loss, accuracy:  0.8535732940956386 0.6916666666666667\n",
      "600 번째 loss, accuracy:  0.8532453634607847 0.6916666666666667\n",
      "601 번째 loss, accuracy:  0.8529177048562692 0.6916666666666667\n",
      "602 번째 loss, accuracy:  0.8525903178294456 0.6916666666666667\n",
      "603 번째 loss, accuracy:  0.8522632019366938 0.6916666666666667\n",
      "604 번째 loss, accuracy:  0.8519363567432483 0.6916666666666667\n",
      "605 번째 loss, accuracy:  0.8516097818230384 0.6916666666666667\n",
      "606 번째 loss, accuracy:  0.851283476758524 0.6916666666666667\n",
      "607 번째 loss, accuracy:  0.85095744114054 0.6916666666666667\n",
      "608 번째 loss, accuracy:  0.8506316745681332 0.6916666666666667\n",
      "609 번째 loss, accuracy:  0.8503061766484179 0.6916666666666667\n",
      "610 번째 loss, accuracy:  0.8499809469964131 0.6916666666666667\n",
      "611 번째 loss, accuracy:  0.8496559852349006 0.6916666666666667\n",
      "612 번째 loss, accuracy:  0.8493312909942775 0.6916666666666667\n",
      "613 번째 loss, accuracy:  0.8490068639124101 0.6916666666666667\n",
      "614 번째 loss, accuracy:  0.8486827036344885 0.6916666666666667\n",
      "615 번째 loss, accuracy:  0.8483588098128921 0.6916666666666667\n",
      "616 번째 loss, accuracy:  0.8480351821070464 0.6916666666666667\n",
      "617 번째 loss, accuracy:  0.8477118201832922 0.6916666666666667\n",
      "618 번째 loss, accuracy:  0.8473887237147494 0.6916666666666667\n",
      "619 번째 loss, accuracy:  0.847065892381183 0.6916666666666667\n",
      "620 번째 loss, accuracy:  0.846743325868876 0.6916666666666667\n",
      "621 번째 loss, accuracy:  0.8464210238705052 0.6916666666666667\n",
      "622 번째 loss, accuracy:  0.8460989860850123 0.6916666666666667\n",
      "623 번째 loss, accuracy:  0.8457772122174811 0.6916666666666667\n",
      "624 번째 loss, accuracy:  0.8454557019790125 0.6916666666666667\n",
      "625 번째 loss, accuracy:  0.8451344550866153 0.6916666666666667\n",
      "626 번째 loss, accuracy:  0.8448134712630755 0.6916666666666667\n",
      "627 번째 loss, accuracy:  0.8444927502368567 0.6916666666666667\n",
      "628 번째 loss, accuracy:  0.8441722917419693 0.6916666666666667\n",
      "629 번째 loss, accuracy:  0.8438520955178745 0.6916666666666667\n",
      "630 번째 loss, accuracy:  0.8435321613093603 0.6916666666666667\n",
      "631 번째 loss, accuracy:  0.8432124888664425 0.6916666666666667\n",
      "632 번째 loss, accuracy:  0.8428930779442567 0.6916666666666667\n",
      "633 번째 loss, accuracy:  0.842573928302951 0.6916666666666667\n",
      "634 번째 loss, accuracy:  0.8422550397075853 0.6916666666666667\n",
      "635 번째 loss, accuracy:  0.8419364119280296 0.6916666666666667\n",
      "636 번째 loss, accuracy:  0.8416180447388634 0.6916666666666667\n",
      "637 번째 loss, accuracy:  0.8412999379192788 0.6916666666666667\n",
      "638 번째 loss, accuracy:  0.8409820912529876 0.6916666666666667\n",
      "639 번째 loss, accuracy:  0.840664504528117 0.6916666666666667\n",
      "640 번째 loss, accuracy:  0.840347177537126 0.6916666666666667\n",
      "641 번째 loss, accuracy:  0.8400301100767075 0.6916666666666667\n",
      "642 번째 loss, accuracy:  0.8397133019477038 0.6916666666666667\n",
      "643 번째 loss, accuracy:  0.8393967529550149 0.6916666666666667\n",
      "644 번째 loss, accuracy:  0.839080462907511 0.6916666666666667\n",
      "645 번째 loss, accuracy:  0.8387644316179487 0.6916666666666667\n",
      "646 번째 loss, accuracy:  0.8384486589028827 0.6916666666666667\n",
      "647 번째 loss, accuracy:  0.8381331445825891 0.6916666666666667\n",
      "648 번째 loss, accuracy:  0.8378178884809794 0.6916666666666667\n",
      "649 번째 loss, accuracy:  0.8375028904255237 0.6916666666666667\n",
      "650 번째 loss, accuracy:  0.8371881502471675 0.6916666666666667\n",
      "651 번째 loss, accuracy:  0.8368736677802621 0.6916666666666667\n",
      "652 번째 loss, accuracy:  0.8365594428624801 0.6916666666666667\n",
      "653 번째 loss, accuracy:  0.8362454753347445 0.6916666666666667\n",
      "654 번째 loss, accuracy:  0.8359317650411576 0.6916666666666667\n",
      "655 번째 loss, accuracy:  0.8356183118289257 0.6916666666666667\n",
      "656 번째 loss, accuracy:  0.8353051155482909 0.6916666666666667\n",
      "657 번째 loss, accuracy:  0.8349921760524549 0.6916666666666667\n",
      "658 번째 loss, accuracy:  0.8346794931975202 0.6916666666666667\n",
      "659 번째 loss, accuracy:  0.8343670668424132 0.6916666666666667\n",
      "660 번째 loss, accuracy:  0.8340548968488266 0.6916666666666667\n",
      "661 번째 loss, accuracy:  0.8337429830811461 0.6916666666666667\n",
      "662 번째 loss, accuracy:  0.8334313254063945 0.6916666666666667\n",
      "663 번째 loss, accuracy:  0.8331199236941652 0.6916666666666667\n",
      "664 번째 loss, accuracy:  0.8328087778165604 0.6916666666666667\n",
      "665 번째 loss, accuracy:  0.8324978876481277 0.6916666666666667\n",
      "666 번째 loss, accuracy:  0.8321872530658064 0.6916666666666667\n",
      "667 번째 loss, accuracy:  0.8318768739488649 0.6916666666666667\n",
      "668 번째 loss, accuracy:  0.8315667501788472 0.6916666666666667\n",
      "669 번째 loss, accuracy:  0.83125688163951 0.6916666666666667\n",
      "670 번째 loss, accuracy:  0.8309472682167722 0.6916666666666667\n",
      "671 번째 loss, accuracy:  0.8306379097986597 0.6916666666666667\n",
      "672 번째 loss, accuracy:  0.8303288062752526 0.6916666666666667\n",
      "673 번째 loss, accuracy:  0.8300199575386272 0.6916666666666667\n",
      "674 번째 loss, accuracy:  0.8297113634828157 0.6916666666666667\n",
      "675 번째 loss, accuracy:  0.8294030240037407 0.6916666666666667\n",
      "676 번째 loss, accuracy:  0.8290949389991804 0.6916666666666667\n",
      "677 번째 loss, accuracy:  0.8287871083687062 0.6916666666666667\n",
      "678 번째 loss, accuracy:  0.8284795320136417 0.6916666666666667\n",
      "679 번째 loss, accuracy:  0.8281722098370191 0.6916666666666667\n",
      "680 번째 loss, accuracy:  0.8278651417435242 0.6916666666666667\n",
      "681 번째 loss, accuracy:  0.8275583276394565 0.6916666666666667\n",
      "682 번째 loss, accuracy:  0.8272517674326837 0.6916666666666667\n",
      "683 번째 loss, accuracy:  0.8269454610325954 0.6916666666666667\n",
      "684 번째 loss, accuracy:  0.8266394083500656 0.6916666666666667\n",
      "685 번째 loss, accuracy:  0.8263336092974024 0.6916666666666667\n",
      "686 번째 loss, accuracy:  0.8260280637883146 0.6916666666666667\n",
      "687 번째 loss, accuracy:  0.8257227717378651 0.6916666666666667\n",
      "688 번째 loss, accuracy:  0.8254177330624353 0.6916666666666667\n",
      "689 번째 loss, accuracy:  0.8251129476796798 0.6916666666666667\n",
      "690 번째 loss, accuracy:  0.8248084155084956 0.6916666666666667\n",
      "691 번째 loss, accuracy:  0.8245041364689787 0.6916666666666667\n",
      "692 번째 loss, accuracy:  0.8242001104823875 0.6916666666666667\n",
      "693 번째 loss, accuracy:  0.8238963374711101 0.6916666666666667\n",
      "694 번째 loss, accuracy:  0.8235928173586249 0.6916666666666667\n",
      "695 번째 loss, accuracy:  0.8232895500694658 0.6916666666666667\n",
      "696 번째 loss, accuracy:  0.8229865355291859 0.6916666666666667\n",
      "697 번째 loss, accuracy:  0.8226837736643338 0.6916666666666667\n",
      "698 번째 loss, accuracy:  0.8223812644024068 0.6916666666666667\n",
      "699 번째 loss, accuracy:  0.8220790076718248 0.6916666666666667\n",
      "700 번째 loss, accuracy:  0.8217770034018994 0.6916666666666667\n",
      "701 번째 loss, accuracy:  0.8214752515228031 0.6916666666666667\n",
      "702 번째 loss, accuracy:  0.8211737519655333 0.6916666666666667\n",
      "703 번째 loss, accuracy:  0.8208725046618869 0.6916666666666667\n",
      "704 번째 loss, accuracy:  0.8205715095444303 0.6916666666666667\n",
      "705 번째 loss, accuracy:  0.8202707665464686 0.6916666666666667\n",
      "706 번째 loss, accuracy:  0.8199702756020173 0.6916666666666667\n",
      "707 번째 loss, accuracy:  0.8196700366457785 0.6916666666666667\n",
      "708 번째 loss, accuracy:  0.8193700496131077 0.6916666666666667\n",
      "709 번째 loss, accuracy:  0.8190703144399883 0.6916666666666667\n",
      "710 번째 loss, accuracy:  0.8187708310630076 0.6916666666666667\n",
      "711 번째 loss, accuracy:  0.8184715994193321 0.6916666666666667\n",
      "712 번째 loss, accuracy:  0.818172619446677 0.6916666666666667\n",
      "713 번째 loss, accuracy:  0.8178738910832847 0.6916666666666667\n",
      "714 번째 loss, accuracy:  0.8175754142679008 0.6916666666666667\n",
      "715 번째 loss, accuracy:  0.8172771889397512 0.6916666666666667\n",
      "716 번째 loss, accuracy:  0.8169792150385111 0.6916666666666667\n",
      "717 번째 loss, accuracy:  0.8166814925042981 0.6916666666666667\n",
      "718 번째 loss, accuracy:  0.8163840212776291 0.6916666666666667\n",
      "719 번째 loss, accuracy:  0.8160868012994168 0.6916666666666667\n",
      "720 번째 loss, accuracy:  0.815789832510935 0.6916666666666667\n",
      "721 번째 loss, accuracy:  0.8154931148538073 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722 번째 loss, accuracy:  0.8151966482699784 0.6916666666666667\n",
      "723 번째 loss, accuracy:  0.8149004327016989 0.6916666666666667\n",
      "724 번째 loss, accuracy:  0.8146044680915019 0.6916666666666667\n",
      "725 번째 loss, accuracy:  0.8143087543821886 0.6916666666666667\n",
      "726 번째 loss, accuracy:  0.8140132915168 0.6916666666666667\n",
      "727 번째 loss, accuracy:  0.8137180794386116 0.6916666666666667\n",
      "728 번째 loss, accuracy:  0.8134231180910999 0.6916666666666667\n",
      "729 번째 loss, accuracy:  0.8131284074179395 0.6916666666666667\n",
      "730 번째 loss, accuracy:  0.8128339473629719 0.6916666666666667\n",
      "731 번째 loss, accuracy:  0.8125397378702003 0.6916666666666667\n",
      "732 번째 loss, accuracy:  0.8122457788837616 0.6916666666666667\n",
      "733 번째 loss, accuracy:  0.8119520703479198 0.6916666666666667\n",
      "734 번째 loss, accuracy:  0.8116586122070418 0.6916666666666667\n",
      "735 번째 loss, accuracy:  0.8113654044055889 0.6916666666666667\n",
      "736 번째 loss, accuracy:  0.8110724468880909 0.6916666666666667\n",
      "737 번째 loss, accuracy:  0.8107797395991465 0.6916666666666667\n",
      "738 번째 loss, accuracy:  0.8104872824833919 0.6916666666666667\n",
      "739 번째 loss, accuracy:  0.8101950754854973 0.6916666666666667\n",
      "740 번째 loss, accuracy:  0.8099031185501533 0.6916666666666667\n",
      "741 번째 loss, accuracy:  0.8096114116220439 0.6916666666666667\n",
      "742 번째 loss, accuracy:  0.8093199546458475 0.6916666666666667\n",
      "743 번째 loss, accuracy:  0.8090287475662178 0.6916666666666667\n",
      "744 번째 loss, accuracy:  0.8087377903277712 0.6916666666666667\n",
      "745 번째 loss, accuracy:  0.8084470828750734 0.6916666666666667\n",
      "746 번째 loss, accuracy:  0.8081566251526267 0.6916666666666667\n",
      "747 번째 loss, accuracy:  0.8078664171048603 0.6916666666666667\n",
      "748 번째 loss, accuracy:  0.8075764586761178 0.6916666666666667\n",
      "749 번째 loss, accuracy:  0.8072867498106404 0.6916666666666667\n",
      "750 번째 loss, accuracy:  0.8069972904525623 0.6916666666666667\n",
      "751 번째 loss, accuracy:  0.8067080805458956 0.6916666666666667\n",
      "752 번째 loss, accuracy:  0.8064191200345223 0.6916666666666667\n",
      "753 번째 loss, accuracy:  0.8061304088621805 0.6916666666666667\n",
      "754 번째 loss, accuracy:  0.8058419469724574 0.6916666666666667\n",
      "755 번째 loss, accuracy:  0.8055537343087772 0.6916666666666667\n",
      "756 번째 loss, accuracy:  0.8052657708143862 0.6916666666666667\n",
      "757 번째 loss, accuracy:  0.8049780564323558 0.6916666666666667\n",
      "758 번째 loss, accuracy:  0.804690591105563 0.6916666666666667\n",
      "759 번째 loss, accuracy:  0.8044033747766807 0.6916666666666667\n",
      "760 번째 loss, accuracy:  0.8041164073881732 0.6916666666666667\n",
      "761 번째 loss, accuracy:  0.8038296888822882 0.6916666666666667\n",
      "762 번째 loss, accuracy:  0.8035432192010433 0.6916666666666667\n",
      "763 번째 loss, accuracy:  0.803256998286219 0.6916666666666667\n",
      "764 번째 loss, accuracy:  0.8029710260793562 0.6916666666666667\n",
      "765 번째 loss, accuracy:  0.8026853025217388 0.6916666666666667\n",
      "766 번째 loss, accuracy:  0.8023998275543952 0.6916666666666667\n",
      "767 번째 loss, accuracy:  0.8021146011180823 0.6916666666666667\n",
      "768 번째 loss, accuracy:  0.8018296231532855 0.6916666666666667\n",
      "769 번째 loss, accuracy:  0.801544893600207 0.6916666666666667\n",
      "770 번째 loss, accuracy:  0.8012604123987591 0.6916666666666667\n",
      "771 번째 loss, accuracy:  0.8009761794885573 0.6916666666666667\n",
      "772 번째 loss, accuracy:  0.8006921948089158 0.6916666666666667\n",
      "773 번째 loss, accuracy:  0.8004084582988419 0.6916666666666667\n",
      "774 번째 loss, accuracy:  0.8001249698970215 0.6916666666666667\n",
      "775 번째 loss, accuracy:  0.7998417295418245 0.6916666666666667\n",
      "776 번째 loss, accuracy:  0.799558737171292 0.6916666666666667\n",
      "777 번째 loss, accuracy:  0.7992759927231281 0.6916666666666667\n",
      "778 번째 loss, accuracy:  0.7989934961347013 0.6916666666666667\n",
      "779 번째 loss, accuracy:  0.7987112473430353 0.6916666666666667\n",
      "780 번째 loss, accuracy:  0.7984292462848013 0.6916666666666667\n",
      "781 번째 loss, accuracy:  0.7981474928963147 0.6916666666666667\n",
      "782 번째 loss, accuracy:  0.7978659871135332 0.6916666666666667\n",
      "783 번째 loss, accuracy:  0.7975847288720466 0.6916666666666667\n",
      "784 번째 loss, accuracy:  0.7973037181070776 0.6916666666666667\n",
      "785 번째 loss, accuracy:  0.7970229547534695 0.6916666666666667\n",
      "786 번째 loss, accuracy:  0.7967424387456908 0.6916666666666667\n",
      "787 번째 loss, accuracy:  0.7964621700178219 0.6916666666666667\n",
      "788 번째 loss, accuracy:  0.7961821485035593 0.6916666666666667\n",
      "789 번째 loss, accuracy:  0.7959023741362048 0.6916666666666667\n",
      "790 번째 loss, accuracy:  0.7956228468486621 0.6916666666666667\n",
      "791 번째 loss, accuracy:  0.7953435665734379 0.6916666666666667\n",
      "792 번째 loss, accuracy:  0.7950645332426355 0.6916666666666667\n",
      "793 번째 loss, accuracy:  0.7947857467879451 0.6916666666666667\n",
      "794 번째 loss, accuracy:  0.7945072071406536 0.6916666666666667\n",
      "795 번째 loss, accuracy:  0.7942289142316256 0.6916666666666667\n",
      "796 번째 loss, accuracy:  0.7939508679913139 0.6916666666666667\n",
      "797 번째 loss, accuracy:  0.7936730683497468 0.6916666666666667\n",
      "798 번째 loss, accuracy:  0.7933955152365293 0.6916666666666667\n",
      "799 번째 loss, accuracy:  0.7931182085808385 0.6916666666666667\n",
      "800 번째 loss, accuracy:  0.792841148311425 0.6916666666666667\n",
      "801 번째 loss, accuracy:  0.7925643343566001 0.6916666666666667\n",
      "802 번째 loss, accuracy:  0.7922877666442475 0.6916666666666667\n",
      "803 번째 loss, accuracy:  0.7920114451018059 0.6916666666666667\n",
      "804 번째 loss, accuracy:  0.7917353696562749 0.6916666666666667\n",
      "805 번째 loss, accuracy:  0.791459540234215 0.6916666666666667\n",
      "806 번째 loss, accuracy:  0.7911839567617373 0.6916666666666667\n",
      "807 번째 loss, accuracy:  0.7909086191645087 0.6916666666666667\n",
      "808 번째 loss, accuracy:  0.7906335273677452 0.6916666666666667\n",
      "809 번째 loss, accuracy:  0.7903586812962075 0.6916666666666667\n",
      "810 번째 loss, accuracy:  0.7900840808742093 0.6916666666666667\n",
      "811 번째 loss, accuracy:  0.7898097260256053 0.6916666666666667\n",
      "812 번째 loss, accuracy:  0.7895356166737926 0.6916666666666667\n",
      "813 번째 loss, accuracy:  0.7892617527417103 0.6916666666666667\n",
      "814 번째 loss, accuracy:  0.7889881341518378 0.6916666666666667\n",
      "815 번째 loss, accuracy:  0.7887147608261882 0.6916666666666667\n",
      "816 번째 loss, accuracy:  0.7884416326863181 0.6916666666666667\n",
      "817 번째 loss, accuracy:  0.788168749653313 0.6916666666666667\n",
      "818 번째 loss, accuracy:  0.7878961116477962 0.6916666666666667\n",
      "819 번째 loss, accuracy:  0.7876237185899225 0.6916666666666667\n",
      "820 번째 loss, accuracy:  0.787351570399377 0.6916666666666667\n",
      "821 번째 loss, accuracy:  0.7870796669953749 0.6916666666666667\n",
      "822 번째 loss, accuracy:  0.7868080082966623 0.6916666666666667\n",
      "823 번째 loss, accuracy:  0.7865365942215148 0.6916666666666667\n",
      "824 번째 loss, accuracy:  0.7862654246877283 0.6916666666666667\n",
      "825 번째 loss, accuracy:  0.7859944996126332 0.6916666666666667\n",
      "826 번째 loss, accuracy:  0.7857238189130816 0.6916666666666667\n",
      "827 번째 loss, accuracy:  0.785453382505454 0.6916666666666667\n",
      "828 번째 loss, accuracy:  0.7851831903056509 0.6916666666666667\n",
      "829 번째 loss, accuracy:  0.7849132422291001 0.6916666666666667\n",
      "830 번째 loss, accuracy:  0.784643538190752 0.6916666666666667\n",
      "831 번째 loss, accuracy:  0.7843740781050764 0.6916666666666667\n",
      "832 번째 loss, accuracy:  0.7841048618860669 0.6916666666666667\n",
      "833 번째 loss, accuracy:  0.7838358894472428 0.6916666666666667\n",
      "834 번째 loss, accuracy:  0.7835671607016411 0.6916666666666667\n",
      "835 번째 loss, accuracy:  0.7832986755618241 0.6916666666666667\n",
      "836 번째 loss, accuracy:  0.7830304339398697 0.6916666666666667\n",
      "837 번째 loss, accuracy:  0.7827624357473812 0.6916666666666667\n",
      "838 번째 loss, accuracy:  0.7824946808954799 0.6916666666666667\n",
      "839 번째 loss, accuracy:  0.7822271692948105 0.6916666666666667\n",
      "840 번째 loss, accuracy:  0.7819599008555362 0.6916666666666667\n",
      "841 번째 loss, accuracy:  0.7816928754873419 0.6916666666666667\n",
      "842 번째 loss, accuracy:  0.7814260930994341 0.6916666666666667\n",
      "843 번째 loss, accuracy:  0.781159553600538 0.6916666666666667\n",
      "844 번째 loss, accuracy:  0.7808932568989019 0.6916666666666667\n",
      "845 번째 loss, accuracy:  0.7806272029022973 0.6916666666666667\n",
      "846 번째 loss, accuracy:  0.7803613915180146 0.6916666666666667\n",
      "847 번째 loss, accuracy:  0.7800958226528648 0.6916666666666667\n",
      "848 번째 loss, accuracy:  0.7798304962131828 0.6916666666666667\n",
      "849 번째 loss, accuracy:  0.7795654121048248 0.6916666666666667\n",
      "850 번째 loss, accuracy:  0.7793005702331726 0.6916666666666667\n",
      "851 번째 loss, accuracy:  0.7790359705031273 0.6916666666666667\n",
      "852 번째 loss, accuracy:  0.7787716128191208 0.6916666666666667\n",
      "853 번째 loss, accuracy:  0.7785074970851009 0.6916666666666667\n",
      "854 번째 loss, accuracy:  0.7782436232045439 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855 번째 loss, accuracy:  0.7779799910804547 0.6916666666666667\n",
      "856 번째 loss, accuracy:  0.7777166006153572 0.6916666666666667\n",
      "857 번째 loss, accuracy:  0.7774534517113084 0.6916666666666667\n",
      "858 번째 loss, accuracy:  0.77719054426989 0.6916666666666667\n",
      "859 번째 loss, accuracy:  0.7769278781922112 0.6916666666666667\n",
      "860 번째 loss, accuracy:  0.7766654533789097 0.6916666666666667\n",
      "861 번째 loss, accuracy:  0.7764032697301544 0.6916666666666667\n",
      "862 번째 loss, accuracy:  0.7761413271456422 0.6916666666666667\n",
      "863 번째 loss, accuracy:  0.7758796255246044 0.6916666666666667\n",
      "864 번째 loss, accuracy:  0.7756181647658025 0.6916666666666667\n",
      "865 번째 loss, accuracy:  0.775356944767529 0.6916666666666667\n",
      "866 번째 loss, accuracy:  0.7750959654276133 0.6916666666666667\n",
      "867 번째 loss, accuracy:  0.7748352266434172 0.6916666666666667\n",
      "868 번째 loss, accuracy:  0.7745747283118392 0.6916666666666667\n",
      "869 번째 loss, accuracy:  0.774314470329314 0.6916666666666667\n",
      "870 번째 loss, accuracy:  0.7740544525918135 0.6916666666666667\n",
      "871 번째 loss, accuracy:  0.7737946749948482 0.6916666666666667\n",
      "872 번째 loss, accuracy:  0.7735351374334715 0.6916666666666667\n",
      "873 번째 loss, accuracy:  0.7732758398022717 0.6916666666666667\n",
      "874 번째 loss, accuracy:  0.7730167819953813 0.6916666666666667\n",
      "875 번째 loss, accuracy:  0.7727579639064783 0.6916666666666667\n",
      "876 번째 loss, accuracy:  0.7724993854287833 0.6916666666666667\n",
      "877 번째 loss, accuracy:  0.7722410464550599 0.6916666666666667\n",
      "878 번째 loss, accuracy:  0.7719829468776197 0.6916666666666667\n",
      "879 번째 loss, accuracy:  0.7717250865883242 0.6916666666666667\n",
      "880 번째 loss, accuracy:  0.7714674654785796 0.6916666666666667\n",
      "881 번째 loss, accuracy:  0.7712100834393413 0.6916666666666667\n",
      "882 번째 loss, accuracy:  0.7709529403611206 0.6916666666666667\n",
      "883 번째 loss, accuracy:  0.7706960361339816 0.6916666666666667\n",
      "884 번째 loss, accuracy:  0.7704393706475358 0.6916666666666667\n",
      "885 번째 loss, accuracy:  0.7701829437909571 0.6916666666666667\n",
      "886 번째 loss, accuracy:  0.7699267554529702 0.6916666666666667\n",
      "887 번째 loss, accuracy:  0.7696708055218601 0.6916666666666667\n",
      "888 번째 loss, accuracy:  0.7694150938854708 0.6916666666666667\n",
      "889 번째 loss, accuracy:  0.7691596204312063 0.6916666666666667\n",
      "890 번째 loss, accuracy:  0.7689043850460326 0.6916666666666667\n",
      "891 번째 loss, accuracy:  0.7686493876164806 0.6916666666666667\n",
      "892 번째 loss, accuracy:  0.7683946280286421 0.6916666666666667\n",
      "893 번째 loss, accuracy:  0.7681401061681792 0.6916666666666667\n",
      "894 번째 loss, accuracy:  0.7678858219203157 0.6916666666666667\n",
      "895 번째 loss, accuracy:  0.7676317751698499 0.6916666666666667\n",
      "896 번째 loss, accuracy:  0.767377965801149 0.6916666666666667\n",
      "897 번째 loss, accuracy:  0.7671243936981483 0.6916666666666667\n",
      "898 번째 loss, accuracy:  0.7668710587443619 0.6916666666666667\n",
      "899 번째 loss, accuracy:  0.7666179608228756 0.6916666666666667\n",
      "900 번째 loss, accuracy:  0.7663650998163533 0.6916666666666667\n",
      "901 번째 loss, accuracy:  0.7661124756070362 0.6916666666666667\n",
      "902 번째 loss, accuracy:  0.7658600880767409 0.6916666666666667\n",
      "903 번째 loss, accuracy:  0.7656079371068693 0.6916666666666667\n",
      "904 번째 loss, accuracy:  0.7653560225784055 0.6916666666666667\n",
      "905 번째 loss, accuracy:  0.7651043443719162 0.6916666666666667\n",
      "906 번째 loss, accuracy:  0.7648529023675537 0.6916666666666667\n",
      "907 번째 loss, accuracy:  0.7646016964450576 0.6916666666666667\n",
      "908 번째 loss, accuracy:  0.7643507264837541 0.6916666666666667\n",
      "909 번째 loss, accuracy:  0.7640999923625639 0.6916666666666667\n",
      "910 번째 loss, accuracy:  0.7638494939599977 0.6916666666666667\n",
      "911 번째 loss, accuracy:  0.7635992311541571 0.6916666666666667\n",
      "912 번째 loss, accuracy:  0.7633492038227431 0.6916666666666667\n",
      "913 번째 loss, accuracy:  0.7630994118430489 0.6916666666666667\n",
      "914 번째 loss, accuracy:  0.7628498550919706 0.6916666666666667\n",
      "915 번째 loss, accuracy:  0.762600533445998 0.6916666666666667\n",
      "916 번째 loss, accuracy:  0.7623514467812295 0.6916666666666667\n",
      "917 번째 loss, accuracy:  0.7621025949733624 0.6916666666666667\n",
      "918 번째 loss, accuracy:  0.7618539778976997 0.6916666666666667\n",
      "919 번째 loss, accuracy:  0.7616055954291513 0.6916666666666667\n",
      "920 번째 loss, accuracy:  0.7613574474422352 0.6916666666666667\n",
      "921 번째 loss, accuracy:  0.7611095338110769 0.6916666666666667\n",
      "922 번째 loss, accuracy:  0.7608618544094179 0.6916666666666667\n",
      "923 번째 loss, accuracy:  0.7606144091106107 0.6916666666666667\n",
      "924 번째 loss, accuracy:  0.7603671977876212 0.6916666666666667\n",
      "925 번째 loss, accuracy:  0.7601202203130317 0.6916666666666667\n",
      "926 번째 loss, accuracy:  0.7598734765590466 0.6916666666666667\n",
      "927 번째 loss, accuracy:  0.7596269663974852 0.6916666666666667\n",
      "928 번째 loss, accuracy:  0.7593806896997941 0.6916666666666667\n",
      "929 번째 loss, accuracy:  0.7591346463370371 0.6916666666666667\n",
      "930 번째 loss, accuracy:  0.7588888361799062 0.6916666666666667\n",
      "931 번째 loss, accuracy:  0.7586432590987215 0.6916666666666667\n",
      "932 번째 loss, accuracy:  0.7583979149634278 0.6916666666666667\n",
      "933 번째 loss, accuracy:  0.7581528036436023 0.6916666666666667\n",
      "934 번째 loss, accuracy:  0.7579079250084537 0.6916666666666667\n",
      "935 번째 loss, accuracy:  0.7576632789268255 0.6916666666666667\n",
      "936 번째 loss, accuracy:  0.7574188652671953 0.6916666666666667\n",
      "937 번째 loss, accuracy:  0.757174683897676 0.6916666666666667\n",
      "938 번째 loss, accuracy:  0.7569307346860238 0.6916666666666667\n",
      "939 번째 loss, accuracy:  0.7566870174996321 0.6916666666666667\n",
      "940 번째 loss, accuracy:  0.7564435322055353 0.6916666666666667\n",
      "941 번째 loss, accuracy:  0.7562002786704142 0.6916666666666667\n",
      "942 번째 loss, accuracy:  0.755957256760596 0.6916666666666667\n",
      "943 번째 loss, accuracy:  0.7557144663420513 0.6916666666666667\n",
      "944 번째 loss, accuracy:  0.7554719072804039 0.6916666666666667\n",
      "945 번째 loss, accuracy:  0.755229579440927 0.6916666666666667\n",
      "946 번째 loss, accuracy:  0.7549874826885467 0.6916666666666667\n",
      "947 번째 loss, accuracy:  0.7547456168878441 0.6916666666666667\n",
      "948 번째 loss, accuracy:  0.7545039819030538 0.6916666666666667\n",
      "949 번째 loss, accuracy:  0.7542625775980706 0.6916666666666667\n",
      "950 번째 loss, accuracy:  0.754021403836448 0.6916666666666667\n",
      "951 번째 loss, accuracy:  0.7537804604814023 0.6916666666666667\n",
      "952 번째 loss, accuracy:  0.7535397473958118 0.6916666666666667\n",
      "953 번째 loss, accuracy:  0.7532992644422182 0.6916666666666667\n",
      "954 번째 loss, accuracy:  0.7530590114828325 0.6916666666666667\n",
      "955 번째 loss, accuracy:  0.7528189883795309 0.6916666666666667\n",
      "956 번째 loss, accuracy:  0.7525791949938615 0.6916666666666667\n",
      "957 번째 loss, accuracy:  0.7523396311870462 0.6916666666666667\n",
      "958 번째 loss, accuracy:  0.7521002968199771 0.6916666666666667\n",
      "959 번째 loss, accuracy:  0.7518611917532229 0.6916666666666667\n",
      "960 번째 loss, accuracy:  0.7516223158470282 0.6916666666666667\n",
      "961 번째 loss, accuracy:  0.7513836689613167 0.6916666666666667\n",
      "962 번째 loss, accuracy:  0.7511452509556956 0.6916666666666667\n",
      "963 번째 loss, accuracy:  0.7509070616894502 0.6916666666666667\n",
      "964 번째 loss, accuracy:  0.7506691010215509 0.6916666666666667\n",
      "965 번째 loss, accuracy:  0.7504313688106569 0.6916666666666667\n",
      "966 번째 loss, accuracy:  0.7501938649151125 0.6916666666666667\n",
      "967 번째 loss, accuracy:  0.7499565891929478 0.6916666666666667\n",
      "968 번째 loss, accuracy:  0.7497195415018899 0.6916666666666667\n",
      "969 번째 loss, accuracy:  0.7494827216993549 0.6916666666666667\n",
      "970 번째 loss, accuracy:  0.7492461296424537 0.6916666666666667\n",
      "971 번째 loss, accuracy:  0.7490097651879942 0.6916666666666667\n",
      "972 번째 loss, accuracy:  0.7487736281924823 0.6916666666666667\n",
      "973 번째 loss, accuracy:  0.7485377185121219 0.6916666666666667\n",
      "974 번째 loss, accuracy:  0.7483020360028189 0.6916666666666667\n",
      "975 번째 loss, accuracy:  0.7480665805201815 0.6916666666666667\n",
      "976 번째 loss, accuracy:  0.7478313519195244 0.6916666666666667\n",
      "977 번째 loss, accuracy:  0.7475963500558666 0.6916666666666667\n",
      "978 번째 loss, accuracy:  0.7473615747839375 0.6916666666666667\n",
      "979 번째 loss, accuracy:  0.7471270259581769 0.6916666666666667\n",
      "980 번째 loss, accuracy:  0.7468927034327326 0.6916666666666667\n",
      "981 번째 loss, accuracy:  0.7466586070614678 0.6916666666666667\n",
      "982 번째 loss, accuracy:  0.7464247366979618 0.6916666666666667\n",
      "983 번째 loss, accuracy:  0.7461910921955055 0.6916666666666667\n",
      "984 번째 loss, accuracy:  0.745957673407114 0.6916666666666667\n",
      "985 번째 loss, accuracy:  0.7457244801855203 0.6916666666666667\n",
      "986 번째 loss, accuracy:  0.7454915123831808 0.6916666666666667\n",
      "987 번째 loss, accuracy:  0.7452587698522729 0.6916666666666667\n",
      "988 번째 loss, accuracy:  0.7450262524447009 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989 번째 loss, accuracy:  0.7447939600120949 0.6916666666666667\n",
      "990 번째 loss, accuracy:  0.7445618924058134 0.6916666666666667\n",
      "991 번째 loss, accuracy:  0.7443300494769471 0.6916666666666667\n",
      "992 번째 loss, accuracy:  0.7440984310763118 0.6916666666666667\n",
      "993 번째 loss, accuracy:  0.7438670370544677 0.6916666666666667\n",
      "994 번째 loss, accuracy:  0.743635867261704 0.6916666666666667\n",
      "995 번째 loss, accuracy:  0.7434049215480452 0.6916666666666667\n",
      "996 번째 loss, accuracy:  0.7431741997632585 0.6916666666666667\n",
      "997 번째 loss, accuracy:  0.7429437017568489 0.6916666666666667\n",
      "998 번째 loss, accuracy:  0.7427134273780661 0.6916666666666667\n",
      "999 번째 loss, accuracy:  0.7424833764758981 0.6916666666666667\n",
      "1000 번째 loss, accuracy:  0.7422535488990827 0.6916666666666667\n",
      "1001 번째 loss, accuracy:  0.7420239444961043 0.6916666666666667\n",
      "1002 번째 loss, accuracy:  0.7417945631151928 0.6916666666666667\n",
      "1003 번째 loss, accuracy:  0.7415654046043321 0.6916666666666667\n",
      "1004 번째 loss, accuracy:  0.7413364688112549 0.6916666666666667\n",
      "1005 번째 loss, accuracy:  0.7411077555834483 0.6916666666666667\n",
      "1006 번째 loss, accuracy:  0.7408792647681555 0.6916666666666667\n",
      "1007 번째 loss, accuracy:  0.7406509962123733 0.6916666666666667\n",
      "1008 번째 loss, accuracy:  0.7404229497628613 0.6916666666666667\n",
      "1009 번째 loss, accuracy:  0.7401951252661364 0.6916666666666667\n",
      "1010 번째 loss, accuracy:  0.7399675225684764 0.6916666666666667\n",
      "1011 번째 loss, accuracy:  0.7397401415159245 0.6916666666666667\n",
      "1012 번째 loss, accuracy:  0.7395129819542874 0.6916666666666667\n",
      "1013 번째 loss, accuracy:  0.7392860437291375 0.6916666666666667\n",
      "1014 번째 loss, accuracy:  0.7390593266858182 0.6916666666666667\n",
      "1015 번째 loss, accuracy:  0.7388328306694381 0.6916666666666667\n",
      "1016 번째 loss, accuracy:  0.7386065555248815 0.6916666666666667\n",
      "1017 번째 loss, accuracy:  0.7383805010968026 0.6916666666666667\n",
      "1018 번째 loss, accuracy:  0.7381546672296312 0.6916666666666667\n",
      "1019 번째 loss, accuracy:  0.7379290537675723 0.6916666666666667\n",
      "1020 번째 loss, accuracy:  0.7377036605546099 0.6916666666666667\n",
      "1021 번째 loss, accuracy:  0.7374784874345042 0.6916666666666667\n",
      "1022 번째 loss, accuracy:  0.7372535342507992 0.6916666666666667\n",
      "1023 번째 loss, accuracy:  0.7370288008468199 0.6916666666666667\n",
      "1024 번째 loss, accuracy:  0.7368042870656752 0.6916666666666667\n",
      "1025 번째 loss, accuracy:  0.7365799927502599 0.6916666666666667\n",
      "1026 번째 loss, accuracy:  0.7363559177432549 0.6916666666666667\n",
      "1027 번째 loss, accuracy:  0.7361320618871314 0.6916666666666667\n",
      "1028 번째 loss, accuracy:  0.7359084250241494 0.6916666666666667\n",
      "1029 번째 loss, accuracy:  0.7356850069963582 0.6916666666666667\n",
      "1030 번째 loss, accuracy:  0.7354618076456038 0.6916666666666667\n",
      "1031 번째 loss, accuracy:  0.7352388268135256 0.6916666666666667\n",
      "1032 번째 loss, accuracy:  0.7350160643415601 0.6916666666666667\n",
      "1033 번째 loss, accuracy:  0.7347935200709412 0.6916666666666667\n",
      "1034 번째 loss, accuracy:  0.7345711938427015 0.6916666666666667\n",
      "1035 번째 loss, accuracy:  0.7343490854976739 0.6916666666666667\n",
      "1036 번째 loss, accuracy:  0.7341271948764934 0.6916666666666667\n",
      "1037 번째 loss, accuracy:  0.7339055218196014 0.6916666666666667\n",
      "1038 번째 loss, accuracy:  0.7336840661672429 0.6916666666666667\n",
      "1039 번째 loss, accuracy:  0.733462827759469 0.6916666666666667\n",
      "1040 번째 loss, accuracy:  0.7332418064361418 0.6916666666666667\n",
      "1041 번째 loss, accuracy:  0.7330210020369302 0.6916666666666667\n",
      "1042 번째 loss, accuracy:  0.732800414401315 0.6916666666666667\n",
      "1043 번째 loss, accuracy:  0.7325800433685921 0.6916666666666667\n",
      "1044 번째 loss, accuracy:  0.7323598887778684 0.6916666666666667\n",
      "1045 번째 loss, accuracy:  0.732139950468068 0.6916666666666667\n",
      "1046 번째 loss, accuracy:  0.7319202282779355 0.6916666666666667\n",
      "1047 번째 loss, accuracy:  0.731700722046029 0.6916666666666667\n",
      "1048 번째 loss, accuracy:  0.7314814316107302 0.6916666666666667\n",
      "1049 번째 loss, accuracy:  0.7312623568102388 0.6916666666666667\n",
      "1050 번째 loss, accuracy:  0.7310434974825836 0.6916666666666667\n",
      "1051 번째 loss, accuracy:  0.7308248534656123 0.6916666666666667\n",
      "1052 번째 loss, accuracy:  0.7306064245970023 0.6916666666666667\n",
      "1053 번째 loss, accuracy:  0.7303882107142555 0.6916666666666667\n",
      "1054 번째 loss, accuracy:  0.7301702116547034 0.6916666666666667\n",
      "1055 번째 loss, accuracy:  0.7299524272555072 0.6916666666666667\n",
      "1056 번째 loss, accuracy:  0.729734857353666 0.6916666666666667\n",
      "1057 번째 loss, accuracy:  0.7295175017860046 0.6916666666666667\n",
      "1058 번째 loss, accuracy:  0.7293003603891836 0.6916666666666667\n",
      "1059 번째 loss, accuracy:  0.7290834329997017 0.6916666666666667\n",
      "1060 번째 loss, accuracy:  0.7288667194538959 0.6916666666666667\n",
      "1061 번째 loss, accuracy:  0.7286502195879387 0.6916666666666667\n",
      "1062 번째 loss, accuracy:  0.7284339332378439 0.6916666666666667\n",
      "1063 번째 loss, accuracy:  0.7282178602394676 0.6916666666666667\n",
      "1064 번째 loss, accuracy:  0.72800200042851 0.6916666666666667\n",
      "1065 번째 loss, accuracy:  0.7277863536405128 0.6916666666666667\n",
      "1066 번째 loss, accuracy:  0.7275709197108658 0.6916666666666667\n",
      "1067 번째 loss, accuracy:  0.7273556984748062 0.6916666666666667\n",
      "1068 번째 loss, accuracy:  0.7271406897674175 0.6916666666666667\n",
      "1069 번째 loss, accuracy:  0.7269258934236354 0.6916666666666667\n",
      "1070 번째 loss, accuracy:  0.7267113092782467 0.6916666666666667\n",
      "1071 번째 loss, accuracy:  0.7264969371658873 0.6916666666666667\n",
      "1072 번째 loss, accuracy:  0.7262827769210515 0.6916666666666667\n",
      "1073 번째 loss, accuracy:  0.7260688283780875 0.6916666666666667\n",
      "1074 번째 loss, accuracy:  0.7258550913712002 0.6916666666666667\n",
      "1075 번째 loss, accuracy:  0.7256415657344497 0.6916666666666667\n",
      "1076 번째 loss, accuracy:  0.72542825130176 0.6916666666666667\n",
      "1077 번째 loss, accuracy:  0.725215147906915 0.6916666666666667\n",
      "1078 번째 loss, accuracy:  0.7250022553835576 0.6916666666666667\n",
      "1079 번째 loss, accuracy:  0.7247895735651961 0.6916666666666667\n",
      "1080 번째 loss, accuracy:  0.7245771022852028 0.6916666666666667\n",
      "1081 번째 loss, accuracy:  0.7243648413768187 0.6916666666666667\n",
      "1082 번째 loss, accuracy:  0.724152790673148 0.6916666666666667\n",
      "1083 번째 loss, accuracy:  0.7239409500071663 0.6916666666666667\n",
      "1084 번째 loss, accuracy:  0.7237293192117177 0.6916666666666667\n",
      "1085 번째 loss, accuracy:  0.7235178981195188 0.6916666666666667\n",
      "1086 번째 loss, accuracy:  0.7233066865631563 0.6916666666666667\n",
      "1087 번째 loss, accuracy:  0.7230956843750926 0.6916666666666667\n",
      "1088 번째 loss, accuracy:  0.7228848913876668 0.6916666666666667\n",
      "1089 번째 loss, accuracy:  0.7226743074330914 0.6916666666666667\n",
      "1090 번째 loss, accuracy:  0.7224639323434585 0.6916666666666667\n",
      "1091 번째 loss, accuracy:  0.7222537659507373 0.6916666666666667\n",
      "1092 번째 loss, accuracy:  0.7220438080867791 0.6916666666666667\n",
      "1093 번째 loss, accuracy:  0.721834058583315 0.6916666666666667\n",
      "1094 번째 loss, accuracy:  0.7216245172719579 0.6916666666666667\n",
      "1095 번째 loss, accuracy:  0.7214151839842095 0.6916666666666667\n",
      "1096 번째 loss, accuracy:  0.7212060585514505 0.6916666666666667\n",
      "1097 번째 loss, accuracy:  0.7209971408049525 0.6916666666666667\n",
      "1098 번째 loss, accuracy:  0.7207884305758733 0.6916666666666667\n",
      "1099 번째 loss, accuracy:  0.7205799276952592 0.6916666666666667\n",
      "1100 번째 loss, accuracy:  0.7203716319940483 0.6916666666666667\n",
      "1101 번째 loss, accuracy:  0.7201635433030678 0.6916666666666667\n",
      "1102 번째 loss, accuracy:  0.7199556614530382 0.6916666666666667\n",
      "1103 번째 loss, accuracy:  0.7197479862745743 0.6916666666666667\n",
      "1104 번째 loss, accuracy:  0.7195405175981864 0.6916666666666667\n",
      "1105 번째 loss, accuracy:  0.7193332552542813 0.6916666666666667\n",
      "1106 번째 loss, accuracy:  0.7191261990731614 0.6916666666666667\n",
      "1107 번째 loss, accuracy:  0.7189193488850277 0.6916666666666667\n",
      "1108 번째 loss, accuracy:  0.7187127045199837 0.6916666666666667\n",
      "1109 번째 loss, accuracy:  0.7185062658080306 0.6916666666666667\n",
      "1110 번째 loss, accuracy:  0.7183000325790735 0.6916666666666667\n",
      "1111 번째 loss, accuracy:  0.718094004662923 0.6916666666666667\n",
      "1112 번째 loss, accuracy:  0.717888181889291 0.6916666666666667\n",
      "1113 번째 loss, accuracy:  0.717682564087797 0.6916666666666667\n",
      "1114 번째 loss, accuracy:  0.7174771510879661 0.6916666666666667\n",
      "1115 번째 loss, accuracy:  0.7172719427192324 0.6916666666666667\n",
      "1116 번째 loss, accuracy:  0.7170669388109397 0.6916666666666667\n",
      "1117 번째 loss, accuracy:  0.7168621391923414 0.6916666666666667\n",
      "1118 번째 loss, accuracy:  0.7166575436926022 0.6916666666666667\n",
      "1119 번째 loss, accuracy:  0.7164531521407996 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120 번째 loss, accuracy:  0.7162489643659261 0.6916666666666667\n",
      "1121 번째 loss, accuracy:  0.716044980196888 0.6916666666666667\n",
      "1122 번째 loss, accuracy:  0.7158411994625077 0.6916666666666667\n",
      "1123 번째 loss, accuracy:  0.7156376219915264 0.6916666666666667\n",
      "1124 번째 loss, accuracy:  0.7154342476126 0.6916666666666667\n",
      "1125 번째 loss, accuracy:  0.7152310761543087 0.6916666666666667\n",
      "1126 번째 loss, accuracy:  0.7150281074451513 0.6916666666666667\n",
      "1127 번째 loss, accuracy:  0.714825341313547 0.6916666666666667\n",
      "1128 번째 loss, accuracy:  0.7146227775878384 0.6916666666666667\n",
      "1129 번째 loss, accuracy:  0.7144204160962945 0.6916666666666667\n",
      "1130 번째 loss, accuracy:  0.7142182566671066 0.6916666666666667\n",
      "1131 번째 loss, accuracy:  0.7140162991283915 0.6916666666666667\n",
      "1132 번째 loss, accuracy:  0.7138145433081953 0.6916666666666667\n",
      "1133 번째 loss, accuracy:  0.7136129890344928 0.6916666666666667\n",
      "1134 번째 loss, accuracy:  0.7134116361351865 0.6916666666666667\n",
      "1135 번째 loss, accuracy:  0.7132104844381101 0.6916666666666667\n",
      "1136 번째 loss, accuracy:  0.7130095337710284 0.6916666666666667\n",
      "1137 번째 loss, accuracy:  0.7128087839616396 0.6916666666666667\n",
      "1138 번째 loss, accuracy:  0.7126082348375756 0.6916666666666667\n",
      "1139 번째 loss, accuracy:  0.7124078862264018 0.6916666666666667\n",
      "1140 번째 loss, accuracy:  0.7122077379556216 0.6916666666666667\n",
      "1141 번째 loss, accuracy:  0.7120077898526731 0.6916666666666667\n",
      "1142 번째 loss, accuracy:  0.711808041744933 0.6916666666666667\n",
      "1143 번째 loss, accuracy:  0.7116084934597188 0.6916666666666667\n",
      "1144 번째 loss, accuracy:  0.7114091448242843 0.6916666666666667\n",
      "1145 번째 loss, accuracy:  0.711209995665826 0.6916666666666667\n",
      "1146 번째 loss, accuracy:  0.7110110458114836 0.6916666666666667\n",
      "1147 번째 loss, accuracy:  0.7108122950883398 0.6916666666666667\n",
      "1148 번째 loss, accuracy:  0.7106137433234196 0.6916666666666667\n",
      "1149 번째 loss, accuracy:  0.7104153903436955 0.6916666666666667\n",
      "1150 번째 loss, accuracy:  0.7102172359760851 0.6916666666666667\n",
      "1151 번째 loss, accuracy:  0.7100192800474512 0.6916666666666667\n",
      "1152 번째 loss, accuracy:  0.709821522384608 0.6916666666666667\n",
      "1153 번째 loss, accuracy:  0.7096239628143176 0.6916666666666667\n",
      "1154 번째 loss, accuracy:  0.7094266011632914 0.6916666666666667\n",
      "1155 번째 loss, accuracy:  0.709229437258193 0.6916666666666667\n",
      "1156 번째 loss, accuracy:  0.709032470925638 0.6916666666666667\n",
      "1157 번째 loss, accuracy:  0.708835701992196 0.6916666666666667\n",
      "1158 번째 loss, accuracy:  0.7086391302843895 0.6916666666666667\n",
      "1159 번째 loss, accuracy:  0.7084427556286956 0.6916666666666667\n",
      "1160 번째 loss, accuracy:  0.7082465778515485 0.6916666666666667\n",
      "1161 번째 loss, accuracy:  0.708050596779339 0.6916666666666667\n",
      "1162 번째 loss, accuracy:  0.7078548122384171 0.6916666666666667\n",
      "1163 번째 loss, accuracy:  0.7076592240550921 0.6916666666666667\n",
      "1164 번째 loss, accuracy:  0.7074638320556298 0.6916666666666667\n",
      "1165 번째 loss, accuracy:  0.7072686360662594 0.6916666666666667\n",
      "1166 번째 loss, accuracy:  0.7070736359131715 0.6916666666666667\n",
      "1167 번째 loss, accuracy:  0.7068788314225223 0.6916666666666667\n",
      "1168 번째 loss, accuracy:  0.7066842224204287 0.6916666666666667\n",
      "1169 번째 loss, accuracy:  0.706489808732972 0.6916666666666667\n",
      "1170 번째 loss, accuracy:  0.7062955901861993 0.6916666666666667\n",
      "1171 번째 loss, accuracy:  0.7061015666061258 0.6916666666666667\n",
      "1172 번째 loss, accuracy:  0.7059077378187333 0.6916666666666667\n",
      "1173 번째 loss, accuracy:  0.7057141036499729 0.6916666666666667\n",
      "1174 번째 loss, accuracy:  0.7055206639257626 0.6916666666666667\n",
      "1175 번째 loss, accuracy:  0.7053274184719954 0.6916666666666667\n",
      "1176 번째 loss, accuracy:  0.7051343671145301 0.6916666666666667\n",
      "1177 번째 loss, accuracy:  0.7049415096791997 0.6916666666666667\n",
      "1178 번째 loss, accuracy:  0.7047488459918111 0.6916666666666667\n",
      "1179 번째 loss, accuracy:  0.7045563758781448 0.6916666666666667\n",
      "1180 번째 loss, accuracy:  0.7043640991639543 0.6916666666666667\n",
      "1181 번째 loss, accuracy:  0.7041720156749718 0.6916666666666667\n",
      "1182 번째 loss, accuracy:  0.7039801252369018 0.6916666666666667\n",
      "1183 번째 loss, accuracy:  0.7037884276754319 0.6916666666666667\n",
      "1184 번째 loss, accuracy:  0.703596922816224 0.6916666666666667\n",
      "1185 번째 loss, accuracy:  0.703405610484921 0.6916666666666667\n",
      "1186 번째 loss, accuracy:  0.7032144905071432 0.6916666666666667\n",
      "1187 번째 loss, accuracy:  0.7030235627084956 0.6916666666666667\n",
      "1188 번째 loss, accuracy:  0.7028328269145632 0.6916666666666667\n",
      "1189 번째 loss, accuracy:  0.7026422829509126 0.6916666666666667\n",
      "1190 번째 loss, accuracy:  0.7024519306430956 0.6916666666666667\n",
      "1191 번째 loss, accuracy:  0.7022617698166489 0.6916666666666667\n",
      "1192 번째 loss, accuracy:  0.7020718002970933 0.6916666666666667\n",
      "1193 번째 loss, accuracy:  0.7018820219099334 0.6916666666666667\n",
      "1194 번째 loss, accuracy:  0.7016924344806649 0.6916666666666667\n",
      "1195 번째 loss, accuracy:  0.7015030378347712 0.6916666666666667\n",
      "1196 번째 loss, accuracy:  0.701313831797722 0.6916666666666667\n",
      "1197 번째 loss, accuracy:  0.7011248161949767 0.6916666666666667\n",
      "1198 번째 loss, accuracy:  0.7009359908519848 0.6916666666666667\n",
      "1199 번째 loss, accuracy:  0.7007473555941892 0.6916666666666667\n",
      "1200 번째 loss, accuracy:  0.7005589102470223 0.6916666666666667\n",
      "1201 번째 loss, accuracy:  0.7003706546359114 0.6916666666666667\n",
      "1202 번째 loss, accuracy:  0.7001825885862752 0.6916666666666667\n",
      "1203 번째 loss, accuracy:  0.6999947119235285 0.6916666666666667\n",
      "1204 번째 loss, accuracy:  0.6998070244730807 0.6916666666666667\n",
      "1205 번째 loss, accuracy:  0.6996195260603386 0.6916666666666667\n",
      "1206 번째 loss, accuracy:  0.699432216510702 0.6916666666666667\n",
      "1207 번째 loss, accuracy:  0.6992450956495728 0.6916666666666667\n",
      "1208 번째 loss, accuracy:  0.6990581633023474 0.6916666666666667\n",
      "1209 번째 loss, accuracy:  0.6988714192944246 0.6916666666666667\n",
      "1210 번째 loss, accuracy:  0.6986848634512017 0.6916666666666667\n",
      "1211 번째 loss, accuracy:  0.6984984955980765 0.6916666666666667\n",
      "1212 번째 loss, accuracy:  0.6983123155604496 0.6916666666666667\n",
      "1213 번째 loss, accuracy:  0.698126323163722 0.6916666666666667\n",
      "1214 번째 loss, accuracy:  0.6979405182332992 0.6916666666666667\n",
      "1215 번째 loss, accuracy:  0.6977549005945918 0.6916666666666667\n",
      "1216 번째 loss, accuracy:  0.6975694700730127 0.6916666666666667\n",
      "1217 번째 loss, accuracy:  0.6973842264939818 0.6916666666666667\n",
      "1218 번째 loss, accuracy:  0.6971991696829238 0.6916666666666667\n",
      "1219 번째 loss, accuracy:  0.6970142994652709 0.6916666666666667\n",
      "1220 번째 loss, accuracy:  0.6968296156664644 0.6916666666666667\n",
      "1221 번째 loss, accuracy:  0.6966451181119514 0.6916666666666667\n",
      "1222 번째 loss, accuracy:  0.6964608066271902 0.6916666666666667\n",
      "1223 번째 loss, accuracy:  0.6962766810376482 0.6916666666666667\n",
      "1224 번째 loss, accuracy:  0.696092741168804 0.6916666666666667\n",
      "1225 번째 loss, accuracy:  0.6959089868461475 0.6916666666666667\n",
      "1226 번째 loss, accuracy:  0.6957254178951803 0.6916666666666667\n",
      "1227 번째 loss, accuracy:  0.6955420341414175 0.6916666666666667\n",
      "1228 번째 loss, accuracy:  0.6953588354103869 0.6916666666666667\n",
      "1229 번째 loss, accuracy:  0.6951758215276324 0.6916666666666667\n",
      "1230 번째 loss, accuracy:  0.6949929923187105 0.6916666666666667\n",
      "1231 번째 loss, accuracy:  0.6948103476091948 0.6916666666666667\n",
      "1232 번째 loss, accuracy:  0.6946278872246757 0.6916666666666667\n",
      "1233 번째 loss, accuracy:  0.6944456109907605 0.6916666666666667\n",
      "1234 번째 loss, accuracy:  0.694263518733073 0.6916666666666667\n",
      "1235 번째 loss, accuracy:  0.6940816102772568 0.6916666666666667\n",
      "1236 번째 loss, accuracy:  0.6938998854489765 0.6916666666666667\n",
      "1237 번째 loss, accuracy:  0.6937183440739124 0.6916666666666667\n",
      "1238 번째 loss, accuracy:  0.6935369859777705 0.6916666666666667\n",
      "1239 번째 loss, accuracy:  0.6933558109862747 0.6916666666666667\n",
      "1240 번째 loss, accuracy:  0.6931748189251731 0.6916666666666667\n",
      "1241 번째 loss, accuracy:  0.6929940096202335 0.6916666666666667\n",
      "1242 번째 loss, accuracy:  0.6928133828972495 0.6916666666666667\n",
      "1243 번째 loss, accuracy:  0.6926329385820392 0.6916666666666667\n",
      "1244 번째 loss, accuracy:  0.6924526765004447 0.6916666666666667\n",
      "1245 번째 loss, accuracy:  0.6922725964783328 0.6916666666666667\n",
      "1246 번째 loss, accuracy:  0.6920926983415973 0.6916666666666667\n",
      "1247 번째 loss, accuracy:  0.6919129819161605 0.6916666666666667\n",
      "1248 번째 loss, accuracy:  0.6917334470279672 0.6916666666666667\n",
      "1249 번째 loss, accuracy:  0.6915540935029955 0.6916666666666667\n",
      "1250 번째 loss, accuracy:  0.6913749211672503 0.6916666666666667\n",
      "1251 번째 loss, accuracy:  0.6911959298467653 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1252 번째 loss, accuracy:  0.6910171193676042 0.6916666666666667\n",
      "1253 번째 loss, accuracy:  0.6908384895558615 0.6916666666666667\n",
      "1254 번째 loss, accuracy:  0.6906600402376654 0.6916666666666667\n",
      "1255 번째 loss, accuracy:  0.6904817712391726 0.6916666666666667\n",
      "1256 번째 loss, accuracy:  0.6903036823865764 0.6916666666666667\n",
      "1257 번째 loss, accuracy:  0.6901257735060989 0.6916666666666667\n",
      "1258 번째 loss, accuracy:  0.6899480444239994 0.6916666666666667\n",
      "1259 번째 loss, accuracy:  0.6897704949665707 0.6916666666666667\n",
      "1260 번째 loss, accuracy:  0.6895931249601402 0.6916666666666667\n",
      "1261 번째 loss, accuracy:  0.6894159342310713 0.6916666666666667\n",
      "1262 번째 loss, accuracy:  0.6892389226057662 0.6916666666666667\n",
      "1263 번째 loss, accuracy:  0.6890620899106599 0.6916666666666667\n",
      "1264 번째 loss, accuracy:  0.6888854359722284 0.6916666666666667\n",
      "1265 번째 loss, accuracy:  0.6887089606169842 0.6916666666666667\n",
      "1266 번째 loss, accuracy:  0.6885326636714789 0.6916666666666667\n",
      "1267 번째 loss, accuracy:  0.6883565449623046 0.6916666666666667\n",
      "1268 번째 loss, accuracy:  0.6881806043160916 0.6916666666666667\n",
      "1269 번째 loss, accuracy:  0.6880048415595137 0.6916666666666667\n",
      "1270 번째 loss, accuracy:  0.6878292565192834 0.6916666666666667\n",
      "1271 번째 loss, accuracy:  0.6876538490221553 0.6916666666666667\n",
      "1272 번째 loss, accuracy:  0.6874786188949269 0.6916666666666667\n",
      "1273 번째 loss, accuracy:  0.6873035659644405 0.6916666666666667\n",
      "1274 번째 loss, accuracy:  0.6871286900575789 0.6916666666666667\n",
      "1275 번째 loss, accuracy:  0.6869539910012716 0.6916666666666667\n",
      "1276 번째 loss, accuracy:  0.686779468622492 0.6916666666666667\n",
      "1277 번째 loss, accuracy:  0.6866051227482598 0.6916666666666667\n",
      "1278 번째 loss, accuracy:  0.686430953205637 0.6916666666666667\n",
      "1279 번째 loss, accuracy:  0.6862569598217374 0.6916666666666667\n",
      "1280 번째 loss, accuracy:  0.6860831424237175 0.6916666666666667\n",
      "1281 번째 loss, accuracy:  0.685909500838784 0.6916666666666667\n",
      "1282 번째 loss, accuracy:  0.6857360348941903 0.6916666666666667\n",
      "1283 번째 loss, accuracy:  0.6855627444172404 0.6916666666666667\n",
      "1284 번째 loss, accuracy:  0.6853896292352863 0.6916666666666667\n",
      "1285 번째 loss, accuracy:  0.685216689175728 0.6916666666666667\n",
      "1286 번째 loss, accuracy:  0.6850439240660201 0.6916666666666667\n",
      "1287 번째 loss, accuracy:  0.6848713337336647 0.6916666666666667\n",
      "1288 번째 loss, accuracy:  0.6846989180062183 0.6916666666666667\n",
      "1289 번째 loss, accuracy:  0.6845266767112863 0.6916666666666667\n",
      "1290 번째 loss, accuracy:  0.6843546096765302 0.6916666666666667\n",
      "1291 번째 loss, accuracy:  0.684182716729662 0.6916666666666667\n",
      "1292 번째 loss, accuracy:  0.6840109976984473 0.6916666666666667\n",
      "1293 번째 loss, accuracy:  0.6838394524107083 0.6916666666666667\n",
      "1294 번째 loss, accuracy:  0.6836680806943197 0.6916666666666667\n",
      "1295 번째 loss, accuracy:  0.6834968823772116 0.6916666666666667\n",
      "1296 번째 loss, accuracy:  0.683325857287371 0.6916666666666667\n",
      "1297 번째 loss, accuracy:  0.6831550052528405 0.6916666666666667\n",
      "1298 번째 loss, accuracy:  0.6829843261017209 0.6916666666666667\n",
      "1299 번째 loss, accuracy:  0.6828138196621686 0.6916666666666667\n",
      "1300 번째 loss, accuracy:  0.6826434857623973 0.6916666666666667\n",
      "1301 번째 loss, accuracy:  0.6824733242306819 0.6916666666666667\n",
      "1302 번째 loss, accuracy:  0.6823033348953534 0.6916666666666667\n",
      "1303 번째 loss, accuracy:  0.682133517584804 0.6916666666666667\n",
      "1304 번째 loss, accuracy:  0.681963872127485 0.6916666666666667\n",
      "1305 번째 loss, accuracy:  0.6817943983519071 0.6916666666666667\n",
      "1306 번째 loss, accuracy:  0.6816250960866446 0.6916666666666667\n",
      "1307 번째 loss, accuracy:  0.6814559651603324 0.6916666666666667\n",
      "1308 번째 loss, accuracy:  0.6812870054016665 0.6916666666666667\n",
      "1309 번째 loss, accuracy:  0.681118216639403 0.6916666666666667\n",
      "1310 번째 loss, accuracy:  0.6809495987023649 0.6916666666666667\n",
      "1311 번째 loss, accuracy:  0.6807811514194362 0.6916666666666667\n",
      "1312 번째 loss, accuracy:  0.6806128746195661 0.6916666666666667\n",
      "1313 번째 loss, accuracy:  0.6804447681317677 0.6916666666666667\n",
      "1314 번째 loss, accuracy:  0.6802768317851176 0.6916666666666667\n",
      "1315 번째 loss, accuracy:  0.6801090654087588 0.6916666666666667\n",
      "1316 번째 loss, accuracy:  0.6799414688319007 0.6916666666666667\n",
      "1317 번째 loss, accuracy:  0.6797740418838176 0.6916666666666667\n",
      "1318 번째 loss, accuracy:  0.6796067843938526 0.6916666666666667\n",
      "1319 번째 loss, accuracy:  0.6794396961914136 0.6916666666666667\n",
      "1320 번째 loss, accuracy:  0.6792727771059762 0.6916666666666667\n",
      "1321 번째 loss, accuracy:  0.6791060269670849 0.6916666666666667\n",
      "1322 번째 loss, accuracy:  0.6789394456043529 0.6916666666666667\n",
      "1323 번째 loss, accuracy:  0.6787730328474628 0.6916666666666667\n",
      "1324 번째 loss, accuracy:  0.678606788526167 0.6916666666666667\n",
      "1325 번째 loss, accuracy:  0.6784407124702838 0.6916666666666667\n",
      "1326 번째 loss, accuracy:  0.6782748045097081 0.6916666666666667\n",
      "1327 번째 loss, accuracy:  0.6781090644744009 0.6916666666666667\n",
      "1328 번째 loss, accuracy:  0.6779434921943971 0.6916666666666667\n",
      "1329 번째 loss, accuracy:  0.6777780874997996 0.6916666666666667\n",
      "1330 번째 loss, accuracy:  0.6776128502207882 0.6916666666666667\n",
      "1331 번째 loss, accuracy:  0.6774477801876134 0.6916666666666667\n",
      "1332 번째 loss, accuracy:  0.6772828772305973 0.6916666666666667\n",
      "1333 번째 loss, accuracy:  0.677118141180138 0.6916666666666667\n",
      "1334 번째 loss, accuracy:  0.6769535718667044 0.6916666666666667\n",
      "1335 번째 loss, accuracy:  0.6767891691208415 0.6916666666666667\n",
      "1336 번째 loss, accuracy:  0.6766249327731696 0.6916666666666667\n",
      "1337 번째 loss, accuracy:  0.6764608626543828 0.6916666666666667\n",
      "1338 번째 loss, accuracy:  0.6762969585952519 0.6916666666666667\n",
      "1339 번째 loss, accuracy:  0.6761332204266228 0.6916666666666667\n",
      "1340 번째 loss, accuracy:  0.6759696479794187 0.6916666666666667\n",
      "1341 번째 loss, accuracy:  0.6758062410846379 0.6916666666666667\n",
      "1342 번째 loss, accuracy:  0.6756429995733576 0.6916666666666667\n",
      "1343 번째 loss, accuracy:  0.6754799232767332 0.6916666666666667\n",
      "1344 번째 loss, accuracy:  0.6753170120259954 0.6916666666666667\n",
      "1345 번째 loss, accuracy:  0.675154265652457 0.6916666666666667\n",
      "1346 번째 loss, accuracy:  0.6749916839875069 0.6916666666666667\n",
      "1347 번째 loss, accuracy:  0.6748292668626132 0.6916666666666667\n",
      "1348 번째 loss, accuracy:  0.6746670141093266 0.6916666666666667\n",
      "1349 번째 loss, accuracy:  0.674504925559274 0.6916666666666667\n",
      "1350 번째 loss, accuracy:  0.6743430010441659 0.6916666666666667\n",
      "1351 번째 loss, accuracy:  0.6741812403957906 0.6916666666666667\n",
      "1352 번째 loss, accuracy:  0.6740196434460214 0.6916666666666667\n",
      "1353 번째 loss, accuracy:  0.6738582100268107 0.6916666666666667\n",
      "1354 번째 loss, accuracy:  0.6736969399701926 0.6916666666666667\n",
      "1355 번째 loss, accuracy:  0.6735358331082855 0.6916666666666667\n",
      "1356 번째 loss, accuracy:  0.6733748892732883 0.6916666666666667\n",
      "1357 번째 loss, accuracy:  0.673214108297485 0.6916666666666667\n",
      "1358 번째 loss, accuracy:  0.6730534900132421 0.6916666666666667\n",
      "1359 번째 loss, accuracy:  0.6728930342530123 0.6916666666666667\n",
      "1360 번째 loss, accuracy:  0.6727327408493298 0.6916666666666667\n",
      "1361 번째 loss, accuracy:  0.6725726096348124 0.6916666666666667\n",
      "1362 번째 loss, accuracy:  0.6724126404421669 0.6916666666666667\n",
      "1363 번째 loss, accuracy:  0.6722528331041834 0.6916666666666667\n",
      "1364 번째 loss, accuracy:  0.6720931874537363 0.6916666666666667\n",
      "1365 번째 loss, accuracy:  0.671933703323788 0.6916666666666667\n",
      "1366 번째 loss, accuracy:  0.6717743805473883 0.6916666666666667\n",
      "1367 번째 loss, accuracy:  0.6716152189576721 0.6916666666666667\n",
      "1368 번째 loss, accuracy:  0.6714562183878611 0.6916666666666667\n",
      "1369 번째 loss, accuracy:  0.6712973786712675 0.6916666666666667\n",
      "1370 번째 loss, accuracy:  0.671138699641288 0.6916666666666667\n",
      "1371 번째 loss, accuracy:  0.6709801811314084 0.6916666666666667\n",
      "1372 번째 loss, accuracy:  0.6708218229752035 0.6916666666666667\n",
      "1373 번째 loss, accuracy:  0.6706636250063398 0.6916666666666667\n",
      "1374 번째 loss, accuracy:  0.6705055870585692 0.6916666666666667\n",
      "1375 번째 loss, accuracy:  0.6703477089657325 0.6916666666666667\n",
      "1376 번째 loss, accuracy:  0.6701899905617653 0.6916666666666667\n",
      "1377 번째 loss, accuracy:  0.6700324316806904 0.6916666666666667\n",
      "1378 번째 loss, accuracy:  0.66987503215662 0.6916666666666667\n",
      "1379 번째 loss, accuracy:  0.66971779182376 0.6916666666666667\n",
      "1380 번째 loss, accuracy:  0.6695607105164078 0.6916666666666667\n",
      "1381 번째 loss, accuracy:  0.6694037880689494 0.6916666666666667\n",
      "1382 번째 loss, accuracy:  0.6692470243158651 0.6916666666666667\n",
      "1383 번째 loss, accuracy:  0.6690904190917275 0.6916666666666667\n",
      "1384 번째 loss, accuracy:  0.6689339722312025 0.6916666666666667\n",
      "1385 번째 loss, accuracy:  0.6687776835690469 0.6916666666666667\n",
      "1386 번째 loss, accuracy:  0.6686215529401122 0.6916666666666667\n",
      "1387 번째 loss, accuracy:  0.6684655801793412 0.6916666666666667\n",
      "1388 번째 loss, accuracy:  0.6683097651217754 0.6916666666666667\n",
      "1389 번째 loss, accuracy:  0.6681541076025472 0.6916666666666667\n",
      "1390 번째 loss, accuracy:  0.667998607456883 0.6916666666666667\n",
      "1391 번째 loss, accuracy:  0.6678432645201063 0.6916666666666667\n",
      "1392 번째 loss, accuracy:  0.6676880786276338 0.6916666666666667\n",
      "1393 번째 loss, accuracy:  0.66753304961498 0.6916666666666667\n",
      "1394 번째 loss, accuracy:  0.667378177317752 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1395 번째 loss, accuracy:  0.6672234615716541 0.6916666666666667\n",
      "1396 번째 loss, accuracy:  0.6670689022124903 0.6916666666666667\n",
      "1397 번째 loss, accuracy:  0.6669144990761577 0.6916666666666667\n",
      "1398 번째 loss, accuracy:  0.6667602519986507 0.6916666666666667\n",
      "1399 번째 loss, accuracy:  0.6666061608160635 0.6916666666666667\n",
      "1400 번째 loss, accuracy:  0.6664522253645838 0.6916666666666667\n",
      "1401 번째 loss, accuracy:  0.6662984454805011 0.6916666666666667\n",
      "1402 번째 loss, accuracy:  0.6661448210001992 0.6916666666666667\n",
      "1403 번째 loss, accuracy:  0.6659913517601666 0.6916666666666667\n",
      "1404 번째 loss, accuracy:  0.6658380375969839 0.6916666666666667\n",
      "1405 번째 loss, accuracy:  0.6656848783473351 0.6916666666666667\n",
      "1406 번째 loss, accuracy:  0.6655318738480014 0.6916666666666667\n",
      "1407 번째 loss, accuracy:  0.6653790239358632 0.6916666666666667\n",
      "1408 번째 loss, accuracy:  0.6652263284479036 0.6916666666666667\n",
      "1409 번째 loss, accuracy:  0.6650737872212029 0.6916666666666667\n",
      "1410 번째 loss, accuracy:  0.6649214000929434 0.6916666666666667\n",
      "1411 번째 loss, accuracy:  0.6647691669004079 0.6916666666666667\n",
      "1412 번째 loss, accuracy:  0.664617087480979 0.6916666666666667\n",
      "1413 번째 loss, accuracy:  0.6644651616721433 0.6916666666666667\n",
      "1414 번째 loss, accuracy:  0.6643133893114874 0.6916666666666667\n",
      "1415 번째 loss, accuracy:  0.6641617702366981 0.6916666666666667\n",
      "1416 번째 loss, accuracy:  0.664010304285567 0.6916666666666667\n",
      "1417 번째 loss, accuracy:  0.6638589912959872 0.6916666666666667\n",
      "1418 번째 loss, accuracy:  0.6637078311059542 0.6916666666666667\n",
      "1419 번째 loss, accuracy:  0.6635568235535659 0.6916666666666667\n",
      "1420 번째 loss, accuracy:  0.6634059684770242 0.6916666666666667\n",
      "1421 번째 loss, accuracy:  0.6632552657146338 0.6916666666666667\n",
      "1422 번째 loss, accuracy:  0.6631047151048028 0.6916666666666667\n",
      "1423 번째 loss, accuracy:  0.6629543164860441 0.6916666666666667\n",
      "1424 번째 loss, accuracy:  0.6628040696969758 0.6916666666666667\n",
      "1425 번째 loss, accuracy:  0.6626539745763185 0.6916666666666667\n",
      "1426 번째 loss, accuracy:  0.6625040309628958 0.6916666666666667\n",
      "1427 번째 loss, accuracy:  0.6623542386956414 0.6916666666666667\n",
      "1428 번째 loss, accuracy:  0.66220459761359 0.6916666666666667\n",
      "1429 번째 loss, accuracy:  0.6620551075558831 0.6916666666666667\n",
      "1430 번째 loss, accuracy:  0.6619057683617664 0.6916666666666667\n",
      "1431 번째 loss, accuracy:  0.6617565798705948 0.6916666666666667\n",
      "1432 번째 loss, accuracy:  0.6616075419218269 0.6916666666666667\n",
      "1433 번째 loss, accuracy:  0.6614586543550272 0.6916666666666667\n",
      "1434 번째 loss, accuracy:  0.6613099170098693 0.6916666666666667\n",
      "1435 번째 loss, accuracy:  0.661161329726132 0.6916666666666667\n",
      "1436 번째 loss, accuracy:  0.6610128923437002 0.6916666666666667\n",
      "1437 번째 loss, accuracy:  0.6608646047025685 0.6916666666666667\n",
      "1438 번째 loss, accuracy:  0.6607164666428382 0.6916666666666667\n",
      "1439 번째 loss, accuracy:  0.6605684780047183 0.6916666666666667\n",
      "1440 번째 loss, accuracy:  0.6604206386285251 0.6916666666666667\n",
      "1441 번째 loss, accuracy:  0.6602729483546831 0.6916666666666667\n",
      "1442 번째 loss, accuracy:  0.6601254070237261 0.6916666666666667\n",
      "1443 번째 loss, accuracy:  0.6599780144762979 0.6916666666666667\n",
      "1444 번째 loss, accuracy:  0.659830770553148 0.6916666666666667\n",
      "1445 번째 loss, accuracy:  0.6596836750951355 0.6916666666666667\n",
      "1446 번째 loss, accuracy:  0.659536727943234 0.6916666666666667\n",
      "1447 번째 loss, accuracy:  0.6593899289385213 0.6916666666666667\n",
      "1448 번째 loss, accuracy:  0.6592432779221866 0.6916666666666667\n",
      "1449 번째 loss, accuracy:  0.659096774735528 0.6916666666666667\n",
      "1450 번째 loss, accuracy:  0.6589504192199555 0.6916666666666667\n",
      "1451 번째 loss, accuracy:  0.6588042112169895 0.6916666666666667\n",
      "1452 번째 loss, accuracy:  0.6586581505682593 0.6916666666666667\n",
      "1453 번째 loss, accuracy:  0.6585122371155075 0.6916666666666667\n",
      "1454 번째 loss, accuracy:  0.6583664707005862 0.6916666666666667\n",
      "1455 번째 loss, accuracy:  0.6582208511654594 0.6916666666666667\n",
      "1456 번째 loss, accuracy:  0.6580753783522025 0.6916666666666667\n",
      "1457 번째 loss, accuracy:  0.6579300521030018 0.6916666666666667\n",
      "1458 번째 loss, accuracy:  0.6577848722601566 0.6916666666666667\n",
      "1459 번째 loss, accuracy:  0.6576398386660766 0.6916666666666667\n",
      "1460 번째 loss, accuracy:  0.6574949511632863 0.6916666666666667\n",
      "1461 번째 loss, accuracy:  0.6573502095944207 0.6916666666666667\n",
      "1462 번째 loss, accuracy:  0.6572056138022284 0.6916666666666667\n",
      "1463 번째 loss, accuracy:  0.6570611636295697 0.6916666666666667\n",
      "1464 번째 loss, accuracy:  0.6569168589194215 0.6916666666666667\n",
      "1465 번째 loss, accuracy:  0.6567726995148692 0.6916666666666667\n",
      "1466 번째 loss, accuracy:  0.6566286852591149 0.6916666666666667\n",
      "1467 번째 loss, accuracy:  0.6564848159954724 0.6916666666666667\n",
      "1468 번째 loss, accuracy:  0.6563410915673684 0.6916666666666667\n",
      "1469 번째 loss, accuracy:  0.6561975118183498 0.6916666666666667\n",
      "1470 번째 loss, accuracy:  0.656054076592071 0.6916666666666667\n",
      "1471 번째 loss, accuracy:  0.6559107857323011 0.6916666666666667\n",
      "1472 번째 loss, accuracy:  0.6557676390829286 0.6916666666666667\n",
      "1473 번째 loss, accuracy:  0.655624636487954 0.6916666666666667\n",
      "1474 번째 loss, accuracy:  0.6554817777914922 0.6916666666666667\n",
      "1475 번째 loss, accuracy:  0.6553390628377728 0.6916666666666667\n",
      "1476 번째 loss, accuracy:  0.6551964914711407 0.6916666666666667\n",
      "1477 번째 loss, accuracy:  0.65505406353606 0.6916666666666667\n",
      "1478 번째 loss, accuracy:  0.6549117788771054 0.6916666666666667\n",
      "1479 번째 loss, accuracy:  0.6547696373389686 0.6916666666666667\n",
      "1480 번째 loss, accuracy:  0.6546276387664602 0.6916666666666667\n",
      "1481 번째 loss, accuracy:  0.6544857830045037 0.6916666666666667\n",
      "1482 번째 loss, accuracy:  0.6543440698981406 0.6916666666666667\n",
      "1483 번째 loss, accuracy:  0.6542024992925294 0.6916666666666667\n",
      "1484 번째 loss, accuracy:  0.654061071032943 0.6916666666666667\n",
      "1485 번째 loss, accuracy:  0.6539197849647728 0.6916666666666667\n",
      "1486 번째 loss, accuracy:  0.6537786409335273 0.6916666666666667\n",
      "1487 번째 loss, accuracy:  0.6536376387848309 0.6916666666666667\n",
      "1488 번째 loss, accuracy:  0.653496778364426 0.6916666666666667\n",
      "1489 번째 loss, accuracy:  0.6533560595181733 0.6916666666666667\n",
      "1490 번째 loss, accuracy:  0.6532154820920493 0.6916666666666667\n",
      "1491 번째 loss, accuracy:  0.6530750459321492 0.6916666666666667\n",
      "1492 번째 loss, accuracy:  0.6529347508846873 0.6916666666666667\n",
      "1493 번째 loss, accuracy:  0.6527945967959937 0.6916666666666667\n",
      "1494 번째 loss, accuracy:  0.652654583512519 0.6916666666666667\n",
      "1495 번째 loss, accuracy:  0.6525147108808305 0.6916666666666667\n",
      "1496 번째 loss, accuracy:  0.6523749787476146 0.6916666666666667\n",
      "1497 번째 loss, accuracy:  0.6522353869596764 0.6916666666666667\n",
      "1498 번째 loss, accuracy:  0.6520959353639407 0.6916666666666667\n",
      "1499 번째 loss, accuracy:  0.6519566238074489 0.6916666666666667\n",
      "1500 번째 loss, accuracy:  0.6518174521373648 0.6916666666666667\n",
      "1501 번째 loss, accuracy:  0.6516784202009692 0.6916666666666667\n",
      "1502 번째 loss, accuracy:  0.6515395278456618 0.6916666666666667\n",
      "1503 번째 loss, accuracy:  0.651400774918965 0.6916666666666667\n",
      "1504 번째 loss, accuracy:  0.6512621612685171 0.6916666666666667\n",
      "1505 번째 loss, accuracy:  0.6511236867420791 0.6916666666666667\n",
      "1506 번째 loss, accuracy:  0.6509853511875306 0.6916666666666667\n",
      "1507 번째 loss, accuracy:  0.6508471544528713 0.6916666666666667\n",
      "1508 번째 loss, accuracy:  0.6507090963862212 0.6916666666666667\n",
      "1509 번째 loss, accuracy:  0.6505711768358226 0.6916666666666667\n",
      "1510 번째 loss, accuracy:  0.6504333956500348 0.6916666666666667\n",
      "1511 번째 loss, accuracy:  0.6502957526773401 0.6916666666666667\n",
      "1512 번째 loss, accuracy:  0.6501582477663417 0.6916666666666667\n",
      "1513 번째 loss, accuracy:  0.6500208807657634 0.6916666666666667\n",
      "1514 번째 loss, accuracy:  0.6498836515244487 0.6916666666666667\n",
      "1515 번째 loss, accuracy:  0.6497465598913638 0.6916666666666667\n",
      "1516 번째 loss, accuracy:  0.6496096057155967 0.6916666666666667\n",
      "1517 번째 loss, accuracy:  0.6494727888463548 0.6916666666666667\n",
      "1518 번째 loss, accuracy:  0.6493361091329685 0.6916666666666667\n",
      "1519 번째 loss, accuracy:  0.6491995664248897 0.6916666666666667\n",
      "1520 번째 loss, accuracy:  0.6490631605716923 0.6916666666666667\n",
      "1521 번째 loss, accuracy:  0.6489268914230704 0.6916666666666667\n",
      "1522 번째 loss, accuracy:  0.6487907588288432 0.6916666666666667\n",
      "1523 번째 loss, accuracy:  0.6486547626389495 0.6916666666666667\n",
      "1524 번째 loss, accuracy:  0.6485189027034522 0.6916666666666667\n",
      "1525 번째 loss, accuracy:  0.648383178872535 0.6916666666666667\n",
      "1526 번째 loss, accuracy:  0.6482475909965043 0.6916666666666667\n",
      "1527 번째 loss, accuracy:  0.6481121389257889 0.6916666666666667\n",
      "1528 번째 loss, accuracy:  0.6479768225109429 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1529 번째 loss, accuracy:  0.6478416416026404 0.6916666666666667\n",
      "1530 번째 loss, accuracy:  0.6477065960516791 0.6916666666666667\n",
      "1531 번째 loss, accuracy:  0.6475716857089819 0.6916666666666667\n",
      "1532 번째 loss, accuracy:  0.6474369104255914 0.6916666666666667\n",
      "1533 번째 loss, accuracy:  0.6473022700526767 0.6916666666666667\n",
      "1534 번째 loss, accuracy:  0.6471677644415263 0.6916666666666667\n",
      "1535 번째 loss, accuracy:  0.6470333934435563 0.6916666666666667\n",
      "1536 번째 loss, accuracy:  0.6468991569103058 0.6916666666666667\n",
      "1537 번째 loss, accuracy:  0.6467650546934341 0.6916666666666667\n",
      "1538 번째 loss, accuracy:  0.6466310866447292 0.6916666666666667\n",
      "1539 번째 loss, accuracy:  0.6464972526160991 0.6916666666666667\n",
      "1540 번째 loss, accuracy:  0.6463635524595778 0.6916666666666667\n",
      "1541 번째 loss, accuracy:  0.6462299860273232 0.6916666666666667\n",
      "1542 번째 loss, accuracy:  0.6460965531716163 0.6916666666666667\n",
      "1543 번째 loss, accuracy:  0.6459632537448651 0.6916666666666667\n",
      "1544 번째 loss, accuracy:  0.6458300875995981 0.6916666666666667\n",
      "1545 번째 loss, accuracy:  0.6456970545884718 0.6916666666666667\n",
      "1546 번째 loss, accuracy:  0.6455641545642661 0.6916666666666667\n",
      "1547 번째 loss, accuracy:  0.6454313873798851 0.6916666666666667\n",
      "1548 번째 loss, accuracy:  0.6452987528883573 0.6916666666666667\n",
      "1549 번째 loss, accuracy:  0.6451662509428376 0.6916666666666667\n",
      "1550 번째 loss, accuracy:  0.6450338813966039 0.6916666666666667\n",
      "1551 번째 loss, accuracy:  0.6449016441030613 0.6916666666666667\n",
      "1552 번째 loss, accuracy:  0.6447695389157393 0.6916666666666667\n",
      "1553 번째 loss, accuracy:  0.6446375656882919 0.6916666666666667\n",
      "1554 번째 loss, accuracy:  0.6445057242744985 0.6916666666666667\n",
      "1555 번째 loss, accuracy:  0.6443740145282655 0.6916666666666667\n",
      "1556 번째 loss, accuracy:  0.644242436303622 0.6916666666666667\n",
      "1557 번째 loss, accuracy:  0.6441109894547247 0.6916666666666667\n",
      "1558 번째 loss, accuracy:  0.6439796738358562 0.6916666666666667\n",
      "1559 번째 loss, accuracy:  0.6438484893014244 0.6916666666666667\n",
      "1560 번째 loss, accuracy:  0.6437174357059613 0.6916666666666667\n",
      "1561 번째 loss, accuracy:  0.6435865129041273 0.6916666666666667\n",
      "1562 번째 loss, accuracy:  0.6434557207507078 0.6916666666666667\n",
      "1563 번째 loss, accuracy:  0.643325059100614 0.6916666666666667\n",
      "1564 번째 loss, accuracy:  0.6431945278088833 0.6916666666666667\n",
      "1565 번째 loss, accuracy:  0.6430641267306794 0.6916666666666667\n",
      "1566 번째 loss, accuracy:  0.6429338557212919 0.6916666666666667\n",
      "1567 번째 loss, accuracy:  0.6428037146361381 0.6916666666666667\n",
      "1568 번째 loss, accuracy:  0.6426737033307606 0.6916666666666667\n",
      "1569 번째 loss, accuracy:  0.6425438216608281 0.6916666666666667\n",
      "1570 번째 loss, accuracy:  0.6424140694821363 0.6916666666666667\n",
      "1571 번째 loss, accuracy:  0.6422844466506097 0.6916666666666667\n",
      "1572 번째 loss, accuracy:  0.6421549530222947 0.6916666666666667\n",
      "1573 번째 loss, accuracy:  0.6420255884533678 0.6916666666666667\n",
      "1574 번째 loss, accuracy:  0.6418963528001331 0.6916666666666667\n",
      "1575 번째 loss, accuracy:  0.6417672459190203 0.6916666666666667\n",
      "1576 번째 loss, accuracy:  0.6416382676665854 0.6916666666666667\n",
      "1577 번째 loss, accuracy:  0.6415094178995123 0.6916666666666667\n",
      "1578 번째 loss, accuracy:  0.6413806964746114 0.6916666666666667\n",
      "1579 번째 loss, accuracy:  0.6412521032488214 0.6916666666666667\n",
      "1580 번째 loss, accuracy:  0.6411236380792078 0.6916666666666667\n",
      "1581 번째 loss, accuracy:  0.6409953008229626 0.6916666666666667\n",
      "1582 번째 loss, accuracy:  0.6408670913374054 0.6916666666666667\n",
      "1583 번째 loss, accuracy:  0.6407390094799842 0.6916666666666667\n",
      "1584 번째 loss, accuracy:  0.6406110551082738 0.6916666666666667\n",
      "1585 번째 loss, accuracy:  0.6404832280799776 0.6916666666666667\n",
      "1586 번째 loss, accuracy:  0.6403555282529239 0.6916666666666667\n",
      "1587 번째 loss, accuracy:  0.6402279554850703 0.6916666666666667\n",
      "1588 번째 loss, accuracy:  0.6401005096345034 0.6916666666666667\n",
      "1589 번째 loss, accuracy:  0.6399731905594341 0.6916666666666667\n",
      "1590 번째 loss, accuracy:  0.6398459981182048 0.6916666666666667\n",
      "1591 번째 loss, accuracy:  0.6397189321692838 0.6916666666666667\n",
      "1592 번째 loss, accuracy:  0.6395919925712672 0.6916666666666667\n",
      "1593 번째 loss, accuracy:  0.6394651791828799 0.6916666666666667\n",
      "1594 번째 loss, accuracy:  0.6393384918629752 0.6916666666666667\n",
      "1595 번째 loss, accuracy:  0.6392119304705332 0.6916666666666667\n",
      "1596 번째 loss, accuracy:  0.6390854948646625 0.6916666666666667\n",
      "1597 번째 loss, accuracy:  0.6389591849046004 0.6916666666666667\n",
      "1598 번째 loss, accuracy:  0.6388330004497125 0.6916666666666667\n",
      "1599 번째 loss, accuracy:  0.6387069413594911 0.6916666666666667\n",
      "1600 번째 loss, accuracy:  0.6385810074935566 0.6916666666666667\n",
      "1601 번째 loss, accuracy:  0.6384551987116621 0.6916666666666667\n",
      "1602 번째 loss, accuracy:  0.6383295148736824 0.6916666666666667\n",
      "1603 번째 loss, accuracy:  0.6382039558396279 0.6916666666666667\n",
      "1604 번째 loss, accuracy:  0.6380785214696325 0.6916666666666667\n",
      "1605 번째 loss, accuracy:  0.6379532116239599 0.6916666666666667\n",
      "1606 번째 loss, accuracy:  0.6378280261630024 0.6916666666666667\n",
      "1607 번째 loss, accuracy:  0.6377029649472803 0.6916666666666667\n",
      "1608 번째 loss, accuracy:  0.6375780278374442 0.6916666666666667\n",
      "1609 번째 loss, accuracy:  0.6374532146942714 0.6916666666666667\n",
      "1610 번째 loss, accuracy:  0.6373285253786692 0.6916666666666667\n",
      "1611 번째 loss, accuracy:  0.6372039597516737 0.6916666666666667\n",
      "1612 번째 loss, accuracy:  0.6370795176744483 0.6916666666666667\n",
      "1613 번째 loss, accuracy:  0.6369551990082873 0.6916666666666667\n",
      "1614 번째 loss, accuracy:  0.636831003614612 0.6916666666666667\n",
      "1615 번째 loss, accuracy:  0.636706931354975 0.6916666666666667\n",
      "1616 번째 loss, accuracy:  0.6365829820910537 0.6916666666666667\n",
      "1617 번째 loss, accuracy:  0.6364591556846577 0.6916666666666667\n",
      "1618 번째 loss, accuracy:  0.6363354519977263 0.6916666666666667\n",
      "1619 번째 loss, accuracy:  0.6362118708923244 0.6916666666666667\n",
      "1620 번째 loss, accuracy:  0.6360884122306494 0.6916666666666667\n",
      "1621 번째 loss, accuracy:  0.6359650758750258 0.6916666666666667\n",
      "1622 번째 loss, accuracy:  0.6358418616879065 0.6916666666666667\n",
      "1623 번째 loss, accuracy:  0.6357187695318748 0.6916666666666667\n",
      "1624 번째 loss, accuracy:  0.6355957992696442 0.6916666666666667\n",
      "1625 번째 loss, accuracy:  0.6354729507640555 0.6916666666666667\n",
      "1626 번째 loss, accuracy:  0.6353502238780792 0.6916666666666667\n",
      "1627 번째 loss, accuracy:  0.6352276184748153 0.6916666666666667\n",
      "1628 번째 loss, accuracy:  0.635105134417493 0.6916666666666667\n",
      "1629 번째 loss, accuracy:  0.6349827715694695 0.6916666666666667\n",
      "1630 번째 loss, accuracy:  0.6348605297942347 0.6916666666666667\n",
      "1631 번째 loss, accuracy:  0.6347384089554035 0.6916666666666667\n",
      "1632 번째 loss, accuracy:  0.6346164089167237 0.6916666666666667\n",
      "1633 번째 loss, accuracy:  0.6344945295420688 0.6916666666666667\n",
      "1634 번째 loss, accuracy:  0.6343727706954454 0.6916666666666667\n",
      "1635 번째 loss, accuracy:  0.6342511322409884 0.6916666666666667\n",
      "1636 번째 loss, accuracy:  0.6341296140429601 0.6916666666666667\n",
      "1637 번째 loss, accuracy:  0.6340082159657557 0.6916666666666667\n",
      "1638 번째 loss, accuracy:  0.633886937873895 0.6916666666666667\n",
      "1639 번째 loss, accuracy:  0.6337657796320328 0.6916666666666667\n",
      "1640 번째 loss, accuracy:  0.6336447411049492 0.6916666666666667\n",
      "1641 번째 loss, accuracy:  0.6335238221575565 0.6916666666666667\n",
      "1642 번째 loss, accuracy:  0.6334030226548941 0.6916666666666667\n",
      "1643 번째 loss, accuracy:  0.6332823424621329 0.6916666666666667\n",
      "1644 번째 loss, accuracy:  0.6331617814445724 0.6916666666666667\n",
      "1645 번째 loss, accuracy:  0.6330413394676415 0.6916666666666667\n",
      "1646 번째 loss, accuracy:  0.6329210163968999 0.6916666666666667\n",
      "1647 번째 loss, accuracy:  0.6328008120980342 0.6916666666666667\n",
      "1648 번째 loss, accuracy:  0.6326807264368647 0.6916666666666667\n",
      "1649 번째 loss, accuracy:  0.6325607592793366 0.6916666666666667\n",
      "1650 번째 loss, accuracy:  0.6324409104915277 0.6916666666666667\n",
      "1651 번째 loss, accuracy:  0.6323211799396452 0.6916666666666667\n",
      "1652 번째 loss, accuracy:  0.6322015674900233 0.6916666666666667\n",
      "1653 번째 loss, accuracy:  0.6320820730091301 0.6916666666666667\n",
      "1654 번째 loss, accuracy:  0.6319626963635608 0.6916666666666667\n",
      "1655 번째 loss, accuracy:  0.6318434374200393 0.6916666666666667\n",
      "1656 번째 loss, accuracy:  0.6317242960454214 0.6916666666666667\n",
      "1657 번째 loss, accuracy:  0.6316052721066918 0.6916666666666667\n",
      "1658 번째 loss, accuracy:  0.631486365470963 0.6916666666666667\n",
      "1659 번째 loss, accuracy:  0.6313675760054807 0.6916666666666667\n",
      "1660 번째 loss, accuracy:  0.6312489035776158 0.6916666666666667\n",
      "1661 번째 loss, accuracy:  0.6311303480548726 0.6916666666666667\n",
      "1662 번째 loss, accuracy:  0.6310119093048839 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663 번째 loss, accuracy:  0.6308935871954114 0.6916666666666667\n",
      "1664 번째 loss, accuracy:  0.6307753815943468 0.6916666666666667\n",
      "1665 번째 loss, accuracy:  0.6306572923697111 0.6916666666666667\n",
      "1666 번째 loss, accuracy:  0.6305393193896568 0.6916666666666667\n",
      "1667 번째 loss, accuracy:  0.6304214625224646 0.6916666666666667\n",
      "1668 번째 loss, accuracy:  0.6303037216365441 0.6916666666666667\n",
      "1669 번째 loss, accuracy:  0.6301860966004358 0.6916666666666667\n",
      "1670 번째 loss, accuracy:  0.6300685872828102 0.6916666666666667\n",
      "1671 번째 loss, accuracy:  0.6299511935524638 0.6916666666666667\n",
      "1672 번째 loss, accuracy:  0.6298339152783282 0.6916666666666667\n",
      "1673 번째 loss, accuracy:  0.6297167523294609 0.6916666666666667\n",
      "1674 번째 loss, accuracy:  0.6295997045750508 0.6916666666666667\n",
      "1675 번째 loss, accuracy:  0.6294827718844148 0.6916666666666667\n",
      "1676 번째 loss, accuracy:  0.629365954127001 0.6916666666666667\n",
      "1677 번째 loss, accuracy:  0.6292492511723863 0.6916666666666667\n",
      "1678 번째 loss, accuracy:  0.6291326628902766 0.6916666666666667\n",
      "1679 번째 loss, accuracy:  0.6290161891505065 0.6916666666666667\n",
      "1680 번째 loss, accuracy:  0.628899829823045 0.6916666666666667\n",
      "1681 번째 loss, accuracy:  0.6287835847779856 0.6916666666666667\n",
      "1682 번째 loss, accuracy:  0.6286674538855515 0.6916666666666667\n",
      "1683 번째 loss, accuracy:  0.6285514370160996 0.6916666666666667\n",
      "1684 번째 loss, accuracy:  0.6284355340401123 0.6916666666666667\n",
      "1685 번째 loss, accuracy:  0.6283197448282029 0.6916666666666667\n",
      "1686 번째 loss, accuracy:  0.6282040692511146 0.6916666666666667\n",
      "1687 번째 loss, accuracy:  0.6280885071797202 0.6916666666666667\n",
      "1688 번째 loss, accuracy:  0.6279730584850206 0.6916666666666667\n",
      "1689 번째 loss, accuracy:  0.6278577230381467 0.6916666666666667\n",
      "1690 번째 loss, accuracy:  0.6277425007103595 0.6916666666666667\n",
      "1691 번째 loss, accuracy:  0.6276273913730475 0.6916666666666667\n",
      "1692 번째 loss, accuracy:  0.6275123948977307 0.6916666666666667\n",
      "1693 번째 loss, accuracy:  0.6273975111560592 0.6916666666666667\n",
      "1694 번째 loss, accuracy:  0.6272827400198101 0.6916666666666667\n",
      "1695 번째 loss, accuracy:  0.6271680813608908 0.6916666666666667\n",
      "1696 번째 loss, accuracy:  0.6270535350513405 0.6916666666666667\n",
      "1697 번째 loss, accuracy:  0.6269391009633221 0.6916666666666667\n",
      "1698 번째 loss, accuracy:  0.6268247789691307 0.6916666666666667\n",
      "1699 번째 loss, accuracy:  0.6267105689411938 0.6916666666666667\n",
      "1700 번째 loss, accuracy:  0.6265964707520634 0.6916666666666667\n",
      "1701 번째 loss, accuracy:  0.6264824842744221 0.6916666666666667\n",
      "1702 번째 loss, accuracy:  0.626368609381084 0.6916666666666667\n",
      "1703 번째 loss, accuracy:  0.62625484594499 0.6916666666666667\n",
      "1704 번째 loss, accuracy:  0.6261411938392105 0.6916666666666667\n",
      "1705 번째 loss, accuracy:  0.6260276529369448 0.6916666666666667\n",
      "1706 번째 loss, accuracy:  0.6259142231115224 0.6916666666666667\n",
      "1707 번째 loss, accuracy:  0.6258009042364001 0.6916666666666667\n",
      "1708 번째 loss, accuracy:  0.6256876961851676 0.6916666666666667\n",
      "1709 번째 loss, accuracy:  0.6255745988315381 0.6916666666666667\n",
      "1710 번째 loss, accuracy:  0.6254616120493596 0.6916666666666667\n",
      "1711 번째 loss, accuracy:  0.6253487357126033 0.6916666666666667\n",
      "1712 번째 loss, accuracy:  0.6252359696953742 0.6916666666666667\n",
      "1713 번째 loss, accuracy:  0.6251233138719043 0.6916666666666667\n",
      "1714 번째 loss, accuracy:  0.6250107681165538 0.6916666666666667\n",
      "1715 번째 loss, accuracy:  0.624898332303813 0.6916666666666667\n",
      "1716 번째 loss, accuracy:  0.6247860063082994 0.6916666666666667\n",
      "1717 번째 loss, accuracy:  0.6246737900047615 0.6916666666666667\n",
      "1718 번째 loss, accuracy:  0.624561683268075 0.6916666666666667\n",
      "1719 번째 loss, accuracy:  0.6244496859732451 0.6916666666666667\n",
      "1720 번째 loss, accuracy:  0.6243377979954057 0.6916666666666667\n",
      "1721 번째 loss, accuracy:  0.624226019209819 0.6916666666666667\n",
      "1722 번째 loss, accuracy:  0.6241143494918752 0.6916666666666667\n",
      "1723 번째 loss, accuracy:  0.6240027887170962 0.6916666666666667\n",
      "1724 번째 loss, accuracy:  0.6238913367611282 0.6916666666666667\n",
      "1725 번째 loss, accuracy:  0.6237799934997486 0.6916666666666667\n",
      "1726 번째 loss, accuracy:  0.6236687588088634 0.6916666666666667\n",
      "1727 번째 loss, accuracy:  0.6235576325645057 0.6916666666666667\n",
      "1728 번째 loss, accuracy:  0.6234466146428385 0.6916666666666667\n",
      "1729 번째 loss, accuracy:  0.6233357049201518 0.6916666666666667\n",
      "1730 번째 loss, accuracy:  0.6232249032728663 0.6916666666666667\n",
      "1731 번째 loss, accuracy:  0.6231142095775293 0.6916666666666667\n",
      "1732 번째 loss, accuracy:  0.6230036237108153 0.6916666666666667\n",
      "1733 번째 loss, accuracy:  0.622893145549529 0.6916666666666667\n",
      "1734 번째 loss, accuracy:  0.6227827749706039 0.6916666666666667\n",
      "1735 번째 loss, accuracy:  0.6226725118510996 0.6916666666666667\n",
      "1736 번째 loss, accuracy:  0.6225623560682055 0.6916666666666667\n",
      "1737 번째 loss, accuracy:  0.6224523074992375 0.6916666666666667\n",
      "1738 번째 loss, accuracy:  0.622342366021642 0.6916666666666667\n",
      "1739 번째 loss, accuracy:  0.6222325315129905 0.6916666666666667\n",
      "1740 번째 loss, accuracy:  0.622122803850985 0.6916666666666667\n",
      "1741 번째 loss, accuracy:  0.6220131829134549 0.6916666666666667\n",
      "1742 번째 loss, accuracy:  0.621903668578356 0.6916666666666667\n",
      "1743 번째 loss, accuracy:  0.6217942607237749 0.6916666666666667\n",
      "1744 번째 loss, accuracy:  0.6216849592279236 0.6916666666666667\n",
      "1745 번째 loss, accuracy:  0.6215757639691435 0.6916666666666667\n",
      "1746 번째 loss, accuracy:  0.6214666748259022 0.6916666666666667\n",
      "1747 번째 loss, accuracy:  0.6213576916767956 0.6916666666666667\n",
      "1748 번째 loss, accuracy:  0.6212488144005474 0.6916666666666667\n",
      "1749 번째 loss, accuracy:  0.6211400428760087 0.6916666666666667\n",
      "1750 번째 loss, accuracy:  0.6210313769821598 0.6916666666666667\n",
      "1751 번째 loss, accuracy:  0.6209228165981066 0.6916666666666667\n",
      "1752 번째 loss, accuracy:  0.6208143616030831 0.6916666666666667\n",
      "1753 번째 loss, accuracy:  0.6207060118764519 0.6916666666666667\n",
      "1754 번째 loss, accuracy:  0.6205977672977004 0.6916666666666667\n",
      "1755 번째 loss, accuracy:  0.620489627746445 0.6916666666666667\n",
      "1756 번째 loss, accuracy:  0.6203815931024307 0.6916666666666667\n",
      "1757 번째 loss, accuracy:  0.6202736632455266 0.6916666666666667\n",
      "1758 번째 loss, accuracy:  0.6201658380557331 0.6916666666666667\n",
      "1759 번째 loss, accuracy:  0.6200581174131744 0.6916666666666667\n",
      "1760 번째 loss, accuracy:  0.6199505011981036 0.6916666666666667\n",
      "1761 번째 loss, accuracy:  0.6198429892909 0.6916666666666667\n",
      "1762 번째 loss, accuracy:  0.6197355815720702 0.6916666666666667\n",
      "1763 번째 loss, accuracy:  0.6196282779222475 0.6916666666666667\n",
      "1764 번째 loss, accuracy:  0.6195210782221926 0.6916666666666667\n",
      "1765 번째 loss, accuracy:  0.6194139823527927 0.6916666666666667\n",
      "1766 번째 loss, accuracy:  0.6193069901950632 0.6916666666666667\n",
      "1767 번째 loss, accuracy:  0.6192001016301447 0.6916666666666667\n",
      "1768 번째 loss, accuracy:  0.6190933165393046 0.6916666666666667\n",
      "1769 번째 loss, accuracy:  0.6189866348039371 0.6916666666666667\n",
      "1770 번째 loss, accuracy:  0.6188800563055651 0.6916666666666667\n",
      "1771 번째 loss, accuracy:  0.6187735809258353 0.6916666666666667\n",
      "1772 번째 loss, accuracy:  0.6186672085465216 0.6916666666666667\n",
      "1773 번째 loss, accuracy:  0.6185609390495247 0.6916666666666667\n",
      "1774 번째 loss, accuracy:  0.618454772316873 0.6916666666666667\n",
      "1775 번째 loss, accuracy:  0.6183487082307185 0.6916666666666667\n",
      "1776 번째 loss, accuracy:  0.6182427466733432 0.6916666666666667\n",
      "1777 번째 loss, accuracy:  0.6181368875271521 0.6916666666666667\n",
      "1778 번째 loss, accuracy:  0.6180311306746777 0.6916666666666667\n",
      "1779 번째 loss, accuracy:  0.6179254759985782 0.6916666666666667\n",
      "1780 번째 loss, accuracy:  0.6178199233816382 0.6916666666666667\n",
      "1781 번째 loss, accuracy:  0.6177144727067688 0.6916666666666667\n",
      "1782 번째 loss, accuracy:  0.6176091238570078 0.6916666666666667\n",
      "1783 번째 loss, accuracy:  0.6175038767155168 0.6916666666666667\n",
      "1784 번째 loss, accuracy:  0.6173987311655833 0.6916666666666667\n",
      "1785 번째 loss, accuracy:  0.6172936870906223 0.6916666666666667\n",
      "1786 번째 loss, accuracy:  0.6171887443741748 0.6916666666666667\n",
      "1787 번째 loss, accuracy:  0.6170839028999053 0.6916666666666667\n",
      "1788 번째 loss, accuracy:  0.6169791625516068 0.6916666666666667\n",
      "1789 번째 loss, accuracy:  0.6168745232131945 0.6916666666666667\n",
      "1790 번째 loss, accuracy:  0.6167699847687114 0.6916666666666667\n",
      "1791 번째 loss, accuracy:  0.6166655471023269 0.6916666666666667\n",
      "1792 번째 loss, accuracy:  0.6165612100983334 0.6916666666666667\n",
      "1793 번째 loss, accuracy:  0.61645697364115 0.6916666666666667\n",
      "1794 번째 loss, accuracy:  0.6163528376153203 0.6916666666666667\n",
      "1795 번째 loss, accuracy:  0.6162488019055142 0.6916666666666667\n",
      "1796 번째 loss, accuracy:  0.616144866396526 0.6916666666666667\n",
      "1797 번째 loss, accuracy:  0.6160410309732751 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1798 번째 loss, accuracy:  0.6159372955208061 0.6916666666666667\n",
      "1799 번째 loss, accuracy:  0.6158336599242895 0.6916666666666667\n",
      "1800 번째 loss, accuracy:  0.6157301240690187 0.6916666666666667\n",
      "1801 번째 loss, accuracy:  0.6156266878404139 0.6916666666666667\n",
      "1802 번째 loss, accuracy:  0.6155233511240203 0.6916666666666667\n",
      "1803 번째 loss, accuracy:  0.6154201138055045 0.6916666666666667\n",
      "1804 번째 loss, accuracy:  0.6153169757706619 0.6916666666666667\n",
      "1805 번째 loss, accuracy:  0.6152139369054108 0.6916666666666667\n",
      "1806 번째 loss, accuracy:  0.6151109970957928 0.6916666666666667\n",
      "1807 번째 loss, accuracy:  0.6150081562279769 0.6916666666666667\n",
      "1808 번째 loss, accuracy:  0.6149054141882537 0.6916666666666667\n",
      "1809 번째 loss, accuracy:  0.6148027708630394 0.6916666666666667\n",
      "1810 번째 loss, accuracy:  0.6147002261388745 0.6916666666666667\n",
      "1811 번째 loss, accuracy:  0.6145977799024233 0.6916666666666667\n",
      "1812 번째 loss, accuracy:  0.6144954320404737 0.6916666666666667\n",
      "1813 번째 loss, accuracy:  0.6143931824399406 0.6916666666666667\n",
      "1814 번째 loss, accuracy:  0.6142910309878594 0.6916666666666667\n",
      "1815 번째 loss, accuracy:  0.6141889775713928 0.6916666666666667\n",
      "1816 번째 loss, accuracy:  0.614087022077823 0.6916666666666667\n",
      "1817 번째 loss, accuracy:  0.6139851643945597 0.6916666666666667\n",
      "1818 번째 loss, accuracy:  0.6138834044091364 0.6916666666666667\n",
      "1819 번째 loss, accuracy:  0.6137817420092079 0.6916666666666667\n",
      "1820 번째 loss, accuracy:  0.613680177082555 0.6916666666666667\n",
      "1821 번째 loss, accuracy:  0.6135787095170795 0.6916666666666667\n",
      "1822 번째 loss, accuracy:  0.6134773392008083 0.6916666666666667\n",
      "1823 번째 loss, accuracy:  0.6133760660218919 0.6916666666666667\n",
      "1824 번째 loss, accuracy:  0.6132748898686039 0.6916666666666667\n",
      "1825 번째 loss, accuracy:  0.6131738106293407 0.6916666666666667\n",
      "1826 번째 loss, accuracy:  0.6130728281926229 0.6916666666666667\n",
      "1827 번째 loss, accuracy:  0.6129719424470921 0.6916666666666667\n",
      "1828 번째 loss, accuracy:  0.612871153281516 0.6916666666666667\n",
      "1829 번째 loss, accuracy:  0.6127704605847832 0.6916666666666667\n",
      "1830 번째 loss, accuracy:  0.6126698642459064 0.6916666666666667\n",
      "1831 번째 loss, accuracy:  0.6125693641540201 0.6916666666666667\n",
      "1832 번째 loss, accuracy:  0.6124689601983815 0.6916666666666667\n",
      "1833 번째 loss, accuracy:  0.6123686522683716 0.6916666666666667\n",
      "1834 번째 loss, accuracy:  0.612268440253493 0.6916666666666667\n",
      "1835 번째 loss, accuracy:  0.6121683240433725 0.6916666666666667\n",
      "1836 번째 loss, accuracy:  0.6120683035277587 0.6916666666666667\n",
      "1837 번째 loss, accuracy:  0.6119683785965199 0.6916666666666667\n",
      "1838 번째 loss, accuracy:  0.6118685491396507 0.6916666666666667\n",
      "1839 번째 loss, accuracy:  0.6117688150472667 0.6916666666666667\n",
      "1840 번째 loss, accuracy:  0.6116691762096046 0.6916666666666667\n",
      "1841 번째 loss, accuracy:  0.6115696325170246 0.6916666666666667\n",
      "1842 번째 loss, accuracy:  0.6114701838600082 0.6916666666666667\n",
      "1843 번째 loss, accuracy:  0.6113708301291586 0.6916666666666667\n",
      "1844 번째 loss, accuracy:  0.6112715712152013 0.6916666666666667\n",
      "1845 번째 loss, accuracy:  0.6111724070089842 0.6916666666666667\n",
      "1846 번째 loss, accuracy:  0.6110733374014771 0.6916666666666667\n",
      "1847 번째 loss, accuracy:  0.6109743622837706 0.6916666666666667\n",
      "1848 번째 loss, accuracy:  0.6108754815470767 0.6916666666666667\n",
      "1849 번째 loss, accuracy:  0.61077669508273 0.6916666666666667\n",
      "1850 번째 loss, accuracy:  0.6106780027821853 0.6916666666666667\n",
      "1851 번째 loss, accuracy:  0.6105794045370205 0.6916666666666667\n",
      "1852 번째 loss, accuracy:  0.6104809002389338 0.6916666666666667\n",
      "1853 번째 loss, accuracy:  0.6103824897797435 0.6916666666666667\n",
      "1854 번째 loss, accuracy:  0.6102841730513917 0.6916666666666667\n",
      "1855 번째 loss, accuracy:  0.6101859499459394 0.6916666666666667\n",
      "1856 번째 loss, accuracy:  0.6100878203555695 0.6916666666666667\n",
      "1857 번째 loss, accuracy:  0.6099897841725841 0.6916666666666667\n",
      "1858 번째 loss, accuracy:  0.6098918412894101 0.6916666666666667\n",
      "1859 번째 loss, accuracy:  0.6097939915985925 0.6916666666666667\n",
      "1860 번째 loss, accuracy:  0.6096962349927956 0.6916666666666667\n",
      "1861 번째 loss, accuracy:  0.6095985713648072 0.6916666666666667\n",
      "1862 번째 loss, accuracy:  0.6095010006075334 0.6916666666666667\n",
      "1863 번째 loss, accuracy:  0.6094035226140041 0.6916666666666667\n",
      "1864 번째 loss, accuracy:  0.6093061372773652 0.6916666666666667\n",
      "1865 번째 loss, accuracy:  0.6092088444908861 0.6916666666666667\n",
      "1866 번째 loss, accuracy:  0.6091116441479552 0.6916666666666667\n",
      "1867 번째 loss, accuracy:  0.6090145361420805 0.6916666666666667\n",
      "1868 번째 loss, accuracy:  0.6089175203668918 0.6916666666666667\n",
      "1869 번째 loss, accuracy:  0.608820596716137 0.6916666666666667\n",
      "1870 번째 loss, accuracy:  0.6087237650836845 0.6916666666666667\n",
      "1871 번째 loss, accuracy:  0.6086270253635242 0.6916666666666667\n",
      "1872 번째 loss, accuracy:  0.6085303774497629 0.6916666666666667\n",
      "1873 번째 loss, accuracy:  0.6084338212366288 0.6916666666666667\n",
      "1874 번째 loss, accuracy:  0.6083373566184699 0.6916666666666667\n",
      "1875 번째 loss, accuracy:  0.6082409834897529 0.6916666666666667\n",
      "1876 번째 loss, accuracy:  0.6081447017450632 0.6916666666666667\n",
      "1877 번째 loss, accuracy:  0.6080485112791079 0.6916666666666667\n",
      "1878 번째 loss, accuracy:  0.6079524119867112 0.6916666666666667\n",
      "1879 번째 loss, accuracy:  0.6078564037628177 0.6916666666666667\n",
      "1880 번째 loss, accuracy:  0.6077604865024914 0.6916666666666667\n",
      "1881 번째 loss, accuracy:  0.6076646601009136 0.6916666666666667\n",
      "1882 번째 loss, accuracy:  0.6075689244533847 0.6916666666666667\n",
      "1883 번째 loss, accuracy:  0.6074732794553266 0.6916666666666667\n",
      "1884 번째 loss, accuracy:  0.6073777250022775 0.6916666666666667\n",
      "1885 번째 loss, accuracy:  0.6072822609898947 0.6916666666666667\n",
      "1886 번째 loss, accuracy:  0.6071868873139532 0.6916666666666667\n",
      "1887 번째 loss, accuracy:  0.6070916038703492 0.6916666666666667\n",
      "1888 번째 loss, accuracy:  0.6069964105550947 0.6916666666666667\n",
      "1889 번째 loss, accuracy:  0.6069013072643218 0.6916666666666667\n",
      "1890 번째 loss, accuracy:  0.6068062938942803 0.6916666666666667\n",
      "1891 번째 loss, accuracy:  0.6067113703413384 0.6916666666666667\n",
      "1892 번째 loss, accuracy:  0.6066165365019813 0.6916666666666667\n",
      "1893 번째 loss, accuracy:  0.6065217922728122 0.6916666666666667\n",
      "1894 번째 loss, accuracy:  0.6064271375505543 0.6916666666666667\n",
      "1895 번째 loss, accuracy:  0.6063325722320478 0.6916666666666667\n",
      "1896 번째 loss, accuracy:  0.6062380962142483 0.6916666666666667\n",
      "1897 번째 loss, accuracy:  0.6061437093942323 0.6916666666666667\n",
      "1898 번째 loss, accuracy:  0.606049411669192 0.6916666666666667\n",
      "1899 번째 loss, accuracy:  0.6059552029364386 0.6916666666666667\n",
      "1900 번째 loss, accuracy:  0.6058610830933991 0.6916666666666667\n",
      "1901 번째 loss, accuracy:  0.6057670520376182 0.6916666666666667\n",
      "1902 번째 loss, accuracy:  0.6056731096667585 0.6916666666666667\n",
      "1903 번째 loss, accuracy:  0.6055792558785996 0.6916666666666667\n",
      "1904 번째 loss, accuracy:  0.6054854905710371 0.6916666666666667\n",
      "1905 번째 loss, accuracy:  0.6053918136420847 0.6916666666666667\n",
      "1906 번째 loss, accuracy:  0.605298224989874 0.6916666666666667\n",
      "1907 번째 loss, accuracy:  0.605204724512651 0.6916666666666667\n",
      "1908 번째 loss, accuracy:  0.6051113121087809 0.6916666666666667\n",
      "1909 번째 loss, accuracy:  0.6050179876767421 0.6916666666666667\n",
      "1910 번째 loss, accuracy:  0.6049247511151327 0.6916666666666667\n",
      "1911 번째 loss, accuracy:  0.6048316023226666 0.6916666666666667\n",
      "1912 번째 loss, accuracy:  0.6047385411981732 0.6916666666666667\n",
      "1913 번째 loss, accuracy:  0.6046455676405984 0.6916666666666667\n",
      "1914 번째 loss, accuracy:  0.6045526815490063 0.6916666666666667\n",
      "1915 번째 loss, accuracy:  0.6044598828225743 0.6916666666666667\n",
      "1916 번째 loss, accuracy:  0.6043671713605961 0.6916666666666667\n",
      "1917 번째 loss, accuracy:  0.6042745470624833 0.6916666666666667\n",
      "1918 번째 loss, accuracy:  0.604182009827762 0.6916666666666667\n",
      "1919 번째 loss, accuracy:  0.6040895595560741 0.6916666666666667\n",
      "1920 번째 loss, accuracy:  0.6039971961471777 0.6916666666666667\n",
      "1921 번째 loss, accuracy:  0.6039049195009459 0.6916666666666667\n",
      "1922 번째 loss, accuracy:  0.6038127295173673 0.6916666666666667\n",
      "1923 번째 loss, accuracy:  0.6037206260965469 0.6916666666666667\n",
      "1924 번째 loss, accuracy:  0.6036286091387023 0.6916666666666667\n",
      "1925 번째 loss, accuracy:  0.6035366785441703 0.6916666666666667\n",
      "1926 번째 loss, accuracy:  0.6034448342134 0.6916666666666667\n",
      "1927 번째 loss, accuracy:  0.6033530760469564 0.6916666666666667\n",
      "1928 번째 loss, accuracy:  0.6032614039455197 0.6916666666666667\n",
      "1929 번째 loss, accuracy:  0.6031698178098835 0.6916666666666667\n",
      "1930 번째 loss, accuracy:  0.6030783175409591 0.6916666666666667\n",
      "1931 번째 loss, accuracy:  0.6029869030397695 0.6916666666666667\n",
      "1932 번째 loss, accuracy:  0.6028955742074541 0.6916666666666667\n",
      "1933 번째 loss, accuracy:  0.6028043309452649 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1934 번째 loss, accuracy:  0.6027131731545708 0.6916666666666667\n",
      "1935 번째 loss, accuracy:  0.6026221007368525 0.6916666666666667\n",
      "1936 번째 loss, accuracy:  0.6025311135937078 0.6916666666666667\n",
      "1937 번째 loss, accuracy:  0.6024402116268468 0.6916666666666667\n",
      "1938 번째 loss, accuracy:  0.6023493947380939 0.6916666666666667\n",
      "1939 번째 loss, accuracy:  0.6022586628293872 0.6916666666666667\n",
      "1940 번째 loss, accuracy:  0.6021680158027791 0.6916666666666667\n",
      "1941 번째 loss, accuracy:  0.6020774535604353 0.6916666666666667\n",
      "1942 번째 loss, accuracy:  0.6019869760046356 0.6916666666666667\n",
      "1943 번째 loss, accuracy:  0.601896583037773 0.6916666666666667\n",
      "1944 번째 loss, accuracy:  0.6018062745623548 0.6916666666666667\n",
      "1945 번째 loss, accuracy:  0.6017160504810015 0.6916666666666667\n",
      "1946 번째 loss, accuracy:  0.6016259106964452 0.6916666666666667\n",
      "1947 번째 loss, accuracy:  0.6015358551115332 0.6916666666666667\n",
      "1948 번째 loss, accuracy:  0.6014458836292268 0.6916666666666667\n",
      "1949 번째 loss, accuracy:  0.601355996152597 0.6916666666666667\n",
      "1950 번째 loss, accuracy:  0.6012661925848313 0.6916666666666667\n",
      "1951 번째 loss, accuracy:  0.6011764728292266 0.6916666666666667\n",
      "1952 번째 loss, accuracy:  0.6010868367891943 0.6916666666666667\n",
      "1953 번째 loss, accuracy:  0.6009972843682602 0.6916666666666667\n",
      "1954 번째 loss, accuracy:  0.6009078154700597 0.6916666666666667\n",
      "1955 번째 loss, accuracy:  0.6008184299983425 0.6916666666666667\n",
      "1956 번째 loss, accuracy:  0.600729127856969 0.6916666666666667\n",
      "1957 번째 loss, accuracy:  0.6006399089499138 0.6916666666666667\n",
      "1958 번째 loss, accuracy:  0.600550773181262 0.6916666666666667\n",
      "1959 번째 loss, accuracy:  0.6004617204552128 0.6916666666666667\n",
      "1960 번째 loss, accuracy:  0.6003727506760765 0.6916666666666667\n",
      "1961 번째 loss, accuracy:  0.6002838637482745 0.6916666666666667\n",
      "1962 번째 loss, accuracy:  0.6001950595763399 0.6916666666666667\n",
      "1963 번째 loss, accuracy:  0.6001063380649195 0.6916666666666667\n",
      "1964 번째 loss, accuracy:  0.6000176991187693 0.6916666666666667\n",
      "1965 번째 loss, accuracy:  0.5999291426427588 0.6916666666666667\n",
      "1966 번째 loss, accuracy:  0.599840668541868 0.6916666666666667\n",
      "1967 번째 loss, accuracy:  0.5997522767211884 0.6916666666666667\n",
      "1968 번째 loss, accuracy:  0.5996639670859217 0.6916666666666667\n",
      "1969 번째 loss, accuracy:  0.5995757395413839 0.6916666666666667\n",
      "1970 번째 loss, accuracy:  0.5994875939929992 0.6916666666666667\n",
      "1971 번째 loss, accuracy:  0.5993995303463017 0.6916666666666667\n",
      "1972 번째 loss, accuracy:  0.5993115485069402 0.6916666666666667\n",
      "1973 번째 loss, accuracy:  0.5992236483806721 0.6916666666666667\n",
      "1974 번째 loss, accuracy:  0.5991358298733639 0.6916666666666667\n",
      "1975 번째 loss, accuracy:  0.5990480928909968 0.6916666666666667\n",
      "1976 번째 loss, accuracy:  0.5989604373396592 0.6916666666666667\n",
      "1977 번째 loss, accuracy:  0.59887286312555 0.6916666666666667\n",
      "1978 번째 loss, accuracy:  0.5987853701549805 0.6916666666666667\n",
      "1979 번째 loss, accuracy:  0.5986979583343697 0.6916666666666667\n",
      "1980 번째 loss, accuracy:  0.5986106275702483 0.6916666666666667\n",
      "1981 번째 loss, accuracy:  0.5985233777692575 0.6916666666666667\n",
      "1982 번째 loss, accuracy:  0.5984362088381466 0.6916666666666667\n",
      "1983 번째 loss, accuracy:  0.598349120683776 0.6916666666666667\n",
      "1984 번째 loss, accuracy:  0.5982621132131152 0.6916666666666667\n",
      "1985 번째 loss, accuracy:  0.5981751863332444 0.6916666666666667\n",
      "1986 번째 loss, accuracy:  0.5980883399513516 0.6916666666666667\n",
      "1987 번째 loss, accuracy:  0.5980015739747359 0.6916666666666667\n",
      "1988 번째 loss, accuracy:  0.5979148883108045 0.6916666666666667\n",
      "1989 번째 loss, accuracy:  0.5978282828670755 0.6916666666666667\n",
      "1990 번째 loss, accuracy:  0.5977417575511744 0.6916666666666667\n",
      "1991 번째 loss, accuracy:  0.5976553122708365 0.6916666666666667\n",
      "1992 번째 loss, accuracy:  0.5975689469339055 0.6916666666666667\n",
      "1993 번째 loss, accuracy:  0.5974826614483344 0.6916666666666667\n",
      "1994 번째 loss, accuracy:  0.5973964557221852 0.6916666666666667\n",
      "1995 번째 loss, accuracy:  0.5973103296636284 0.6916666666666667\n",
      "1996 번째 loss, accuracy:  0.5972242831809425 0.6916666666666667\n",
      "1997 번째 loss, accuracy:  0.5971383161825154 0.6916666666666667\n",
      "1998 번째 loss, accuracy:  0.5970524285768429 0.6916666666666667\n",
      "1999 번째 loss, accuracy:  0.5969666202725288 0.6916666666666667\n",
      "2000 번째 loss, accuracy:  0.5968808911782852 0.6916666666666667\n",
      "2001 번째 loss, accuracy:  0.5967952412029329 0.6916666666666667\n",
      "2002 번째 loss, accuracy:  0.5967096702554003 0.6916666666666667\n",
      "2003 번째 loss, accuracy:  0.5966241782447234 0.6916666666666667\n",
      "2004 번째 loss, accuracy:  0.5965387650800451 0.6916666666666667\n",
      "2005 번째 loss, accuracy:  0.5964534306706192 0.6916666666666667\n",
      "2006 번째 loss, accuracy:  0.5963681749258035 0.6916666666666667\n",
      "2007 번째 loss, accuracy:  0.596282997755065 0.6916666666666667\n",
      "2008 번째 loss, accuracy:  0.5961978990679777 0.6916666666666667\n",
      "2009 번째 loss, accuracy:  0.5961128787742235 0.6916666666666667\n",
      "2010 번째 loss, accuracy:  0.5960279367835902 0.6916666666666667\n",
      "2011 번째 loss, accuracy:  0.5959430730059749 0.6916666666666667\n",
      "2012 번째 loss, accuracy:  0.5958582873513795 0.6916666666666667\n",
      "2013 번째 loss, accuracy:  0.595773579729914 0.6916666666666667\n",
      "2014 번째 loss, accuracy:  0.5956889500517947 0.6916666666666667\n",
      "2015 번째 loss, accuracy:  0.5956043982273445 0.6916666666666667\n",
      "2016 번째 loss, accuracy:  0.5955199241669931 0.6916666666666667\n",
      "2017 번째 loss, accuracy:  0.5954355277812773 0.6916666666666667\n",
      "2018 번째 loss, accuracy:  0.5953512089808404 0.6916666666666667\n",
      "2019 번째 loss, accuracy:  0.5952669676764294 0.6916666666666667\n",
      "2020 번째 loss, accuracy:  0.5951828037789009 0.6916666666666667\n",
      "2021 번째 loss, accuracy:  0.595098717199216 0.6916666666666667\n",
      "2022 번째 loss, accuracy:  0.5950147078484425 0.6916666666666667\n",
      "2023 번째 loss, accuracy:  0.5949307756377527 0.6916666666666667\n",
      "2024 번째 loss, accuracy:  0.5948469204784262 0.6916666666666667\n",
      "2025 번째 loss, accuracy:  0.5947631422818488 0.6916666666666667\n",
      "2026 번째 loss, accuracy:  0.5946794409595088 0.6916666666666667\n",
      "2027 번째 loss, accuracy:  0.5945958164230032 0.6916666666666667\n",
      "2028 번째 loss, accuracy:  0.5945122685840342 0.6916666666666667\n",
      "2029 번째 loss, accuracy:  0.5944287973544079 0.6916666666666667\n",
      "2030 번째 loss, accuracy:  0.5943454026460359 0.6916666666666667\n",
      "2031 번째 loss, accuracy:  0.5942620843709367 0.6916666666666667\n",
      "2032 번째 loss, accuracy:  0.5941788424412306 0.6916666666666667\n",
      "2033 번째 loss, accuracy:  0.5940956767691455 0.6916666666666667\n",
      "2034 번째 loss, accuracy:  0.5940125872670124 0.6916666666666667\n",
      "2035 번째 loss, accuracy:  0.593929573847269 0.6916666666666667\n",
      "2036 번째 loss, accuracy:  0.5938466364224557 0.6916666666666667\n",
      "2037 번째 loss, accuracy:  0.5937637749052197 0.6916666666666667\n",
      "2038 번째 loss, accuracy:  0.5936809892083095 0.6916666666666667\n",
      "2039 번째 loss, accuracy:  0.5935982792445801 0.6916666666666667\n",
      "2040 번째 loss, accuracy:  0.5935156449269899 0.6916666666666667\n",
      "2041 번째 loss, accuracy:  0.593433086168602 0.6916666666666667\n",
      "2042 번째 loss, accuracy:  0.5933506028825837 0.6916666666666667\n",
      "2043 번째 loss, accuracy:  0.5932681949822054 0.6916666666666667\n",
      "2044 번째 loss, accuracy:  0.5931858623808428 0.6916666666666667\n",
      "2045 번째 loss, accuracy:  0.5931036049919732 0.6916666666666667\n",
      "2046 번째 loss, accuracy:  0.5930214227291787 0.6916666666666667\n",
      "2047 번째 loss, accuracy:  0.5929393155061452 0.6916666666666667\n",
      "2048 번째 loss, accuracy:  0.5928572832366623 0.6916666666666667\n",
      "2049 번째 loss, accuracy:  0.5927753258346212 0.6916666666666667\n",
      "2050 번째 loss, accuracy:  0.5926934432140182 0.6916666666666667\n",
      "2051 번째 loss, accuracy:  0.5926116352889517 0.6916666666666667\n",
      "2052 번째 loss, accuracy:  0.5925299019736239 0.6916666666666667\n",
      "2053 번째 loss, accuracy:  0.592448243182339 0.6916666666666667\n",
      "2054 번째 loss, accuracy:  0.5923666588295051 0.6916666666666667\n",
      "2055 번째 loss, accuracy:  0.5922851488296316 0.6916666666666667\n",
      "2056 번째 loss, accuracy:  0.5922037130973323 0.6916666666666667\n",
      "2057 번째 loss, accuracy:  0.592122351547323 0.6916666666666667\n",
      "2058 번째 loss, accuracy:  0.5920410640944201 0.6916666666666667\n",
      "2059 번째 loss, accuracy:  0.5919598506535436 0.6916666666666667\n",
      "2060 번째 loss, accuracy:  0.591878711139717 0.6916666666666667\n",
      "2061 번째 loss, accuracy:  0.5917976454680646 0.6916666666666667\n",
      "2062 번째 loss, accuracy:  0.5917166535538139 0.6916666666666667\n",
      "2063 번째 loss, accuracy:  0.5916357353122924 0.6916666666666667\n",
      "2064 번째 loss, accuracy:  0.5915548906589304 0.6916666666666667\n",
      "2065 번째 loss, accuracy:  0.5914741195092612 0.6916666666666667\n",
      "2066 번째 loss, accuracy:  0.591393421778917 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2067 번째 loss, accuracy:  0.5913127973836324 0.6916666666666667\n",
      "2068 번째 loss, accuracy:  0.5912322462392455 0.6916666666666667\n",
      "2069 번째 loss, accuracy:  0.5911517682616958 0.6916666666666667\n",
      "2070 번째 loss, accuracy:  0.5910713633670213 0.6916666666666667\n",
      "2071 번째 loss, accuracy:  0.5909910314713617 0.6916666666666667\n",
      "2072 번째 loss, accuracy:  0.5909107724909591 0.6916666666666667\n",
      "2073 번째 loss, accuracy:  0.5908305863421546 0.6916666666666667\n",
      "2074 번째 loss, accuracy:  0.5907504729413928 0.6916666666666667\n",
      "2075 번째 loss, accuracy:  0.590670432205219 0.6916666666666667\n",
      "2076 번째 loss, accuracy:  0.5905904640502749 0.6916666666666667\n",
      "2077 번째 loss, accuracy:  0.590510568393308 0.6916666666666667\n",
      "2078 번째 loss, accuracy:  0.5904307451511616 0.6916666666666667\n",
      "2079 번째 loss, accuracy:  0.5903509942407824 0.6916666666666667\n",
      "2080 번째 loss, accuracy:  0.5902713155792161 0.6916666666666667\n",
      "2081 번째 loss, accuracy:  0.5901917090836105 0.6916666666666667\n",
      "2082 번째 loss, accuracy:  0.59011217467121 0.6916666666666667\n",
      "2083 번째 loss, accuracy:  0.5900327122593618 0.6916666666666667\n",
      "2084 번째 loss, accuracy:  0.5899533217655112 0.6916666666666667\n",
      "2085 번째 loss, accuracy:  0.5898740031072044 0.6916666666666667\n",
      "2086 번째 loss, accuracy:  0.5897947562020864 0.6916666666666667\n",
      "2087 번째 loss, accuracy:  0.5897155809679018 0.6916666666666667\n",
      "2088 번째 loss, accuracy:  0.5896364773224946 0.6916666666666667\n",
      "2089 번째 loss, accuracy:  0.5895574451838089 0.6916666666666667\n",
      "2090 번째 loss, accuracy:  0.5894784844698889 0.6916666666666667\n",
      "2091 번째 loss, accuracy:  0.5893995950988746 0.6916666666666667\n",
      "2092 번째 loss, accuracy:  0.5893207769890078 0.6916666666666667\n",
      "2093 번째 loss, accuracy:  0.5892420300586274 0.6916666666666667\n",
      "2094 번째 loss, accuracy:  0.5891633542261736 0.6916666666666667\n",
      "2095 번째 loss, accuracy:  0.5890847494101821 0.6916666666666667\n",
      "2096 번째 loss, accuracy:  0.5890062155292894 0.6916666666666667\n",
      "2097 번째 loss, accuracy:  0.5889277525022296 0.6916666666666667\n",
      "2098 번째 loss, accuracy:  0.588849360247837 0.6916666666666667\n",
      "2099 번째 loss, accuracy:  0.5887710386850415 0.6916666666666667\n",
      "2100 번째 loss, accuracy:  0.5886927877328738 0.6916666666666667\n",
      "2101 번째 loss, accuracy:  0.5886146073104602 0.6916666666666667\n",
      "2102 번째 loss, accuracy:  0.5885364973370273 0.6916666666666667\n",
      "2103 번째 loss, accuracy:  0.5884584577318982 0.6916666666666667\n",
      "2104 번째 loss, accuracy:  0.5883804884144934 0.6916666666666667\n",
      "2105 번째 loss, accuracy:  0.5883025893043329 0.6916666666666667\n",
      "2106 번째 loss, accuracy:  0.5882247603210339 0.6916666666666667\n",
      "2107 번째 loss, accuracy:  0.5881470013843085 0.6916666666666667\n",
      "2108 번째 loss, accuracy:  0.5880693124139699 0.6916666666666667\n",
      "2109 번째 loss, accuracy:  0.5879916933299263 0.6916666666666667\n",
      "2110 번째 loss, accuracy:  0.5879141440521839 0.6916666666666667\n",
      "2111 번째 loss, accuracy:  0.5878366645008458 0.6916666666666667\n",
      "2112 번째 loss, accuracy:  0.5877592545961118 0.6916666666666667\n",
      "2113 번째 loss, accuracy:  0.5876819142582789 0.6916666666666667\n",
      "2114 번째 loss, accuracy:  0.587604643407741 0.6916666666666667\n",
      "2115 번째 loss, accuracy:  0.5875274419649884 0.6916666666666667\n",
      "2116 번째 loss, accuracy:  0.587450309850609 0.6916666666666667\n",
      "2117 번째 loss, accuracy:  0.5873732469852866 0.6916666666666667\n",
      "2118 번째 loss, accuracy:  0.5872962532898003 0.6916666666666667\n",
      "2119 번째 loss, accuracy:  0.5872193286850267 0.6916666666666667\n",
      "2120 번째 loss, accuracy:  0.5871424730919391 0.6916666666666667\n",
      "2121 번째 loss, accuracy:  0.5870656864316052 0.6916666666666667\n",
      "2122 번째 loss, accuracy:  0.5869889686251898 0.6916666666666667\n",
      "2123 번째 loss, accuracy:  0.5869123195939532 0.6916666666666667\n",
      "2124 번째 loss, accuracy:  0.5868357392592526 0.6916666666666667\n",
      "2125 번째 loss, accuracy:  0.5867592275425383 0.6916666666666667\n",
      "2126 번째 loss, accuracy:  0.5866827843653591 0.6916666666666667\n",
      "2127 번째 loss, accuracy:  0.5866064096493576 0.6916666666666667\n",
      "2128 번째 loss, accuracy:  0.5865301033162728 0.6916666666666667\n",
      "2129 번째 loss, accuracy:  0.5864538652879382 0.6916666666666667\n",
      "2130 번째 loss, accuracy:  0.586377695486284 0.6916666666666667\n",
      "2131 번째 loss, accuracy:  0.5863015938333331 0.6916666666666667\n",
      "2132 번째 loss, accuracy:  0.5862255602512039 0.6916666666666667\n",
      "2133 번째 loss, accuracy:  0.5861495946621111 0.6916666666666667\n",
      "2134 번째 loss, accuracy:  0.5860736969883631 0.6916666666666667\n",
      "2135 번째 loss, accuracy:  0.5859978671523628 0.6916666666666667\n",
      "2136 번째 loss, accuracy:  0.5859221050766085 0.6916666666666667\n",
      "2137 번째 loss, accuracy:  0.5858464106836936 0.6916666666666667\n",
      "2138 번째 loss, accuracy:  0.5857707838963034 0.6916666666666667\n",
      "2139 번째 loss, accuracy:  0.5856952246372215 0.6916666666666667\n",
      "2140 번째 loss, accuracy:  0.5856197328293199 0.6916666666666667\n",
      "2141 번째 loss, accuracy:  0.5855443083955701 0.6916666666666667\n",
      "2142 번째 loss, accuracy:  0.5854689512590345 0.6916666666666667\n",
      "2143 번째 loss, accuracy:  0.5853936613428707 0.6916666666666667\n",
      "2144 번째 loss, accuracy:  0.5853184385703315 0.6916666666666667\n",
      "2145 번째 loss, accuracy:  0.5852432828647596 0.6916666666666667\n",
      "2146 번째 loss, accuracy:  0.5851681941495931 0.6916666666666667\n",
      "2147 번째 loss, accuracy:  0.5850931723483644 0.6916666666666667\n",
      "2148 번째 loss, accuracy:  0.585018217384699 0.6916666666666667\n",
      "2149 번째 loss, accuracy:  0.5849433291823148 0.6916666666666667\n",
      "2150 번째 loss, accuracy:  0.5848685076650244 0.6916666666666667\n",
      "2151 번째 loss, accuracy:  0.5847937527567315 0.6916666666666667\n",
      "2152 번째 loss, accuracy:  0.5847190643814338 0.6916666666666667\n",
      "2153 번째 loss, accuracy:  0.584644442463222 0.6916666666666667\n",
      "2154 번째 loss, accuracy:  0.5845698869262795 0.6916666666666667\n",
      "2155 번째 loss, accuracy:  0.5844953976948827 0.6916666666666667\n",
      "2156 번째 loss, accuracy:  0.5844209746934006 0.6916666666666667\n",
      "2157 번째 loss, accuracy:  0.5843466178462923 0.6916666666666667\n",
      "2158 번째 loss, accuracy:  0.5842723270781133 0.6916666666666667\n",
      "2159 번째 loss, accuracy:  0.5841981023135081 0.6916666666666667\n",
      "2160 번째 loss, accuracy:  0.5841239434772137 0.6916666666666667\n",
      "2161 번째 loss, accuracy:  0.5840498504940626 0.6916666666666667\n",
      "2162 번째 loss, accuracy:  0.5839758232889755 0.6916666666666667\n",
      "2163 번째 loss, accuracy:  0.5839018617869658 0.6916666666666667\n",
      "2164 번째 loss, accuracy:  0.5838279659131399 0.6916666666666667\n",
      "2165 번째 loss, accuracy:  0.5837541355926948 0.6916666666666667\n",
      "2166 번째 loss, accuracy:  0.5836803707509193 0.6916666666666667\n",
      "2167 번째 loss, accuracy:  0.5836066713131937 0.6916666666666667\n",
      "2168 번째 loss, accuracy:  0.5835330372049903 0.6916666666666667\n",
      "2169 번째 loss, accuracy:  0.5834594683518717 0.6916666666666667\n",
      "2170 번째 loss, accuracy:  0.5833859646794923 0.6916666666666667\n",
      "2171 번째 loss, accuracy:  0.5833125261135971 0.6916666666666667\n",
      "2172 번째 loss, accuracy:  0.5832391525800221 0.6916666666666667\n",
      "2173 번째 loss, accuracy:  0.583165844004694 0.6916666666666667\n",
      "2174 번째 loss, accuracy:  0.5830926003136315 0.6916666666666667\n",
      "2175 번째 loss, accuracy:  0.5830194214329426 0.6916666666666667\n",
      "2176 번째 loss, accuracy:  0.5829463072888283 0.6916666666666667\n",
      "2177 번째 loss, accuracy:  0.582873257807576 0.6916666666666667\n",
      "2178 번째 loss, accuracy:  0.5828002729155669 0.6916666666666667\n",
      "2179 번째 loss, accuracy:  0.5827273525392707 0.6916666666666667\n",
      "2180 번째 loss, accuracy:  0.5826544966052476 0.6916666666666667\n",
      "2181 번째 loss, accuracy:  0.5825817050401493 0.6916666666666667\n",
      "2182 번째 loss, accuracy:  0.5825089777707148 0.6916666666666667\n",
      "2183 번째 loss, accuracy:  0.5824363147237759 0.6916666666666667\n",
      "2184 번째 loss, accuracy:  0.5823637158262528 0.6916666666666667\n",
      "2185 번째 loss, accuracy:  0.582291181005155 0.6916666666666667\n",
      "2186 번째 loss, accuracy:  0.5822187101875812 0.6916666666666667\n",
      "2187 번째 loss, accuracy:  0.582146303300721 0.6916666666666667\n",
      "2188 번째 loss, accuracy:  0.582073960271854 0.6916666666666667\n",
      "2189 번째 loss, accuracy:  0.5820016810283454 0.6916666666666667\n",
      "2190 번째 loss, accuracy:  0.5819294654976533 0.6916666666666667\n",
      "2191 번째 loss, accuracy:  0.5818573136073238 0.6916666666666667\n",
      "2192 번째 loss, accuracy:  0.5817852252849912 0.6916666666666667\n",
      "2193 번째 loss, accuracy:  0.5817132004583798 0.6916666666666667\n",
      "2194 번째 loss, accuracy:  0.581641239055302 0.6916666666666667\n",
      "2195 번째 loss, accuracy:  0.5815693410036591 0.6916666666666667\n",
      "2196 번째 loss, accuracy:  0.5814975062314416 0.6916666666666667\n",
      "2197 번째 loss, accuracy:  0.5814257346667268 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2198 번째 loss, accuracy:  0.5813540262376818 0.6916666666666667\n",
      "2199 번째 loss, accuracy:  0.5812823808725618 0.6916666666666667\n",
      "2200 번째 loss, accuracy:  0.5812107984997098 0.6916666666666667\n",
      "2201 번째 loss, accuracy:  0.581139279047557 0.6916666666666667\n",
      "2202 번째 loss, accuracy:  0.5810678224446235 0.6916666666666667\n",
      "2203 번째 loss, accuracy:  0.5809964286195161 0.6916666666666667\n",
      "2204 번째 loss, accuracy:  0.580925097500929 0.6916666666666667\n",
      "2205 번째 loss, accuracy:  0.5808538290176471 0.6916666666666667\n",
      "2206 번째 loss, accuracy:  0.5807826230985385 0.6916666666666667\n",
      "2207 번째 loss, accuracy:  0.5807114796725621 0.6916666666666667\n",
      "2208 번째 loss, accuracy:  0.5806403986687628 0.6916666666666667\n",
      "2209 번째 loss, accuracy:  0.5805693800162729 0.6916666666666667\n",
      "2210 번째 loss, accuracy:  0.5804984236443129 0.6916666666666667\n",
      "2211 번째 loss, accuracy:  0.5804275294821899 0.6916666666666667\n",
      "2212 번째 loss, accuracy:  0.5803566974592979 0.6916666666666667\n",
      "2213 번째 loss, accuracy:  0.580285927505117 0.6916666666666667\n",
      "2214 번째 loss, accuracy:  0.5802152195492148 0.6916666666666667\n",
      "2215 번째 loss, accuracy:  0.5801445735212466 0.6916666666666667\n",
      "2216 번째 loss, accuracy:  0.5800739893509527 0.6916666666666667\n",
      "2217 번째 loss, accuracy:  0.5800034669681596 0.6916666666666667\n",
      "2218 번째 loss, accuracy:  0.5799330063027839 0.6916666666666667\n",
      "2219 번째 loss, accuracy:  0.5798626072848234 0.6916666666666667\n",
      "2220 번째 loss, accuracy:  0.5797922698443656 0.6916666666666667\n",
      "2221 번째 loss, accuracy:  0.579721993911583 0.6916666666666667\n",
      "2222 번째 loss, accuracy:  0.5796517794167352 0.6916666666666667\n",
      "2223 번째 loss, accuracy:  0.5795816262901666 0.6916666666666667\n",
      "2224 번째 loss, accuracy:  0.5795115344623062 0.6916666666666667\n",
      "2225 번째 loss, accuracy:  0.5794415038636717 0.6916666666666667\n",
      "2226 번째 loss, accuracy:  0.5793715344248637 0.6916666666666667\n",
      "2227 번째 loss, accuracy:  0.57930162607657 0.6916666666666667\n",
      "2228 번째 loss, accuracy:  0.5792317787495633 0.6916666666666667\n",
      "2229 번째 loss, accuracy:  0.5791619923747023 0.6916666666666667\n",
      "2230 번째 loss, accuracy:  0.57909226688293 0.6916666666666667\n",
      "2231 번째 loss, accuracy:  0.5790226022052759 0.6916666666666667\n",
      "2232 번째 loss, accuracy:  0.5789529982728523 0.6916666666666667\n",
      "2233 번째 loss, accuracy:  0.5788834550168586 0.6916666666666667\n",
      "2234 번째 loss, accuracy:  0.5788139723685773 0.6916666666666667\n",
      "2235 번째 loss, accuracy:  0.5787445502593777 0.6916666666666667\n",
      "2236 번째 loss, accuracy:  0.5786751886207127 0.6916666666666667\n",
      "2237 번째 loss, accuracy:  0.578605887384119 0.6916666666666667\n",
      "2238 번째 loss, accuracy:  0.5785366464812189 0.6916666666666667\n",
      "2239 번째 loss, accuracy:  0.578467465843719 0.6916666666666667\n",
      "2240 번째 loss, accuracy:  0.5783983454034095 0.6916666666666667\n",
      "2241 번째 loss, accuracy:  0.5783292850921655 0.6916666666666667\n",
      "2242 번째 loss, accuracy:  0.5782602848419446 0.6916666666666667\n",
      "2243 번째 loss, accuracy:  0.5781913445847909 0.6916666666666667\n",
      "2244 번째 loss, accuracy:  0.5781224642528316 0.6916666666666667\n",
      "2245 번째 loss, accuracy:  0.5780536437782772 0.6916666666666667\n",
      "2246 번째 loss, accuracy:  0.5779848830934203 0.6916666666666667\n",
      "2247 번째 loss, accuracy:  0.5779161821306401 0.6916666666666667\n",
      "2248 번째 loss, accuracy:  0.5778475408223981 0.6916666666666667\n",
      "2249 번째 loss, accuracy:  0.5777789591012376 0.6916666666666667\n",
      "2250 번째 loss, accuracy:  0.5777104368997876 0.6916666666666667\n",
      "2251 번째 loss, accuracy:  0.57764197415076 0.6916666666666667\n",
      "2252 번째 loss, accuracy:  0.577573570786948 0.6916666666666667\n",
      "2253 번째 loss, accuracy:  0.5775052267412302 0.6916666666666667\n",
      "2254 번째 loss, accuracy:  0.5774369419465664 0.6916666666666667\n",
      "2255 번째 loss, accuracy:  0.5773687163360002 0.6916666666666667\n",
      "2256 번째 loss, accuracy:  0.5773005498426561 0.6916666666666667\n",
      "2257 번째 loss, accuracy:  0.5772324423997433 0.6916666666666667\n",
      "2258 번째 loss, accuracy:  0.5771643939405539 0.6916666666666667\n",
      "2259 번째 loss, accuracy:  0.5770964043984611 0.6916666666666667\n",
      "2260 번째 loss, accuracy:  0.5770284737069197 0.6916666666666667\n",
      "2261 번째 loss, accuracy:  0.5769606017994687 0.6916666666666667\n",
      "2262 번째 loss, accuracy:  0.5768927886097281 0.6916666666666667\n",
      "2263 번째 loss, accuracy:  0.5768250340714016 0.6916666666666667\n",
      "2264 번째 loss, accuracy:  0.5767573381182716 0.6916666666666667\n",
      "2265 번째 loss, accuracy:  0.5766897006842053 0.6916666666666667\n",
      "2266 번째 loss, accuracy:  0.5766221217031501 0.6916666666666667\n",
      "2267 번째 loss, accuracy:  0.5765546011091361 0.6916666666666667\n",
      "2268 번째 loss, accuracy:  0.5764871388362752 0.6916666666666667\n",
      "2269 번째 loss, accuracy:  0.5764197348187587 0.6916666666666667\n",
      "2270 번째 loss, accuracy:  0.5763523889908619 0.6916666666666667\n",
      "2271 번째 loss, accuracy:  0.5762851012869398 0.6916666666666667\n",
      "2272 번째 loss, accuracy:  0.576217871641428 0.6916666666666667\n",
      "2273 번째 loss, accuracy:  0.5761506999888468 0.6916666666666667\n",
      "2274 번째 loss, accuracy:  0.5760835862637926 0.6916666666666667\n",
      "2275 번째 loss, accuracy:  0.5760165304009465 0.6916666666666667\n",
      "2276 번째 loss, accuracy:  0.575949532335067 0.6916666666666667\n",
      "2277 번째 loss, accuracy:  0.5758825920009973 0.6916666666666667\n",
      "2278 번째 loss, accuracy:  0.5758157093336592 0.6916666666666667\n",
      "2279 번째 loss, accuracy:  0.5757488842680539 0.6916666666666667\n",
      "2280 번째 loss, accuracy:  0.5756821167392657 0.6916666666666667\n",
      "2281 번째 loss, accuracy:  0.5756154066824558 0.6916666666666667\n",
      "2282 번째 loss, accuracy:  0.5755487540328693 0.6916666666666667\n",
      "2283 번째 loss, accuracy:  0.5754821587258291 0.6916666666666667\n",
      "2284 번째 loss, accuracy:  0.5754156206967395 0.6916666666666667\n",
      "2285 번째 loss, accuracy:  0.5753491398810827 0.6916666666666667\n",
      "2286 번째 loss, accuracy:  0.5752827162144244 0.6916666666666667\n",
      "2287 번째 loss, accuracy:  0.5752163496324062 0.6916666666666667\n",
      "2288 번째 loss, accuracy:  0.5751500400707513 0.6916666666666667\n",
      "2289 번째 loss, accuracy:  0.5750837874652622 0.6916666666666667\n",
      "2290 번째 loss, accuracy:  0.5750175917518212 0.6916666666666667\n",
      "2291 번째 loss, accuracy:  0.5749514528663899 0.6916666666666667\n",
      "2292 번째 loss, accuracy:  0.5748853707450077 0.6916666666666667\n",
      "2293 번째 loss, accuracy:  0.5748193453237972 0.6916666666666667\n",
      "2294 번째 loss, accuracy:  0.5747533765389562 0.6916666666666667\n",
      "2295 번째 loss, accuracy:  0.5746874643267629 0.6916666666666667\n",
      "2296 번째 loss, accuracy:  0.5746216086235734 0.6916666666666667\n",
      "2297 번째 loss, accuracy:  0.5745558093658248 0.6916666666666667\n",
      "2298 번째 loss, accuracy:  0.5744900664900314 0.6916666666666667\n",
      "2299 번째 loss, accuracy:  0.5744243799327862 0.6916666666666667\n",
      "2300 번째 loss, accuracy:  0.5743587496307611 0.6916666666666667\n",
      "2301 번째 loss, accuracy:  0.5742931755207074 0.6916666666666667\n",
      "2302 번째 loss, accuracy:  0.5742276575394527 0.6916666666666667\n",
      "2303 번째 loss, accuracy:  0.5741621956239048 0.6916666666666667\n",
      "2304 번째 loss, accuracy:  0.5740967897110479 0.6916666666666667\n",
      "2305 번째 loss, accuracy:  0.5740314397379467 0.6916666666666667\n",
      "2306 번째 loss, accuracy:  0.5739661456417421 0.6916666666666667\n",
      "2307 번째 loss, accuracy:  0.5739009073596522 0.6916666666666667\n",
      "2308 번째 loss, accuracy:  0.5738357248289745 0.6916666666666667\n",
      "2309 번째 loss, accuracy:  0.5737705979870839 0.6916666666666667\n",
      "2310 번째 loss, accuracy:  0.5737055267714325 0.6916666666666667\n",
      "2311 번째 loss, accuracy:  0.5736405111195507 0.6916666666666667\n",
      "2312 번째 loss, accuracy:  0.5735755509690452 0.6916666666666667\n",
      "2313 번째 loss, accuracy:  0.5735106462576002 0.6916666666666667\n",
      "2314 번째 loss, accuracy:  0.5734457969229788 0.6916666666666667\n",
      "2315 번째 loss, accuracy:  0.5733810029030199 0.6916666666666667\n",
      "2316 번째 loss, accuracy:  0.5733162641356392 0.6916666666666667\n",
      "2317 번째 loss, accuracy:  0.5732515805588297 0.6916666666666667\n",
      "2318 번째 loss, accuracy:  0.5731869521106622 0.6916666666666667\n",
      "2319 번째 loss, accuracy:  0.5731223787292828 0.6916666666666667\n",
      "2320 번째 loss, accuracy:  0.5730578603529151 0.6916666666666667\n",
      "2321 번째 loss, accuracy:  0.5729933969198593 0.6916666666666667\n",
      "2322 번째 loss, accuracy:  0.5729289883684924 0.6916666666666667\n",
      "2323 번째 loss, accuracy:  0.5728646346372676 0.6916666666666667\n",
      "2324 번째 loss, accuracy:  0.5728003356647133 0.6916666666666667\n",
      "2325 번째 loss, accuracy:  0.5727360913894358 0.6916666666666667\n",
      "2326 번째 loss, accuracy:  0.5726719017501163 0.6916666666666667\n",
      "2327 번째 loss, accuracy:  0.572607766685514 0.6916666666666667\n",
      "2328 번째 loss, accuracy:  0.5725436861344614 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2329 번째 loss, accuracy:  0.5724796600358687 0.6916666666666667\n",
      "2330 번째 loss, accuracy:  0.5724156883287217 0.6916666666666667\n",
      "2331 번째 loss, accuracy:  0.5723517709520808 0.6916666666666667\n",
      "2332 번째 loss, accuracy:  0.5722879078450831 0.6916666666666667\n",
      "2333 번째 loss, accuracy:  0.5722240989469408 0.6916666666666667\n",
      "2334 번째 loss, accuracy:  0.5721603441969424 0.6916666666666667\n",
      "2335 번째 loss, accuracy:  0.5720966435344498 0.6916666666666667\n",
      "2336 번째 loss, accuracy:  0.5720329968989012 0.6916666666666667\n",
      "2337 번째 loss, accuracy:  0.5719694042298109 0.6916666666666667\n",
      "2338 번째 loss, accuracy:  0.5719058654667674 0.6916666666666667\n",
      "2339 번째 loss, accuracy:  0.5718423805494331 0.6916666666666667\n",
      "2340 번째 loss, accuracy:  0.5717789494175468 0.6916666666666667\n",
      "2341 번째 loss, accuracy:  0.5717155720109217 0.6916666666666667\n",
      "2342 번째 loss, accuracy:  0.5716522482694458 0.6916666666666667\n",
      "2343 번째 loss, accuracy:  0.5715889781330811 0.6916666666666667\n",
      "2344 번째 loss, accuracy:  0.5715257615418642 0.6916666666666667\n",
      "2345 번째 loss, accuracy:  0.5714625984359066 0.6916666666666667\n",
      "2346 번째 loss, accuracy:  0.5713994887553943 0.6916666666666667\n",
      "2347 번째 loss, accuracy:  0.5713364324405863 0.6916666666666667\n",
      "2348 번째 loss, accuracy:  0.5712734294318174 0.6916666666666667\n",
      "2349 번째 loss, accuracy:  0.5712104796694947 0.6916666666666667\n",
      "2350 번째 loss, accuracy:  0.5711475830941021 0.6916666666666667\n",
      "2351 번째 loss, accuracy:  0.5710847396461927 0.6916666666666667\n",
      "2352 번째 loss, accuracy:  0.5710219492663983 0.6916666666666667\n",
      "2353 번째 loss, accuracy:  0.5709592118954222 0.6916666666666667\n",
      "2354 번째 loss, accuracy:  0.5708965274740402 0.6916666666666667\n",
      "2355 번째 loss, accuracy:  0.5708338959431031 0.6916666666666667\n",
      "2356 번째 loss, accuracy:  0.5707713172435357 0.6916666666666667\n",
      "2357 번째 loss, accuracy:  0.5707087913163339 0.6916666666666667\n",
      "2358 번째 loss, accuracy:  0.570646318102569 0.6916666666666667\n",
      "2359 번째 loss, accuracy:  0.5705838975433848 0.6916666666666667\n",
      "2360 번째 loss, accuracy:  0.5705215295799986 0.6916666666666667\n",
      "2361 번째 loss, accuracy:  0.5704592141536987 0.6916666666666667\n",
      "2362 번째 loss, accuracy:  0.5703969512058481 0.6916666666666667\n",
      "2363 번째 loss, accuracy:  0.5703347406778827 0.6916666666666667\n",
      "2364 번째 loss, accuracy:  0.5702725825113102 0.6916666666666667\n",
      "2365 번째 loss, accuracy:  0.5702104766477124 0.6916666666666667\n",
      "2366 번째 loss, accuracy:  0.5701484230287414 0.6916666666666667\n",
      "2367 번째 loss, accuracy:  0.5700864215961224 0.6916666666666667\n",
      "2368 번째 loss, accuracy:  0.5700244722916542 0.6916666666666667\n",
      "2369 번째 loss, accuracy:  0.5699625750572075 0.6916666666666667\n",
      "2370 번째 loss, accuracy:  0.569900729834724 0.6916666666666667\n",
      "2371 번째 loss, accuracy:  0.5698389365662186 0.6916666666666667\n",
      "2372 번째 loss, accuracy:  0.5697771951937783 0.6916666666666667\n",
      "2373 번째 loss, accuracy:  0.5697155056595614 0.6916666666666667\n",
      "2374 번째 loss, accuracy:  0.5696538679057982 0.6916666666666667\n",
      "2375 번째 loss, accuracy:  0.5695922818747903 0.6916666666666667\n",
      "2376 번째 loss, accuracy:  0.5695307475089124 0.6916666666666667\n",
      "2377 번째 loss, accuracy:  0.5694692647506088 0.6916666666666667\n",
      "2378 번째 loss, accuracy:  0.569407833542397 0.6916666666666667\n",
      "2379 번째 loss, accuracy:  0.5693464538268642 0.6916666666666667\n",
      "2380 번째 loss, accuracy:  0.5692851255466697 0.6916666666666667\n",
      "2381 번째 loss, accuracy:  0.5692238486445452 0.6916666666666667\n",
      "2382 번째 loss, accuracy:  0.5691626230632922 0.6916666666666667\n",
      "2383 번째 loss, accuracy:  0.5691014487457836 0.6916666666666667\n",
      "2384 번째 loss, accuracy:  0.5690403256349633 0.6916666666666667\n",
      "2385 번째 loss, accuracy:  0.568979253673844 0.6916666666666667\n",
      "2386 번째 loss, accuracy:  0.5689182328055135 0.6916666666666667\n",
      "2387 번째 loss, accuracy:  0.5688572629731261 0.6916666666666667\n",
      "2388 번째 loss, accuracy:  0.5687963441199095 0.6916666666666667\n",
      "2389 번째 loss, accuracy:  0.5687354761891598 0.6916666666666667\n",
      "2390 번째 loss, accuracy:  0.5686746591242461 0.6916666666666667\n",
      "2391 번째 loss, accuracy:  0.5686138928686046 0.6916666666666667\n",
      "2392 번째 loss, accuracy:  0.5685531773657441 0.6916666666666667\n",
      "2393 번째 loss, accuracy:  0.5684925125592424 0.6916666666666667\n",
      "2394 번째 loss, accuracy:  0.5684318983927488 0.6916666666666667\n",
      "2395 번째 loss, accuracy:  0.5683713348099813 0.6916666666666667\n",
      "2396 번째 loss, accuracy:  0.5683108217547269 0.6916666666666667\n",
      "2397 번째 loss, accuracy:  0.5682503591708451 0.6916666666666667\n",
      "2398 번째 loss, accuracy:  0.5681899470022639 0.6916666666666667\n",
      "2399 번째 loss, accuracy:  0.5681295851929795 0.6916666666666667\n",
      "2400 번째 loss, accuracy:  0.5680692736870586 0.6916666666666667\n",
      "2401 번째 loss, accuracy:  0.5680090124286394 0.6916666666666667\n",
      "2402 번째 loss, accuracy:  0.5679488013619263 0.6916666666666667\n",
      "2403 번째 loss, accuracy:  0.5678886404311948 0.6916666666666667\n",
      "2404 번째 loss, accuracy:  0.5678285295807893 0.6916666666666667\n",
      "2405 번째 loss, accuracy:  0.567768468755123 0.6916666666666667\n",
      "2406 번째 loss, accuracy:  0.5677084578986782 0.6916666666666667\n",
      "2407 번째 loss, accuracy:  0.5676484969560064 0.6916666666666667\n",
      "2408 번째 loss, accuracy:  0.5675885858717277 0.6916666666666667\n",
      "2409 번째 loss, accuracy:  0.5675287245905322 0.6916666666666667\n",
      "2410 번째 loss, accuracy:  0.567468913057176 0.6916666666666667\n",
      "2411 번째 loss, accuracy:  0.5674091512164857 0.6916666666666667\n",
      "2412 번째 loss, accuracy:  0.5673494390133571 0.6916666666666667\n",
      "2413 번째 loss, accuracy:  0.567289776392752 0.6916666666666667\n",
      "2414 번째 loss, accuracy:  0.5672301632997031 0.6916666666666667\n",
      "2415 번째 loss, accuracy:  0.5671705996793105 0.6916666666666667\n",
      "2416 번째 loss, accuracy:  0.5671110854767425 0.6916666666666667\n",
      "2417 번째 loss, accuracy:  0.5670516206372339 0.6916666666666667\n",
      "2418 번째 loss, accuracy:  0.5669922051060896 0.6916666666666667\n",
      "2419 번째 loss, accuracy:  0.5669328388286826 0.6916666666666667\n",
      "2420 번째 loss, accuracy:  0.5668735217504505 0.6916666666666667\n",
      "2421 번째 loss, accuracy:  0.5668142538169024 0.6916666666666667\n",
      "2422 번째 loss, accuracy:  0.5667550349736143 0.6916666666666667\n",
      "2423 번째 loss, accuracy:  0.5666958651662287 0.6916666666666667\n",
      "2424 번째 loss, accuracy:  0.5666367443404555 0.6916666666666667\n",
      "2425 번째 loss, accuracy:  0.5665776724420724 0.6916666666666667\n",
      "2426 번째 loss, accuracy:  0.5665186494169248 0.6916666666666667\n",
      "2427 번째 loss, accuracy:  0.5664596752109254 0.6916666666666667\n",
      "2428 번째 loss, accuracy:  0.5664007497700543 0.6916666666666667\n",
      "2429 번째 loss, accuracy:  0.5663418730403573 0.6916666666666667\n",
      "2430 번째 loss, accuracy:  0.5662830449679472 0.6916666666666667\n",
      "2431 번째 loss, accuracy:  0.5662242654990053 0.6916666666666667\n",
      "2432 번째 loss, accuracy:  0.5661655345797797 0.6916666666666667\n",
      "2433 번째 loss, accuracy:  0.5661068521565846 0.6916666666666667\n",
      "2434 번째 loss, accuracy:  0.5660482181757993 0.6916666666666667\n",
      "2435 번째 loss, accuracy:  0.5659896325838722 0.6916666666666667\n",
      "2436 번째 loss, accuracy:  0.5659310953273168 0.6916666666666667\n",
      "2437 번째 loss, accuracy:  0.5658726063527133 0.6916666666666667\n",
      "2438 번째 loss, accuracy:  0.5658141656067087 0.6916666666666667\n",
      "2439 번째 loss, accuracy:  0.5657557730360153 0.6916666666666667\n",
      "2440 번째 loss, accuracy:  0.5656974285874123 0.6916666666666667\n",
      "2441 번째 loss, accuracy:  0.5656391322077454 0.6916666666666667\n",
      "2442 번째 loss, accuracy:  0.5655808838439245 0.6916666666666667\n",
      "2443 번째 loss, accuracy:  0.5655226834429267 0.6916666666666667\n",
      "2444 번째 loss, accuracy:  0.5654645309517946 0.6916666666666667\n",
      "2445 번째 loss, accuracy:  0.5654064263176376 0.6916666666666667\n",
      "2446 번째 loss, accuracy:  0.5653483694876292 0.6916666666666667\n",
      "2447 번째 loss, accuracy:  0.5652903604090089 0.6916666666666667\n",
      "2448 번째 loss, accuracy:  0.565232399029082 0.6916666666666667\n",
      "2449 번째 loss, accuracy:  0.5651744852952189 0.6916666666666667\n",
      "2450 번째 loss, accuracy:  0.5651166191548559 0.6916666666666667\n",
      "2451 번째 loss, accuracy:  0.5650588005554951 0.6916666666666667\n",
      "2452 번째 loss, accuracy:  0.5650010294447017 0.6916666666666667\n",
      "2453 번째 loss, accuracy:  0.5649433057701075 0.6916666666666667\n",
      "2454 번째 loss, accuracy:  0.5648856294794086 0.6916666666666667\n",
      "2455 번째 loss, accuracy:  0.564828000520366 0.6916666666666667\n",
      "2456 번째 loss, accuracy:  0.5647704188408061 0.6916666666666667\n",
      "2457 번째 loss, accuracy:  0.5647128843886208 0.6916666666666667\n",
      "2458 번째 loss, accuracy:  0.5646553971117653 0.6916666666666667\n",
      "2459 번째 loss, accuracy:  0.5645979569582587 0.6916666666666667\n",
      "2460 번째 loss, accuracy:  0.5645405638761863 0.6916666666666667\n",
      "2461 번째 loss, accuracy:  0.564483217813697 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2462 번째 loss, accuracy:  0.5644259187190056 0.6916666666666667\n",
      "2463 번째 loss, accuracy:  0.5643686665403881 0.6916666666666667\n",
      "2464 번째 loss, accuracy:  0.5643114612261874 0.6916666666666667\n",
      "2465 번째 loss, accuracy:  0.5642543027248093 0.6916666666666667\n",
      "2466 번째 loss, accuracy:  0.5641971909847235 0.6916666666666667\n",
      "2467 번째 loss, accuracy:  0.5641401259544632 0.6916666666666667\n",
      "2468 번째 loss, accuracy:  0.5640831075826273 0.6916666666666667\n",
      "2469 번째 loss, accuracy:  0.5640261358178779 0.6916666666666667\n",
      "2470 번째 loss, accuracy:  0.5639692106089389 0.6916666666666667\n",
      "2471 번째 loss, accuracy:  0.5639123319045994 0.6916666666666667\n",
      "2472 번째 loss, accuracy:  0.563855499653712 0.6916666666666667\n",
      "2473 번째 loss, accuracy:  0.5637987138051926 0.6916666666666667\n",
      "2474 번째 loss, accuracy:  0.5637419743080209 0.6916666666666667\n",
      "2475 번째 loss, accuracy:  0.5636852811112382 0.6916666666666667\n",
      "2476 번째 loss, accuracy:  0.5636286341639509 0.6916666666666667\n",
      "2477 번째 loss, accuracy:  0.5635720334153282 0.6916666666666667\n",
      "2478 번째 loss, accuracy:  0.5635154788146022 0.6916666666666667\n",
      "2479 번째 loss, accuracy:  0.5634589703110662 0.6916666666666667\n",
      "2480 번째 loss, accuracy:  0.5634025078540785 0.6916666666666667\n",
      "2481 번째 loss, accuracy:  0.563346091393061 0.6916666666666667\n",
      "2482 번째 loss, accuracy:  0.5632897208774958 0.6916666666666667\n",
      "2483 번째 loss, accuracy:  0.5632333962569288 0.6916666666666667\n",
      "2484 번째 loss, accuracy:  0.5631771174809683 0.6916666666666667\n",
      "2485 번째 loss, accuracy:  0.5631208844992855 0.6916666666666667\n",
      "2486 번째 loss, accuracy:  0.5630646972616139 0.6916666666666667\n",
      "2487 번째 loss, accuracy:  0.5630085557177498 0.6916666666666667\n",
      "2488 번째 loss, accuracy:  0.56295245981755 0.6916666666666667\n",
      "2489 번째 loss, accuracy:  0.5628964095109358 0.6916666666666667\n",
      "2490 번째 loss, accuracy:  0.5628404047478883 0.6916666666666667\n",
      "2491 번째 loss, accuracy:  0.562784445478452 0.6916666666666667\n",
      "2492 번째 loss, accuracy:  0.5627285316527336 0.6916666666666667\n",
      "2493 번째 loss, accuracy:  0.5626726632209001 0.6916666666666667\n",
      "2494 번째 loss, accuracy:  0.5626168401331824 0.6916666666666667\n",
      "2495 번째 loss, accuracy:  0.5625610623398714 0.6916666666666667\n",
      "2496 번째 loss, accuracy:  0.5625053297913204 0.6916666666666667\n",
      "2497 번째 loss, accuracy:  0.5624496424379439 0.6916666666666667\n",
      "2498 번째 loss, accuracy:  0.5623940002302175 0.6916666666666667\n",
      "2499 번째 loss, accuracy:  0.5623384031186796 0.6916666666666667\n",
      "2500 번째 loss, accuracy:  0.5622828510539276 0.6916666666666667\n",
      "2501 번째 loss, accuracy:  0.5622273439866224 0.6916666666666667\n",
      "2502 번째 loss, accuracy:  0.5621718818674855 0.6916666666666667\n",
      "2503 번째 loss, accuracy:  0.5621164646472985 0.6916666666666667\n",
      "2504 번째 loss, accuracy:  0.5620610922769042 0.6916666666666667\n",
      "2505 번째 loss, accuracy:  0.5620057647072078 0.6916666666666667\n",
      "2506 번째 loss, accuracy:  0.5619504818891738 0.6916666666666667\n",
      "2507 번째 loss, accuracy:  0.561895243773828 0.6916666666666667\n",
      "2508 번째 loss, accuracy:  0.5618400503122556 0.6916666666666667\n",
      "2509 번째 loss, accuracy:  0.5617849014556043 0.6916666666666667\n",
      "2510 번째 loss, accuracy:  0.5617297971550819 0.6916666666666667\n",
      "2511 번째 loss, accuracy:  0.5616747373619562 0.6916666666666667\n",
      "2512 번째 loss, accuracy:  0.5616197220275545 0.6916666666666667\n",
      "2513 번째 loss, accuracy:  0.5615647511032665 0.6916666666666667\n",
      "2514 번째 loss, accuracy:  0.561509824540541 0.6916666666666667\n",
      "2515 번째 loss, accuracy:  0.5614549422908867 0.6916666666666667\n",
      "2516 번째 loss, accuracy:  0.5614001043058715 0.6916666666666667\n",
      "2517 번째 loss, accuracy:  0.561345310537126 0.6916666666666667\n",
      "2518 번째 loss, accuracy:  0.5612905609363381 0.6916666666666667\n",
      "2519 번째 loss, accuracy:  0.5612358554552557 0.6916666666666667\n",
      "2520 번째 loss, accuracy:  0.5611811940456887 0.6916666666666667\n",
      "2521 번째 loss, accuracy:  0.5611265766595044 0.6916666666666667\n",
      "2522 번째 loss, accuracy:  0.5610720032486296 0.6916666666666667\n",
      "2523 번째 loss, accuracy:  0.5610174737650535 0.6916666666666667\n",
      "2524 번째 loss, accuracy:  0.5609629881608211 0.6916666666666667\n",
      "2525 번째 loss, accuracy:  0.5609085463880391 0.6916666666666667\n",
      "2526 번째 loss, accuracy:  0.5608541483988733 0.6916666666666667\n",
      "2527 번째 loss, accuracy:  0.5607997941455468 0.6916666666666667\n",
      "2528 번째 loss, accuracy:  0.560745483580344 0.6916666666666667\n",
      "2529 번째 loss, accuracy:  0.5606912166556074 0.6916666666666667\n",
      "2530 번째 loss, accuracy:  0.5606369933237396 0.6916666666666667\n",
      "2531 번째 loss, accuracy:  0.5605828135371999 0.6916666666666667\n",
      "2532 번째 loss, accuracy:  0.5605286772485073 0.6916666666666667\n",
      "2533 번째 loss, accuracy:  0.5604745844102408 0.6916666666666667\n",
      "2534 번째 loss, accuracy:  0.5604205349750377 0.6916666666666667\n",
      "2535 번째 loss, accuracy:  0.5603665288955931 0.6916666666666667\n",
      "2536 번째 loss, accuracy:  0.5603125661246608 0.6916666666666667\n",
      "2537 번째 loss, accuracy:  0.5602586466150531 0.6916666666666667\n",
      "2538 번째 loss, accuracy:  0.5602047703196408 0.6916666666666667\n",
      "2539 번째 loss, accuracy:  0.5601509371913524 0.6916666666666667\n",
      "2540 번째 loss, accuracy:  0.5600971471831763 0.6916666666666667\n",
      "2541 번째 loss, accuracy:  0.5600434002481578 0.6916666666666667\n",
      "2542 번째 loss, accuracy:  0.5599896963393999 0.6916666666666667\n",
      "2543 번째 loss, accuracy:  0.559936035410064 0.6916666666666667\n",
      "2544 번째 loss, accuracy:  0.5598824174133701 0.6916666666666667\n",
      "2545 번째 loss, accuracy:  0.5598288423025953 0.6916666666666667\n",
      "2546 번째 loss, accuracy:  0.5597753100310748 0.6916666666666667\n",
      "2547 번째 loss, accuracy:  0.5597218205522011 0.6916666666666667\n",
      "2548 번째 loss, accuracy:  0.5596683738194255 0.6916666666666667\n",
      "2549 번째 loss, accuracy:  0.5596149697862554 0.6916666666666667\n",
      "2550 번째 loss, accuracy:  0.5595616084062559 0.6916666666666667\n",
      "2551 번째 loss, accuracy:  0.5595082896330502 0.6916666666666667\n",
      "2552 번째 loss, accuracy:  0.5594550134203177 0.6916666666666667\n",
      "2553 번째 loss, accuracy:  0.5594017797217966 0.6916666666666667\n",
      "2554 번째 loss, accuracy:  0.5593485884912817 0.6916666666666667\n",
      "2555 번째 loss, accuracy:  0.5592954396826244 0.6916666666666667\n",
      "2556 번째 loss, accuracy:  0.5592423332497337 0.6916666666666667\n",
      "2557 번째 loss, accuracy:  0.5591892691465747 0.6916666666666667\n",
      "2558 번째 loss, accuracy:  0.5591362473271707 0.6916666666666667\n",
      "2559 번째 loss, accuracy:  0.5590832677456009 0.6916666666666667\n",
      "2560 번째 loss, accuracy:  0.5590303303560019 0.6916666666666667\n",
      "2561 번째 loss, accuracy:  0.558977435112565 0.6916666666666667\n",
      "2562 번째 loss, accuracy:  0.5589245819695408 0.6916666666666667\n",
      "2563 번째 loss, accuracy:  0.558871770881235 0.6916666666666667\n",
      "2564 번째 loss, accuracy:  0.5588190018020103 0.6916666666666667\n",
      "2565 번째 loss, accuracy:  0.5587662746862851 0.6916666666666667\n",
      "2566 번째 loss, accuracy:  0.5587135894885333 0.6916666666666667\n",
      "2567 번째 loss, accuracy:  0.5586609461632885 0.6916666666666667\n",
      "2568 번째 loss, accuracy:  0.5586083446651365 0.6916666666666667\n",
      "2569 번째 loss, accuracy:  0.5585557849487208 0.6916666666666667\n",
      "2570 번째 loss, accuracy:  0.558503266968741 0.6916666666666667\n",
      "2571 번째 loss, accuracy:  0.5584507906799528 0.6916666666666667\n",
      "2572 번째 loss, accuracy:  0.5583983560371668 0.6916666666666667\n",
      "2573 번째 loss, accuracy:  0.5583459629952505 0.6916666666666667\n",
      "2574 번째 loss, accuracy:  0.5582936115091269 0.6916666666666667\n",
      "2575 번째 loss, accuracy:  0.5582413015337747 0.6916666666666667\n",
      "2576 번째 loss, accuracy:  0.558189033024227 0.6916666666666667\n",
      "2577 번째 loss, accuracy:  0.5581368059355744 0.6916666666666667\n",
      "2578 번째 loss, accuracy:  0.5580846202229609 0.6916666666666667\n",
      "2579 번째 loss, accuracy:  0.5580324758415875 0.6916666666666667\n",
      "2580 번째 loss, accuracy:  0.5579803727467085 0.6916666666666667\n",
      "2581 번째 loss, accuracy:  0.5579283108936355 0.6916666666666667\n",
      "2582 번째 loss, accuracy:  0.557876290237734 0.6916666666666667\n",
      "2583 번째 loss, accuracy:  0.5578243107344253 0.6916666666666667\n",
      "2584 번째 loss, accuracy:  0.5577723723391853 0.6916666666666667\n",
      "2585 번째 loss, accuracy:  0.5577204750075447 0.6916666666666667\n",
      "2586 번째 loss, accuracy:  0.5576686186950894 0.6916666666666667\n",
      "2587 번째 loss, accuracy:  0.5576168033574601 0.6916666666666667\n",
      "2588 번째 loss, accuracy:  0.5575650289503516 0.6916666666666667\n",
      "2589 번째 loss, accuracy:  0.5575132954295139 0.6916666666666667\n",
      "2590 번째 loss, accuracy:  0.5574616027507502 0.6916666666666667\n",
      "2591 번째 loss, accuracy:  0.5574099508699211 0.6916666666666667\n",
      "2592 번째 loss, accuracy:  0.55735833974294 0.6916666666666667\n",
      "2593 번째 loss, accuracy:  0.5573067693257736 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2594 번째 loss, accuracy:  0.557255239574444 0.6916666666666667\n",
      "2595 번째 loss, accuracy:  0.5572037504450281 0.6916666666666667\n",
      "2596 번째 loss, accuracy:  0.5571523018936554 0.6916666666666667\n",
      "2597 번째 loss, accuracy:  0.5571008938765105 0.6916666666666667\n",
      "2598 번째 loss, accuracy:  0.5570495263498313 0.6916666666666667\n",
      "2599 번째 loss, accuracy:  0.5569981992699109 0.6916666666666667\n",
      "2600 번째 loss, accuracy:  0.556946912593095 0.6916666666666667\n",
      "2601 번째 loss, accuracy:  0.5568956662757841 0.6916666666666667\n",
      "2602 번째 loss, accuracy:  0.556844460274431 0.6916666666666667\n",
      "2603 번째 loss, accuracy:  0.5567932945455436 0.6916666666666667\n",
      "2604 번째 loss, accuracy:  0.556742169045682 0.6916666666666667\n",
      "2605 번째 loss, accuracy:  0.5566910837314614 0.6916666666666667\n",
      "2606 번째 loss, accuracy:  0.5566400385595496 0.6916666666666667\n",
      "2607 번째 loss, accuracy:  0.5565890334866671 0.6916666666666667\n",
      "2608 번째 loss, accuracy:  0.556538068469589 0.6916666666666667\n",
      "2609 번째 loss, accuracy:  0.5564871434651428 0.6916666666666667\n",
      "2610 번째 loss, accuracy:  0.5564362584302095 0.6916666666666667\n",
      "2611 번째 loss, accuracy:  0.5563854133217224 0.6916666666666667\n",
      "2612 번째 loss, accuracy:  0.5563346080966697 0.6916666666666667\n",
      "2613 번째 loss, accuracy:  0.5562838427120902 0.6916666666666667\n",
      "2614 번째 loss, accuracy:  0.556233117125077 0.6916666666666667\n",
      "2615 번째 loss, accuracy:  0.5561824312927759 0.6916666666666667\n",
      "2616 번째 loss, accuracy:  0.5561317851723847 0.6916666666666667\n",
      "2617 번째 loss, accuracy:  0.5560811787211551 0.6916666666666667\n",
      "2618 번째 loss, accuracy:  0.556030611896391 0.6916666666666667\n",
      "2619 번째 loss, accuracy:  0.5559800846554469 0.6916666666666667\n",
      "2620 번째 loss, accuracy:  0.555929596955733 0.6916666666666667\n",
      "2621 번째 loss, accuracy:  0.55587914875471 0.6916666666666667\n",
      "2622 번째 loss, accuracy:  0.5558287400098909 0.6916666666666667\n",
      "2623 번째 loss, accuracy:  0.5557783706788418 0.6916666666666667\n",
      "2624 번째 loss, accuracy:  0.5557280407191801 0.6916666666666667\n",
      "2625 번째 loss, accuracy:  0.555677750088576 0.6916666666666667\n",
      "2626 번째 loss, accuracy:  0.5556274987447515 0.6916666666666667\n",
      "2627 번째 loss, accuracy:  0.5555772866454796 0.6916666666666667\n",
      "2628 번째 loss, accuracy:  0.5555271137485871 0.6916666666666667\n",
      "2629 번째 loss, accuracy:  0.5554769800119518 0.6916666666666667\n",
      "2630 번째 loss, accuracy:  0.555426885393503 0.6916666666666667\n",
      "2631 번째 loss, accuracy:  0.5553768298512215 0.6916666666666667\n",
      "2632 번째 loss, accuracy:  0.5553268133431405 0.6916666666666667\n",
      "2633 번째 loss, accuracy:  0.5552768358273444 0.6916666666666667\n",
      "2634 번째 loss, accuracy:  0.5552268972619697 0.6916666666666667\n",
      "2635 번째 loss, accuracy:  0.5551769976052034 0.6916666666666667\n",
      "2636 번째 loss, accuracy:  0.5551271368152839 0.6916666666666667\n",
      "2637 번째 loss, accuracy:  0.5550773148505013 0.6916666666666667\n",
      "2638 번째 loss, accuracy:  0.5550275316691966 0.6916666666666667\n",
      "2639 번째 loss, accuracy:  0.5549777872297632 0.6916666666666667\n",
      "2640 번째 loss, accuracy:  0.5549280814906443 0.6916666666666667\n",
      "2641 번째 loss, accuracy:  0.5548784144103345 0.6916666666666667\n",
      "2642 번째 loss, accuracy:  0.5548287859473793 0.6916666666666667\n",
      "2643 번째 loss, accuracy:  0.5547791960603752 0.6916666666666667\n",
      "2644 번째 loss, accuracy:  0.5547296447079693 0.6916666666666667\n",
      "2645 번째 loss, accuracy:  0.5546801318488602 0.6916666666666667\n",
      "2646 번째 loss, accuracy:  0.5546306574417964 0.6916666666666667\n",
      "2647 번째 loss, accuracy:  0.554581221445578 0.6916666666666667\n",
      "2648 번째 loss, accuracy:  0.5545318238190544 0.6916666666666667\n",
      "2649 번째 loss, accuracy:  0.5544824645211255 0.6916666666666667\n",
      "2650 번째 loss, accuracy:  0.5544331435107437 0.6916666666666667\n",
      "2651 번째 loss, accuracy:  0.5543838607469088 0.6916666666666667\n",
      "2652 번째 loss, accuracy:  0.5543346161886731 0.6916666666666667\n",
      "2653 번째 loss, accuracy:  0.5542854097951389 0.6916666666666667\n",
      "2654 번째 loss, accuracy:  0.5542362415254585 0.6916666666666667\n",
      "2655 번째 loss, accuracy:  0.5541871113388331 0.6916666666666667\n",
      "2656 번째 loss, accuracy:  0.5541380191945149 0.6916666666666667\n",
      "2657 번째 loss, accuracy:  0.5540889650518065 0.6916666666666667\n",
      "2658 번째 loss, accuracy:  0.55403994887006 0.6916666666666667\n",
      "2659 번째 loss, accuracy:  0.5539909706086769 0.6916666666666667\n",
      "2660 번째 loss, accuracy:  0.5539420302271094 0.6916666666666667\n",
      "2661 번째 loss, accuracy:  0.5538931276848591 0.6916666666666667\n",
      "2662 번째 loss, accuracy:  0.5538442629414766 0.6916666666666667\n",
      "2663 번째 loss, accuracy:  0.553795435956562 0.6916666666666667\n",
      "2664 번째 loss, accuracy:  0.5537466466897653 0.6916666666666667\n",
      "2665 번째 loss, accuracy:  0.5536978951007873 0.6916666666666667\n",
      "2666 번째 loss, accuracy:  0.553649181149377 0.6916666666666667\n",
      "2667 번째 loss, accuracy:  0.5536005047953315 0.6916666666666667\n",
      "2668 번째 loss, accuracy:  0.5535518659984995 0.6916666666666667\n",
      "2669 번째 loss, accuracy:  0.5535032647187764 0.6916666666666667\n",
      "2670 번째 loss, accuracy:  0.5534547009161094 0.6916666666666667\n",
      "2671 번째 loss, accuracy:  0.5534061745504923 0.6916666666666667\n",
      "2672 번째 loss, accuracy:  0.5533576855819701 0.6916666666666667\n",
      "2673 번째 loss, accuracy:  0.553309233970635 0.6916666666666667\n",
      "2674 번째 loss, accuracy:  0.5532608196766283 0.6916666666666667\n",
      "2675 번째 loss, accuracy:  0.5532124426601412 0.6916666666666667\n",
      "2676 번째 loss, accuracy:  0.5531641028814124 0.6916666666666667\n",
      "2677 번째 loss, accuracy:  0.5531158003007307 0.6916666666666667\n",
      "2678 번째 loss, accuracy:  0.5530675348784315 0.6916666666666667\n",
      "2679 번째 loss, accuracy:  0.5530193065749004 0.6916666666666667\n",
      "2680 번째 loss, accuracy:  0.5529711153505715 0.6916666666666667\n",
      "2681 번째 loss, accuracy:  0.5529229611659268 0.6916666666666667\n",
      "2682 번째 loss, accuracy:  0.5528748439814957 0.6916666666666667\n",
      "2683 번째 loss, accuracy:  0.5528267637578567 0.6916666666666667\n",
      "2684 번째 loss, accuracy:  0.552778720455637 0.6916666666666667\n",
      "2685 번째 loss, accuracy:  0.5527307140355118 0.6916666666666667\n",
      "2686 번째 loss, accuracy:  0.552682744458204 0.6916666666666667\n",
      "2687 번째 loss, accuracy:  0.5526348116844847 0.6916666666666667\n",
      "2688 번째 loss, accuracy:  0.5525869156751728 0.6916666666666667\n",
      "2689 번째 loss, accuracy:  0.5525390563911361 0.6916666666666667\n",
      "2690 번째 loss, accuracy:  0.5524912337932887 0.6916666666666667\n",
      "2691 번째 loss, accuracy:  0.552443447842593 0.6916666666666667\n",
      "2692 번째 loss, accuracy:  0.5523956985000607 0.6916666666666667\n",
      "2693 번째 loss, accuracy:  0.5523479857267481 0.6916666666666667\n",
      "2694 번째 loss, accuracy:  0.5523003094837615 0.6916666666666667\n",
      "2695 번째 loss, accuracy:  0.5522526697322548 0.6916666666666667\n",
      "2696 번째 loss, accuracy:  0.5522050664334268 0.6916666666666667\n",
      "2697 번째 loss, accuracy:  0.5521574995485266 0.6916666666666667\n",
      "2698 번째 loss, accuracy:  0.5521099690388499 0.6916666666666667\n",
      "2699 번째 loss, accuracy:  0.552062474865738 0.6916666666666667\n",
      "2700 번째 loss, accuracy:  0.5520150169905821 0.6916666666666667\n",
      "2701 번째 loss, accuracy:  0.551967595374818 0.6916666666666667\n",
      "2702 번째 loss, accuracy:  0.5519202099799294 0.6916666666666667\n",
      "2703 번째 loss, accuracy:  0.551872860767448 0.6916666666666667\n",
      "2704 번째 loss, accuracy:  0.5518255476989519 0.6916666666666667\n",
      "2705 번째 loss, accuracy:  0.5517782707360659 0.6916666666666667\n",
      "2706 번째 loss, accuracy:  0.5517310298404626 0.6916666666666667\n",
      "2707 번째 loss, accuracy:  0.5516838249738598 0.6916666666666667\n",
      "2708 번째 loss, accuracy:  0.5516366560980224 0.6916666666666667\n",
      "2709 번째 loss, accuracy:  0.5515895231747625 0.6916666666666667\n",
      "2710 번째 loss, accuracy:  0.5515424261659388 0.6916666666666667\n",
      "2711 번째 loss, accuracy:  0.5514953650334566 0.6916666666666667\n",
      "2712 번째 loss, accuracy:  0.5514483397392667 0.6916666666666667\n",
      "2713 번째 loss, accuracy:  0.5514013502453677 0.6916666666666667\n",
      "2714 번째 loss, accuracy:  0.5513543965138041 0.6916666666666667\n",
      "2715 번째 loss, accuracy:  0.551307478506665 0.6916666666666667\n",
      "2716 번째 loss, accuracy:  0.5512605961860882 0.6916666666666667\n",
      "2717 번째 loss, accuracy:  0.5512137495142562 0.6916666666666667\n",
      "2718 번째 loss, accuracy:  0.5511669384533983 0.6916666666666667\n",
      "2719 번째 loss, accuracy:  0.5511201629657897 0.6916666666666667\n",
      "2720 번째 loss, accuracy:  0.5510734230137508 0.6916666666666667\n",
      "2721 번째 loss, accuracy:  0.5510267185596494 0.6916666666666667\n",
      "2722 번째 loss, accuracy:  0.5509800495658972 0.6916666666666667\n",
      "2723 번째 loss, accuracy:  0.5509334159949536 0.6916666666666667\n",
      "2724 번째 loss, accuracy:  0.5508868178093226 0.6916666666666667\n",
      "2725 번째 loss, accuracy:  0.5508402549715549 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2726 번째 loss, accuracy:  0.5507937274442454 0.6916666666666667\n",
      "2727 번째 loss, accuracy:  0.5507472351900357 0.6916666666666667\n",
      "2728 번째 loss, accuracy:  0.5507007781716114 0.6916666666666667\n",
      "2729 번째 loss, accuracy:  0.550654356351706 0.6916666666666667\n",
      "2730 번째 loss, accuracy:  0.5506079696930961 0.6916666666666667\n",
      "2731 번째 loss, accuracy:  0.5505616181586047 0.6916666666666667\n",
      "2732 번째 loss, accuracy:  0.5505153017110996 0.6916666666666667\n",
      "2733 번째 loss, accuracy:  0.5504690203134948 0.6916666666666667\n",
      "2734 번째 loss, accuracy:  0.5504227739287482 0.6916666666666667\n",
      "2735 번째 loss, accuracy:  0.550376562519863 0.6916666666666667\n",
      "2736 번째 loss, accuracy:  0.5503303860498875 0.6916666666666667\n",
      "2737 번째 loss, accuracy:  0.550284244481915 0.6916666666666667\n",
      "2738 번째 loss, accuracy:  0.550238137779084 0.6916666666666667\n",
      "2739 번째 loss, accuracy:  0.5501920659045783 0.6916666666666667\n",
      "2740 번째 loss, accuracy:  0.5501460288216246 0.6916666666666667\n",
      "2741 번째 loss, accuracy:  0.5501000264934965 0.6916666666666667\n",
      "2742 번째 loss, accuracy:  0.5500540588835101 0.6916666666666667\n",
      "2743 번째 loss, accuracy:  0.5500081259550279 0.6916666666666667\n",
      "2744 번째 loss, accuracy:  0.5499622276714569 0.6916666666666667\n",
      "2745 번째 loss, accuracy:  0.5499163639962468 0.6916666666666667\n",
      "2746 번째 loss, accuracy:  0.5498705348928935 0.6916666666666667\n",
      "2747 번째 loss, accuracy:  0.5498247403249361 0.6916666666666667\n",
      "2748 번째 loss, accuracy:  0.5497789802559595 0.6916666666666667\n",
      "2749 번째 loss, accuracy:  0.5497332546495913 0.6916666666666667\n",
      "2750 번째 loss, accuracy:  0.5496875634695031 0.6916666666666667\n",
      "2751 번째 loss, accuracy:  0.5496419066794117 0.6916666666666667\n",
      "2752 번째 loss, accuracy:  0.5495962842430785 0.6916666666666667\n",
      "2753 번째 loss, accuracy:  0.5495506961243064 0.6916666666666667\n",
      "2754 번째 loss, accuracy:  0.549505142286946 0.6916666666666667\n",
      "2755 번째 loss, accuracy:  0.5494596226948878 0.6916666666666667\n",
      "2756 번째 loss, accuracy:  0.5494141373120687 0.6916666666666667\n",
      "2757 번째 loss, accuracy:  0.5493686861024686 0.6916666666666667\n",
      "2758 번째 loss, accuracy:  0.5493232690301115 0.6916666666666667\n",
      "2759 번째 loss, accuracy:  0.5492778860590644 0.6916666666666667\n",
      "2760 번째 loss, accuracy:  0.5492325371534382 0.6916666666666667\n",
      "2761 번째 loss, accuracy:  0.5491872222773874 0.6916666666666667\n",
      "2762 번째 loss, accuracy:  0.5491419413951086 0.6916666666666667\n",
      "2763 번째 loss, accuracy:  0.5490966944708456 0.6916666666666667\n",
      "2764 번째 loss, accuracy:  0.5490514814688822 0.6916666666666667\n",
      "2765 번째 loss, accuracy:  0.5490063023535459 0.6916666666666667\n",
      "2766 번째 loss, accuracy:  0.5489611570892078 0.6916666666666667\n",
      "2767 번째 loss, accuracy:  0.5489160456402827 0.6916666666666667\n",
      "2768 번째 loss, accuracy:  0.5488709679712287 0.6916666666666667\n",
      "2769 번째 loss, accuracy:  0.5488259240465455 0.6916666666666667\n",
      "2770 번째 loss, accuracy:  0.5487809138307782 0.6916666666666667\n",
      "2771 번째 loss, accuracy:  0.5487359372885126 0.6916666666666667\n",
      "2772 번째 loss, accuracy:  0.5486909943843775 0.6916666666666667\n",
      "2773 번째 loss, accuracy:  0.5486460850830465 0.6916666666666667\n",
      "2774 번째 loss, accuracy:  0.5486012093492345 0.6916666666666667\n",
      "2775 번째 loss, accuracy:  0.5485563671476991 0.6916666666666667\n",
      "2776 번째 loss, accuracy:  0.5485115584432411 0.6916666666666667\n",
      "2777 번째 loss, accuracy:  0.548466783200703 0.6916666666666667\n",
      "2778 번째 loss, accuracy:  0.5484220413849716 0.6916666666666667\n",
      "2779 번째 loss, accuracy:  0.5483773329609745 0.6916666666666667\n",
      "2780 번째 loss, accuracy:  0.5483326578936835 0.6916666666666667\n",
      "2781 번째 loss, accuracy:  0.5482880161481102 0.6916666666666667\n",
      "2782 번째 loss, accuracy:  0.5482434076893106 0.6916666666666667\n",
      "2783 번째 loss, accuracy:  0.548198832482383 0.6916666666666667\n",
      "2784 번째 loss, accuracy:  0.5481542904924671 0.6916666666666667\n",
      "2785 번째 loss, accuracy:  0.5481097816847444 0.6916666666666667\n",
      "2786 번째 loss, accuracy:  0.5480653060244407 0.6916666666666667\n",
      "2787 번째 loss, accuracy:  0.5480208634768207 0.6916666666666667\n",
      "2788 번째 loss, accuracy:  0.5479764540071934 0.6916666666666667\n",
      "2789 번째 loss, accuracy:  0.5479320775809088 0.6916666666666667\n",
      "2790 번째 loss, accuracy:  0.5478877341633591 0.6916666666666667\n",
      "2791 번째 loss, accuracy:  0.5478434237199785 0.6916666666666667\n",
      "2792 번째 loss, accuracy:  0.5477991462162426 0.6916666666666667\n",
      "2793 번째 loss, accuracy:  0.5477549016176687 0.6916666666666667\n",
      "2794 번째 loss, accuracy:  0.547710689889816 0.6916666666666667\n",
      "2795 번째 loss, accuracy:  0.5476665109982854 0.6916666666666667\n",
      "2796 번째 loss, accuracy:  0.5476223649087187 0.6916666666666667\n",
      "2797 번째 loss, accuracy:  0.5475782515868001 0.6916666666666667\n",
      "2798 번째 loss, accuracy:  0.5475341709982542 0.6916666666666667\n",
      "2799 번째 loss, accuracy:  0.5474901231088481 0.6916666666666667\n",
      "2800 번째 loss, accuracy:  0.5474461078843897 0.6916666666666667\n",
      "2801 번째 loss, accuracy:  0.5474021252907285 0.6916666666666667\n",
      "2802 번째 loss, accuracy:  0.5473581752937542 0.6916666666666667\n",
      "2803 번째 loss, accuracy:  0.5473142578593991 0.6916666666666667\n",
      "2804 번째 loss, accuracy:  0.5472703729536353 0.6916666666666667\n",
      "2805 번째 loss, accuracy:  0.547226520542477 0.6916666666666667\n",
      "2806 번째 loss, accuracy:  0.5471827005919792 0.6916666666666667\n",
      "2807 번째 loss, accuracy:  0.547138913068237 0.6916666666666667\n",
      "2808 번째 loss, accuracy:  0.5470951579373872 0.6916666666666667\n",
      "2809 번째 loss, accuracy:  0.5470514351656068 0.6916666666666667\n",
      "2810 번째 loss, accuracy:  0.5470077447191145 0.6916666666666667\n",
      "2811 번째 loss, accuracy:  0.5469640865641693 0.6916666666666667\n",
      "2812 번째 loss, accuracy:  0.5469204606670703 0.6916666666666667\n",
      "2813 번째 loss, accuracy:  0.546876866994158 0.6916666666666667\n",
      "2814 번째 loss, accuracy:  0.5468333055118137 0.6916666666666667\n",
      "2815 번째 loss, accuracy:  0.5467897761864585 0.6916666666666667\n",
      "2816 번째 loss, accuracy:  0.5467462789845536 0.6916666666666667\n",
      "2817 번째 loss, accuracy:  0.5467028138726021 0.6916666666666667\n",
      "2818 번째 loss, accuracy:  0.5466593808171457 0.6916666666666667\n",
      "2819 번째 loss, accuracy:  0.5466159797847668 0.6916666666666667\n",
      "2820 번째 loss, accuracy:  0.5465726107420893 0.6916666666666667\n",
      "2821 번째 loss, accuracy:  0.5465292736557764 0.6916666666666667\n",
      "2822 번째 loss, accuracy:  0.5464859684925315 0.6916666666666667\n",
      "2823 번째 loss, accuracy:  0.5464426952190974 0.6916666666666667\n",
      "2824 번째 loss, accuracy:  0.5463994538022587 0.6916666666666667\n",
      "2825 번째 loss, accuracy:  0.5463562442088374 0.6916666666666667\n",
      "2826 번째 loss, accuracy:  0.5463130664056981 0.6916666666666667\n",
      "2827 번째 loss, accuracy:  0.5462699203597439 0.6916666666666667\n",
      "2828 번째 loss, accuracy:  0.5462268060379171 0.6916666666666667\n",
      "2829 번째 loss, accuracy:  0.5461837234072008 0.6916666666666667\n",
      "2830 번째 loss, accuracy:  0.5461406724346176 0.6916666666666667\n",
      "2831 번째 loss, accuracy:  0.54609765308723 0.6916666666666667\n",
      "2832 번째 loss, accuracy:  0.546054665332139 0.6916666666666667\n",
      "2833 번째 loss, accuracy:  0.5460117091364869 0.6916666666666667\n",
      "2834 번째 loss, accuracy:  0.5459687844674537 0.6916666666666667\n",
      "2835 번째 loss, accuracy:  0.5459258912922597 0.6916666666666667\n",
      "2836 번째 loss, accuracy:  0.5458830295781646 0.6916666666666667\n",
      "2837 번째 loss, accuracy:  0.5458401992924676 0.6916666666666667\n",
      "2838 번째 loss, accuracy:  0.5457974004025073 0.6916666666666667\n",
      "2839 번째 loss, accuracy:  0.5457546328756605 0.6916666666666667\n",
      "2840 번째 loss, accuracy:  0.5457118966793442 0.6916666666666667\n",
      "2841 번째 loss, accuracy:  0.545669191781014 0.6916666666666667\n",
      "2842 번째 loss, accuracy:  0.5456265181481649 0.6916666666666667\n",
      "2843 번째 loss, accuracy:  0.5455838757483303 0.6916666666666667\n",
      "2844 번째 loss, accuracy:  0.5455412645490841 0.6916666666666667\n",
      "2845 번째 loss, accuracy:  0.5454986845180374 0.6916666666666667\n",
      "2846 번째 loss, accuracy:  0.545456135622841 0.6916666666666667\n",
      "2847 번째 loss, accuracy:  0.545413617831185 0.6916666666666667\n",
      "2848 번째 loss, accuracy:  0.5453711311107959 0.6916666666666667\n",
      "2849 번째 loss, accuracy:  0.5453286754294415 0.6916666666666667\n",
      "2850 번째 loss, accuracy:  0.5452862507549284 0.6916666666666667\n",
      "2851 번째 loss, accuracy:  0.5452438570550993 0.6916666666666667\n",
      "2852 번째 loss, accuracy:  0.5452014942978374 0.6916666666666667\n",
      "2853 번째 loss, accuracy:  0.5451591624510644 0.6916666666666667\n",
      "2854 번째 loss, accuracy:  0.5451168614827395 0.6916666666666667\n",
      "2855 번째 loss, accuracy:  0.545074591360861 0.6916666666666667\n",
      "2856 번째 loss, accuracy:  0.5450323520534658 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2857 번째 loss, accuracy:  0.5449901435286274 0.6916666666666667\n",
      "2858 번째 loss, accuracy:  0.5449479657544597 0.6916666666666667\n",
      "2859 번째 loss, accuracy:  0.5449058186991134 0.6916666666666667\n",
      "2860 번째 loss, accuracy:  0.5448637023307782 0.6916666666666667\n",
      "2861 번째 loss, accuracy:  0.5448216166176818 0.6916666666666667\n",
      "2862 번째 loss, accuracy:  0.5447795615280892 0.6916666666666667\n",
      "2863 번째 loss, accuracy:  0.5447375370303038 0.6916666666666667\n",
      "2864 번째 loss, accuracy:  0.5446955430926667 0.6916666666666667\n",
      "2865 번째 loss, accuracy:  0.5446535796835578 0.6916666666666667\n",
      "2866 번째 loss, accuracy:  0.5446116467713947 0.6916666666666667\n",
      "2867 번째 loss, accuracy:  0.5445697443246311 0.6916666666666667\n",
      "2868 번째 loss, accuracy:  0.54452787231176 0.6916666666666667\n",
      "2869 번째 loss, accuracy:  0.5444860307013119 0.6916666666666667\n",
      "2870 번째 loss, accuracy:  0.5444442194618548 0.6916666666666667\n",
      "2871 번째 loss, accuracy:  0.5444024385619937 0.6916666666666667\n",
      "2872 번째 loss, accuracy:  0.5443606879703727 0.6916666666666667\n",
      "2873 번째 loss, accuracy:  0.5443189676556718 0.6916666666666667\n",
      "2874 번째 loss, accuracy:  0.5442772775866087 0.6916666666666667\n",
      "2875 번째 loss, accuracy:  0.5442356177319391 0.6916666666666667\n",
      "2876 번째 loss, accuracy:  0.5441939880604557 0.6916666666666667\n",
      "2877 번째 loss, accuracy:  0.544152388540989 0.6916666666666667\n",
      "2878 번째 loss, accuracy:  0.5441108191424056 0.6916666666666667\n",
      "2879 번째 loss, accuracy:  0.5440692798336098 0.6916666666666667\n",
      "2880 번째 loss, accuracy:  0.5440277705835437 0.6916666666666667\n",
      "2881 번째 loss, accuracy:  0.5439862913611851 0.6916666666666667\n",
      "2882 번째 loss, accuracy:  0.5439448421355506 0.6916666666666667\n",
      "2883 번째 loss, accuracy:  0.5439034228756922 0.6916666666666667\n",
      "2884 번째 loss, accuracy:  0.5438620335506996 0.6916666666666667\n",
      "2885 번째 loss, accuracy:  0.5438206741296995 0.6916666666666667\n",
      "2886 번째 loss, accuracy:  0.5437793445818553 0.6916666666666667\n",
      "2887 번째 loss, accuracy:  0.5437380448763671 0.6916666666666667\n",
      "2888 번째 loss, accuracy:  0.5436967749824713 0.6916666666666667\n",
      "2889 번째 loss, accuracy:  0.5436555348694418 0.6916666666666667\n",
      "2890 번째 loss, accuracy:  0.5436143245065885 0.6916666666666667\n",
      "2891 번째 loss, accuracy:  0.5435731438632592 0.6916666666666667\n",
      "2892 번째 loss, accuracy:  0.5435319929088357 0.6916666666666667\n",
      "2893 번째 loss, accuracy:  0.5434908716127389 0.6916666666666667\n",
      "2894 번째 loss, accuracy:  0.5434497799444247 0.6916666666666667\n",
      "2895 번째 loss, accuracy:  0.5434087178733852 0.6916666666666667\n",
      "2896 번째 loss, accuracy:  0.5433676853691498 0.6916666666666667\n",
      "2897 번째 loss, accuracy:  0.5433266824012839 0.6916666666666667\n",
      "2898 번째 loss, accuracy:  0.5432857089393893 0.6916666666666667\n",
      "2899 번째 loss, accuracy:  0.543244764953103 0.6916666666666667\n",
      "2900 번째 loss, accuracy:  0.5432038504120995 0.6916666666666667\n",
      "2901 번째 loss, accuracy:  0.5431629652860887 0.6916666666666667\n",
      "2902 번째 loss, accuracy:  0.5431221095448161 0.6916666666666667\n",
      "2903 번째 loss, accuracy:  0.5430812831580644 0.6916666666666667\n",
      "2904 번째 loss, accuracy:  0.5430404860956519 0.6916666666666667\n",
      "2905 번째 loss, accuracy:  0.542999718327432 0.6916666666666667\n",
      "2906 번째 loss, accuracy:  0.5429589798232946 0.6916666666666667\n",
      "2907 번째 loss, accuracy:  0.5429182705531654 0.6916666666666667\n",
      "2908 번째 loss, accuracy:  0.5428775904870056 0.6916666666666667\n",
      "2909 번째 loss, accuracy:  0.5428369395948118 0.6916666666666667\n",
      "2910 번째 loss, accuracy:  0.5427963178466183 0.6916666666666667\n",
      "2911 번째 loss, accuracy:  0.5427557252124913 0.6916666666666667\n",
      "2912 번째 loss, accuracy:  0.5427151616625364 0.6916666666666667\n",
      "2913 번째 loss, accuracy:  0.5426746271668929 0.6916666666666667\n",
      "2914 번째 loss, accuracy:  0.5426341216957353 0.6916666666666667\n",
      "2915 번째 loss, accuracy:  0.5425936452192739 0.6916666666666667\n",
      "2916 번째 loss, accuracy:  0.5425531977077548 0.6916666666666667\n",
      "2917 번째 loss, accuracy:  0.5425127791314593 0.6916666666666667\n",
      "2918 번째 loss, accuracy:  0.5424723894607036 0.6916666666666667\n",
      "2919 번째 loss, accuracy:  0.5424320286658395 0.6916666666666667\n",
      "2920 번째 loss, accuracy:  0.5423916967172537 0.6916666666666667\n",
      "2921 번째 loss, accuracy:  0.5423513935853677 0.6916666666666667\n",
      "2922 번째 loss, accuracy:  0.542311119240639 0.6916666666666667\n",
      "2923 번째 loss, accuracy:  0.54227087365356 0.6916666666666667\n",
      "2924 번째 loss, accuracy:  0.5422306567946574 0.6916666666666667\n",
      "2925 번째 loss, accuracy:  0.5421904686344934 0.6916666666666667\n",
      "2926 번째 loss, accuracy:  0.5421503091436656 0.6916666666666667\n",
      "2927 번째 loss, accuracy:  0.5421101782928055 0.6916666666666667\n",
      "2928 번째 loss, accuracy:  0.5420700760525802 0.6916666666666667\n",
      "2929 번째 loss, accuracy:  0.54203000239369 0.6916666666666667\n",
      "2930 번째 loss, accuracy:  0.5419899572868726 0.6916666666666667\n",
      "2931 번째 loss, accuracy:  0.5419499407028981 0.6916666666666667\n",
      "2932 번째 loss, accuracy:  0.5419099526125719 0.6916666666666667\n",
      "2933 번째 loss, accuracy:  0.5418699929867352 0.6916666666666667\n",
      "2934 번째 loss, accuracy:  0.5418300617962614 0.6916666666666667\n",
      "2935 번째 loss, accuracy:  0.5417901590120597 0.6916666666666667\n",
      "2936 번째 loss, accuracy:  0.5417502846050745 0.6916666666666667\n",
      "2937 번째 loss, accuracy:  0.5417104385462833 0.6916666666666667\n",
      "2938 번째 loss, accuracy:  0.5416706208066978 0.6916666666666667\n",
      "2939 번째 loss, accuracy:  0.5416308313573656 0.6916666666666667\n",
      "2940 번째 loss, accuracy:  0.5415910701693679 0.6916666666666667\n",
      "2941 번째 loss, accuracy:  0.5415513372138192 0.6916666666666667\n",
      "2942 번째 loss, accuracy:  0.5415116324618694 0.6916666666666667\n",
      "2943 번째 loss, accuracy:  0.5414719558847013 0.6916666666666667\n",
      "2944 번째 loss, accuracy:  0.5414323074535328 0.6916666666666667\n",
      "2945 번째 loss, accuracy:  0.5413926871396153 0.6916666666666667\n",
      "2946 번째 loss, accuracy:  0.5413530949142341 0.6916666666666667\n",
      "2947 번째 loss, accuracy:  0.5413135307487094 0.6916666666666667\n",
      "2948 번째 loss, accuracy:  0.541273994614394 0.6916666666666667\n",
      "2949 번째 loss, accuracy:  0.5412344864826752 0.6916666666666667\n",
      "2950 번째 loss, accuracy:  0.5411950063249744 0.6916666666666667\n",
      "2951 번째 loss, accuracy:  0.5411555541127461 0.6916666666666667\n",
      "2952 번째 loss, accuracy:  0.5411161298174784 0.6916666666666667\n",
      "2953 번째 loss, accuracy:  0.5410767334106943 0.6916666666666667\n",
      "2954 번째 loss, accuracy:  0.5410373648639494 0.6916666666666667\n",
      "2955 번째 loss, accuracy:  0.5409980241488321 0.6916666666666667\n",
      "2956 번째 loss, accuracy:  0.5409587112369665 0.6916666666666667\n",
      "2957 번째 loss, accuracy:  0.5409194261000095 0.6916666666666667\n",
      "2958 번째 loss, accuracy:  0.5408801687096499 0.6916666666666667\n",
      "2959 번째 loss, accuracy:  0.5408409390376108 0.6916666666666667\n",
      "2960 번째 loss, accuracy:  0.5408017370556497 0.6916666666666667\n",
      "2961 번째 loss, accuracy:  0.5407625627355562 0.6916666666666667\n",
      "2962 번째 loss, accuracy:  0.5407234160491533 0.6916666666666667\n",
      "2963 번째 loss, accuracy:  0.5406842969682978 0.6916666666666667\n",
      "2964 번째 loss, accuracy:  0.5406452054648787 0.6916666666666667\n",
      "2965 번째 loss, accuracy:  0.5406061415108191 0.6916666666666667\n",
      "2966 번째 loss, accuracy:  0.5405671050780748 0.6916666666666667\n",
      "2967 번째 loss, accuracy:  0.5405280961386351 0.6916666666666667\n",
      "2968 번째 loss, accuracy:  0.540489114664521 0.6916666666666667\n",
      "2969 번째 loss, accuracy:  0.5404501606277883 0.6916666666666667\n",
      "2970 번째 loss, accuracy:  0.5404112340005243 0.6916666666666667\n",
      "2971 번째 loss, accuracy:  0.5403723347548492 0.6916666666666667\n",
      "2972 번째 loss, accuracy:  0.5403334628629168 0.6916666666666667\n",
      "2973 번째 loss, accuracy:  0.540294618296913 0.6916666666666667\n",
      "2974 번째 loss, accuracy:  0.5402558010290573 0.6916666666666667\n",
      "2975 번째 loss, accuracy:  0.5402170110316015 0.6916666666666667\n",
      "2976 번째 loss, accuracy:  0.5401782482768297 0.6916666666666667\n",
      "2977 번째 loss, accuracy:  0.5401395127370583 0.6916666666666667\n",
      "2978 번째 loss, accuracy:  0.5401008043846375 0.6916666666666667\n",
      "2979 번째 loss, accuracy:  0.540062123191948 0.6916666666666667\n",
      "2980 번째 loss, accuracy:  0.540023469131405 0.6916666666666667\n",
      "2981 번째 loss, accuracy:  0.5399848421754556 0.6916666666666667\n",
      "2982 번째 loss, accuracy:  0.5399462422965786 0.6916666666666667\n",
      "2983 번째 loss, accuracy:  0.5399076694672857 0.6916666666666667\n",
      "2984 번째 loss, accuracy:  0.5398691236601205 0.6916666666666667\n",
      "2985 번째 loss, accuracy:  0.5398306048476601 0.6916666666666667\n",
      "2986 번째 loss, accuracy:  0.5397921130025125 0.6916666666666667\n",
      "2987 번째 loss, accuracy:  0.5397536480973173 0.6916666666666667\n",
      "2988 번째 loss, accuracy:  0.5397152101047481 0.6916666666666667\n",
      "2989 번째 loss, accuracy:  0.5396767989975089 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2990 번째 loss, accuracy:  0.5396384147483368 0.6916666666666667\n",
      "2991 번째 loss, accuracy:  0.5396000573300008 0.6916666666666667\n",
      "2992 번째 loss, accuracy:  0.5395617267153016 0.6916666666666667\n",
      "2993 번째 loss, accuracy:  0.5395234228770718 0.6916666666666667\n",
      "2994 번째 loss, accuracy:  0.539485145788176 0.6916666666666667\n",
      "2995 번째 loss, accuracy:  0.5394468954215105 0.6916666666666667\n",
      "2996 번째 loss, accuracy:  0.5394086717500034 0.6916666666666667\n",
      "2997 번째 loss, accuracy:  0.539370474746614 0.6916666666666667\n",
      "2998 번째 loss, accuracy:  0.5393323043843343 0.6916666666666667\n",
      "2999 번째 loss, accuracy:  0.5392941606361874 0.6916666666666667\n",
      "3000 번째 loss, accuracy:  0.5392560434752284 0.6916666666666667\n",
      "3001 번째 loss, accuracy:  0.5392179528745434 0.6916666666666667\n",
      "3002 번째 loss, accuracy:  0.5391798888072498 0.6916666666666667\n",
      "3003 번째 loss, accuracy:  0.5391418512464978 0.6916666666666667\n",
      "3004 번째 loss, accuracy:  0.539103840165468 0.6916666666666667\n",
      "3005 번째 loss, accuracy:  0.5390658555373722 0.6916666666666667\n",
      "3006 번째 loss, accuracy:  0.539027897335455 0.6916666666666667\n",
      "3007 번째 loss, accuracy:  0.5389899655329901 0.6916666666666667\n",
      "3008 번째 loss, accuracy:  0.5389520601032849 0.6916666666666667\n",
      "3009 번째 loss, accuracy:  0.5389141810196757 0.6916666666666667\n",
      "3010 번째 loss, accuracy:  0.538876328255532 0.6916666666666667\n",
      "3011 번째 loss, accuracy:  0.5388385017842529 0.6916666666666667\n",
      "3012 번째 loss, accuracy:  0.5388007015792698 0.6916666666666667\n",
      "3013 번째 loss, accuracy:  0.5387629276140445 0.6916666666666667\n",
      "3014 번째 loss, accuracy:  0.53872517986207 0.6916666666666667\n",
      "3015 번째 loss, accuracy:  0.5386874582968701 0.6916666666666667\n",
      "3016 번째 loss, accuracy:  0.5386497628919991 0.6916666666666667\n",
      "3017 번째 loss, accuracy:  0.5386120936210433 0.6916666666666667\n",
      "3018 번째 loss, accuracy:  0.5385744504576195 0.6916666666666667\n",
      "3019 번째 loss, accuracy:  0.5385368333753746 0.6916666666666667\n",
      "3020 번째 loss, accuracy:  0.5384992423479875 0.6916666666666667\n",
      "3021 번째 loss, accuracy:  0.538461677349167 0.6916666666666667\n",
      "3022 번째 loss, accuracy:  0.5384241383526525 0.6916666666666667\n",
      "3023 번째 loss, accuracy:  0.538386625332214 0.6916666666666667\n",
      "3024 번째 loss, accuracy:  0.5383491382616533 0.6916666666666667\n",
      "3025 번째 loss, accuracy:  0.5383116771148011 0.6916666666666667\n",
      "3026 번째 loss, accuracy:  0.5382742418655201 0.6916666666666667\n",
      "3027 번째 loss, accuracy:  0.5382368324877019 0.6916666666666667\n",
      "3028 번째 loss, accuracy:  0.5381994489552702 0.6916666666666667\n",
      "3029 번째 loss, accuracy:  0.5381620912421781 0.6916666666666667\n",
      "3030 번째 loss, accuracy:  0.5381247593224092 0.6916666666666667\n",
      "3031 번째 loss, accuracy:  0.5380874531699775 0.6916666666666667\n",
      "3032 번째 loss, accuracy:  0.5380501727589276 0.6916666666666667\n",
      "3033 번째 loss, accuracy:  0.5380129180633335 0.6916666666666667\n",
      "3034 번째 loss, accuracy:  0.537975689057301 0.6916666666666667\n",
      "3035 번째 loss, accuracy:  0.537938485714964 0.6916666666666667\n",
      "3036 번째 loss, accuracy:  0.5379013080104877 0.6916666666666667\n",
      "3037 번째 loss, accuracy:  0.5378641559180679 0.6916666666666667\n",
      "3038 번째 loss, accuracy:  0.5378270294119294 0.6916666666666667\n",
      "3039 번째 loss, accuracy:  0.5377899284663276 0.6916666666666667\n",
      "3040 번째 loss, accuracy:  0.5377528530555471 0.6916666666666667\n",
      "3041 번째 loss, accuracy:  0.5377158031539028 0.6916666666666667\n",
      "3042 번째 loss, accuracy:  0.5376787787357401 0.6916666666666667\n",
      "3043 번째 loss, accuracy:  0.5376417797754341 0.6916666666666667\n",
      "3044 번째 loss, accuracy:  0.5376048062473884 0.6916666666666667\n",
      "3045 번째 loss, accuracy:  0.5375678581260377 0.6916666666666667\n",
      "3046 번째 loss, accuracy:  0.5375309353858461 0.6916666666666667\n",
      "3047 번째 loss, accuracy:  0.5374940380013078 0.6916666666666667\n",
      "3048 번째 loss, accuracy:  0.5374571659469455 0.6916666666666667\n",
      "3049 번째 loss, accuracy:  0.5374203191973124 0.6916666666666667\n",
      "3050 번째 loss, accuracy:  0.5373834977269909 0.6916666666666667\n",
      "3051 번째 loss, accuracy:  0.5373467015105933 0.6916666666666667\n",
      "3052 번째 loss, accuracy:  0.537309930522761 0.6916666666666667\n",
      "3053 번째 loss, accuracy:  0.537273184738165 0.6916666666666667\n",
      "3054 번째 loss, accuracy:  0.5372364641315054 0.6916666666666667\n",
      "3055 번째 loss, accuracy:  0.5371997686775117 0.6916666666666667\n",
      "3056 번째 loss, accuracy:  0.5371630983509434 0.6916666666666667\n",
      "3057 번째 loss, accuracy:  0.5371264531265889 0.6916666666666667\n",
      "3058 번째 loss, accuracy:  0.5370898329792659 0.6916666666666667\n",
      "3059 번째 loss, accuracy:  0.5370532378838208 0.6916666666666667\n",
      "3060 번째 loss, accuracy:  0.53701666781513 0.6916666666666667\n",
      "3061 번째 loss, accuracy:  0.5369801227480981 0.6916666666666667\n",
      "3062 번째 loss, accuracy:  0.5369436026576598 0.6916666666666667\n",
      "3063 번째 loss, accuracy:  0.5369071075187783 0.6916666666666667\n",
      "3064 번째 loss, accuracy:  0.5368706373064451 0.6916666666666667\n",
      "3065 번째 loss, accuracy:  0.5368341919956818 0.6916666666666667\n",
      "3066 번째 loss, accuracy:  0.5367977715615383 0.6916666666666667\n",
      "3067 번째 loss, accuracy:  0.5367613759790939 0.6916666666666667\n",
      "3068 번째 loss, accuracy:  0.5367250052234566 0.6916666666666667\n",
      "3069 번째 loss, accuracy:  0.536688659269763 0.6916666666666667\n",
      "3070 번째 loss, accuracy:  0.5366523380931782 0.6916666666666667\n",
      "3071 번째 loss, accuracy:  0.536616041668897 0.6916666666666667\n",
      "3072 번째 loss, accuracy:  0.5365797699721425 0.6916666666666667\n",
      "3073 번째 loss, accuracy:  0.5365435229781658 0.6916666666666667\n",
      "3074 번째 loss, accuracy:  0.5365073006622466 0.6916666666666667\n",
      "3075 번째 loss, accuracy:  0.5364711029996937 0.6916666666666667\n",
      "3076 번째 loss, accuracy:  0.5364349299658461 0.6916666666666667\n",
      "3077 번째 loss, accuracy:  0.5363987815360678 0.6916666666666667\n",
      "3078 번째 loss, accuracy:  0.536362657685754 0.6916666666666667\n",
      "3079 번째 loss, accuracy:  0.5363265583903264 0.6916666666666667\n",
      "3080 번째 loss, accuracy:  0.5362904836252375 0.6916666666666667\n",
      "3081 번째 loss, accuracy:  0.5362544333659663 0.6916666666666667\n",
      "3082 번째 loss, accuracy:  0.5362184075880209 0.6916666666666667\n",
      "3083 번째 loss, accuracy:  0.5361824062669364 0.6916666666666667\n",
      "3084 번째 loss, accuracy:  0.5361464293782777 0.6916666666666667\n",
      "3085 번째 loss, accuracy:  0.5361104768976376 0.6916666666666667\n",
      "3086 번째 loss, accuracy:  0.5360745488006364 0.6916666666666667\n",
      "3087 번째 loss, accuracy:  0.5360386450629229 0.6916666666666667\n",
      "3088 번째 loss, accuracy:  0.5360027656601747 0.6916666666666667\n",
      "3089 번째 loss, accuracy:  0.5359669105680958 0.6916666666666667\n",
      "3090 번째 loss, accuracy:  0.5359310797624199 0.6916666666666667\n",
      "3091 번째 loss, accuracy:  0.5358952732189084 0.6916666666666667\n",
      "3092 번째 loss, accuracy:  0.535859490913349 0.6916666666666667\n",
      "3093 번째 loss, accuracy:  0.5358237328215588 0.6916666666666667\n",
      "3094 번째 loss, accuracy:  0.5357879989193833 0.6916666666666667\n",
      "3095 번째 loss, accuracy:  0.5357522891826946 0.6916666666666667\n",
      "3096 번째 loss, accuracy:  0.5357166035873924 0.6916666666666667\n",
      "3097 번째 loss, accuracy:  0.5356809421094053 0.6916666666666667\n",
      "3098 번째 loss, accuracy:  0.5356453047246892 0.6916666666666667\n",
      "3099 번째 loss, accuracy:  0.5356096914092274 0.6916666666666667\n",
      "3100 번째 loss, accuracy:  0.5355741021390309 0.6916666666666667\n",
      "3101 번째 loss, accuracy:  0.5355385368901385 0.6916666666666667\n",
      "3102 번째 loss, accuracy:  0.5355029956386163 0.6916666666666667\n",
      "3103 번째 loss, accuracy:  0.5354674783605577 0.6916666666666667\n",
      "3104 번째 loss, accuracy:  0.5354319850320852 0.6916666666666667\n",
      "3105 번째 loss, accuracy:  0.5353965156293466 0.6916666666666667\n",
      "3106 번째 loss, accuracy:  0.5353610701285181 0.6916666666666667\n",
      "3107 번째 loss, accuracy:  0.535325648505804 0.6916666666666667\n",
      "3108 번째 loss, accuracy:  0.5352902507374345 0.6916666666666667\n",
      "3109 번째 loss, accuracy:  0.5352548767996683 0.6916666666666667\n",
      "3110 번째 loss, accuracy:  0.5352195266687905 0.6916666666666667\n",
      "3111 번째 loss, accuracy:  0.5351842003211135 0.6916666666666667\n",
      "3112 번째 loss, accuracy:  0.5351488977329785 0.6916666666666667\n",
      "3113 번째 loss, accuracy:  0.5351136188807508 0.6916666666666667\n",
      "3114 번째 loss, accuracy:  0.5350783637408261 0.6916666666666667\n",
      "3115 번째 loss, accuracy:  0.5350431322896253 0.6916666666666667\n",
      "3116 번째 loss, accuracy:  0.5350079245035961 0.6916666666666667\n",
      "3117 번째 loss, accuracy:  0.5349727403592148 0.6916666666666667\n",
      "3118 번째 loss, accuracy:  0.5349375798329833 0.6916666666666667\n",
      "3119 번째 loss, accuracy:  0.5349024429014315 0.6916666666666667\n",
      "3120 번째 loss, accuracy:  0.5348673295411146 0.6916666666666667\n",
      "3121 번째 loss, accuracy:  0.5348322397286165 0.6916666666666667\n",
      "3122 번째 loss, accuracy:  0.5347971734405469 0.6916666666666667\n",
      "3123 번째 loss, accuracy:  0.5347621306535427 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3124 번째 loss, accuracy:  0.5347271113442673 0.6916666666666667\n",
      "3125 번째 loss, accuracy:  0.534692115489411 0.6916666666666667\n",
      "3126 번째 loss, accuracy:  0.5346571430656906 0.6916666666666667\n",
      "3127 번째 loss, accuracy:  0.5346221940498495 0.6916666666666667\n",
      "3128 번째 loss, accuracy:  0.5345872684186591 0.6916666666666667\n",
      "3129 번째 loss, accuracy:  0.5345523661489149 0.6916666666666667\n",
      "3130 번째 loss, accuracy:  0.5345174872174407 0.6916666666666667\n",
      "3131 번째 loss, accuracy:  0.5344826316010863 0.6916666666666667\n",
      "3132 번째 loss, accuracy:  0.534447799276728 0.6916666666666667\n",
      "3133 번째 loss, accuracy:  0.5344129902212692 0.6916666666666667\n",
      "3134 번째 loss, accuracy:  0.5343782044116386 0.6916666666666667\n",
      "3135 번째 loss, accuracy:  0.5343434418247922 0.6916666666666667\n",
      "3136 번째 loss, accuracy:  0.5343087024377113 0.6916666666666667\n",
      "3137 번째 loss, accuracy:  0.534273986227405 0.6916666666666667\n",
      "3138 번째 loss, accuracy:  0.5342392931709073 0.6916666666666667\n",
      "3139 번째 loss, accuracy:  0.5342046232452787 0.6916666666666667\n",
      "3140 번째 loss, accuracy:  0.534169976427607 0.6916666666666667\n",
      "3141 번째 loss, accuracy:  0.5341353526950049 0.6916666666666667\n",
      "3142 번째 loss, accuracy:  0.5341007520246109 0.6916666666666667\n",
      "3143 번째 loss, accuracy:  0.5340661743935914 0.6916666666666667\n",
      "3144 번째 loss, accuracy:  0.5340316197791373 0.6916666666666667\n",
      "3145 번째 loss, accuracy:  0.5339970881584665 0.6916666666666667\n",
      "3146 번째 loss, accuracy:  0.5339625795088223 0.6916666666666667\n",
      "3147 번째 loss, accuracy:  0.5339280938074739 0.6916666666666667\n",
      "3148 번째 loss, accuracy:  0.5338936310317158 0.6916666666666667\n",
      "3149 번째 loss, accuracy:  0.5338591911588705 0.6916666666666667\n",
      "3150 번째 loss, accuracy:  0.5338247741662846 0.6916666666666667\n",
      "3151 번째 loss, accuracy:  0.5337903800313304 0.6916666666666667\n",
      "3152 번째 loss, accuracy:  0.5337560087314069 0.6916666666666667\n",
      "3153 번째 loss, accuracy:  0.5337216602439386 0.6916666666666667\n",
      "3154 번째 loss, accuracy:  0.5336873345463755 0.6916666666666667\n",
      "3155 번째 loss, accuracy:  0.5336530316161938 0.6916666666666667\n",
      "3156 번째 loss, accuracy:  0.5336187514308945 0.6916666666666667\n",
      "3157 번째 loss, accuracy:  0.5335844939680043 0.6916666666666667\n",
      "3158 번째 loss, accuracy:  0.5335502592050766 0.6916666666666667\n",
      "3159 번째 loss, accuracy:  0.5335160471196886 0.6916666666666667\n",
      "3160 번째 loss, accuracy:  0.5334818576894451 0.6916666666666667\n",
      "3161 번째 loss, accuracy:  0.5334476908919742 0.6916666666666667\n",
      "3162 번째 loss, accuracy:  0.5334135467049308 0.6916666666666667\n",
      "3163 번째 loss, accuracy:  0.5333794251059947 0.6916666666666667\n",
      "3164 번째 loss, accuracy:  0.5333453260728713 0.6916666666666667\n",
      "3165 번째 loss, accuracy:  0.5333112495832918 0.6916666666666667\n",
      "3166 번째 loss, accuracy:  0.5332771956150113 0.6916666666666667\n",
      "3167 번째 loss, accuracy:  0.533243164145812 0.6916666666666667\n",
      "3168 번째 loss, accuracy:  0.5332091551534995 0.6916666666666667\n",
      "3169 번째 loss, accuracy:  0.5331751686159063 0.6916666666666667\n",
      "3170 번째 loss, accuracy:  0.5331412045108884 0.6916666666666667\n",
      "3171 번째 loss, accuracy:  0.5331072628163285 0.6916666666666667\n",
      "3172 번째 loss, accuracy:  0.5330733435101335 0.6916666666666667\n",
      "3173 번째 loss, accuracy:  0.5330394465702349 0.6916666666666667\n",
      "3174 번째 loss, accuracy:  0.5330055719745911 0.6916666666666667\n",
      "3175 번째 loss, accuracy:  0.532971719701184 0.6916666666666667\n",
      "3176 번째 loss, accuracy:  0.5329378897280195 0.6916666666666667\n",
      "3177 번째 loss, accuracy:  0.5329040820331312 0.6916666666666667\n",
      "3178 번째 loss, accuracy:  0.532870296594575 0.6916666666666667\n",
      "3179 번째 loss, accuracy:  0.5328365333904331 0.6916666666666667\n",
      "3180 번째 loss, accuracy:  0.5328027923988128 0.6916666666666667\n",
      "3181 번째 loss, accuracy:  0.5327690735978448 0.6916666666666667\n",
      "3182 번째 loss, accuracy:  0.5327353769656856 0.6916666666666667\n",
      "3183 번째 loss, accuracy:  0.5327017024805164 0.6916666666666667\n",
      "3184 번째 loss, accuracy:  0.5326680501205432 0.6916666666666667\n",
      "3185 번째 loss, accuracy:  0.5326344198639953 0.6916666666666667\n",
      "3186 번째 loss, accuracy:  0.5326008116891283 0.6916666666666667\n",
      "3187 번째 loss, accuracy:  0.5325672255742214 0.6916666666666667\n",
      "3188 번째 loss, accuracy:  0.5325336614975797 0.6916666666666667\n",
      "3189 번째 loss, accuracy:  0.5325001194375315 0.6916666666666667\n",
      "3190 번째 loss, accuracy:  0.5324665993724297 0.6916666666666667\n",
      "3191 번째 loss, accuracy:  0.5324331012806521 0.6916666666666667\n",
      "3192 번째 loss, accuracy:  0.5323996251406012 0.6916666666666667\n",
      "3193 번째 loss, accuracy:  0.532366170930703 0.6916666666666667\n",
      "3194 번째 loss, accuracy:  0.5323327386294084 0.6916666666666667\n",
      "3195 번째 loss, accuracy:  0.5322993282151928 0.6916666666666667\n",
      "3196 번째 loss, accuracy:  0.5322659396665557 0.6916666666666667\n",
      "3197 번째 loss, accuracy:  0.532232572962021 0.6916666666666667\n",
      "3198 번째 loss, accuracy:  0.5321992280801365 0.6916666666666667\n",
      "3199 번째 loss, accuracy:  0.5321659049994746 0.6916666666666667\n",
      "3200 번째 loss, accuracy:  0.5321326036986318 0.6916666666666667\n",
      "3201 번째 loss, accuracy:  0.532099324156229 0.6916666666666667\n",
      "3202 번째 loss, accuracy:  0.5320660663509105 0.6916666666666667\n",
      "3203 번째 loss, accuracy:  0.5320328302613446 0.6916666666666667\n",
      "3204 번째 loss, accuracy:  0.5319996158662251 0.6916666666666667\n",
      "3205 번째 loss, accuracy:  0.5319664231442681 0.6916666666666667\n",
      "3206 번째 loss, accuracy:  0.5319332520742154 0.6916666666666667\n",
      "3207 번째 loss, accuracy:  0.531900102634831 0.6916666666666667\n",
      "3208 번째 loss, accuracy:  0.5318669748049036 0.6916666666666667\n",
      "3209 번째 loss, accuracy:  0.5318338685632462 0.6916666666666667\n",
      "3210 번째 loss, accuracy:  0.5318007838886949 0.6916666666666667\n",
      "3211 번째 loss, accuracy:  0.5317677207601099 0.6916666666666667\n",
      "3212 번째 loss, accuracy:  0.5317346791563756 0.6916666666666667\n",
      "3213 번째 loss, accuracy:  0.5317016590563995 0.6916666666666667\n",
      "3214 번째 loss, accuracy:  0.5316686604391136 0.6916666666666667\n",
      "3215 번째 loss, accuracy:  0.5316356832834727 0.6916666666666667\n",
      "3216 번째 loss, accuracy:  0.5316027275684558 0.6916666666666667\n",
      "3217 번째 loss, accuracy:  0.5315697932730657 0.6916666666666667\n",
      "3218 번째 loss, accuracy:  0.5315368803763286 0.6916666666666667\n",
      "3219 번째 loss, accuracy:  0.5315039888572938 0.6916666666666667\n",
      "3220 번째 loss, accuracy:  0.5314711186950348 0.6916666666666667\n",
      "3221 번째 loss, accuracy:  0.5314382698686482 0.6916666666666667\n",
      "3222 번째 loss, accuracy:  0.5314054423572551 0.6916666666666667\n",
      "3223 번째 loss, accuracy:  0.5313726361399986 0.6916666666666667\n",
      "3224 번째 loss, accuracy:  0.5313398511960457 0.6916666666666667\n",
      "3225 번째 loss, accuracy:  0.5313070875045867 0.6916666666666667\n",
      "3226 번째 loss, accuracy:  0.5312743450448358 0.6916666666666667\n",
      "3227 번째 loss, accuracy:  0.5312416237960306 0.6916666666666667\n",
      "3228 번째 loss, accuracy:  0.5312089237374307 0.6916666666666667\n",
      "3229 번째 loss, accuracy:  0.53117624484832 0.6916666666666667\n",
      "3230 번째 loss, accuracy:  0.5311435871080058 0.6916666666666667\n",
      "3231 번째 loss, accuracy:  0.5311109504958182 0.6916666666666667\n",
      "3232 번째 loss, accuracy:  0.5310783349911106 0.6916666666666667\n",
      "3233 번째 loss, accuracy:  0.5310457405732593 0.6916666666666667\n",
      "3234 번째 loss, accuracy:  0.5310131672216635 0.6916666666666667\n",
      "3235 번째 loss, accuracy:  0.5309806149157459 0.6916666666666667\n",
      "3236 번째 loss, accuracy:  0.5309480836349525 0.6916666666666667\n",
      "3237 번째 loss, accuracy:  0.530915573358752 0.6916666666666667\n",
      "3238 번째 loss, accuracy:  0.5308830840666359 0.6916666666666667\n",
      "3239 번째 loss, accuracy:  0.5308506157381189 0.6916666666666667\n",
      "3240 번째 loss, accuracy:  0.5308181683527381 0.6916666666666667\n",
      "3241 번째 loss, accuracy:  0.5307857418900543 0.6916666666666667\n",
      "3242 번째 loss, accuracy:  0.5307533363296507 0.6916666666666667\n",
      "3243 번째 loss, accuracy:  0.5307209516511336 0.6916666666666667\n",
      "3244 번째 loss, accuracy:  0.5306885878341316 0.6916666666666667\n",
      "3245 번째 loss, accuracy:  0.5306562448582967 0.6916666666666667\n",
      "3246 번째 loss, accuracy:  0.5306239227033029 0.6916666666666667\n",
      "3247 번째 loss, accuracy:  0.5305916213488474 0.6916666666666667\n",
      "3248 번째 loss, accuracy:  0.5305593407746498 0.6916666666666667\n",
      "3249 번째 loss, accuracy:  0.5305270809604532 0.6916666666666667\n",
      "3250 번째 loss, accuracy:  0.5304948418860216 0.6916666666666667\n",
      "3251 번째 loss, accuracy:  0.5304626235311434 0.6916666666666667\n",
      "3252 번째 loss, accuracy:  0.5304304258756289 0.6916666666666667\n",
      "3253 번째 loss, accuracy:  0.5303982488993101 0.6916666666666667\n",
      "3254 번째 loss, accuracy:  0.5303660925820427 0.6916666666666667\n",
      "3255 번째 loss, accuracy:  0.530333956903704 0.6916666666666667\n",
      "3256 번째 loss, accuracy:  0.5303018418441945 0.6916666666666667\n",
      "3257 번째 loss, accuracy:  0.530269747383437 0.6916666666666667\n",
      "3258 번째 loss, accuracy:  0.5302376735013754 0.6916666666666667\n",
      "3259 번째 loss, accuracy:  0.5302056201779775 0.6916666666666667\n",
      "3260 번째 loss, accuracy:  0.5301735873932326 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3261 번째 loss, accuracy:  0.530141575127153 0.6916666666666667\n",
      "3262 번째 loss, accuracy:  0.5301095833597722 0.6916666666666667\n",
      "3263 번째 loss, accuracy:  0.5300776120711463 0.6916666666666667\n",
      "3264 번째 loss, accuracy:  0.5300456612413548 0.6916666666666667\n",
      "3265 번째 loss, accuracy:  0.5300137308504976 0.6916666666666667\n",
      "3266 번째 loss, accuracy:  0.5299818208786984 0.6916666666666667\n",
      "3267 번째 loss, accuracy:  0.5299499313061008 0.6916666666666667\n",
      "3268 번째 loss, accuracy:  0.5299180621128725 0.6916666666666667\n",
      "3269 번째 loss, accuracy:  0.5298862132792029 0.6916666666666667\n",
      "3270 번째 loss, accuracy:  0.5298543847853022 0.6916666666666667\n",
      "3271 번째 loss, accuracy:  0.529822576611404 0.6916666666666667\n",
      "3272 번째 loss, accuracy:  0.5297907887377632 0.6916666666666667\n",
      "3273 번째 loss, accuracy:  0.5297590211446568 0.6916666666666667\n",
      "3274 번째 loss, accuracy:  0.5297272738123834 0.6916666666666667\n",
      "3275 번째 loss, accuracy:  0.5296955467212637 0.6916666666666667\n",
      "3276 번째 loss, accuracy:  0.5296638398516403 0.6916666666666667\n",
      "3277 번째 loss, accuracy:  0.5296321531838781 0.6916666666666667\n",
      "3278 번째 loss, accuracy:  0.5296004866983628 0.6916666666666667\n",
      "3279 번째 loss, accuracy:  0.5295688403755021 0.6916666666666667\n",
      "3280 번째 loss, accuracy:  0.5295372141957262 0.6916666666666667\n",
      "3281 번째 loss, accuracy:  0.529505608139486 0.6916666666666667\n",
      "3282 번째 loss, accuracy:  0.5294740221872541 0.6916666666666667\n",
      "3283 번째 loss, accuracy:  0.5294424563195265 0.6916666666666667\n",
      "3284 번째 loss, accuracy:  0.5294109105168185 0.6916666666666667\n",
      "3285 번째 loss, accuracy:  0.5293793847596682 0.6916666666666667\n",
      "3286 번째 loss, accuracy:  0.5293478790286344 0.6916666666666667\n",
      "3287 번째 loss, accuracy:  0.5293163933042988 0.6916666666666667\n",
      "3288 번째 loss, accuracy:  0.5292849275672635 0.6916666666666667\n",
      "3289 번째 loss, accuracy:  0.5292534817981526 0.6916666666666667\n",
      "3290 번째 loss, accuracy:  0.529222055977612 0.6916666666666667\n",
      "3291 번째 loss, accuracy:  0.5291906500863068 0.6916666666666667\n",
      "3292 번째 loss, accuracy:  0.5291592641049265 0.6916666666666667\n",
      "3293 번째 loss, accuracy:  0.5291278980141798 0.6916666666666667\n",
      "3294 번째 loss, accuracy:  0.529096551794798 0.6916666666666667\n",
      "3295 번째 loss, accuracy:  0.5290652254275324 0.6916666666666667\n",
      "3296 번째 loss, accuracy:  0.5290339188931579 0.6916666666666667\n",
      "3297 번째 loss, accuracy:  0.5290026321724676 0.6916666666666667\n",
      "3298 번째 loss, accuracy:  0.5289713652462779 0.6916666666666667\n",
      "3299 번째 loss, accuracy:  0.5289401180954264 0.6916666666666667\n",
      "3300 번째 loss, accuracy:  0.5289088907007702 0.6916666666666667\n",
      "3301 번째 loss, accuracy:  0.528877683043189 0.6916666666666667\n",
      "3302 번째 loss, accuracy:  0.5288464951035835 0.6916666666666667\n",
      "3303 번째 loss, accuracy:  0.5288153268628751 0.6916666666666667\n",
      "3304 번째 loss, accuracy:  0.5287841783020062 0.6916666666666667\n",
      "3305 번째 loss, accuracy:  0.5287530494019398 0.6916666666666667\n",
      "3306 번째 loss, accuracy:  0.5287219401436606 0.6916666666666667\n",
      "3307 번째 loss, accuracy:  0.5286908505081748 0.6916666666666667\n",
      "3308 번째 loss, accuracy:  0.5286597804765079 0.6916666666666667\n",
      "3309 번째 loss, accuracy:  0.5286287300297077 0.6916666666666667\n",
      "3310 번째 loss, accuracy:  0.5285976991488422 0.6916666666666667\n",
      "3311 번째 loss, accuracy:  0.5285666878150008 0.6916666666666667\n",
      "3312 번째 loss, accuracy:  0.5285356960092928 0.6916666666666667\n",
      "3313 번째 loss, accuracy:  0.5285047237128492 0.6916666666666667\n",
      "3314 번째 loss, accuracy:  0.528473770906821 0.6916666666666667\n",
      "3315 번째 loss, accuracy:  0.528442837572381 0.6916666666666667\n",
      "3316 번째 loss, accuracy:  0.5284119236907215 0.6916666666666667\n",
      "3317 번째 loss, accuracy:  0.5283810292430562 0.6916666666666667\n",
      "3318 번째 loss, accuracy:  0.5283501542106189 0.6916666666666667\n",
      "3319 번째 loss, accuracy:  0.528319298574665 0.6916666666666667\n",
      "3320 번째 loss, accuracy:  0.52828846231647 0.6916666666666667\n",
      "3321 번째 loss, accuracy:  0.5282576454173292 0.6916666666666667\n",
      "3322 번째 loss, accuracy:  0.5282268478585593 0.6916666666666667\n",
      "3323 번째 loss, accuracy:  0.5281960696214976 0.6916666666666667\n",
      "3324 번째 loss, accuracy:  0.5281653106875017 0.6916666666666667\n",
      "3325 번째 loss, accuracy:  0.528134571037949 0.6916666666666667\n",
      "3326 번째 loss, accuracy:  0.5281038506542388 0.6916666666666667\n",
      "3327 번째 loss, accuracy:  0.5280731495177893 0.6916666666666667\n",
      "3328 번째 loss, accuracy:  0.5280424676100403 0.6916666666666667\n",
      "3329 번째 loss, accuracy:  0.5280118049124509 0.6916666666666667\n",
      "3330 번째 loss, accuracy:  0.5279811614065006 0.6916666666666667\n",
      "3331 번째 loss, accuracy:  0.5279505370736899 0.6916666666666667\n",
      "3332 번째 loss, accuracy:  0.5279199318955399 0.6916666666666667\n",
      "3333 번째 loss, accuracy:  0.5278893458535903 0.6916666666666667\n",
      "3334 번째 loss, accuracy:  0.5278587789294034 0.6916666666666667\n",
      "3335 번째 loss, accuracy:  0.5278282311045592 0.6916666666666667\n",
      "3336 번째 loss, accuracy:  0.5277977023606594 0.6916666666666667\n",
      "3337 번째 loss, accuracy:  0.5277671926793254 0.6916666666666667\n",
      "3338 번째 loss, accuracy:  0.5277367020421987 0.6916666666666667\n",
      "3339 번째 loss, accuracy:  0.5277062304309411 0.6916666666666667\n",
      "3340 번째 loss, accuracy:  0.5276757778272338 0.6916666666666667\n",
      "3341 번째 loss, accuracy:  0.5276453442127791 0.6916666666666667\n",
      "3342 번째 loss, accuracy:  0.5276149295692985 0.6916666666666667\n",
      "3343 번째 loss, accuracy:  0.5275845338785333 0.6916666666666667\n",
      "3344 번째 loss, accuracy:  0.5275541571222461 0.6916666666666667\n",
      "3345 번째 loss, accuracy:  0.5275237992822176 0.6916666666666667\n",
      "3346 번째 loss, accuracy:  0.5274934603402496 0.6916666666666667\n",
      "3347 번째 loss, accuracy:  0.5274631402781634 0.6916666666666667\n",
      "3348 번째 loss, accuracy:  0.5274328390778 0.6916666666666667\n",
      "3349 번째 loss, accuracy:  0.5274025567210209 0.6916666666666667\n",
      "3350 번째 loss, accuracy:  0.5273722931897064 0.6916666666666667\n",
      "3351 번째 loss, accuracy:  0.5273420484657573 0.6916666666666667\n",
      "3352 번째 loss, accuracy:  0.5273118225310939 0.6916666666666667\n",
      "3353 번째 loss, accuracy:  0.5272816153676565 0.6916666666666667\n",
      "3354 번째 loss, accuracy:  0.5272514269574045 0.6916666666666667\n",
      "3355 번째 loss, accuracy:  0.5272212572823171 0.6916666666666667\n",
      "3356 번째 loss, accuracy:  0.5271911063243935 0.6916666666666667\n",
      "3357 번째 loss, accuracy:  0.5271609740656524 0.6916666666666667\n",
      "3358 번째 loss, accuracy:  0.5271308604881321 0.6916666666666667\n",
      "3359 번째 loss, accuracy:  0.5271007655738895 0.6916666666666667\n",
      "3360 번째 loss, accuracy:  0.527070689305003 0.6916666666666667\n",
      "3361 번째 loss, accuracy:  0.5270406316635688 0.6916666666666667\n",
      "3362 번째 loss, accuracy:  0.5270105926317036 0.6916666666666667\n",
      "3363 번째 loss, accuracy:  0.5269805721915433 0.6916666666666667\n",
      "3364 번째 loss, accuracy:  0.526950570325242 0.6916666666666667\n",
      "3365 번째 loss, accuracy:  0.5269205870149752 0.6916666666666667\n",
      "3366 번째 loss, accuracy:  0.5268906222429367 0.6916666666666667\n",
      "3367 번째 loss, accuracy:  0.5268606759913393 0.6916666666666667\n",
      "3368 번째 loss, accuracy:  0.526830748242416 0.6916666666666667\n",
      "3369 번째 loss, accuracy:  0.5268008389784186 0.6916666666666667\n",
      "3370 번째 loss, accuracy:  0.5267709481816186 0.6916666666666667\n",
      "3371 번째 loss, accuracy:  0.5267410758343063 0.6916666666666667\n",
      "3372 번째 loss, accuracy:  0.5267112219187908 0.6916666666666667\n",
      "3373 번째 loss, accuracy:  0.5266813864174019 0.6916666666666667\n",
      "3374 번째 loss, accuracy:  0.5266515693124867 0.6916666666666667\n",
      "3375 번째 loss, accuracy:  0.5266217705864128 0.6916666666666667\n",
      "3376 번째 loss, accuracy:  0.5265919902215661 0.6916666666666667\n",
      "3377 번째 loss, accuracy:  0.5265622282003519 0.6916666666666667\n",
      "3378 번째 loss, accuracy:  0.5265324845051956 0.6916666666666667\n",
      "3379 번째 loss, accuracy:  0.5265027591185399 0.6916666666666667\n",
      "3380 번째 loss, accuracy:  0.5264730520228474 0.6916666666666667\n",
      "3381 번째 loss, accuracy:  0.5264433632006 0.6916666666666667\n",
      "3382 번째 loss, accuracy:  0.5264136926342976 0.6916666666666667\n",
      "3383 번째 loss, accuracy:  0.5263840403064602 0.6916666666666667\n",
      "3384 번째 loss, accuracy:  0.5263544061996257 0.6916666666666667\n",
      "3385 번째 loss, accuracy:  0.5263247902963514 0.6916666666666667\n",
      "3386 번째 loss, accuracy:  0.5262951925792139 0.6916666666666667\n",
      "3387 번째 loss, accuracy:  0.5262656130308075 0.6916666666666667\n",
      "3388 번째 loss, accuracy:  0.5262360516337462 0.6916666666666667\n",
      "3389 번째 loss, accuracy:  0.5262065083706624 0.6916666666666667\n",
      "3390 번째 loss, accuracy:  0.526176983224207 0.6916666666666667\n",
      "3391 번째 loss, accuracy:  0.526147476177051 0.6916666666666667\n",
      "3392 번째 loss, accuracy:  0.5261179872118824 0.6916666666666667\n",
      "3393 번째 loss, accuracy:  0.5260885163114094 0.6916666666666667\n",
      "3394 번째 loss, accuracy:  0.5260590634583572 0.6916666666666667\n",
      "3395 번째 loss, accuracy:  0.5260296286354713 0.6916666666666667\n",
      "3396 번째 loss, accuracy:  0.5260002118255148 0.6916666666666667\n",
      "3397 번째 loss, accuracy:  0.5259708130112698 0.6916666666666667\n",
      "3398 번째 loss, accuracy:  0.5259414321755372 0.6916666666666667\n",
      "3399 번째 loss, accuracy:  0.5259120693011352 0.6916666666666667\n",
      "3400 번째 loss, accuracy:  0.5258827243709027 0.6916666666666667\n",
      "3401 번째 loss, accuracy:  0.5258533973676951 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3402 번째 loss, accuracy:  0.5258240882743864 0.6916666666666667\n",
      "3403 번째 loss, accuracy:  0.5257947970738702 0.6916666666666667\n",
      "3404 번째 loss, accuracy:  0.5257655237490584 0.6916666666666667\n",
      "3405 번째 loss, accuracy:  0.52573626828288 0.6916666666666667\n",
      "3406 번째 loss, accuracy:  0.5257070306582841 0.6916666666666667\n",
      "3407 번째 loss, accuracy:  0.5256778108582362 0.6916666666666667\n",
      "3408 번째 loss, accuracy:  0.5256486088657221 0.6916666666666667\n",
      "3409 번째 loss, accuracy:  0.5256194246637445 0.6916666666666667\n",
      "3410 번째 loss, accuracy:  0.5255902582353253 0.6916666666666667\n",
      "3411 번째 loss, accuracy:  0.525561109563504 0.6916666666666667\n",
      "3412 번째 loss, accuracy:  0.5255319786313383 0.6916666666666667\n",
      "3413 번째 loss, accuracy:  0.5255028654219049 0.6916666666666667\n",
      "3414 번째 loss, accuracy:  0.5254737699182975 0.6916666666666667\n",
      "3415 번째 loss, accuracy:  0.5254446921036288 0.6916666666666667\n",
      "3416 번째 loss, accuracy:  0.5254156319610297 0.6916666666666667\n",
      "3417 번째 loss, accuracy:  0.525386589473649 0.6916666666666667\n",
      "3418 번째 loss, accuracy:  0.5253575646246532 0.6916666666666667\n",
      "3419 번째 loss, accuracy:  0.5253285573972273 0.6916666666666667\n",
      "3420 번째 loss, accuracy:  0.5252995677745741 0.6916666666666667\n",
      "3421 번째 loss, accuracy:  0.5252705957399146 0.6916666666666667\n",
      "3422 번째 loss, accuracy:  0.5252416412764878 0.6916666666666667\n",
      "3423 번째 loss, accuracy:  0.52521270436755 0.6916666666666667\n",
      "3424 번째 loss, accuracy:  0.5251837849963764 0.6916666666666667\n",
      "3425 번째 loss, accuracy:  0.5251548831462596 0.6916666666666667\n",
      "3426 번째 loss, accuracy:  0.5251259988005104 0.6916666666666667\n",
      "3427 번째 loss, accuracy:  0.5250971319424574 0.6916666666666667\n",
      "3428 번째 loss, accuracy:  0.5250682825554466 0.6916666666666667\n",
      "3429 번째 loss, accuracy:  0.5250394506228423 0.6916666666666667\n",
      "3430 번째 loss, accuracy:  0.5250106361280262 0.6916666666666667\n",
      "3431 번째 loss, accuracy:  0.5249818390543981 0.6916666666666667\n",
      "3432 번째 loss, accuracy:  0.5249530593853758 0.6916666666666667\n",
      "3433 번째 loss, accuracy:  0.524924297104394 0.6916666666666667\n",
      "3434 번째 loss, accuracy:  0.5248955521949057 0.6916666666666667\n",
      "3435 번째 loss, accuracy:  0.5248668246403816 0.6916666666666667\n",
      "3436 번째 loss, accuracy:  0.5248381144243103 0.6916666666666667\n",
      "3437 번째 loss, accuracy:  0.5248094215301975 0.6916666666666667\n",
      "3438 번째 loss, accuracy:  0.5247807459415658 0.6916666666666667\n",
      "3439 번째 loss, accuracy:  0.5247520876419567 0.6916666666666667\n",
      "3440 번째 loss, accuracy:  0.524723446614929 0.6916666666666667\n",
      "3441 번째 loss, accuracy:  0.5246948228440587 0.6916666666666667\n",
      "3442 번째 loss, accuracy:  0.5246662163129395 0.6916666666666667\n",
      "3443 번째 loss, accuracy:  0.5246376270051827 0.6916666666666667\n",
      "3444 번째 loss, accuracy:  0.5246090549044168 0.6916666666666667\n",
      "3445 번째 loss, accuracy:  0.5245804999942881 0.6916666666666667\n",
      "3446 번째 loss, accuracy:  0.5245519622584599 0.6916666666666667\n",
      "3447 번째 loss, accuracy:  0.5245234416806128 0.6916666666666667\n",
      "3448 번째 loss, accuracy:  0.5244949382444453 0.6916666666666667\n",
      "3449 번째 loss, accuracy:  0.5244664519336731 0.6916666666666667\n",
      "3450 번째 loss, accuracy:  0.524437982732029 0.6916666666666667\n",
      "3451 번째 loss, accuracy:  0.5244095306232637 0.6916666666666667\n",
      "3452 번째 loss, accuracy:  0.5243810955911442 0.6916666666666667\n",
      "3453 번째 loss, accuracy:  0.5243526776194556 0.6916666666666667\n",
      "3454 번째 loss, accuracy:  0.5243242766919999 0.6916666666666667\n",
      "3455 번째 loss, accuracy:  0.5242958927925959 0.6916666666666667\n",
      "3456 번째 loss, accuracy:  0.5242675259050809 0.6916666666666667\n",
      "3457 번째 loss, accuracy:  0.5242391760133075 0.6916666666666667\n",
      "3458 번째 loss, accuracy:  0.524210843101147 0.6916666666666667\n",
      "3459 번째 loss, accuracy:  0.5241825271524877 0.6916666666666667\n",
      "3460 번째 loss, accuracy:  0.5241542281512345 0.6916666666666667\n",
      "3461 번째 loss, accuracy:  0.5241259460813086 0.6916666666666667\n",
      "3462 번째 loss, accuracy:  0.5240976809266499 0.6916666666666667\n",
      "3463 번째 loss, accuracy:  0.5240694326712145 0.6916666666666667\n",
      "3464 번째 loss, accuracy:  0.5240412012989757 0.6916666666666667\n",
      "3465 번째 loss, accuracy:  0.5240129867939233 0.6916666666666667\n",
      "3466 번째 loss, accuracy:  0.5239847891400645 0.6916666666666667\n",
      "3467 번째 loss, accuracy:  0.5239566083214235 0.6916666666666667\n",
      "3468 번째 loss, accuracy:  0.523928444322041 0.6916666666666667\n",
      "3469 번째 loss, accuracy:  0.5239002971259755 0.6916666666666667\n",
      "3470 번째 loss, accuracy:  0.5238721667173013 0.6916666666666667\n",
      "3471 번째 loss, accuracy:  0.5238440530801104 0.6916666666666667\n",
      "3472 번째 loss, accuracy:  0.5238159561985108 0.6916666666666667\n",
      "3473 번째 loss, accuracy:  0.523787876056628 0.6916666666666667\n",
      "3474 번째 loss, accuracy:  0.5237598126386044 0.6916666666666667\n",
      "3475 번째 loss, accuracy:  0.5237317659285986 0.6916666666666667\n",
      "3476 번째 loss, accuracy:  0.5237037359107858 0.6916666666666667\n",
      "3477 번째 loss, accuracy:  0.5236757225693586 0.6916666666666667\n",
      "3478 번째 loss, accuracy:  0.5236477258885261 0.6916666666666667\n",
      "3479 번째 loss, accuracy:  0.523619745852514 0.6916666666666667\n",
      "3480 번째 loss, accuracy:  0.5235917824455645 0.6916666666666667\n",
      "3481 번째 loss, accuracy:  0.5235638356519369 0.6916666666666667\n",
      "3482 번째 loss, accuracy:  0.5235359054559059 0.6916666666666667\n",
      "3483 번째 loss, accuracy:  0.523507991841764 0.6916666666666667\n",
      "3484 번째 loss, accuracy:  0.5234800947938199 0.6916666666666667\n",
      "3485 번째 loss, accuracy:  0.5234522142963994 0.6916666666666667\n",
      "3486 번째 loss, accuracy:  0.5234243503338438 0.6916666666666667\n",
      "3487 번째 loss, accuracy:  0.5233965028905114 0.6916666666666667\n",
      "3488 번째 loss, accuracy:  0.5233686719507771 0.6916666666666667\n",
      "3489 번째 loss, accuracy:  0.5233408574990324 0.6916666666666667\n",
      "3490 번째 loss, accuracy:  0.5233130595196847 0.6916666666666667\n",
      "3491 번째 loss, accuracy:  0.5232852779971577 0.6916666666666667\n",
      "3492 번째 loss, accuracy:  0.5232575129158927 0.6916666666666667\n",
      "3493 번째 loss, accuracy:  0.523229764260346 0.6916666666666667\n",
      "3494 번째 loss, accuracy:  0.5232020320149905 0.6916666666666667\n",
      "3495 번째 loss, accuracy:  0.523174316164316 0.6916666666666667\n",
      "3496 번째 loss, accuracy:  0.5231466166928289 0.6916666666666667\n",
      "3497 번째 loss, accuracy:  0.5231189335850505 0.6916666666666667\n",
      "3498 번째 loss, accuracy:  0.52309126682552 0.6916666666666667\n",
      "3499 번째 loss, accuracy:  0.523063616398791 0.6916666666666667\n",
      "3500 번째 loss, accuracy:  0.5230359822894349 0.6916666666666667\n",
      "3501 번째 loss, accuracy:  0.5230083644820387 0.6916666666666667\n",
      "3502 번째 loss, accuracy:  0.5229807629612055 0.6916666666666667\n",
      "3503 번째 loss, accuracy:  0.5229531777115548 0.6916666666666667\n",
      "3504 번째 loss, accuracy:  0.522925608717722 0.6916666666666667\n",
      "3505 번째 loss, accuracy:  0.5228980559643586 0.6916666666666667\n",
      "3506 번째 loss, accuracy:  0.5228705194361324 0.6916666666666667\n",
      "3507 번째 loss, accuracy:  0.5228429991177269 0.6916666666666667\n",
      "3508 번째 loss, accuracy:  0.5228154949938423 0.6916666666666667\n",
      "3509 번째 loss, accuracy:  0.5227880070491943 0.6916666666666667\n",
      "3510 번째 loss, accuracy:  0.5227605352685153 0.6916666666666667\n",
      "3511 번째 loss, accuracy:  0.522733079636552 0.6916666666666667\n",
      "3512 번째 loss, accuracy:  0.5227056401380685 0.6916666666666667\n",
      "3513 번째 loss, accuracy:  0.5226782167578452 0.6916666666666667\n",
      "3514 번째 loss, accuracy:  0.5226508094806771 0.6916666666666667\n",
      "3515 번째 loss, accuracy:  0.5226234182913757 0.6916666666666667\n",
      "3516 번째 loss, accuracy:  0.522596043174769 0.6916666666666667\n",
      "3517 번째 loss, accuracy:  0.5225686841157001 0.6916666666666667\n",
      "3518 번째 loss, accuracy:  0.5225413410990281 0.6916666666666667\n",
      "3519 번째 loss, accuracy:  0.5225140141096277 0.6916666666666667\n",
      "3520 번째 loss, accuracy:  0.5224867031323899 0.6916666666666667\n",
      "3521 번째 loss, accuracy:  0.5224594081522211 0.6916666666666667\n",
      "3522 번째 loss, accuracy:  0.5224321291540438 0.6916666666666667\n",
      "3523 번째 loss, accuracy:  0.5224048661227957 0.6916666666666667\n",
      "3524 번째 loss, accuracy:  0.5223776190434305 0.6916666666666667\n",
      "3525 번째 loss, accuracy:  0.5223503879009176 0.6916666666666667\n",
      "3526 번째 loss, accuracy:  0.5223231726802425 0.6916666666666667\n",
      "3527 번째 loss, accuracy:  0.522295973366406 0.6916666666666667\n",
      "3528 번째 loss, accuracy:  0.5222687899444239 0.6916666666666667\n",
      "3529 번째 loss, accuracy:  0.5222416223993283 0.6916666666666667\n",
      "3530 번째 loss, accuracy:  0.5222144707161664 0.6916666666666667\n",
      "3531 번째 loss, accuracy:  0.5221873348800017 0.6916666666666667\n",
      "3532 번째 loss, accuracy:  0.5221602148759127 0.6916666666666667\n",
      "3533 번째 loss, accuracy:  0.5221331106889939 0.6916666666666667\n",
      "3534 번째 loss, accuracy:  0.5221060223043551 0.6916666666666667\n",
      "3535 번째 loss, accuracy:  0.5220789497071211 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3536 번째 loss, accuracy:  0.5220518928824326 0.6916666666666667\n",
      "3537 번째 loss, accuracy:  0.5220248518154459 0.6916666666666667\n",
      "3538 번째 loss, accuracy:  0.5219978264913325 0.6916666666666667\n",
      "3539 번째 loss, accuracy:  0.5219708168952787 0.6916666666666667\n",
      "3540 번째 loss, accuracy:  0.5219438230124874 0.6916666666666667\n",
      "3541 번째 loss, accuracy:  0.5219168448281762 0.6916666666666667\n",
      "3542 번째 loss, accuracy:  0.5218898823275779 0.6916666666666667\n",
      "3543 번째 loss, accuracy:  0.5218629354959413 0.6916666666666667\n",
      "3544 번째 loss, accuracy:  0.5218360043185294 0.6916666666666667\n",
      "3545 번째 loss, accuracy:  0.5218090887806214 0.6916666666666667\n",
      "3546 번째 loss, accuracy:  0.5217821888675113 0.6916666666666667\n",
      "3547 번째 loss, accuracy:  0.5217553045645084 0.6916666666666667\n",
      "3548 번째 loss, accuracy:  0.5217284358569376 0.6916666666666667\n",
      "3549 번째 loss, accuracy:  0.5217015827301387 0.6916666666666667\n",
      "3550 번째 loss, accuracy:  0.5216747451694667 0.6916666666666667\n",
      "3551 번째 loss, accuracy:  0.5216479231602916 0.6916666666666667\n",
      "3552 번째 loss, accuracy:  0.5216211166879992 0.6916666666666667\n",
      "3553 번째 loss, accuracy:  0.5215943257379895 0.6916666666666667\n",
      "3554 번째 loss, accuracy:  0.5215675502956783 0.6916666666666667\n",
      "3555 번째 loss, accuracy:  0.5215407903464959 0.6916666666666667\n",
      "3556 번째 loss, accuracy:  0.521514045875888 0.6916666666666667\n",
      "3557 번째 loss, accuracy:  0.5214873168693154 0.6916666666666667\n",
      "3558 번째 loss, accuracy:  0.5214606033122536 0.6916666666666667\n",
      "3559 번째 loss, accuracy:  0.5214339051901941 0.6916666666666667\n",
      "3560 번째 loss, accuracy:  0.5214072224886415 0.6916666666666667\n",
      "3561 번째 loss, accuracy:  0.5213805551931169 0.6916666666666667\n",
      "3562 번째 loss, accuracy:  0.5213539032891563 0.6916666666666667\n",
      "3563 번째 loss, accuracy:  0.5213272667623099 0.6916666666666667\n",
      "3564 번째 loss, accuracy:  0.5213006455981432 0.6916666666666667\n",
      "3565 번째 loss, accuracy:  0.5212740397822365 0.6916666666666667\n",
      "3566 번째 loss, accuracy:  0.521247449300185 0.6916666666666667\n",
      "3567 번째 loss, accuracy:  0.5212208741375985 0.6916666666666667\n",
      "3568 번째 loss, accuracy:  0.5211943142801022 0.6916666666666667\n",
      "3569 번째 loss, accuracy:  0.5211677697133359 0.6916666666666667\n",
      "3570 번째 loss, accuracy:  0.5211412404229533 0.6916666666666667\n",
      "3571 번째 loss, accuracy:  0.5211147263946245 0.6916666666666667\n",
      "3572 번째 loss, accuracy:  0.5210882276140324 0.6916666666666667\n",
      "3573 번째 loss, accuracy:  0.5210617440668763 0.6916666666666667\n",
      "3574 번째 loss, accuracy:  0.5210352757388695 0.6916666666666667\n",
      "3575 번째 loss, accuracy:  0.5210088226157403 0.6916666666666667\n",
      "3576 번째 loss, accuracy:  0.5209823846832309 0.6916666666666667\n",
      "3577 번째 loss, accuracy:  0.520955961927099 0.6916666666666667\n",
      "3578 번째 loss, accuracy:  0.5209295543331168 0.6916666666666667\n",
      "3579 번째 loss, accuracy:  0.5209031618870706 0.6916666666666667\n",
      "3580 번째 loss, accuracy:  0.5208767845747615 0.6916666666666667\n",
      "3581 번째 loss, accuracy:  0.5208504223820054 0.6916666666666667\n",
      "3582 번째 loss, accuracy:  0.5208240752946328 0.6916666666666667\n",
      "3583 번째 loss, accuracy:  0.5207977432984886 0.6916666666666667\n",
      "3584 번째 loss, accuracy:  0.5207714263794317 0.6916666666666667\n",
      "3585 번째 loss, accuracy:  0.5207451245233364 0.6916666666666667\n",
      "3586 번째 loss, accuracy:  0.5207188377160908 0.6916666666666667\n",
      "3587 번째 loss, accuracy:  0.5206925659435978 0.6916666666666667\n",
      "3588 번째 loss, accuracy:  0.5206663091917743 0.6916666666666667\n",
      "3589 번째 loss, accuracy:  0.5206400674465524 0.6916666666666667\n",
      "3590 번째 loss, accuracy:  0.5206138406938778 0.6916666666666667\n",
      "3591 번째 loss, accuracy:  0.520587628919711 0.6916666666666667\n",
      "3592 번째 loss, accuracy:  0.5205614321100271 0.6916666666666667\n",
      "3593 번째 loss, accuracy:  0.5205352502508149 0.6916666666666667\n",
      "3594 번째 loss, accuracy:  0.5205090833280778 0.6916666666666667\n",
      "3595 번째 loss, accuracy:  0.520482931327834 0.6916666666666667\n",
      "3596 번째 loss, accuracy:  0.5204567942361149 0.6916666666666667\n",
      "3597 번째 loss, accuracy:  0.5204306720389669 0.6916666666666667\n",
      "3598 번째 loss, accuracy:  0.5204045647224506 0.6916666666666667\n",
      "3599 번째 loss, accuracy:  0.5203784722726409 0.6916666666666667\n",
      "3600 번째 loss, accuracy:  0.5203523946756268 0.6916666666666667\n",
      "3601 번째 loss, accuracy:  0.520326331917511 0.6916666666666667\n",
      "3602 번째 loss, accuracy:  0.5203002839844115 0.6916666666666667\n",
      "3603 번째 loss, accuracy:  0.5202742508624598 0.6916666666666667\n",
      "3604 번째 loss, accuracy:  0.5202482325378011 0.6916666666666667\n",
      "3605 번째 loss, accuracy:  0.5202222289965952 0.6916666666666667\n",
      "3606 번째 loss, accuracy:  0.520196240225016 0.6916666666666667\n",
      "3607 번째 loss, accuracy:  0.5201702662092517 0.6916666666666667\n",
      "3608 번째 loss, accuracy:  0.5201443069355041 0.6916666666666667\n",
      "3609 번째 loss, accuracy:  0.5201183623899885 0.6916666666666667\n",
      "3610 번째 loss, accuracy:  0.5200924325589362 0.6916666666666667\n",
      "3611 번째 loss, accuracy:  0.5200665174285901 0.6916666666666667\n",
      "3612 번째 loss, accuracy:  0.5200406169852086 0.6916666666666667\n",
      "3613 번째 loss, accuracy:  0.5200147312150639 0.6916666666666667\n",
      "3614 번째 loss, accuracy:  0.5199888601044418 0.6916666666666667\n",
      "3615 번째 loss, accuracy:  0.5199630036396422 0.6916666666666667\n",
      "3616 번째 loss, accuracy:  0.5199371618069791 0.6916666666666667\n",
      "3617 번째 loss, accuracy:  0.5199113345927796 0.6916666666666667\n",
      "3618 번째 loss, accuracy:  0.5198855219833859 0.6916666666666667\n",
      "3619 번째 loss, accuracy:  0.5198597239651529 0.6916666666666667\n",
      "3620 번째 loss, accuracy:  0.5198339405244499 0.6916666666666667\n",
      "3621 번째 loss, accuracy:  0.5198081716476598 0.6916666666666667\n",
      "3622 번째 loss, accuracy:  0.5197824173211802 0.6916666666666667\n",
      "3623 번째 loss, accuracy:  0.5197566775314212 0.6916666666666667\n",
      "3624 번째 loss, accuracy:  0.5197309522648073 0.6916666666666667\n",
      "3625 번째 loss, accuracy:  0.5197052415077763 0.6916666666666667\n",
      "3626 번째 loss, accuracy:  0.5196795452467804 0.6916666666666667\n",
      "3627 번째 loss, accuracy:  0.5196538634682856 0.6916666666666667\n",
      "3628 번째 loss, accuracy:  0.5196281961587705 0.6916666666666667\n",
      "3629 번째 loss, accuracy:  0.5196025433047279 0.6916666666666667\n",
      "3630 번째 loss, accuracy:  0.5195769048926654 0.6916666666666667\n",
      "3631 번째 loss, accuracy:  0.5195512809091024 0.6916666666666667\n",
      "3632 번째 loss, accuracy:  0.5195256713405734 0.6916666666666667\n",
      "3633 번째 loss, accuracy:  0.519500076173625 0.6916666666666667\n",
      "3634 번째 loss, accuracy:  0.5194744953948188 0.6916666666666667\n",
      "3635 번째 loss, accuracy:  0.5194489289907299 0.6916666666666667\n",
      "3636 번째 loss, accuracy:  0.519423376947946 0.6916666666666667\n",
      "3637 번째 loss, accuracy:  0.5193978392530688 0.6916666666666667\n",
      "3638 번째 loss, accuracy:  0.5193723158927132 0.6916666666666667\n",
      "3639 번째 loss, accuracy:  0.5193468068535079 0.6916666666666667\n",
      "3640 번째 loss, accuracy:  0.5193213121220956 0.6916666666666667\n",
      "3641 번째 loss, accuracy:  0.5192958316851322 0.6916666666666667\n",
      "3642 번째 loss, accuracy:  0.5192703655292855 0.6916666666666667\n",
      "3643 번째 loss, accuracy:  0.5192449136412394 0.6916666666666667\n",
      "3644 번째 loss, accuracy:  0.5192194760076893 0.6916666666666667\n",
      "3645 번째 loss, accuracy:  0.519194052615344 0.6916666666666667\n",
      "3646 번째 loss, accuracy:  0.5191686434509271 0.6916666666666667\n",
      "3647 번째 loss, accuracy:  0.5191432485011738 0.6916666666666667\n",
      "3648 번째 loss, accuracy:  0.5191178677528338 0.6916666666666667\n",
      "3649 번째 loss, accuracy:  0.5190925011926695 0.6916666666666667\n",
      "3650 번째 loss, accuracy:  0.5190671488074572 0.6916666666666667\n",
      "3651 번째 loss, accuracy:  0.5190418105839865 0.6916666666666667\n",
      "3652 번째 loss, accuracy:  0.5190164865090593 0.6916666666666667\n",
      "3653 번째 loss, accuracy:  0.5189911765694918 0.6916666666666667\n",
      "3654 번째 loss, accuracy:  0.5189658807521123 0.6916666666666667\n",
      "3655 번째 loss, accuracy:  0.5189405990437639 0.6916666666666667\n",
      "3656 번째 loss, accuracy:  0.5189153314313016 0.6916666666666667\n",
      "3657 번째 loss, accuracy:  0.5188900779015935 0.6916666666666667\n",
      "3658 번째 loss, accuracy:  0.5188648384415224 0.6916666666666667\n",
      "3659 번째 loss, accuracy:  0.5188396130379825 0.6916666666666667\n",
      "3660 번째 loss, accuracy:  0.5188144016778816 0.6916666666666667\n",
      "3661 번째 loss, accuracy:  0.5187892043481416 0.6916666666666667\n",
      "3662 번째 loss, accuracy:  0.5187640210356957 0.6916666666666667\n",
      "3663 번째 loss, accuracy:  0.5187388517274921 0.6916666666666667\n",
      "3664 번째 loss, accuracy:  0.5187136964104904 0.6916666666666667\n",
      "3665 번째 loss, accuracy:  0.5186885550716639 0.6916666666666667\n",
      "3666 번째 loss, accuracy:  0.5186634276979999 0.6916666666666667\n",
      "3667 번째 loss, accuracy:  0.5186383142764975 0.6916666666666667\n",
      "3668 번째 loss, accuracy:  0.5186132147941689 0.6916666666666667\n",
      "3669 번째 loss, accuracy:  0.5185881292380391 0.6916666666666667\n",
      "3670 번째 loss, accuracy:  0.518563057595147 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671 번째 loss, accuracy:  0.518537999852543 0.6916666666666667\n",
      "3672 번째 loss, accuracy:  0.5185129559972921 0.6916666666666667\n",
      "3673 번째 loss, accuracy:  0.5184879260164709 0.6916666666666667\n",
      "3674 번째 loss, accuracy:  0.51846290989717 0.6916666666666667\n",
      "3675 번째 loss, accuracy:  0.5184379076264913 0.6916666666666667\n",
      "3676 번째 loss, accuracy:  0.5184129191915511 0.6916666666666667\n",
      "3677 번째 loss, accuracy:  0.5183879445794773 0.6916666666666667\n",
      "3678 번째 loss, accuracy:  0.5183629837774121 0.6916666666666667\n",
      "3679 번째 loss, accuracy:  0.5183380367725089 0.6916666666666667\n",
      "3680 번째 loss, accuracy:  0.5183131035519345 0.6916666666666667\n",
      "3681 번째 loss, accuracy:  0.518288184102869 0.6916666666666667\n",
      "3682 번째 loss, accuracy:  0.5182632784125045 0.6916666666666667\n",
      "3683 번째 loss, accuracy:  0.5182383864680463 0.6916666666666667\n",
      "3684 번째 loss, accuracy:  0.5182135082567122 0.6916666666666667\n",
      "3685 번째 loss, accuracy:  0.5181886437657329 0.6916666666666667\n",
      "3686 번째 loss, accuracy:  0.5181637929823517 0.6916666666666667\n",
      "3687 번째 loss, accuracy:  0.5181389558938243 0.6916666666666667\n",
      "3688 번째 loss, accuracy:  0.5181141324874192 0.6916666666666667\n",
      "3689 번째 loss, accuracy:  0.5180893227504175 0.6916666666666667\n",
      "3690 번째 loss, accuracy:  0.5180645266701129 0.6916666666666667\n",
      "3691 번째 loss, accuracy:  0.5180397442338119 0.6916666666666667\n",
      "3692 번째 loss, accuracy:  0.5180149754288339 0.6916666666666667\n",
      "3693 번째 loss, accuracy:  0.5179902202425102 0.6916666666666667\n",
      "3694 번째 loss, accuracy:  0.5179654786621843 0.6916666666666667\n",
      "3695 번째 loss, accuracy:  0.5179407506752137 0.6916666666666667\n",
      "3696 번째 loss, accuracy:  0.5179160362689669 0.6916666666666667\n",
      "3697 번째 loss, accuracy:  0.5178913354308257 0.6916666666666667\n",
      "3698 번째 loss, accuracy:  0.5178666481481841 0.6916666666666667\n",
      "3699 번째 loss, accuracy:  0.5178419744084486 0.6916666666666667\n",
      "3700 번째 loss, accuracy:  0.5178173141990389 0.6916666666666667\n",
      "3701 번째 loss, accuracy:  0.5177926675073853 0.6916666666666667\n",
      "3702 번째 loss, accuracy:  0.5177680343209329 0.6916666666666667\n",
      "3703 번째 loss, accuracy:  0.5177434146271366 0.6916666666666667\n",
      "3704 번째 loss, accuracy:  0.5177188084134661 0.6916666666666667\n",
      "3705 번째 loss, accuracy:  0.517694215667402 0.6916666666666667\n",
      "3706 번째 loss, accuracy:  0.5176696363764377 0.6916666666666667\n",
      "3707 번째 loss, accuracy:  0.5176450705280788 0.6916666666666667\n",
      "3708 번째 loss, accuracy:  0.5176205181098436 0.6916666666666667\n",
      "3709 번째 loss, accuracy:  0.5175959791092624 0.6916666666666667\n",
      "3710 번째 loss, accuracy:  0.5175714535138776 0.6916666666666667\n",
      "3711 번째 loss, accuracy:  0.517546941311244 0.6916666666666667\n",
      "3712 번째 loss, accuracy:  0.5175224424889288 0.6916666666666667\n",
      "3713 번째 loss, accuracy:  0.5174979570345116 0.6916666666666667\n",
      "3714 번째 loss, accuracy:  0.5174734849355834 0.6916666666666667\n",
      "3715 번째 loss, accuracy:  0.5174490261797486 0.6916666666666667\n",
      "3716 번째 loss, accuracy:  0.5174245807546227 0.6916666666666667\n",
      "3717 번째 loss, accuracy:  0.517400148647834 0.6916666666666667\n",
      "3718 번째 loss, accuracy:  0.5173757298470228 0.6916666666666667\n",
      "3719 번째 loss, accuracy:  0.5173513243398413 0.6916666666666667\n",
      "3720 번째 loss, accuracy:  0.5173269321139546 0.6916666666666667\n",
      "3721 번째 loss, accuracy:  0.5173025531570391 0.6916666666666667\n",
      "3722 번째 loss, accuracy:  0.5172781874567834 0.6916666666666667\n",
      "3723 번째 loss, accuracy:  0.5172538350008885 0.6916666666666667\n",
      "3724 번째 loss, accuracy:  0.5172294957770672 0.6916666666666667\n",
      "3725 번째 loss, accuracy:  0.5172051697730445 0.6916666666666667\n",
      "3726 번째 loss, accuracy:  0.5171808569765569 0.6916666666666667\n",
      "3727 번째 loss, accuracy:  0.5171565573753543 0.6916666666666667\n",
      "3728 번째 loss, accuracy:  0.5171322709571965 0.6916666666666667\n",
      "3729 번째 loss, accuracy:  0.5171079977098573 0.6916666666666667\n",
      "3730 번째 loss, accuracy:  0.5170837376211215 0.6916666666666667\n",
      "3731 번째 loss, accuracy:  0.5170594906787854 0.6916666666666667\n",
      "3732 번째 loss, accuracy:  0.5170352568706584 0.6916666666666667\n",
      "3733 번째 loss, accuracy:  0.517011036184561 0.6916666666666667\n",
      "3734 번째 loss, accuracy:  0.5169868286083258 0.6916666666666667\n",
      "3735 번째 loss, accuracy:  0.5169626341297973 0.6916666666666667\n",
      "3736 번째 loss, accuracy:  0.5169384527368317 0.6916666666666667\n",
      "3737 번째 loss, accuracy:  0.5169142844172971 0.6916666666666667\n",
      "3738 번째 loss, accuracy:  0.5168901291590743 0.6916666666666667\n",
      "3739 번째 loss, accuracy:  0.5168659869500544 0.6916666666666667\n",
      "3740 번째 loss, accuracy:  0.5168418577781412 0.6916666666666667\n",
      "3741 번째 loss, accuracy:  0.5168177416312505 0.6916666666666667\n",
      "3742 번째 loss, accuracy:  0.5167936384973094 0.6916666666666667\n",
      "3743 번째 loss, accuracy:  0.5167695483642561 0.6916666666666667\n",
      "3744 번째 loss, accuracy:  0.5167454712200427 0.6916666666666667\n",
      "3745 번째 loss, accuracy:  0.516721407052631 0.6916666666666667\n",
      "3746 번째 loss, accuracy:  0.5166973558499949 0.6916666666666667\n",
      "3747 번째 loss, accuracy:  0.5166733176001207 0.6916666666666667\n",
      "3748 번째 loss, accuracy:  0.5166492922910059 0.6916666666666667\n",
      "3749 번째 loss, accuracy:  0.5166252799106599 0.6916666666666667\n",
      "3750 번째 loss, accuracy:  0.5166012804471031 0.6916666666666667\n",
      "3751 번째 loss, accuracy:  0.5165772938883683 0.6916666666666667\n",
      "3752 번째 loss, accuracy:  0.5165533202224997 0.6916666666666667\n",
      "3753 번째 loss, accuracy:  0.516529359437553 0.6916666666666667\n",
      "3754 번째 loss, accuracy:  0.5165054115215953 0.6916666666666667\n",
      "3755 번째 loss, accuracy:  0.5164814764627058 0.6916666666666667\n",
      "3756 번째 loss, accuracy:  0.5164575542489745 0.6916666666666667\n",
      "3757 번째 loss, accuracy:  0.516433644868504 0.6916666666666667\n",
      "3758 번째 loss, accuracy:  0.5164097483094074 0.6916666666666667\n",
      "3759 번째 loss, accuracy:  0.5163858645598101 0.6916666666666667\n",
      "3760 번째 loss, accuracy:  0.5163619936078484 0.6916666666666667\n",
      "3761 번째 loss, accuracy:  0.5163381354416705 0.6916666666666667\n",
      "3762 번째 loss, accuracy:  0.5163142900494357 0.6916666666666667\n",
      "3763 번째 loss, accuracy:  0.5162904574193151 0.6916666666666667\n",
      "3764 번째 loss, accuracy:  0.5162666375394911 0.6916666666666667\n",
      "3765 번째 loss, accuracy:  0.5162428303981572 0.6916666666666667\n",
      "3766 번째 loss, accuracy:  0.5162190359835193 0.6916666666666667\n",
      "3767 번째 loss, accuracy:  0.5161952542837931 0.6916666666666667\n",
      "3768 번째 loss, accuracy:  0.5161714852872069 0.6916666666666667\n",
      "3769 번째 loss, accuracy:  0.5161477289820005 0.6916666666666667\n",
      "3770 번째 loss, accuracy:  0.5161239853564242 0.6916666666666667\n",
      "3771 번째 loss, accuracy:  0.5161002543987399 0.6916666666666667\n",
      "3772 번째 loss, accuracy:  0.516076536097221 0.6916666666666667\n",
      "3773 번째 loss, accuracy:  0.5160528304401525 0.6916666666666667\n",
      "3774 번째 loss, accuracy:  0.5160291374158302 0.6916666666666667\n",
      "3775 번째 loss, accuracy:  0.5160054570125608 0.6916666666666667\n",
      "3776 번째 loss, accuracy:  0.5159817892186631 0.6916666666666667\n",
      "3777 번째 loss, accuracy:  0.5159581340224666 0.6916666666666667\n",
      "3778 번째 loss, accuracy:  0.5159344914123125 0.6916666666666667\n",
      "3779 번째 loss, accuracy:  0.5159108613765531 0.6916666666666667\n",
      "3780 번째 loss, accuracy:  0.5158872439035508 0.6916666666666667\n",
      "3781 번째 loss, accuracy:  0.5158636389816814 0.6916666666666667\n",
      "3782 번째 loss, accuracy:  0.5158400465993296 0.6916666666666667\n",
      "3783 번째 loss, accuracy:  0.5158164667448923 0.6916666666666667\n",
      "3784 번째 loss, accuracy:  0.5157928994067776 0.6916666666666667\n",
      "3785 번째 loss, accuracy:  0.5157693445734046 0.6916666666666667\n",
      "3786 번째 loss, accuracy:  0.5157458022332037 0.6916666666666667\n",
      "3787 번째 loss, accuracy:  0.5157222723746159 0.6916666666666667\n",
      "3788 번째 loss, accuracy:  0.5156987549860935 0.6916666666666667\n",
      "3789 번째 loss, accuracy:  0.5156752500561005 0.6916666666666667\n",
      "3790 번째 loss, accuracy:  0.515651757573111 0.6916666666666667\n",
      "3791 번째 loss, accuracy:  0.5156282775256104 0.6916666666666667\n",
      "3792 번째 loss, accuracy:  0.5156048099020956 0.6916666666666667\n",
      "3793 번째 loss, accuracy:  0.5155813546910732 0.6916666666666667\n",
      "3794 번째 loss, accuracy:  0.5155579118810628 0.6916666666666667\n",
      "3795 번째 loss, accuracy:  0.5155344814605936 0.6916666666666667\n",
      "3796 번째 loss, accuracy:  0.5155110634182057 0.6916666666666667\n",
      "3797 번째 loss, accuracy:  0.5154876577424506 0.6916666666666667\n",
      "3798 번째 loss, accuracy:  0.5154642644218911 0.6916666666666667\n",
      "3799 번째 loss, accuracy:  0.5154408834451003 0.6916666666666667\n",
      "3800 번째 loss, accuracy:  0.5154175148006618 0.6916666666666667\n",
      "3801 번째 loss, accuracy:  0.5153941584771711 0.6916666666666667\n",
      "3802 번째 loss, accuracy:  0.5153708144632336 0.6916666666666667\n",
      "3803 번째 loss, accuracy:  0.5153474827474672 0.6916666666666667\n",
      "3804 번째 loss, accuracy:  0.5153241633184987 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3805 번째 loss, accuracy:  0.515300856164967 0.6916666666666667\n",
      "3806 번째 loss, accuracy:  0.515277561275521 0.6916666666666667\n",
      "3807 번째 loss, accuracy:  0.515254278638821 0.6916666666666667\n",
      "3808 번째 loss, accuracy:  0.5152310082435376 0.6916666666666667\n",
      "3809 번째 loss, accuracy:  0.5152077500783527 0.6916666666666667\n",
      "3810 번째 loss, accuracy:  0.5151845041319589 0.6916666666666667\n",
      "3811 번째 loss, accuracy:  0.5151612703930587 0.6916666666666667\n",
      "3812 번째 loss, accuracy:  0.5151380488503664 0.6916666666666667\n",
      "3813 번째 loss, accuracy:  0.5151148394926067 0.6916666666666667\n",
      "3814 번째 loss, accuracy:  0.5150916423085146 0.6916666666666667\n",
      "3815 번째 loss, accuracy:  0.515068457286836 0.6916666666666667\n",
      "3816 번째 loss, accuracy:  0.5150452844163278 0.6916666666666667\n",
      "3817 번째 loss, accuracy:  0.5150221236857573 0.6916666666666667\n",
      "3818 번째 loss, accuracy:  0.5149989750839026 0.6916666666666667\n",
      "3819 번째 loss, accuracy:  0.5149758385995524 0.6916666666666667\n",
      "3820 번째 loss, accuracy:  0.5149527142215055 0.6916666666666667\n",
      "3821 번째 loss, accuracy:  0.5149296019385716 0.6916666666666667\n",
      "3822 번째 loss, accuracy:  0.514906501739572 0.6916666666666667\n",
      "3823 번째 loss, accuracy:  0.5148834136133366 0.6916666666666667\n",
      "3824 번째 loss, accuracy:  0.5148603375487075 0.6916666666666667\n",
      "3825 번째 loss, accuracy:  0.5148372735345367 0.6916666666666667\n",
      "3826 번째 loss, accuracy:  0.5148142215596869 0.6916666666666667\n",
      "3827 번째 loss, accuracy:  0.5147911816130315 0.6916666666666667\n",
      "3828 번째 loss, accuracy:  0.5147681536834533 0.6916666666666667\n",
      "3829 번째 loss, accuracy:  0.514745137759847 0.6916666666666667\n",
      "3830 번째 loss, accuracy:  0.5147221338311174 0.6916666666666667\n",
      "3831 번째 loss, accuracy:  0.5146991418861792 0.6916666666666667\n",
      "3832 번째 loss, accuracy:  0.5146761619139578 0.6916666666666667\n",
      "3833 번째 loss, accuracy:  0.5146531939033893 0.6916666666666667\n",
      "3834 번째 loss, accuracy:  0.5146302378434203 0.6916666666666667\n",
      "3835 번째 loss, accuracy:  0.5146072937230078 0.6916666666666667\n",
      "3836 번째 loss, accuracy:  0.5145843615311188 0.6916666666666667\n",
      "3837 번째 loss, accuracy:  0.5145614412567302 0.6916666666666667\n",
      "3838 번째 loss, accuracy:  0.5145385328888311 0.6916666666666667\n",
      "3839 번째 loss, accuracy:  0.5145156364164187 0.6916666666666667\n",
      "3840 번째 loss, accuracy:  0.5144927518285024 0.6916666666666667\n",
      "3841 번째 loss, accuracy:  0.5144698791141005 0.6916666666666667\n",
      "3842 번째 loss, accuracy:  0.5144470182622431 0.6916666666666667\n",
      "3843 번째 loss, accuracy:  0.5144241692619687 0.6916666666666667\n",
      "3844 번째 loss, accuracy:  0.5144013321023277 0.6916666666666667\n",
      "3845 번째 loss, accuracy:  0.5143785067723804 0.6916666666666667\n",
      "3846 번째 loss, accuracy:  0.5143556932611968 0.6916666666666667\n",
      "3847 번째 loss, accuracy:  0.5143328915578576 0.6916666666666667\n",
      "3848 번째 loss, accuracy:  0.5143101016514535 0.6916666666666667\n",
      "3849 번째 loss, accuracy:  0.5142873235310861 0.6916666666666667\n",
      "3850 번째 loss, accuracy:  0.5142645571858667 0.6916666666666667\n",
      "3851 번째 loss, accuracy:  0.5142418026049164 0.6916666666666667\n",
      "3852 번째 loss, accuracy:  0.5142190597773663 0.6916666666666667\n",
      "3853 번째 loss, accuracy:  0.5141963286923585 0.6916666666666667\n",
      "3854 번째 loss, accuracy:  0.5141736093390453 0.6916666666666667\n",
      "3855 번째 loss, accuracy:  0.5141509017065886 0.6916666666666667\n",
      "3856 번째 loss, accuracy:  0.5141282057841605 0.6916666666666667\n",
      "3857 번째 loss, accuracy:  0.5141055215609434 0.6916666666666667\n",
      "3858 번째 loss, accuracy:  0.5140828490261297 0.6916666666666667\n",
      "3859 번째 loss, accuracy:  0.5140601881689213 0.6916666666666667\n",
      "3860 번째 loss, accuracy:  0.5140375389785317 0.6916666666666667\n",
      "3861 번째 loss, accuracy:  0.5140149014441828 0.6916666666666667\n",
      "3862 번째 loss, accuracy:  0.5139922755551072 0.6916666666666667\n",
      "3863 번째 loss, accuracy:  0.5139696613005476 0.6916666666666667\n",
      "3864 번째 loss, accuracy:  0.5139470586697568 0.6916666666666667\n",
      "3865 번째 loss, accuracy:  0.5139244676519976 0.6916666666666667\n",
      "3866 번째 loss, accuracy:  0.5139018882365424 0.6916666666666667\n",
      "3867 번째 loss, accuracy:  0.5138793204126743 0.6916666666666667\n",
      "3868 번째 loss, accuracy:  0.5138567641696855 0.6916666666666667\n",
      "3869 번째 loss, accuracy:  0.5138342194968782 0.6916666666666667\n",
      "3870 번째 loss, accuracy:  0.5138116863835653 0.6916666666666667\n",
      "3871 번째 loss, accuracy:  0.5137891648190693 0.6916666666666667\n",
      "3872 번째 loss, accuracy:  0.5137666547927221 0.6916666666666667\n",
      "3873 번째 loss, accuracy:  0.5137441562938658 0.6916666666666667\n",
      "3874 번째 loss, accuracy:  0.5137216693118527 0.6916666666666667\n",
      "3875 번째 loss, accuracy:  0.5136991938360449 0.6916666666666667\n",
      "3876 번째 loss, accuracy:  0.5136767298558138 0.6916666666666667\n",
      "3877 번째 loss, accuracy:  0.5136542773605414 0.6916666666666667\n",
      "3878 번째 loss, accuracy:  0.5136318363396188 0.6916666666666667\n",
      "3879 번째 loss, accuracy:  0.5136094067824476 0.6916666666666667\n",
      "3880 번째 loss, accuracy:  0.5135869886784387 0.6916666666666667\n",
      "3881 번째 loss, accuracy:  0.5135645820170129 0.6916666666666667\n",
      "3882 번째 loss, accuracy:  0.5135421867876013 0.6916666666666667\n",
      "3883 번째 loss, accuracy:  0.513519802979644 0.6916666666666667\n",
      "3884 번째 loss, accuracy:  0.513497430582591 0.6916666666666667\n",
      "3885 번째 loss, accuracy:  0.5134750695859022 0.6916666666666667\n",
      "3886 번째 loss, accuracy:  0.513452719979047 0.6916666666666667\n",
      "3887 번째 loss, accuracy:  0.513430381751505 0.6916666666666667\n",
      "3888 번째 loss, accuracy:  0.5134080548927654 0.6916666666666667\n",
      "3889 번째 loss, accuracy:  0.5133857393923268 0.6916666666666667\n",
      "3890 번째 loss, accuracy:  0.5133634352396974 0.6916666666666667\n",
      "3891 번째 loss, accuracy:  0.5133411424243952 0.6916666666666667\n",
      "3892 번째 loss, accuracy:  0.513318860935948 0.6916666666666667\n",
      "3893 번째 loss, accuracy:  0.5132965907638934 0.6916666666666667\n",
      "3894 번째 loss, accuracy:  0.5132743318977776 0.6916666666666667\n",
      "3895 번째 loss, accuracy:  0.5132520843271577 0.6916666666666667\n",
      "3896 번째 loss, accuracy:  0.5132298480415994 0.6916666666666667\n",
      "3897 번째 loss, accuracy:  0.513207623030679 0.6916666666666667\n",
      "3898 번째 loss, accuracy:  0.5131854092839816 0.6916666666666667\n",
      "3899 번째 loss, accuracy:  0.5131632067911014 0.6916666666666667\n",
      "3900 번째 loss, accuracy:  0.5131410155416435 0.6916666666666667\n",
      "3901 번째 loss, accuracy:  0.5131188355252218 0.6916666666666667\n",
      "3902 번째 loss, accuracy:  0.5130966667314592 0.6916666666666667\n",
      "3903 번째 loss, accuracy:  0.5130745091499889 0.6916666666666667\n",
      "3904 번째 loss, accuracy:  0.5130523627704537 0.6916666666666667\n",
      "3905 번째 loss, accuracy:  0.5130302275825048 0.6916666666666667\n",
      "3906 번째 loss, accuracy:  0.513008103575804 0.6916666666666667\n",
      "3907 번째 loss, accuracy:  0.5129859907400226 0.6916666666666667\n",
      "3908 번째 loss, accuracy:  0.51296388906484 0.6916666666666667\n",
      "3909 번째 loss, accuracy:  0.5129417985399467 0.6916666666666667\n",
      "3910 번째 loss, accuracy:  0.5129197191550409 0.6916666666666667\n",
      "3911 번째 loss, accuracy:  0.5128976508998313 0.6916666666666667\n",
      "3912 번째 loss, accuracy:  0.5128755937640364 0.6916666666666667\n",
      "3913 번째 loss, accuracy:  0.5128535477373833 0.6916666666666667\n",
      "3914 번째 loss, accuracy:  0.5128315128096083 0.6916666666666667\n",
      "3915 번째 loss, accuracy:  0.5128094889704579 0.6916666666666667\n",
      "3916 번째 loss, accuracy:  0.5127874762096867 0.6916666666666667\n",
      "3917 번째 loss, accuracy:  0.51276547451706 0.6916666666666667\n",
      "3918 번째 loss, accuracy:  0.5127434838823514 0.6916666666666667\n",
      "3919 번째 loss, accuracy:  0.5127215042953444 0.6916666666666667\n",
      "3920 번째 loss, accuracy:  0.5126995357458316 0.6916666666666667\n",
      "3921 번째 loss, accuracy:  0.5126775782236149 0.6916666666666667\n",
      "3922 번째 loss, accuracy:  0.5126556317185059 0.6916666666666667\n",
      "3923 번째 loss, accuracy:  0.5126336962203242 0.6916666666666667\n",
      "3924 번째 loss, accuracy:  0.5126117717188995 0.6916666666666667\n",
      "3925 번째 loss, accuracy:  0.5125898582040709 0.6916666666666667\n",
      "3926 번째 loss, accuracy:  0.5125679556656862 0.6916666666666667\n",
      "3927 번째 loss, accuracy:  0.5125460640936033 0.6916666666666667\n",
      "3928 번째 loss, accuracy:  0.5125241834776882 0.6916666666666667\n",
      "3929 번째 loss, accuracy:  0.5125023138078166 0.6916666666666667\n",
      "3930 번째 loss, accuracy:  0.5124804550738732 0.6916666666666667\n",
      "3931 번째 loss, accuracy:  0.5124586072657519 0.6916666666666667\n",
      "3932 번째 loss, accuracy:  0.5124367703733562 0.6916666666666667\n",
      "3933 번째 loss, accuracy:  0.5124149443865981 0.6916666666666667\n",
      "3934 번째 loss, accuracy:  0.5123931292953986 0.6916666666666667\n",
      "3935 번째 loss, accuracy:  0.5123713250896886 0.6916666666666667\n",
      "3936 번째 loss, accuracy:  0.5123495317594078 0.6916666666666667\n",
      "3937 번째 loss, accuracy:  0.5123277492945048 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3938 번째 loss, accuracy:  0.512305977684937 0.6916666666666667\n",
      "3939 번째 loss, accuracy:  0.5122842169206714 0.6916666666666667\n",
      "3940 번째 loss, accuracy:  0.5122624669916833 0.6916666666666667\n",
      "3941 번째 loss, accuracy:  0.5122407278879583 0.6916666666666667\n",
      "3942 번째 loss, accuracy:  0.5122189995994897 0.6916666666666667\n",
      "3943 번째 loss, accuracy:  0.5121972821162807 0.6916666666666667\n",
      "3944 번째 loss, accuracy:  0.5121755754283429 0.6916666666666667\n",
      "3945 번째 loss, accuracy:  0.5121538795256971 0.6916666666666667\n",
      "3946 번째 loss, accuracy:  0.5121321943983738 0.6916666666666667\n",
      "3947 번째 loss, accuracy:  0.5121105200364112 0.6916666666666667\n",
      "3948 번째 loss, accuracy:  0.5120888564298572 0.6916666666666667\n",
      "3949 번째 loss, accuracy:  0.5120672035687682 0.6916666666666667\n",
      "3950 번째 loss, accuracy:  0.5120455614432099 0.6916666666666667\n",
      "3951 번째 loss, accuracy:  0.512023930043257 0.6916666666666667\n",
      "3952 번째 loss, accuracy:  0.5120023093589926 0.6916666666666667\n",
      "3953 번째 loss, accuracy:  0.5119806993805092 0.6916666666666667\n",
      "3954 번째 loss, accuracy:  0.511959100097908 0.6916666666666667\n",
      "3955 번째 loss, accuracy:  0.5119375115012992 0.6916666666666667\n",
      "3956 번째 loss, accuracy:  0.5119159335808011 0.6916666666666667\n",
      "3957 번째 loss, accuracy:  0.5118943663265421 0.6916666666666667\n",
      "3958 번째 loss, accuracy:  0.5118728097286586 0.6916666666666667\n",
      "3959 번째 loss, accuracy:  0.5118512637772956 0.6916666666666667\n",
      "3960 번째 loss, accuracy:  0.5118297284626079 0.6916666666666667\n",
      "3961 번째 loss, accuracy:  0.5118082037747578 0.6916666666666667\n",
      "3962 번째 loss, accuracy:  0.5117866897039173 0.6916666666666667\n",
      "3963 번째 loss, accuracy:  0.5117651862402666 0.6916666666666667\n",
      "3964 번째 loss, accuracy:  0.5117436933739956 0.6916666666666667\n",
      "3965 번째 loss, accuracy:  0.5117222110953018 0.6916666666666667\n",
      "3966 번째 loss, accuracy:  0.5117007393943924 0.6916666666666667\n",
      "3967 번째 loss, accuracy:  0.5116792782614822 0.6916666666666667\n",
      "3968 번째 loss, accuracy:  0.5116578276867961 0.6916666666666667\n",
      "3969 번째 loss, accuracy:  0.5116363876605671 0.6916666666666667\n",
      "3970 번째 loss, accuracy:  0.5116149581730364 0.6916666666666667\n",
      "3971 번째 loss, accuracy:  0.511593539214454 0.6916666666666667\n",
      "3972 번째 loss, accuracy:  0.511572130775079 0.6916666666666667\n",
      "3973 번째 loss, accuracy:  0.5115507328451793 0.6916666666666667\n",
      "3974 번째 loss, accuracy:  0.5115293454150304 0.6916666666666667\n",
      "3975 번째 loss, accuracy:  0.511507968474918 0.6916666666666667\n",
      "3976 번째 loss, accuracy:  0.5114866020151346 0.6916666666666667\n",
      "3977 번째 loss, accuracy:  0.5114652460259829 0.6916666666666667\n",
      "3978 번째 loss, accuracy:  0.5114439004977732 0.6916666666666667\n",
      "3979 번째 loss, accuracy:  0.5114225654208251 0.6916666666666667\n",
      "3980 번째 loss, accuracy:  0.5114012407854659 0.6916666666666667\n",
      "3981 번째 loss, accuracy:  0.5113799265820325 0.6916666666666667\n",
      "3982 번째 loss, accuracy:  0.5113586228008694 0.6916666666666667\n",
      "3983 번째 loss, accuracy:  0.5113373294323302 0.6916666666666667\n",
      "3984 번째 loss, accuracy:  0.5113160464667772 0.6916666666666667\n",
      "3985 번째 loss, accuracy:  0.5112947738945804 0.6916666666666667\n",
      "3986 번째 loss, accuracy:  0.5112735117061189 0.6916666666666667\n",
      "3987 번째 loss, accuracy:  0.5112522598917805 0.6916666666666667\n",
      "3988 번째 loss, accuracy:  0.5112310184419605 0.6916666666666667\n",
      "3989 번째 loss, accuracy:  0.5112097873470637 0.6916666666666667\n",
      "3990 번째 loss, accuracy:  0.511188566597503 0.6916666666666667\n",
      "3991 번째 loss, accuracy:  0.5111673561836995 0.6916666666666667\n",
      "3992 번째 loss, accuracy:  0.5111461560960827 0.6916666666666667\n",
      "3993 번째 loss, accuracy:  0.5111249663250917 0.6916666666666667\n",
      "3994 번째 loss, accuracy:  0.5111037868611722 0.6916666666666667\n",
      "3995 번째 loss, accuracy:  0.5110826176947795 0.6916666666666667\n",
      "3996 번째 loss, accuracy:  0.5110614588163769 0.6916666666666667\n",
      "3997 번째 loss, accuracy:  0.5110403102164364 0.6916666666666667\n",
      "3998 번째 loss, accuracy:  0.5110191718854379 0.6916666666666667\n",
      "3999 번째 loss, accuracy:  0.5109980438138699 0.6916666666666667\n",
      "4000 번째 loss, accuracy:  0.5109769259922289 0.6916666666666667\n",
      "4001 번째 loss, accuracy:  0.5109558184110202 0.6916666666666667\n",
      "4002 번째 loss, accuracy:  0.5109347210607573 0.6916666666666667\n",
      "4003 번째 loss, accuracy:  0.5109136339319618 0.6916666666666667\n",
      "4004 번째 loss, accuracy:  0.5108925570151638 0.6916666666666667\n",
      "4005 번째 loss, accuracy:  0.510871490300902 0.6916666666666667\n",
      "4006 번째 loss, accuracy:  0.5108504337797226 0.6916666666666667\n",
      "4007 번째 loss, accuracy:  0.5108293874421809 0.6916666666666667\n",
      "4008 번째 loss, accuracy:  0.5108083512788394 0.6916666666666667\n",
      "4009 번째 loss, accuracy:  0.5107873252802698 0.6916666666666667\n",
      "4010 번째 loss, accuracy:  0.5107663094370516 0.6916666666666667\n",
      "4011 번째 loss, accuracy:  0.5107453037397727 0.6916666666666667\n",
      "4012 번째 loss, accuracy:  0.510724308179029 0.6916666666666667\n",
      "4013 번째 loss, accuracy:  0.5107033227454246 0.6916666666666667\n",
      "4014 번째 loss, accuracy:  0.5106823474295722 0.6916666666666667\n",
      "4015 번째 loss, accuracy:  0.5106613822220918 0.6916666666666667\n",
      "4016 번째 loss, accuracy:  0.510640427113613 0.6916666666666667\n",
      "4017 번째 loss, accuracy:  0.5106194820947724 0.6916666666666667\n",
      "4018 번째 loss, accuracy:  0.510598547156215 0.6916666666666667\n",
      "4019 번째 loss, accuracy:  0.5105776222885936 0.6916666666666667\n",
      "4020 번째 loss, accuracy:  0.5105567074825701 0.6916666666666667\n",
      "4021 번째 loss, accuracy:  0.5105358027288129 0.6916666666666667\n",
      "4022 번째 loss, accuracy:  0.5105149080180001 0.6916666666666667\n",
      "4023 번째 loss, accuracy:  0.5104940233408172 0.6916666666666667\n",
      "4024 번째 loss, accuracy:  0.510473148687958 0.6916666666666667\n",
      "4025 번째 loss, accuracy:  0.5104522840501239 0.6916666666666667\n",
      "4026 번째 loss, accuracy:  0.510431429418025 0.6916666666666667\n",
      "4027 번째 loss, accuracy:  0.5104105847823786 0.6916666666666667\n",
      "4028 번째 loss, accuracy:  0.5103897501339104 0.6916666666666667\n",
      "4029 번째 loss, accuracy:  0.5103689254633554 0.6916666666666667\n",
      "4030 번째 loss, accuracy:  0.5103481107614544 0.6916666666666667\n",
      "4031 번째 loss, accuracy:  0.5103273060189571 0.6916666666666667\n",
      "4032 번째 loss, accuracy:  0.5103065112266222 0.6916666666666667\n",
      "4033 번째 loss, accuracy:  0.5102857263752147 0.6916666666666667\n",
      "4034 번째 loss, accuracy:  0.5102649514555089 0.6916666666666667\n",
      "4035 번째 loss, accuracy:  0.5102441864582865 0.6916666666666667\n",
      "4036 번째 loss, accuracy:  0.5102234313743366 0.6916666666666667\n",
      "4037 번째 loss, accuracy:  0.5102026861944572 0.6916666666666667\n",
      "4038 번째 loss, accuracy:  0.5101819509094541 0.6916666666666667\n",
      "4039 번째 loss, accuracy:  0.5101612255101405 0.6916666666666667\n",
      "4040 번째 loss, accuracy:  0.5101405099873376 0.6916666666666667\n",
      "4041 번째 loss, accuracy:  0.5101198043318746 0.6916666666666667\n",
      "4042 번째 loss, accuracy:  0.5100991085345891 0.6916666666666667\n",
      "4043 번째 loss, accuracy:  0.510078422586325 0.6916666666666667\n",
      "4044 번째 loss, accuracy:  0.5100577464779363 0.6916666666666667\n",
      "4045 번째 loss, accuracy:  0.5100370802002829 0.6916666666666667\n",
      "4046 번째 loss, accuracy:  0.5100164237442342 0.6916666666666667\n",
      "4047 번째 loss, accuracy:  0.5099957771006653 0.6916666666666667\n",
      "4048 번째 loss, accuracy:  0.5099751402604614 0.6916666666666667\n",
      "4049 번째 loss, accuracy:  0.5099545132145139 0.6916666666666667\n",
      "4050 번째 loss, accuracy:  0.509933895953723 0.6916666666666667\n",
      "4051 번째 loss, accuracy:  0.5099132884689955 0.6916666666666667\n",
      "4052 번째 loss, accuracy:  0.5098926907512472 0.6916666666666667\n",
      "4053 번째 loss, accuracy:  0.5098721027914009 0.6916666666666667\n",
      "4054 번째 loss, accuracy:  0.5098515245803878 0.6916666666666667\n",
      "4055 번째 loss, accuracy:  0.509830956109146 0.6916666666666667\n",
      "4056 번째 loss, accuracy:  0.5098103973686218 0.6916666666666667\n",
      "4057 번째 loss, accuracy:  0.5097898483497697 0.6916666666666667\n",
      "4058 번째 loss, accuracy:  0.509769309043551 0.6916666666666667\n",
      "4059 번째 loss, accuracy:  0.5097487794409352 0.6916666666666667\n",
      "4060 번째 loss, accuracy:  0.5097282595328994 0.6916666666666667\n",
      "4061 번째 loss, accuracy:  0.5097077493104284 0.6916666666666667\n",
      "4062 번째 loss, accuracy:  0.5096872487645147 0.6916666666666667\n",
      "4063 번째 loss, accuracy:  0.5096667578861581 0.6916666666666667\n",
      "4064 번째 loss, accuracy:  0.5096462766663669 0.6916666666666667\n",
      "4065 번째 loss, accuracy:  0.5096258050961556 0.6916666666666667\n",
      "4066 번째 loss, accuracy:  0.509605343166548 0.6916666666666667\n",
      "4067 번째 loss, accuracy:  0.5095848908685742 0.6916666666666667\n",
      "4068 번째 loss, accuracy:  0.5095644481932723 0.6916666666666667\n",
      "4069 번째 loss, accuracy:  0.5095440151316886 0.6916666666666667\n",
      "4070 번째 loss, accuracy:  0.509523591674876 0.6916666666666667\n",
      "4071 번째 loss, accuracy:  0.5095031778138959 0.6916666666666667\n",
      "4072 번째 loss, accuracy:  0.5094827735398162 0.6916666666666667\n",
      "4073 번째 loss, accuracy:  0.5094623788437137 0.6916666666666667\n",
      "4074 번째 loss, accuracy:  0.509441993716672 0.6916666666666667\n",
      "4075 번째 loss, accuracy:  0.5094216181497815 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4076 번째 loss, accuracy:  0.5094012521341414 0.6916666666666667\n",
      "4077 번째 loss, accuracy:  0.5093808956608581 0.6916666666666667\n",
      "4078 번째 loss, accuracy:  0.5093605487210445 0.6916666666666667\n",
      "4079 번째 loss, accuracy:  0.5093402113058227 0.6916666666666667\n",
      "4080 번째 loss, accuracy:  0.5093198834063205 0.6916666666666667\n",
      "4081 번째 loss, accuracy:  0.5092995650136743 0.6916666666666667\n",
      "4082 번째 loss, accuracy:  0.5092792561190278 0.6916666666666667\n",
      "4083 번째 loss, accuracy:  0.5092589567135318 0.6916666666666667\n",
      "4084 번째 loss, accuracy:  0.5092386667883451 0.6916666666666667\n",
      "4085 번째 loss, accuracy:  0.5092183863346331 0.6916666666666667\n",
      "4086 번째 loss, accuracy:  0.5091981153435692 0.6916666666666667\n",
      "4087 번째 loss, accuracy:  0.5091778538063344 0.6916666666666667\n",
      "4088 번째 loss, accuracy:  0.5091576017141166 0.6916666666666667\n",
      "4089 번째 loss, accuracy:  0.5091373590581111 0.6916666666666667\n",
      "4090 번째 loss, accuracy:  0.5091171258295211 0.6916666666666667\n",
      "4091 번째 loss, accuracy:  0.5090969020195568 0.6916666666666667\n",
      "4092 번째 loss, accuracy:  0.5090766876194355 0.6916666666666667\n",
      "4093 번째 loss, accuracy:  0.5090564826203826 0.6916666666666667\n",
      "4094 번째 loss, accuracy:  0.5090362870136299 0.6916666666666667\n",
      "4095 번째 loss, accuracy:  0.509016100790417 0.6916666666666667\n",
      "4096 번째 loss, accuracy:  0.5089959239419911 0.6916666666666667\n",
      "4097 번째 loss, accuracy:  0.5089757564596067 0.6916666666666667\n",
      "4098 번째 loss, accuracy:  0.5089555983345242 0.6916666666666667\n",
      "4099 번째 loss, accuracy:  0.5089354495580132 0.6916666666666667\n",
      "4100 번째 loss, accuracy:  0.5089153101213498 0.6916666666666667\n",
      "4101 번째 loss, accuracy:  0.5088951800158171 0.6916666666666667\n",
      "4102 번째 loss, accuracy:  0.508875059232706 0.6916666666666667\n",
      "4103 번째 loss, accuracy:  0.508854947763314 0.6916666666666667\n",
      "4104 번째 loss, accuracy:  0.5088348455989464 0.6916666666666667\n",
      "4105 번째 loss, accuracy:  0.5088147527309157 0.6916666666666667\n",
      "4106 번째 loss, accuracy:  0.5087946691505406 0.6916666666666667\n",
      "4107 번째 loss, accuracy:  0.5087745948491483 0.6916666666666667\n",
      "4108 번째 loss, accuracy:  0.508754529818073 0.6916666666666667\n",
      "4109 번째 loss, accuracy:  0.5087344740486553 0.6916666666666667\n",
      "4110 번째 loss, accuracy:  0.5087144275322442 0.6916666666666667\n",
      "4111 번째 loss, accuracy:  0.5086943902601945 0.6916666666666667\n",
      "4112 번째 loss, accuracy:  0.5086743622238686 0.6916666666666667\n",
      "4113 번째 loss, accuracy:  0.5086543434146368 0.6916666666666667\n",
      "4114 번째 loss, accuracy:  0.5086343338238757 0.6916666666666667\n",
      "4115 번째 loss, accuracy:  0.5086143334429697 0.6916666666666667\n",
      "4116 번째 loss, accuracy:  0.5085943422633094 0.6916666666666667\n",
      "4117 번째 loss, accuracy:  0.5085743602762929 0.6916666666666667\n",
      "4118 번째 loss, accuracy:  0.5085543874733263 0.6916666666666667\n",
      "4119 번째 loss, accuracy:  0.5085344238458215 0.6916666666666667\n",
      "4120 번째 loss, accuracy:  0.508514469385198 0.6916666666666667\n",
      "4121 번째 loss, accuracy:  0.5084945240828828 0.6916666666666667\n",
      "4122 번째 loss, accuracy:  0.5084745879303089 0.6916666666666667\n",
      "4123 번째 loss, accuracy:  0.508454660918917 0.6916666666666667\n",
      "4124 번째 loss, accuracy:  0.508434743040155 0.6916666666666667\n",
      "4125 번째 loss, accuracy:  0.5084148342854777 0.6916666666666667\n",
      "4126 번째 loss, accuracy:  0.5083949346463467 0.6916666666666667\n",
      "4127 번째 loss, accuracy:  0.5083750441142308 0.6916666666666667\n",
      "4128 번째 loss, accuracy:  0.5083551626806055 0.6916666666666667\n",
      "4129 번째 loss, accuracy:  0.5083352903369542 0.6916666666666667\n",
      "4130 번째 loss, accuracy:  0.5083154270747661 0.6916666666666667\n",
      "4131 번째 loss, accuracy:  0.5082955728855378 0.6916666666666667\n",
      "4132 번째 loss, accuracy:  0.5082757277607735 0.6916666666666667\n",
      "4133 번째 loss, accuracy:  0.5082558916919832 0.6916666666666667\n",
      "4134 번째 loss, accuracy:  0.5082360646706846 0.6916666666666667\n",
      "4135 번째 loss, accuracy:  0.5082162466884025 0.6916666666666667\n",
      "4136 번째 loss, accuracy:  0.5081964377366676 0.6916666666666667\n",
      "4137 번째 loss, accuracy:  0.5081766378070188 0.6916666666666667\n",
      "4138 번째 loss, accuracy:  0.5081568468910015 0.6916666666666667\n",
      "4139 번째 loss, accuracy:  0.5081370649801674 0.6916666666666667\n",
      "4140 번째 loss, accuracy:  0.5081172920660754 0.6916666666666667\n",
      "4141 번째 loss, accuracy:  0.5080975281402915 0.6916666666666667\n",
      "4142 번째 loss, accuracy:  0.5080777731943883 0.6916666666666667\n",
      "4143 번째 loss, accuracy:  0.5080580272199456 0.6916666666666667\n",
      "4144 번째 loss, accuracy:  0.5080382902085496 0.6916666666666667\n",
      "4145 번째 loss, accuracy:  0.5080185621517939 0.6916666666666667\n",
      "4146 번째 loss, accuracy:  0.5079988430412778 0.6916666666666667\n",
      "4147 번째 loss, accuracy:  0.5079791328686091 0.6916666666666667\n",
      "4148 번째 loss, accuracy:  0.507959431625401 0.6916666666666667\n",
      "4149 번째 loss, accuracy:  0.5079397393032739 0.6916666666666667\n",
      "4150 번째 loss, accuracy:  0.5079200558938551 0.6916666666666667\n",
      "4151 번째 loss, accuracy:  0.5079003813887795 0.6916666666666667\n",
      "4152 번째 loss, accuracy:  0.5078807157796866 0.6916666666666667\n",
      "4153 번째 loss, accuracy:  0.5078610590582245 0.6916666666666667\n",
      "4154 번째 loss, accuracy:  0.5078414112160481 0.6916666666666667\n",
      "4155 번째 loss, accuracy:  0.5078217722448177 0.6916666666666667\n",
      "4156 번째 loss, accuracy:  0.5078021421362015 0.6916666666666667\n",
      "4157 번째 loss, accuracy:  0.5077825208818741 0.6916666666666667\n",
      "4158 번째 loss, accuracy:  0.5077629084735168 0.6916666666666667\n",
      "4159 번째 loss, accuracy:  0.5077433049028168 0.6916666666666667\n",
      "4160 번째 loss, accuracy:  0.5077237101614698 0.6916666666666667\n",
      "4161 번째 loss, accuracy:  0.5077041242411761 0.6916666666666667\n",
      "4162 번째 loss, accuracy:  0.5076845471336442 0.6916666666666667\n",
      "4163 번째 loss, accuracy:  0.5076649788305887 0.6916666666666667\n",
      "4164 번째 loss, accuracy:  0.5076454193237309 0.6916666666666667\n",
      "4165 번째 loss, accuracy:  0.5076258686047986 0.6916666666666667\n",
      "4166 번째 loss, accuracy:  0.5076063266655267 0.6916666666666667\n",
      "4167 번째 loss, accuracy:  0.5075867934976562 0.6916666666666667\n",
      "4168 번째 loss, accuracy:  0.5075672690929353 0.6916666666666667\n",
      "4169 번째 loss, accuracy:  0.5075477534431178 0.6916666666666667\n",
      "4170 번째 loss, accuracy:  0.5075282465399653 0.6916666666666667\n",
      "4171 번째 loss, accuracy:  0.5075087483752453 0.6916666666666667\n",
      "4172 번째 loss, accuracy:  0.5074892589407317 0.6916666666666667\n",
      "4173 번째 loss, accuracy:  0.5074697782282055 0.6916666666666667\n",
      "4174 번째 loss, accuracy:  0.5074503062294543 0.6916666666666667\n",
      "4175 번째 loss, accuracy:  0.5074308429362719 0.6916666666666667\n",
      "4176 번째 loss, accuracy:  0.5074113883404582 0.6916666666666667\n",
      "4177 번째 loss, accuracy:  0.5073919424338211 0.6916666666666667\n",
      "4178 번째 loss, accuracy:  0.5073725052081735 0.6916666666666667\n",
      "4179 번째 loss, accuracy:  0.5073530766553357 0.6916666666666667\n",
      "4180 번째 loss, accuracy:  0.5073336567671337 0.6916666666666667\n",
      "4181 번째 loss, accuracy:  0.507314245535401 0.6916666666666667\n",
      "4182 번째 loss, accuracy:  0.5072948429519767 0.6916666666666667\n",
      "4183 번째 loss, accuracy:  0.5072754490087075 0.6916666666666667\n",
      "4184 번째 loss, accuracy:  0.5072560636974454 0.6916666666666667\n",
      "4185 번째 loss, accuracy:  0.5072366870100492 0.6916666666666667\n",
      "4186 번째 loss, accuracy:  0.5072173189383847 0.6916666666666667\n",
      "4187 번째 loss, accuracy:  0.5071979594743233 0.6916666666666667\n",
      "4188 번째 loss, accuracy:  0.5071786086097435 0.6916666666666667\n",
      "4189 번째 loss, accuracy:  0.50715926633653 0.6916666666666667\n",
      "4190 번째 loss, accuracy:  0.5071399326465736 0.6916666666666667\n",
      "4191 번째 loss, accuracy:  0.5071206075317728 0.6916666666666667\n",
      "4192 번째 loss, accuracy:  0.5071012909840301 0.6916666666666667\n",
      "4193 번째 loss, accuracy:  0.5070819829952568 0.6916666666666667\n",
      "4194 번째 loss, accuracy:  0.5070626835573693 0.6916666666666667\n",
      "4195 번째 loss, accuracy:  0.5070433926622899 0.6916666666666667\n",
      "4196 번째 loss, accuracy:  0.507024110301949 0.6916666666666667\n",
      "4197 번째 loss, accuracy:  0.5070048364682821 0.6916666666666667\n",
      "4198 번째 loss, accuracy:  0.5069855711532311 0.6916666666666667\n",
      "4199 번째 loss, accuracy:  0.5069663143487444 0.6916666666666667\n",
      "4200 번째 loss, accuracy:  0.5069470660467771 0.6916666666666667\n",
      "4201 번째 loss, accuracy:  0.50692782623929 0.6916666666666667\n",
      "4202 번째 loss, accuracy:  0.5069085949182504 0.6916666666666667\n",
      "4203 번째 loss, accuracy:  0.5068893720756321 0.6916666666666667\n",
      "4204 번째 loss, accuracy:  0.5068701577034154 0.6916666666666667\n",
      "4205 번째 loss, accuracy:  0.5068509517935859 0.6916666666666667\n",
      "4206 번째 loss, accuracy:  0.5068317543381367 0.6916666666666667\n",
      "4207 번째 loss, accuracy:  0.5068125653290658 0.6916666666666667\n",
      "4208 번째 loss, accuracy:  0.506793384758379 0.6916666666666667\n",
      "4209 번째 loss, accuracy:  0.5067742126180875 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4210 번째 loss, accuracy:  0.5067550489002086 0.6916666666666667\n",
      "4211 번째 loss, accuracy:  0.5067358935967662 0.6916666666666667\n",
      "4212 번째 loss, accuracy:  0.5067167466997903 0.6916666666666667\n",
      "4213 번째 loss, accuracy:  0.5066976082013165 0.6916666666666667\n",
      "4214 번째 loss, accuracy:  0.5066784780933882 0.6916666666666667\n",
      "4215 번째 loss, accuracy:  0.506659356368053 0.6916666666666667\n",
      "4216 번째 loss, accuracy:  0.5066402430173665 0.6916666666666667\n",
      "4217 번째 loss, accuracy:  0.5066211380333893 0.6916666666666667\n",
      "4218 번째 loss, accuracy:  0.5066020414081878 0.6916666666666667\n",
      "4219 번째 loss, accuracy:  0.5065829531338361 0.6916666666666667\n",
      "4220 번째 loss, accuracy:  0.5065638732024137 0.6916666666666667\n",
      "4221 번째 loss, accuracy:  0.5065448016060057 0.6916666666666667\n",
      "4222 번째 loss, accuracy:  0.5065257383367038 0.6916666666666667\n",
      "4223 번째 loss, accuracy:  0.5065066833866054 0.6916666666666667\n",
      "4224 번째 loss, accuracy:  0.5064876367478152 0.6916666666666667\n",
      "4225 번째 loss, accuracy:  0.5064685984124425 0.6916666666666667\n",
      "4226 번째 loss, accuracy:  0.5064495683726038 0.6916666666666667\n",
      "4227 번째 loss, accuracy:  0.5064305466204212 0.6916666666666667\n",
      "4228 번째 loss, accuracy:  0.5064115331480233 0.6916666666666667\n",
      "4229 번째 loss, accuracy:  0.5063925279475439 0.6916666666666667\n",
      "4230 번째 loss, accuracy:  0.5063735310111236 0.6916666666666667\n",
      "4231 번째 loss, accuracy:  0.5063545423309088 0.6916666666666667\n",
      "4232 번째 loss, accuracy:  0.5063355618990522 0.6916666666666667\n",
      "4233 번째 loss, accuracy:  0.5063165897077121 0.6916666666666667\n",
      "4234 번째 loss, accuracy:  0.5062976257490529 0.6916666666666667\n",
      "4235 번째 loss, accuracy:  0.5062786700152456 0.6916666666666667\n",
      "4236 번째 loss, accuracy:  0.5062597224984665 0.6916666666666667\n",
      "4237 번째 loss, accuracy:  0.5062407831908984 0.6916666666666667\n",
      "4238 번째 loss, accuracy:  0.5062218520847296 0.6916666666666667\n",
      "4239 번째 loss, accuracy:  0.5062029291721541 0.6916666666666667\n",
      "4240 번째 loss, accuracy:  0.5061840144453738 0.6916666666666667\n",
      "4241 번째 loss, accuracy:  0.506165107896594 0.6916666666666667\n",
      "4242 번째 loss, accuracy:  0.5061462095180276 0.6916666666666667\n",
      "4243 번째 loss, accuracy:  0.5061273193018934 0.6916666666666667\n",
      "4244 번째 loss, accuracy:  0.5061084372404152 0.6916666666666667\n",
      "4245 번째 loss, accuracy:  0.5060895633258231 0.6916666666666667\n",
      "4246 번째 loss, accuracy:  0.5060706975503542 0.6916666666666667\n",
      "4247 번째 loss, accuracy:  0.5060518399062491 0.6916666666666667\n",
      "4248 번째 loss, accuracy:  0.5060329903857571 0.6916666666666667\n",
      "4249 번째 loss, accuracy:  0.5060141489811315 0.6916666666666667\n",
      "4250 번째 loss, accuracy:  0.5059953156846325 0.6916666666666667\n",
      "4251 번째 loss, accuracy:  0.5059764904885253 0.6916666666666667\n",
      "4252 번째 loss, accuracy:  0.505957673385082 0.6916666666666667\n",
      "4253 번째 loss, accuracy:  0.5059388643665794 0.6916666666666667\n",
      "4254 번째 loss, accuracy:  0.5059200634253009 0.6916666666666667\n",
      "4255 번째 loss, accuracy:  0.5059012705535362 0.6916666666666667\n",
      "4256 번째 loss, accuracy:  0.5058824857435796 0.6916666666666667\n",
      "4257 번째 loss, accuracy:  0.505863708987732 0.6916666666666667\n",
      "4258 번째 loss, accuracy:  0.5058449402783001 0.6916666666666667\n",
      "4259 번째 loss, accuracy:  0.5058261796075966 0.6916666666666667\n",
      "4260 번째 loss, accuracy:  0.5058074269679392 0.6916666666666667\n",
      "4261 번째 loss, accuracy:  0.5057886823516522 0.6916666666666667\n",
      "4262 번째 loss, accuracy:  0.5057699457510649 0.6916666666666667\n",
      "4263 번째 loss, accuracy:  0.5057512171585137 0.6916666666666667\n",
      "4264 번째 loss, accuracy:  0.5057324965663391 0.6916666666666667\n",
      "4265 번째 loss, accuracy:  0.5057137839668887 0.6916666666666667\n",
      "4266 번째 loss, accuracy:  0.5056950793525152 0.6916666666666667\n",
      "4267 번째 loss, accuracy:  0.5056763827155772 0.6916666666666667\n",
      "4268 번째 loss, accuracy:  0.5056576940484392 0.6916666666666667\n",
      "4269 번째 loss, accuracy:  0.5056390133434714 0.6916666666666667\n",
      "4270 번째 loss, accuracy:  0.5056203405930493 0.6916666666666667\n",
      "4271 번째 loss, accuracy:  0.5056016757895544 0.6916666666666667\n",
      "4272 번째 loss, accuracy:  0.5055830189253739 0.6916666666666667\n",
      "4273 번째 loss, accuracy:  0.5055643699929009 0.6916666666666667\n",
      "4274 번째 loss, accuracy:  0.5055457289845339 0.6916666666666667\n",
      "4275 번째 loss, accuracy:  0.505527095892677 0.6916666666666667\n",
      "4276 번째 loss, accuracy:  0.50550847070974 0.6916666666666667\n",
      "4277 번째 loss, accuracy:  0.505489853428139 0.6916666666666667\n",
      "4278 번째 loss, accuracy:  0.505471244040295 0.6916666666666667\n",
      "4279 번째 loss, accuracy:  0.5054526425386353 0.6916666666666667\n",
      "4280 번째 loss, accuracy:  0.5054340489155916 0.6916666666666667\n",
      "4281 번째 loss, accuracy:  0.5054154631636024 0.6916666666666667\n",
      "4282 번째 loss, accuracy:  0.5053968852751118 0.6916666666666667\n",
      "4283 번째 loss, accuracy:  0.5053783152425692 0.6916666666666667\n",
      "4284 번째 loss, accuracy:  0.5053597530584291 0.6916666666666667\n",
      "4285 번째 loss, accuracy:  0.5053411987151525 0.6916666666666667\n",
      "4286 번째 loss, accuracy:  0.5053226522052053 0.6916666666666667\n",
      "4287 번째 loss, accuracy:  0.5053041135210596 0.6916666666666667\n",
      "4288 번째 loss, accuracy:  0.5052855826551927 0.6916666666666667\n",
      "4289 번째 loss, accuracy:  0.5052670596000871 0.6916666666666667\n",
      "4290 번째 loss, accuracy:  0.5052485443482319 0.6916666666666667\n",
      "4291 번째 loss, accuracy:  0.5052300368921205 0.6916666666666667\n",
      "4292 번째 loss, accuracy:  0.5052115372242529 0.6916666666666667\n",
      "4293 번째 loss, accuracy:  0.505193045337134 0.6916666666666667\n",
      "4294 번째 loss, accuracy:  0.5051745612232742 0.6916666666666667\n",
      "4295 번째 loss, accuracy:  0.5051560848751897 0.6916666666666667\n",
      "4296 번째 loss, accuracy:  0.5051376162854023 0.6916666666666667\n",
      "4297 번째 loss, accuracy:  0.5051191554464391 0.6916666666666667\n",
      "4298 번째 loss, accuracy:  0.5051007023508325 0.6916666666666667\n",
      "4299 번째 loss, accuracy:  0.5050822569911205 0.6916666666666667\n",
      "4300 번째 loss, accuracy:  0.5050638193598476 0.6916666666666667\n",
      "4301 번째 loss, accuracy:  0.5050453894495617 0.6916666666666667\n",
      "4302 번째 loss, accuracy:  0.5050269672528176 0.6916666666666667\n",
      "4303 번째 loss, accuracy:  0.5050085527621758 0.6916666666666667\n",
      "4304 번째 loss, accuracy:  0.5049901459702012 0.6916666666666667\n",
      "4305 번째 loss, accuracy:  0.5049717468694646 0.6916666666666667\n",
      "4306 번째 loss, accuracy:  0.5049533554525419 0.6916666666666667\n",
      "4307 번째 loss, accuracy:  0.5049349717120156 0.6916666666666667\n",
      "4308 번째 loss, accuracy:  0.5049165956404719 0.6916666666666667\n",
      "4309 번째 loss, accuracy:  0.504898227230504 0.6916666666666667\n",
      "4310 번째 loss, accuracy:  0.5048798664747097 0.6916666666666667\n",
      "4311 번째 loss, accuracy:  0.5048615133656918 0.6916666666666667\n",
      "4312 번째 loss, accuracy:  0.5048431678960593 0.6916666666666667\n",
      "4313 번째 loss, accuracy:  0.5048248300584262 0.6916666666666667\n",
      "4314 번째 loss, accuracy:  0.5048064998454117 0.6916666666666667\n",
      "4315 번째 loss, accuracy:  0.5047881772496405 0.6916666666666667\n",
      "4316 번째 loss, accuracy:  0.5047698622637428 0.6916666666666667\n",
      "4317 번째 loss, accuracy:  0.504751554880354 0.6916666666666667\n",
      "4318 번째 loss, accuracy:  0.5047332550921146 0.6916666666666667\n",
      "4319 번째 loss, accuracy:  0.5047149628916708 0.6916666666666667\n",
      "4320 번째 loss, accuracy:  0.5046966782716741 0.6916666666666667\n",
      "4321 번째 loss, accuracy:  0.5046784012247812 0.6916666666666667\n",
      "4322 번째 loss, accuracy:  0.5046601317436541 0.6916666666666667\n",
      "4323 번째 loss, accuracy:  0.5046418698209599 0.6916666666666667\n",
      "4324 번째 loss, accuracy:  0.5046236154493708 0.6916666666666667\n",
      "4325 번째 loss, accuracy:  0.5046053686215652 0.6916666666666667\n",
      "4326 번째 loss, accuracy:  0.5045871293302261 0.6916666666666667\n",
      "4327 번째 loss, accuracy:  0.5045688975680417 0.6916666666666667\n",
      "4328 번째 loss, accuracy:  0.5045506733277054 0.6916666666666667\n",
      "4329 번째 loss, accuracy:  0.5045324566019166 0.6916666666666667\n",
      "4330 번째 loss, accuracy:  0.5045142473833791 0.6916666666666667\n",
      "4331 번째 loss, accuracy:  0.5044960456648024 0.6916666666666667\n",
      "4332 번째 loss, accuracy:  0.5044778514389009 0.6916666666666667\n",
      "4333 번째 loss, accuracy:  0.5044596646983941 0.6916666666666667\n",
      "4334 번째 loss, accuracy:  0.5044414854360071 0.6916666666666667\n",
      "4335 번째 loss, accuracy:  0.5044233136444702 0.6916666666666667\n",
      "4336 번째 loss, accuracy:  0.504405149316519 0.6916666666666667\n",
      "4337 번째 loss, accuracy:  0.5043869924448934 0.6916666666666667\n",
      "4338 번째 loss, accuracy:  0.5043688430223395 0.6916666666666667\n",
      "4339 번째 loss, accuracy:  0.5043507010416078 0.6916666666666667\n",
      "4340 번째 loss, accuracy:  0.5043325664954548 0.6916666666666667\n",
      "4341 번째 loss, accuracy:  0.5043144393766413 0.6916666666666667\n",
      "4342 번째 loss, accuracy:  0.5042963196779339 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4343 번째 loss, accuracy:  0.5042782073921036 0.6916666666666667\n",
      "4344 번째 loss, accuracy:  0.5042601025119278 0.6916666666666667\n",
      "4345 번째 loss, accuracy:  0.5042420050301877 0.6916666666666667\n",
      "4346 번째 loss, accuracy:  0.5042239149396696 0.6916666666666667\n",
      "4347 번째 loss, accuracy:  0.5042058322331663 0.6916666666666667\n",
      "4348 번째 loss, accuracy:  0.5041877569034742 0.6916666666666667\n",
      "4349 번째 loss, accuracy:  0.5041696889433956 0.6916666666666667\n",
      "4350 번째 loss, accuracy:  0.5041516283457377 0.6916666666666667\n",
      "4351 번째 loss, accuracy:  0.5041335751033126 0.6916666666666667\n",
      "4352 번째 loss, accuracy:  0.5041155292089378 0.6916666666666667\n",
      "4353 번째 loss, accuracy:  0.5040974906554357 0.6916666666666667\n",
      "4354 번째 loss, accuracy:  0.5040794594356339 0.6916666666666667\n",
      "4355 번째 loss, accuracy:  0.5040614355423648 0.6916666666666667\n",
      "4356 번째 loss, accuracy:  0.5040434189684654 0.6916666666666667\n",
      "4357 번째 loss, accuracy:  0.5040254097067786 0.6916666666666667\n",
      "4358 번째 loss, accuracy:  0.504007407750152 0.6916666666666667\n",
      "4359 번째 loss, accuracy:  0.5039894130914381 0.6916666666666667\n",
      "4360 번째 loss, accuracy:  0.5039714257234944 0.6916666666666667\n",
      "4361 번째 loss, accuracy:  0.5039534456391837 0.6916666666666667\n",
      "4362 번째 loss, accuracy:  0.5039354728313732 0.6916666666666667\n",
      "4363 번째 loss, accuracy:  0.5039175072929357 0.6916666666666667\n",
      "4364 번째 loss, accuracy:  0.5038995490167488 0.6916666666666667\n",
      "4365 번째 loss, accuracy:  0.5038815979956949 0.6916666666666667\n",
      "4366 번째 loss, accuracy:  0.5038636542226614 0.6916666666666667\n",
      "4367 번째 loss, accuracy:  0.5038457176905403 0.6916666666666667\n",
      "4368 번째 loss, accuracy:  0.5038277883922295 0.6916666666666667\n",
      "4369 번째 loss, accuracy:  0.5038098663206313 0.6916666666666667\n",
      "4370 번째 loss, accuracy:  0.5037919514686527 0.6916666666666667\n",
      "4371 번째 loss, accuracy:  0.5037740438292061 0.6916666666666667\n",
      "4372 번째 loss, accuracy:  0.5037561433952081 0.6916666666666667\n",
      "4373 번째 loss, accuracy:  0.5037382501595808 0.6916666666666667\n",
      "4374 번째 loss, accuracy:  0.5037203641152515 0.6916666666666667\n",
      "4375 번째 loss, accuracy:  0.5037024852551516 0.6916666666666667\n",
      "4376 번째 loss, accuracy:  0.5036846135722175 0.6916666666666667\n",
      "4377 번째 loss, accuracy:  0.5036667490593908 0.6916666666666667\n",
      "4378 번째 loss, accuracy:  0.5036488917096181 0.6916666666666667\n",
      "4379 번째 loss, accuracy:  0.5036310415158506 0.6916666666666667\n",
      "4380 번째 loss, accuracy:  0.5036131984710441 0.6916666666666667\n",
      "4381 번째 loss, accuracy:  0.50359536256816 0.6916666666666667\n",
      "4382 번째 loss, accuracy:  0.5035775338001637 0.6916666666666667\n",
      "4383 번째 loss, accuracy:  0.503559712160026 0.6916666666666667\n",
      "4384 번째 loss, accuracy:  0.5035418976407222 0.6916666666666667\n",
      "4385 번째 loss, accuracy:  0.5035240902352326 0.6916666666666667\n",
      "4386 번째 loss, accuracy:  0.5035062899365425 0.6916666666666667\n",
      "4387 번째 loss, accuracy:  0.5034884967376418 0.6916666666666667\n",
      "4388 번째 loss, accuracy:  0.5034707106315247 0.6916666666666667\n",
      "4389 번째 loss, accuracy:  0.503452931611191 0.6916666666666667\n",
      "4390 번째 loss, accuracy:  0.5034351596696446 0.6916666666666667\n",
      "4391 번째 loss, accuracy:  0.503417394799895 0.6916666666666667\n",
      "4392 번째 loss, accuracy:  0.5033996369949555 0.6916666666666667\n",
      "4393 번째 loss, accuracy:  0.5033818862478449 0.6916666666666667\n",
      "4394 번째 loss, accuracy:  0.5033641425515866 0.6916666666666667\n",
      "4395 번째 loss, accuracy:  0.5033464058992085 0.6916666666666667\n",
      "4396 번째 loss, accuracy:  0.5033286762837431 0.6916666666666667\n",
      "4397 번째 loss, accuracy:  0.5033109536982284 0.6916666666666667\n",
      "4398 번째 loss, accuracy:  0.5032932381357063 0.6916666666666667\n",
      "4399 번째 loss, accuracy:  0.503275529589224 0.6916666666666667\n",
      "4400 번째 loss, accuracy:  0.5032578280518327 0.6916666666666667\n",
      "4401 번째 loss, accuracy:  0.5032401335165895 0.6916666666666667\n",
      "4402 번째 loss, accuracy:  0.5032224459765546 0.6916666666666667\n",
      "4403 번째 loss, accuracy:  0.5032047654247942 0.6916666666666667\n",
      "4404 번째 loss, accuracy:  0.5031870918543785 0.6916666666666667\n",
      "4405 번째 loss, accuracy:  0.5031694252583827 0.6916666666666667\n",
      "4406 번째 loss, accuracy:  0.5031517656298868 0.6916666666666667\n",
      "4407 번째 loss, accuracy:  0.5031341129619747 0.6916666666666667\n",
      "4408 번째 loss, accuracy:  0.5031164672477354 0.6916666666666667\n",
      "4409 번째 loss, accuracy:  0.503098828480263 0.6916666666666667\n",
      "4410 번째 loss, accuracy:  0.5030811966526554 0.6916666666666667\n",
      "4411 번째 loss, accuracy:  0.503063571758016 0.6916666666666667\n",
      "4412 번째 loss, accuracy:  0.5030459537894522 0.6916666666666667\n",
      "4413 번째 loss, accuracy:  0.503028342740076 0.6916666666666667\n",
      "4414 번째 loss, accuracy:  0.5030107386030045 0.6916666666666667\n",
      "4415 번째 loss, accuracy:  0.5029931413713589 0.6916666666666667\n",
      "4416 번째 loss, accuracy:  0.5029755510382651 0.6916666666666667\n",
      "4417 번째 loss, accuracy:  0.5029579675968541 0.6916666666666667\n",
      "4418 번째 loss, accuracy:  0.5029403910402606 0.6916666666666667\n",
      "4419 번째 loss, accuracy:  0.5029228213616241 0.6916666666666667\n",
      "4420 번째 loss, accuracy:  0.5029052585540895 0.6916666666666667\n",
      "4421 번째 loss, accuracy:  0.5028877026108055 0.6916666666666667\n",
      "4422 번째 loss, accuracy:  0.502870153524925 0.6916666666666667\n",
      "4423 번째 loss, accuracy:  0.5028526112896065 0.6916666666666667\n",
      "4424 번째 loss, accuracy:  0.5028350758980122 0.6916666666666667\n",
      "4425 번째 loss, accuracy:  0.5028175473433093 0.6916666666666667\n",
      "4426 번째 loss, accuracy:  0.502800025618669 0.6916666666666667\n",
      "4427 번째 loss, accuracy:  0.5027825107172675 0.6916666666666667\n",
      "4428 번째 loss, accuracy:  0.5027650026322854 0.6916666666666667\n",
      "4429 번째 loss, accuracy:  0.5027475013569077 0.6916666666666667\n",
      "4430 번째 loss, accuracy:  0.5027300068843237 0.6916666666666667\n",
      "4431 번째 loss, accuracy:  0.5027125192077275 0.6916666666666667\n",
      "4432 번째 loss, accuracy:  0.5026950383203176 0.6916666666666667\n",
      "4433 번째 loss, accuracy:  0.5026775642152973 0.6916666666666667\n",
      "4434 번째 loss, accuracy:  0.5026600968858734 0.6916666666666667\n",
      "4435 번째 loss, accuracy:  0.502642636325258 0.6916666666666667\n",
      "4436 번째 loss, accuracy:  0.5026251825266678 0.6916666666666667\n",
      "4437 번째 loss, accuracy:  0.5026077354833233 0.6916666666666667\n",
      "4438 번째 loss, accuracy:  0.5025902951884498 0.6916666666666667\n",
      "4439 번째 loss, accuracy:  0.5025728616352768 0.6916666666666667\n",
      "4440 번째 loss, accuracy:  0.5025554348170385 0.6916666666666667\n",
      "4441 번째 loss, accuracy:  0.5025380147269731 0.6916666666666667\n",
      "4442 번째 loss, accuracy:  0.5025206013583235 0.6916666666666667\n",
      "4443 번째 loss, accuracy:  0.5025031947043375 0.6916666666666667\n",
      "4444 번째 loss, accuracy:  0.5024857947582664 0.6916666666666667\n",
      "4445 번째 loss, accuracy:  0.5024684015133664 0.6916666666666667\n",
      "4446 번째 loss, accuracy:  0.5024510149628976 0.6916666666666667\n",
      "4447 번째 loss, accuracy:  0.5024336351001252 0.6916666666666667\n",
      "4448 번째 loss, accuracy:  0.5024162619183183 0.6916666666666667\n",
      "4449 번째 loss, accuracy:  0.5023988954107506 0.6916666666666667\n",
      "4450 번째 loss, accuracy:  0.5023815355706992 0.6916666666666667\n",
      "4451 번째 loss, accuracy:  0.5023641823914475 0.6916666666666667\n",
      "4452 번째 loss, accuracy:  0.502346835866281 0.6916666666666667\n",
      "4453 번째 loss, accuracy:  0.5023294959884912 0.6916666666666667\n",
      "4454 번째 loss, accuracy:  0.5023121627513732 0.6916666666666667\n",
      "4455 번째 loss, accuracy:  0.5022948361482268 0.6916666666666667\n",
      "4456 번째 loss, accuracy:  0.5022775161723556 0.6916666666666667\n",
      "4457 번째 loss, accuracy:  0.5022602028170678 0.6916666666666667\n",
      "4458 번째 loss, accuracy:  0.502242896075676 0.6916666666666667\n",
      "4459 번째 loss, accuracy:  0.5022255959414968 0.6916666666666667\n",
      "4460 번째 loss, accuracy:  0.5022083024078513 0.6916666666666667\n",
      "4461 번째 loss, accuracy:  0.5021910154680649 0.6916666666666667\n",
      "4462 번째 loss, accuracy:  0.5021737351154673 0.6916666666666667\n",
      "4463 번째 loss, accuracy:  0.5021564613433915 0.6916666666666667\n",
      "4464 번째 loss, accuracy:  0.5021391941451765 0.6916666666666667\n",
      "4465 번째 loss, accuracy:  0.5021219335141645 0.6916666666666667\n",
      "4466 번째 loss, accuracy:  0.502104679443702 0.6916666666666667\n",
      "4467 번째 loss, accuracy:  0.5020874319271397 0.6916666666666667\n",
      "4468 번째 loss, accuracy:  0.5020701909578328 0.6916666666666667\n",
      "4469 번째 loss, accuracy:  0.5020529565291404 0.6916666666666667\n",
      "4470 번째 loss, accuracy:  0.5020357286344264 0.6916666666666667\n",
      "4471 번째 loss, accuracy:  0.5020185072670581 0.6916666666666667\n",
      "4472 번째 loss, accuracy:  0.5020012924204074 0.6916666666666667\n",
      "4473 번째 loss, accuracy:  0.5019840840878508 0.6916666666666667\n",
      "4474 번째 loss, accuracy:  0.5019668822627683 0.6916666666666667\n",
      "4475 번째 loss, accuracy:  0.5019496869385445 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4476 번째 loss, accuracy:  0.5019324981085675 0.6916666666666667\n",
      "4477 번째 loss, accuracy:  0.5019153157662307 0.6916666666666667\n",
      "4478 번째 loss, accuracy:  0.5018981399049307 0.6916666666666667\n",
      "4479 번째 loss, accuracy:  0.5018809705180692 0.6916666666666667\n",
      "4480 번째 loss, accuracy:  0.501863807599051 0.6916666666666667\n",
      "4481 번째 loss, accuracy:  0.5018466511412853 0.6916666666666667\n",
      "4482 번째 loss, accuracy:  0.5018295011381863 0.6916666666666667\n",
      "4483 번째 loss, accuracy:  0.5018123575831712 0.6916666666666667\n",
      "4484 번째 loss, accuracy:  0.5017952204696621 0.6916666666666667\n",
      "4485 번째 loss, accuracy:  0.5017780897910842 0.6916666666666667\n",
      "4486 번째 loss, accuracy:  0.5017609655408684 0.6916666666666667\n",
      "4487 번째 loss, accuracy:  0.5017438477124483 0.6916666666666667\n",
      "4488 번째 loss, accuracy:  0.5017267362992622 0.6916666666666667\n",
      "4489 번째 loss, accuracy:  0.5017096312947525 0.6916666666666667\n",
      "4490 번째 loss, accuracy:  0.501692532692365 0.6916666666666667\n",
      "4491 번째 loss, accuracy:  0.5016754404855508 0.6916666666666667\n",
      "4492 번째 loss, accuracy:  0.5016583546677641 0.6916666666666667\n",
      "4493 번째 loss, accuracy:  0.5016412752324638 0.6916666666666667\n",
      "4494 번째 loss, accuracy:  0.5016242021731123 0.6916666666666667\n",
      "4495 번째 loss, accuracy:  0.5016071354831763 0.6916666666666667\n",
      "4496 번째 loss, accuracy:  0.5015900751561265 0.6916666666666667\n",
      "4497 번째 loss, accuracy:  0.5015730211854376 0.6916666666666667\n",
      "4498 번째 loss, accuracy:  0.5015559735645885 0.6916666666666667\n",
      "4499 번째 loss, accuracy:  0.5015389322870617 0.6916666666666667\n",
      "4500 번째 loss, accuracy:  0.5015218973463441 0.6916666666666667\n",
      "4501 번째 loss, accuracy:  0.5015048687359268 0.6916666666666667\n",
      "4502 번째 loss, accuracy:  0.5014878464493042 0.6916666666666667\n",
      "4503 번째 loss, accuracy:  0.5014708304799756 0.6916666666666667\n",
      "4504 번째 loss, accuracy:  0.5014538208214433 0.6916666666666667\n",
      "4505 번째 loss, accuracy:  0.5014368174672141 0.6916666666666667\n",
      "4506 번째 loss, accuracy:  0.501419820410799 0.6916666666666667\n",
      "4507 번째 loss, accuracy:  0.5014028296457127 0.6916666666666667\n",
      "4508 번째 loss, accuracy:  0.5013858451654738 0.6916666666666667\n",
      "4509 번째 loss, accuracy:  0.5013688669636048 0.6916666666666667\n",
      "4510 번째 loss, accuracy:  0.5013518950336325 0.6916666666666667\n",
      "4511 번째 loss, accuracy:  0.5013349293690873 0.6916666666666667\n",
      "4512 번째 loss, accuracy:  0.5013179699635034 0.6916666666666667\n",
      "4513 번째 loss, accuracy:  0.5013010168104196 0.6916666666666667\n",
      "4514 번째 loss, accuracy:  0.5012840699033778 0.6916666666666667\n",
      "4515 번째 loss, accuracy:  0.5012671292359245 0.6916666666666667\n",
      "4516 번째 loss, accuracy:  0.5012501948016103 0.6916666666666667\n",
      "4517 번째 loss, accuracy:  0.5012332665939881 0.6916666666666667\n",
      "4518 번째 loss, accuracy:  0.5012163446066162 0.6916666666666667\n",
      "4519 번째 loss, accuracy:  0.5011994288330569 0.6916666666666667\n",
      "4520 번째 loss, accuracy:  0.5011825192668758 0.6916666666666667\n",
      "4521 번째 loss, accuracy:  0.5011656159016421 0.6916666666666667\n",
      "4522 번째 loss, accuracy:  0.5011487187309296 0.6916666666666667\n",
      "4523 번째 loss, accuracy:  0.5011318277483152 0.6916666666666667\n",
      "4524 번째 loss, accuracy:  0.5011149429473801 0.6916666666666667\n",
      "4525 번째 loss, accuracy:  0.5010980643217098 0.6916666666666667\n",
      "4526 번째 loss, accuracy:  0.5010811918648926 0.6916666666666667\n",
      "4527 번째 loss, accuracy:  0.5010643255705213 0.6916666666666667\n",
      "4528 번째 loss, accuracy:  0.5010474654321924 0.6916666666666667\n",
      "4529 번째 loss, accuracy:  0.5010306114435062 0.6916666666666667\n",
      "4530 번째 loss, accuracy:  0.5010137635980672 0.6916666666666667\n",
      "4531 번째 loss, accuracy:  0.5009969218894831 0.6916666666666667\n",
      "4532 번째 loss, accuracy:  0.5009800863113659 0.6916666666666667\n",
      "4533 번째 loss, accuracy:  0.500963256857331 0.6916666666666667\n",
      "4534 번째 loss, accuracy:  0.5009464335209975 0.6916666666666667\n",
      "4535 번째 loss, accuracy:  0.5009296162959892 0.6916666666666667\n",
      "4536 번째 loss, accuracy:  0.5009128051759323 0.6916666666666667\n",
      "4537 번째 loss, accuracy:  0.500896000154458 0.6916666666666667\n",
      "4538 번째 loss, accuracy:  0.5008792012252005 0.6916666666666667\n",
      "4539 번째 loss, accuracy:  0.5008624083817979 0.6916666666666667\n",
      "4540 번째 loss, accuracy:  0.5008456216178924 0.6916666666666667\n",
      "4541 번째 loss, accuracy:  0.5008288409271299 0.6916666666666667\n",
      "4542 번째 loss, accuracy:  0.5008120663031594 0.6916666666666667\n",
      "4543 번째 loss, accuracy:  0.5007952977396346 0.6916666666666667\n",
      "4544 번째 loss, accuracy:  0.5007785352302124 0.6916666666666667\n",
      "4545 번째 loss, accuracy:  0.500761778768553 0.6916666666666667\n",
      "4546 번째 loss, accuracy:  0.5007450283483209 0.6916666666666667\n",
      "4547 번째 loss, accuracy:  0.5007282839631843 0.6916666666666667\n",
      "4548 번째 loss, accuracy:  0.5007115456068153 0.6916666666666667\n",
      "4549 번째 loss, accuracy:  0.5006948132728889 0.6916666666666667\n",
      "4550 번째 loss, accuracy:  0.5006780869550848 0.6916666666666667\n",
      "4551 번째 loss, accuracy:  0.500661366647085 0.6916666666666667\n",
      "4552 번째 loss, accuracy:  0.5006446523425768 0.6916666666666667\n",
      "4553 번째 loss, accuracy:  0.50062794403525 0.6916666666666667\n",
      "4554 번째 loss, accuracy:  0.5006112417187989 0.6916666666666667\n",
      "4555 번째 loss, accuracy:  0.5005945453869204 0.6916666666666667\n",
      "4556 번째 loss, accuracy:  0.500577855033316 0.6916666666666667\n",
      "4557 번째 loss, accuracy:  0.5005611706516905 0.6916666666666667\n",
      "4558 번째 loss, accuracy:  0.5005444922357521 0.6916666666666667\n",
      "4559 번째 loss, accuracy:  0.5005278197792136 0.6916666666666667\n",
      "4560 번째 loss, accuracy:  0.5005111532757899 0.6916666666666667\n",
      "4561 번째 loss, accuracy:  0.5004944927192007 0.6916666666666667\n",
      "4562 번째 loss, accuracy:  0.5004778381031689 0.6916666666666667\n",
      "4563 번째 loss, accuracy:  0.500461189421421 0.6916666666666667\n",
      "4564 번째 loss, accuracy:  0.5004445466676876 0.6916666666666667\n",
      "4565 번째 loss, accuracy:  0.5004279098357022 0.6916666666666667\n",
      "4566 번째 loss, accuracy:  0.5004112789192018 0.6916666666666667\n",
      "4567 번째 loss, accuracy:  0.500394653911928 0.6916666666666667\n",
      "4568 번째 loss, accuracy:  0.500378034807625 0.6916666666666667\n",
      "4569 번째 loss, accuracy:  0.5003614216000405 0.6916666666666667\n",
      "4570 번째 loss, accuracy:  0.5003448142829265 0.6916666666666667\n",
      "4571 번째 loss, accuracy:  0.500328212850038 0.6916666666666667\n",
      "4572 번째 loss, accuracy:  0.5003116172951342 0.6916666666666667\n",
      "4573 번째 loss, accuracy:  0.500295027611977 0.6916666666666667\n",
      "4574 번째 loss, accuracy:  0.5002784437943327 0.6916666666666667\n",
      "4575 번째 loss, accuracy:  0.5002618658359702 0.6916666666666667\n",
      "4576 번째 loss, accuracy:  0.5002452937306628 0.6916666666666667\n",
      "4577 번째 loss, accuracy:  0.5002287274721867 0.6916666666666667\n",
      "4578 번째 loss, accuracy:  0.5002121670543214 0.6916666666666667\n",
      "4579 번째 loss, accuracy:  0.5001956124708509 0.6916666666666667\n",
      "4580 번째 loss, accuracy:  0.5001790637155625 0.6916666666666667\n",
      "4581 번째 loss, accuracy:  0.500162520782246 0.6916666666666667\n",
      "4582 번째 loss, accuracy:  0.5001459836646956 0.6916666666666667\n",
      "4583 번째 loss, accuracy:  0.5001294523567089 0.6916666666666667\n",
      "4584 번째 loss, accuracy:  0.5001129268520865 0.6916666666666667\n",
      "4585 번째 loss, accuracy:  0.5000964071446327 0.6916666666666667\n",
      "4586 번째 loss, accuracy:  0.5000798932281556 0.6916666666666667\n",
      "4587 번째 loss, accuracy:  0.5000633850964665 0.6916666666666667\n",
      "4588 번째 loss, accuracy:  0.50004688274338 0.6916666666666667\n",
      "4589 번째 loss, accuracy:  0.5000303861627144 0.6916666666666667\n",
      "4590 번째 loss, accuracy:  0.5000138953482917 0.6916666666666667\n",
      "4591 번째 loss, accuracy:  0.4999974102939363 0.6916666666666667\n",
      "4592 번째 loss, accuracy:  0.49998093099347707 0.6916666666666667\n",
      "4593 번째 loss, accuracy:  0.49996445744074586 0.6916666666666667\n",
      "4594 번째 loss, accuracy:  0.49994798962957826 0.6916666666666667\n",
      "4595 번째 loss, accuracy:  0.49993152755381287 0.6916666666666667\n",
      "4596 번째 loss, accuracy:  0.4999150712072917 0.6916666666666667\n",
      "4597 번째 loss, accuracy:  0.49989862058386053 0.6916666666666667\n",
      "4598 번째 loss, accuracy:  0.4998821756773683 0.6916666666666667\n",
      "4599 번째 loss, accuracy:  0.4998657364816675 0.6916666666666667\n",
      "4600 번째 loss, accuracy:  0.4998493029906138 0.6916666666666667\n",
      "4601 번째 loss, accuracy:  0.4998328751980659 0.6916666666666667\n",
      "4602 번째 loss, accuracy:  0.4998164530978869 0.6916666666666667\n",
      "4603 번째 loss, accuracy:  0.49980003668394224 0.6916666666666667\n",
      "4604 번째 loss, accuracy:  0.49978362595010123 0.6916666666666667\n",
      "4605 번째 loss, accuracy:  0.4997672208902365 0.6916666666666667\n",
      "4606 번째 loss, accuracy:  0.49975082149822386 0.6916666666666667\n",
      "4607 번째 loss, accuracy:  0.4997344277679426 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608 번째 loss, accuracy:  0.49971803969327516 0.6916666666666667\n",
      "4609 번째 loss, accuracy:  0.4997016572681076 0.6916666666666667\n",
      "4610 번째 loss, accuracy:  0.49968528048632893 0.6916666666666667\n",
      "4611 번째 loss, accuracy:  0.49966890934183184 0.6916666666666667\n",
      "4612 번째 loss, accuracy:  0.4996525438285122 0.6916666666666667\n",
      "4613 번째 loss, accuracy:  0.49963618394026904 0.6916666666666667\n",
      "4614 번째 loss, accuracy:  0.4996198296710047 0.6916666666666667\n",
      "4615 번째 loss, accuracy:  0.4996034810146251 0.6916666666666667\n",
      "4616 번째 loss, accuracy:  0.49958713796503923 0.6916666666666667\n",
      "4617 번째 loss, accuracy:  0.49957080051615926 0.6916666666666667\n",
      "4618 번째 loss, accuracy:  0.499554468661901 0.6916666666666667\n",
      "4619 번째 loss, accuracy:  0.49953814239618316 0.6916666666666667\n",
      "4620 번째 loss, accuracy:  0.49952182171292786 0.6916666666666667\n",
      "4621 번째 loss, accuracy:  0.49950550660606013 0.6916666666666667\n",
      "4622 번째 loss, accuracy:  0.4994891970695091 0.6916666666666667\n",
      "4623 번째 loss, accuracy:  0.4994728930972065 0.6916666666666667\n",
      "4624 번째 loss, accuracy:  0.499456594683087 0.6916666666666667\n",
      "4625 번째 loss, accuracy:  0.4994403018210895 0.6916666666666667\n",
      "4626 번째 loss, accuracy:  0.4994240145051551 0.6916666666666667\n",
      "4627 번째 loss, accuracy:  0.49940773272922867 0.6916666666666667\n",
      "4628 번째 loss, accuracy:  0.49939145648725825 0.6916666666666667\n",
      "4629 번째 loss, accuracy:  0.4993751857731951 0.6916666666666667\n",
      "4630 번째 loss, accuracy:  0.4993589205809934 0.6916666666666667\n",
      "4631 번째 loss, accuracy:  0.49934266090461094 0.6916666666666667\n",
      "4632 번째 loss, accuracy:  0.4993264067380083 0.6916666666666667\n",
      "4633 번째 loss, accuracy:  0.4993101580751497 0.6916666666666667\n",
      "4634 번째 loss, accuracy:  0.4992939149100019 0.6916666666666667\n",
      "4635 번째 loss, accuracy:  0.49927767723653554 0.6916666666666667\n",
      "4636 번째 loss, accuracy:  0.499261445048724 0.6916666666666667\n",
      "4637 번째 loss, accuracy:  0.4992452183405438 0.6916666666666667\n",
      "4638 번째 loss, accuracy:  0.4992289971059749 0.6916666666666667\n",
      "4639 번째 loss, accuracy:  0.49921278133899993 0.6916666666666667\n",
      "4640 번째 loss, accuracy:  0.49919657103360543 0.6916666666666667\n",
      "4641 번째 loss, accuracy:  0.4991803661837803 0.6916666666666667\n",
      "4642 번째 loss, accuracy:  0.49916416678351694 0.6916666666666667\n",
      "4643 번째 loss, accuracy:  0.49914797282681117 0.6916666666666667\n",
      "4644 번째 loss, accuracy:  0.49913178430766114 0.6916666666666667\n",
      "4645 번째 loss, accuracy:  0.4991156012200687 0.6916666666666667\n",
      "4646 번째 loss, accuracy:  0.49909942355803844 0.6916666666666667\n",
      "4647 번째 loss, accuracy:  0.49908325131557885 0.6916666666666667\n",
      "4648 번째 loss, accuracy:  0.4990670844867008 0.6916666666666667\n",
      "4649 번째 loss, accuracy:  0.4990509230654182 0.6916666666666667\n",
      "4650 번째 loss, accuracy:  0.4990347670457483 0.6916666666666667\n",
      "4651 번째 loss, accuracy:  0.49901861642171147 0.6916666666666667\n",
      "4652 번째 loss, accuracy:  0.49900247118733093 0.6916666666666667\n",
      "4653 번째 loss, accuracy:  0.4989863313366331 0.6916666666666667\n",
      "4654 번째 loss, accuracy:  0.49897019686364785 0.6916666666666667\n",
      "4655 번째 loss, accuracy:  0.4989540677624073 0.6916666666666667\n",
      "4656 번째 loss, accuracy:  0.49893794402694724 0.6916666666666667\n",
      "4657 번째 loss, accuracy:  0.4989218256513064 0.6916666666666667\n",
      "4658 번째 loss, accuracy:  0.4989057126295261 0.6916666666666667\n",
      "4659 번째 loss, accuracy:  0.4988896049556514 0.6916666666666667\n",
      "4660 번째 loss, accuracy:  0.4988735026237299 0.6916666666666667\n",
      "4661 번째 loss, accuracy:  0.4988574056278126 0.6916666666666667\n",
      "4662 번째 loss, accuracy:  0.49884131396195314 0.6916666666666667\n",
      "4663 번째 loss, accuracy:  0.4988252276202079 0.6916666666666667\n",
      "4664 번째 loss, accuracy:  0.4988091465966373 0.6916666666666667\n",
      "4665 번째 loss, accuracy:  0.4987930708853038 0.6916666666666667\n",
      "4666 번째 loss, accuracy:  0.49877700048027335 0.6916666666666667\n",
      "4667 번째 loss, accuracy:  0.4987609353756144 0.6916666666666667\n",
      "4668 번째 loss, accuracy:  0.4987448755653991 0.6916666666666667\n",
      "4669 번째 loss, accuracy:  0.49872882104370214 0.6916666666666667\n",
      "4670 번째 loss, accuracy:  0.4987127718046012 0.6916666666666667\n",
      "4671 번째 loss, accuracy:  0.49869672784217717 0.6916666666666667\n",
      "4672 번째 loss, accuracy:  0.498680689150513 0.6916666666666667\n",
      "4673 번째 loss, accuracy:  0.4986646557236958 0.6916666666666667\n",
      "4674 번째 loss, accuracy:  0.4986486275558151 0.6916666666666667\n",
      "4675 번째 loss, accuracy:  0.4986326046409633 0.6916666666666667\n",
      "4676 번째 loss, accuracy:  0.49861658697323574 0.6916666666666667\n",
      "4677 번째 loss, accuracy:  0.49860057454673085 0.6916666666666667\n",
      "4678 번째 loss, accuracy:  0.49858456735554985 0.6916666666666667\n",
      "4679 번째 loss, accuracy:  0.4985685653937972 0.6916666666666667\n",
      "4680 번째 loss, accuracy:  0.49855256865557973 0.6916666666666667\n",
      "4681 번째 loss, accuracy:  0.49853657713500754 0.6916666666666667\n",
      "4682 번째 loss, accuracy:  0.49852059082619343 0.6916666666666667\n",
      "4683 번째 loss, accuracy:  0.4985046097232535 0.6916666666666667\n",
      "4684 번째 loss, accuracy:  0.49848863382030617 0.6916666666666667\n",
      "4685 번째 loss, accuracy:  0.49847266311147337 0.6916666666666667\n",
      "4686 번째 loss, accuracy:  0.49845669759087935 0.6916666666666667\n",
      "4687 번째 loss, accuracy:  0.49844073725265164 0.6916666666666667\n",
      "4688 번째 loss, accuracy:  0.4984247820909201 0.6916666666666667\n",
      "4689 번째 loss, accuracy:  0.498408832099818 0.6916666666666667\n",
      "4690 번째 loss, accuracy:  0.4983928872734816 0.6916666666666667\n",
      "4691 번째 loss, accuracy:  0.49837694760604934 0.6916666666666667\n",
      "4692 번째 loss, accuracy:  0.4983610130916628 0.6916666666666667\n",
      "4693 번째 loss, accuracy:  0.4983450837244669 0.6916666666666667\n",
      "4694 번째 loss, accuracy:  0.49832915949860873 0.6916666666666667\n",
      "4695 번째 loss, accuracy:  0.49831324040823843 0.6916666666666667\n",
      "4696 번째 loss, accuracy:  0.49829732644750874 0.6916666666666667\n",
      "4697 번째 loss, accuracy:  0.49828141761057576 0.6916666666666667\n",
      "4698 번째 loss, accuracy:  0.4982655138915982 0.6916666666666667\n",
      "4699 번째 loss, accuracy:  0.4982496152847371 0.6916666666666667\n",
      "4700 번째 loss, accuracy:  0.4982337217841568 0.6916666666666667\n",
      "4701 번째 loss, accuracy:  0.4982178333840246 0.6916666666666667\n",
      "4702 번째 loss, accuracy:  0.4982019500785102 0.6916666666666667\n",
      "4703 번째 loss, accuracy:  0.4981860718617861 0.6916666666666667\n",
      "4704 번째 loss, accuracy:  0.4981701987280277 0.6916666666666667\n",
      "4705 번째 loss, accuracy:  0.4981543306714131 0.6916666666666667\n",
      "4706 번째 loss, accuracy:  0.49813846768612335 0.6916666666666667\n",
      "4707 번째 loss, accuracy:  0.4981226097663422 0.6916666666666667\n",
      "4708 번째 loss, accuracy:  0.49810675690625605 0.6916666666666667\n",
      "4709 번째 loss, accuracy:  0.4980909091000541 0.6916666666666667\n",
      "4710 번째 loss, accuracy:  0.49807506634192816 0.6916666666666667\n",
      "4711 번째 loss, accuracy:  0.49805922862607294 0.6916666666666667\n",
      "4712 번째 loss, accuracy:  0.49804339594668623 0.6916666666666667\n",
      "4713 번째 loss, accuracy:  0.4980275682979677 0.6916666666666667\n",
      "4714 번째 loss, accuracy:  0.4980117456741207 0.6916666666666667\n",
      "4715 번째 loss, accuracy:  0.4979959280693505 0.6916666666666667\n",
      "4716 번째 loss, accuracy:  0.4979801154778654 0.6916666666666667\n",
      "4717 번째 loss, accuracy:  0.49796430789387663 0.6916666666666667\n",
      "4718 번째 loss, accuracy:  0.49794850531159796 0.6916666666666667\n",
      "4719 번째 loss, accuracy:  0.4979327077252456 0.6916666666666667\n",
      "4720 번째 loss, accuracy:  0.49791691512903874 0.6916666666666667\n",
      "4721 번째 loss, accuracy:  0.49790112751719945 0.6916666666666667\n",
      "4722 번째 loss, accuracy:  0.49788534488395203 0.6916666666666667\n",
      "4723 번째 loss, accuracy:  0.49786956722352377 0.6916666666666667\n",
      "4724 번째 loss, accuracy:  0.497853794530144 0.6916666666666667\n",
      "4725 번째 loss, accuracy:  0.49783802679804573 0.6916666666666667\n",
      "4726 번째 loss, accuracy:  0.4978222640214642 0.6916666666666667\n",
      "4727 번째 loss, accuracy:  0.49780650619463707 0.6916666666666667\n",
      "4728 번째 loss, accuracy:  0.4977907533118047 0.6916666666666667\n",
      "4729 번째 loss, accuracy:  0.4977750053672104 0.6916666666666667\n",
      "4730 번째 loss, accuracy:  0.49775926235509993 0.6916666666666667\n",
      "4731 번째 loss, accuracy:  0.4977435242697216 0.6916666666666667\n",
      "4732 번째 loss, accuracy:  0.49772779110532656 0.6916666666666667\n",
      "4733 번째 loss, accuracy:  0.49771206285616826 0.6916666666666667\n",
      "4734 번째 loss, accuracy:  0.497696339516503 0.6916666666666667\n",
      "4735 번째 loss, accuracy:  0.4976806210805896 0.6916666666666667\n",
      "4736 번째 loss, accuracy:  0.49766490754269 0.6916666666666667\n",
      "4737 번째 loss, accuracy:  0.49764919889706766 0.6916666666666667\n",
      "4738 번째 loss, accuracy:  0.4976334951379895 0.6916666666666667\n",
      "4739 번째 loss, accuracy:  0.49761779625972496 0.6916666666666667\n",
      "4740 번째 loss, accuracy:  0.4976021022565456 0.6916666666666667\n",
      "4741 번째 loss, accuracy:  0.497586413122726 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4742 번째 loss, accuracy:  0.49757072885254333 0.6916666666666667\n",
      "4743 번째 loss, accuracy:  0.4975550494402769 0.6916666666666667\n",
      "4744 번째 loss, accuracy:  0.4975393748802088 0.6916666666666667\n",
      "4745 번째 loss, accuracy:  0.497523705166624 0.6916666666666667\n",
      "4746 번째 loss, accuracy:  0.49750804029380963 0.6916666666666667\n",
      "4747 번째 loss, accuracy:  0.4974923802560556 0.6916666666666667\n",
      "4748 번째 loss, accuracy:  0.4974767250476539 0.6916666666666667\n",
      "4749 번째 loss, accuracy:  0.49746107466289996 0.6916666666666667\n",
      "4750 번째 loss, accuracy:  0.4974454290960909 0.6916666666666667\n",
      "4751 번째 loss, accuracy:  0.4974297883415265 0.6916666666666667\n",
      "4752 번째 loss, accuracy:  0.49741415239350956 0.6916666666666667\n",
      "4753 번째 loss, accuracy:  0.4973985212463449 0.6916666666666667\n",
      "4754 번째 loss, accuracy:  0.49738289489434 0.6916666666666667\n",
      "4755 번째 loss, accuracy:  0.4973672733318047 0.6916666666666667\n",
      "4756 번째 loss, accuracy:  0.49735165655305186 0.6916666666666667\n",
      "4757 번째 loss, accuracy:  0.49733604455239594 0.6916666666666667\n",
      "4758 번째 loss, accuracy:  0.4973204373241547 0.6916666666666667\n",
      "4759 번째 loss, accuracy:  0.4973048348626482 0.6916666666666667\n",
      "4760 번째 loss, accuracy:  0.4972892371621987 0.6916666666666667\n",
      "4761 번째 loss, accuracy:  0.4972736442171314 0.6916666666666667\n",
      "4762 번째 loss, accuracy:  0.4972580560217735 0.6916666666666667\n",
      "4763 번째 loss, accuracy:  0.49724247257045473 0.6916666666666667\n",
      "4764 번째 loss, accuracy:  0.49722689385750757 0.6916666666666667\n",
      "4765 번째 loss, accuracy:  0.4972113198772669 0.6916666666666667\n",
      "4766 번째 loss, accuracy:  0.4971957506240695 0.6916666666666667\n",
      "4767 번째 loss, accuracy:  0.4971801860922554 0.6916666666666667\n",
      "4768 번째 loss, accuracy:  0.4971646262761665 0.6916666666666667\n",
      "4769 번째 loss, accuracy:  0.4971490711701473 0.6916666666666667\n",
      "4770 번째 loss, accuracy:  0.4971335207685448 0.6916666666666667\n",
      "4771 번째 loss, accuracy:  0.49711797506570854 0.6916666666666667\n",
      "4772 번째 loss, accuracy:  0.49710243405599014 0.6916666666666667\n",
      "4773 번째 loss, accuracy:  0.49708689773374376 0.6916666666666667\n",
      "4774 번째 loss, accuracy:  0.49707136609332603 0.6916666666666667\n",
      "4775 번째 loss, accuracy:  0.49705583912909584 0.6916666666666667\n",
      "4776 번째 loss, accuracy:  0.49704031683541483 0.6916666666666667\n",
      "4777 번째 loss, accuracy:  0.4970247992066465 0.6916666666666667\n",
      "4778 번째 loss, accuracy:  0.4970092862371574 0.6916666666666667\n",
      "4779 번째 loss, accuracy:  0.4969937779213156 0.6916666666666667\n",
      "4780 번째 loss, accuracy:  0.49697827425349245 0.6916666666666667\n",
      "4781 번째 loss, accuracy:  0.496962775228061 0.6916666666666667\n",
      "4782 번째 loss, accuracy:  0.49694728083939677 0.6916666666666667\n",
      "4783 번째 loss, accuracy:  0.4969317910818782 0.6916666666666667\n",
      "4784 번째 loss, accuracy:  0.4969163059498854 0.6916666666666667\n",
      "4785 번째 loss, accuracy:  0.49690082543780095 0.6916666666666667\n",
      "4786 번째 loss, accuracy:  0.4968853495400104 0.6916666666666667\n",
      "4787 번째 loss, accuracy:  0.4968698782509006 0.6916666666666667\n",
      "4788 번째 loss, accuracy:  0.4968544115648618 0.6916666666666667\n",
      "4789 번째 loss, accuracy:  0.4968389494762858 0.6916666666666667\n",
      "4790 번째 loss, accuracy:  0.496823491979567 0.6916666666666667\n",
      "4791 번째 loss, accuracy:  0.4968080390691019 0.6916666666666667\n",
      "4792 번째 loss, accuracy:  0.49679259073928983 0.6916666666666667\n",
      "4793 번째 loss, accuracy:  0.4967771469845322 0.6916666666666667\n",
      "4794 번째 loss, accuracy:  0.49676170779923223 0.6916666666666667\n",
      "4795 번째 loss, accuracy:  0.49674627317779624 0.6916666666666667\n",
      "4796 번째 loss, accuracy:  0.49673084311463234 0.6916666666666667\n",
      "4797 번째 loss, accuracy:  0.496715417604151 0.6916666666666667\n",
      "4798 번째 loss, accuracy:  0.4966999966407648 0.6916666666666667\n",
      "4799 번째 loss, accuracy:  0.4966845802188892 0.6916666666666667\n",
      "4800 번째 loss, accuracy:  0.4966691683329413 0.6916666666666667\n",
      "4801 번째 loss, accuracy:  0.496653760977341 0.6916666666666667\n",
      "4802 번째 loss, accuracy:  0.49663835814650975 0.6916666666666667\n",
      "4803 번째 loss, accuracy:  0.4966229598348721 0.6916666666666667\n",
      "4804 번째 loss, accuracy:  0.4966075660368541 0.6916666666666667\n",
      "4805 번째 loss, accuracy:  0.4965921767468845 0.6916666666666667\n",
      "4806 번째 loss, accuracy:  0.49657679195939414 0.6916666666666667\n",
      "4807 번째 loss, accuracy:  0.49656141166881596 0.6916666666666667\n",
      "4808 번째 loss, accuracy:  0.49654603586958573 0.6916666666666667\n",
      "4809 번째 loss, accuracy:  0.49653066455614053 0.6916666666666667\n",
      "4810 번째 loss, accuracy:  0.49651529772292047 0.6916666666666667\n",
      "4811 번째 loss, accuracy:  0.4964999353643674 0.6916666666666667\n",
      "4812 번째 loss, accuracy:  0.4964845774749257 0.6916666666666667\n",
      "4813 번째 loss, accuracy:  0.4964692240490417 0.6916666666666667\n",
      "4814 번째 loss, accuracy:  0.49645387508116395 0.6916666666666667\n",
      "4815 번째 loss, accuracy:  0.4964385305657435 0.6916666666666667\n",
      "4816 번째 loss, accuracy:  0.4964231904972331 0.6916666666666667\n",
      "4817 번째 loss, accuracy:  0.49640785487008804 0.6916666666666667\n",
      "4818 번째 loss, accuracy:  0.4963925236787658 0.6916666666666667\n",
      "4819 번째 loss, accuracy:  0.4963771969177258 0.6916666666666667\n",
      "4820 번째 loss, accuracy:  0.4963618745814297 0.6916666666666667\n",
      "4821 번째 loss, accuracy:  0.4963465566643414 0.6916666666666667\n",
      "4822 번째 loss, accuracy:  0.49633124316092725 0.6916666666666667\n",
      "4823 번째 loss, accuracy:  0.49631593406565533 0.6916666666666667\n",
      "4824 번째 loss, accuracy:  0.4963006293729959 0.6916666666666667\n",
      "4825 번째 loss, accuracy:  0.4962853290774216 0.6916666666666667\n",
      "4826 번째 loss, accuracy:  0.49627003317340684 0.6916666666666667\n",
      "4827 번째 loss, accuracy:  0.4962547416554289 0.6916666666666667\n",
      "4828 번째 loss, accuracy:  0.4962394545179662 0.6916666666666667\n",
      "4829 번째 loss, accuracy:  0.49622417175549977 0.6916666666666667\n",
      "4830 번째 loss, accuracy:  0.496208893362513 0.6916666666666667\n",
      "4831 번째 loss, accuracy:  0.496193619333491 0.6916666666666667\n",
      "4832 번째 loss, accuracy:  0.4961783496629214 0.6916666666666667\n",
      "4833 번째 loss, accuracy:  0.4961630843452937 0.6916666666666667\n",
      "4834 번째 loss, accuracy:  0.4961478233750996 0.6916666666666667\n",
      "4835 번째 loss, accuracy:  0.49613256674683254 0.6916666666666667\n",
      "4836 번째 loss, accuracy:  0.4961173144549884 0.6916666666666667\n",
      "4837 번째 loss, accuracy:  0.4961020664940649 0.6916666666666667\n",
      "4838 번째 loss, accuracy:  0.49608682285856237 0.6916666666666667\n",
      "4839 번째 loss, accuracy:  0.4960715835429825 0.6916666666666667\n",
      "4840 번째 loss, accuracy:  0.4960563485418296 0.6916666666666667\n",
      "4841 번째 loss, accuracy:  0.49604111784960986 0.6916666666666667\n",
      "4842 번째 loss, accuracy:  0.49602589146083115 0.6916666666666667\n",
      "4843 번째 loss, accuracy:  0.4960106693700043 0.6916666666666667\n",
      "4844 번째 loss, accuracy:  0.4959954515716415 0.6916666666666667\n",
      "4845 번째 loss, accuracy:  0.4959802380602572 0.6916666666666667\n",
      "4846 번째 loss, accuracy:  0.4959650288303675 0.6916666666666667\n",
      "4847 번째 loss, accuracy:  0.4959498238764913 0.6916666666666667\n",
      "4848 번째 loss, accuracy:  0.4959346231931489 0.6916666666666667\n",
      "4849 번째 loss, accuracy:  0.49591942677486295 0.6916666666666667\n",
      "4850 번째 loss, accuracy:  0.4959042346161579 0.6916666666666667\n",
      "4851 번째 loss, accuracy:  0.49588904671156053 0.6916666666666667\n",
      "4852 번째 loss, accuracy:  0.49587386305559905 0.6916666666666667\n",
      "4853 번째 loss, accuracy:  0.4958586836428046 0.6916666666666667\n",
      "4854 번째 loss, accuracy:  0.4958435084677094 0.6916666666666667\n",
      "4855 번째 loss, accuracy:  0.49582833752484823 0.6916666666666667\n",
      "4856 번째 loss, accuracy:  0.4958131708087576 0.6916666666666667\n",
      "4857 번째 loss, accuracy:  0.4957980083139761 0.6916666666666667\n",
      "4858 번째 loss, accuracy:  0.49578285003504435 0.6916666666666667\n",
      "4859 번째 loss, accuracy:  0.49576769596650494 0.6916666666666667\n",
      "4860 번째 loss, accuracy:  0.49575254610290265 0.6916666666666667\n",
      "4861 번째 loss, accuracy:  0.49573740043878367 0.6916666666666667\n",
      "4862 번째 loss, accuracy:  0.49572225896869665 0.6916666666666667\n",
      "4863 번째 loss, accuracy:  0.49570712168719183 0.6916666666666667\n",
      "4864 번째 loss, accuracy:  0.49569198858882174 0.6916666666666667\n",
      "4865 번째 loss, accuracy:  0.4956768596681408 0.6916666666666667\n",
      "4866 번째 loss, accuracy:  0.49566173491970494 0.6916666666666667\n",
      "4867 번째 loss, accuracy:  0.4956466143380727 0.6916666666666667\n",
      "4868 번째 loss, accuracy:  0.49563149791780425 0.6916666666666667\n",
      "4869 번째 loss, accuracy:  0.4956163856534617 0.6916666666666667\n",
      "4870 번째 loss, accuracy:  0.49560127753960875 0.6916666666666667\n",
      "4871 번째 loss, accuracy:  0.49558617357081164 0.6916666666666667\n",
      "4872 번째 loss, accuracy:  0.4955710737416382 0.6916666666666667\n",
      "4873 번째 loss, accuracy:  0.49555597804665796 0.6916666666666667\n",
      "4874 번째 loss, accuracy:  0.49554088648044314 0.6916666666666667\n",
      "4875 번째 loss, accuracy:  0.49552579903756705 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4876 번째 loss, accuracy:  0.49551071571260497 0.6916666666666667\n",
      "4877 번째 loss, accuracy:  0.49549563650013445 0.6916666666666667\n",
      "4878 번째 loss, accuracy:  0.4954805613947347 0.6916666666666667\n",
      "4879 번째 loss, accuracy:  0.4954654903909869 0.6916666666666667\n",
      "4880 번째 loss, accuracy:  0.495450423483474 0.6916666666666667\n",
      "4881 번째 loss, accuracy:  0.4954353606667812 0.6916666666666667\n",
      "4882 번째 loss, accuracy:  0.4954203019354949 0.6916666666666667\n",
      "4883 번째 loss, accuracy:  0.49540524728420415 0.6916666666666667\n",
      "4884 번째 loss, accuracy:  0.49539019670749923 0.6916666666666667\n",
      "4885 번째 loss, accuracy:  0.49537515019997225 0.6916666666666667\n",
      "4886 번째 loss, accuracy:  0.49536010775621747 0.6916666666666667\n",
      "4887 번째 loss, accuracy:  0.49534506937083134 0.6916666666666667\n",
      "4888 번째 loss, accuracy:  0.4953300350384114 0.6916666666666667\n",
      "4889 번째 loss, accuracy:  0.4953150047535575 0.6916666666666667\n",
      "4890 번째 loss, accuracy:  0.4952999785108714 0.6916666666666667\n",
      "4891 번째 loss, accuracy:  0.4952849563049561 0.6916666666666667\n",
      "4892 번째 loss, accuracy:  0.49526993813041725 0.6916666666666667\n",
      "4893 번째 loss, accuracy:  0.49525492398186144 0.6916666666666667\n",
      "4894 번째 loss, accuracy:  0.495239913853898 0.6916666666666667\n",
      "4895 번째 loss, accuracy:  0.49522490774113703 0.6916666666666667\n",
      "4896 번째 loss, accuracy:  0.49520990563819145 0.6916666666666667\n",
      "4897 번째 loss, accuracy:  0.4951949075396751 0.6916666666666667\n",
      "4898 번째 loss, accuracy:  0.49517991344020446 0.6916666666666667\n",
      "4899 번째 loss, accuracy:  0.49516492333439716 0.6916666666666667\n",
      "4900 번째 loss, accuracy:  0.4951499372168726 0.6916666666666667\n",
      "4901 번째 loss, accuracy:  0.4951349550822524 0.6916666666666667\n",
      "4902 번째 loss, accuracy:  0.4951199769251597 0.6916666666666667\n",
      "4903 번째 loss, accuracy:  0.4951050027402198 0.6916666666666667\n",
      "4904 번째 loss, accuracy:  0.495090032522059 0.6916666666666667\n",
      "4905 번째 loss, accuracy:  0.49507506626530595 0.6916666666666667\n",
      "4906 번째 loss, accuracy:  0.49506010396459094 0.6916666666666667\n",
      "4907 번째 loss, accuracy:  0.4950451456145457 0.6916666666666667\n",
      "4908 번째 loss, accuracy:  0.49503019120980424 0.6916666666666667\n",
      "4909 번째 loss, accuracy:  0.4950152407450021 0.6916666666666667\n",
      "4910 번째 loss, accuracy:  0.49500029421477615 0.6916666666666667\n",
      "4911 번째 loss, accuracy:  0.4949853516137655 0.6916666666666667\n",
      "4912 번째 loss, accuracy:  0.49497041293661087 0.6916666666666667\n",
      "4913 번째 loss, accuracy:  0.49495547817795466 0.6916666666666667\n",
      "4914 번째 loss, accuracy:  0.494940547332441 0.6916666666666667\n",
      "4915 번째 loss, accuracy:  0.49492562039471577 0.6916666666666667\n",
      "4916 번째 loss, accuracy:  0.4949106973594264 0.6916666666666667\n",
      "4917 번째 loss, accuracy:  0.4948957782212224 0.6916666666666667\n",
      "4918 번째 loss, accuracy:  0.49488086297475464 0.6916666666666667\n",
      "4919 번째 loss, accuracy:  0.4948659516146757 0.6916666666666667\n",
      "4920 번째 loss, accuracy:  0.49485104413563996 0.6916666666666667\n",
      "4921 번째 loss, accuracy:  0.4948361405323035 0.6916666666666667\n",
      "4922 번째 loss, accuracy:  0.49482124079932427 0.6916666666666667\n",
      "4923 번째 loss, accuracy:  0.4948063449313613 0.6916666666666667\n",
      "4924 번째 loss, accuracy:  0.4947914529230758 0.6916666666666667\n",
      "4925 번째 loss, accuracy:  0.4947765647691305 0.6916666666666667\n",
      "4926 번째 loss, accuracy:  0.49476168046418995 0.6916666666666667\n",
      "4927 번째 loss, accuracy:  0.49474680000292015 0.6916666666666667\n",
      "4928 번째 loss, accuracy:  0.49473192337998867 0.6916666666666667\n",
      "4929 번째 loss, accuracy:  0.49471705059006504 0.6916666666666667\n",
      "4930 번째 loss, accuracy:  0.4947021816278204 0.6916666666666667\n",
      "4931 번째 loss, accuracy:  0.49468731648792713 0.6916666666666667\n",
      "4932 번째 loss, accuracy:  0.4946724551650599 0.6916666666666667\n",
      "4933 번째 loss, accuracy:  0.49465759765389433 0.6916666666666667\n",
      "4934 번째 loss, accuracy:  0.4946427439491084 0.6916666666666667\n",
      "4935 번째 loss, accuracy:  0.4946278940453809 0.6916666666666667\n",
      "4936 번째 loss, accuracy:  0.49461304793739275 0.6916666666666667\n",
      "4937 번째 loss, accuracy:  0.4945982056198267 0.6916666666666667\n",
      "4938 번째 loss, accuracy:  0.49458336708736644 0.6916666666666667\n",
      "4939 번째 loss, accuracy:  0.4945685323346979 0.6916666666666667\n",
      "4940 번째 loss, accuracy:  0.49455370135650806 0.6916666666666667\n",
      "4941 번째 loss, accuracy:  0.4945388741474857 0.6916666666666667\n",
      "4942 번째 loss, accuracy:  0.49452405070232147 0.6916666666666667\n",
      "4943 번째 loss, accuracy:  0.4945092310157076 0.6916666666666667\n",
      "4944 번째 loss, accuracy:  0.49449441508233755 0.6916666666666667\n",
      "4945 번째 loss, accuracy:  0.49447960289690635 0.6916666666666667\n",
      "4946 번째 loss, accuracy:  0.4944647944541111 0.6916666666666667\n",
      "4947 번째 loss, accuracy:  0.4944499897486497 0.6916666666666667\n",
      "4948 번째 loss, accuracy:  0.4944351887752222 0.6916666666666667\n",
      "4949 번째 loss, accuracy:  0.4944203915285301 0.6916666666666667\n",
      "4950 번째 loss, accuracy:  0.4944055980032767 0.6916666666666667\n",
      "4951 번째 loss, accuracy:  0.4943908081941663 0.6916666666666667\n",
      "4952 번째 loss, accuracy:  0.49437602209590525 0.6916666666666667\n",
      "4953 번째 loss, accuracy:  0.4943612397032009 0.6916666666666667\n",
      "4954 번째 loss, accuracy:  0.4943464610107627 0.6916666666666667\n",
      "4955 번째 loss, accuracy:  0.49433168601330096 0.6916666666666667\n",
      "4956 번째 loss, accuracy:  0.49431691470552863 0.6916666666666667\n",
      "4957 번째 loss, accuracy:  0.49430214708215925 0.6916666666666667\n",
      "4958 번째 loss, accuracy:  0.49428738313790815 0.6916666666666667\n",
      "4959 번째 loss, accuracy:  0.4942726228674919 0.6916666666666667\n",
      "4960 번째 loss, accuracy:  0.4942578662656292 0.6916666666666667\n",
      "4961 번째 loss, accuracy:  0.4942431133270399 0.6916666666666667\n",
      "4962 번째 loss, accuracy:  0.49422836404644527 0.6916666666666667\n",
      "4963 번째 loss, accuracy:  0.4942136184185682 0.6916666666666667\n",
      "4964 번째 loss, accuracy:  0.49419887643813304 0.6916666666666667\n",
      "4965 번째 loss, accuracy:  0.4941841380998656 0.6916666666666667\n",
      "4966 번째 loss, accuracy:  0.4941694033984933 0.6916666666666667\n",
      "4967 번째 loss, accuracy:  0.49415467232874505 0.6916666666666667\n",
      "4968 번째 loss, accuracy:  0.494139944885351 0.6916666666666667\n",
      "4969 번째 loss, accuracy:  0.49412522106304285 0.6916666666666667\n",
      "4970 번째 loss, accuracy:  0.494110500856554 0.6916666666666667\n",
      "4971 번째 loss, accuracy:  0.4940957842606191 0.6916666666666667\n",
      "4972 번째 loss, accuracy:  0.49408107126997436 0.6916666666666667\n",
      "4973 번째 loss, accuracy:  0.49406636187935743 0.6916666666666667\n",
      "4974 번째 loss, accuracy:  0.49405165608350704 0.6916666666666667\n",
      "4975 번째 loss, accuracy:  0.4940369538771641 0.6916666666666667\n",
      "4976 번째 loss, accuracy:  0.4940222552550706 0.6916666666666667\n",
      "4977 번째 loss, accuracy:  0.49400756021196945 0.6916666666666667\n",
      "4978 번째 loss, accuracy:  0.4939928687426061 0.6916666666666667\n",
      "4979 번째 loss, accuracy:  0.49397818084172646 0.6916666666666667\n",
      "4980 번째 loss, accuracy:  0.4939634965040784 0.6916666666666667\n",
      "4981 번째 loss, accuracy:  0.4939488157244109 0.6916666666666667\n",
      "4982 번째 loss, accuracy:  0.49393413849747436 0.6916666666666667\n",
      "4983 번째 loss, accuracy:  0.493919464818021 0.6916666666666667\n",
      "4984 번째 loss, accuracy:  0.493904794680804 0.6916666666666667\n",
      "4985 번째 loss, accuracy:  0.49389012808057814 0.6916666666666667\n",
      "4986 번째 loss, accuracy:  0.4938754650120996 0.6916666666666667\n",
      "4987 번째 loss, accuracy:  0.49386080547012595 0.6916666666666667\n",
      "4988 번째 loss, accuracy:  0.493846149449416 0.6916666666666667\n",
      "4989 번째 loss, accuracy:  0.4938314969447302 0.6916666666666667\n",
      "4990 번째 loss, accuracy:  0.49381684795083036 0.6916666666666667\n",
      "4991 번째 loss, accuracy:  0.4938022024624792 0.6916666666666667\n",
      "4992 번째 loss, accuracy:  0.4937875604744413 0.6916666666666667\n",
      "4993 번째 loss, accuracy:  0.4937729219814827 0.6916666666666667\n",
      "4994 번째 loss, accuracy:  0.4937582869783704 0.6916666666666667\n",
      "4995 번째 loss, accuracy:  0.4937436554598732 0.6916666666666667\n",
      "4996 번째 loss, accuracy:  0.4937290274207607 0.6916666666666667\n",
      "4997 번째 loss, accuracy:  0.4937144028558042 0.6916666666666667\n",
      "4998 번째 loss, accuracy:  0.4936997817597766 0.6916666666666667\n",
      "4999 번째 loss, accuracy:  0.4936851641274516 0.6916666666666667\n",
      "5000 번째 loss, accuracy:  0.4936705499536044 0.6916666666666667\n",
      "5001 번째 loss, accuracy:  0.49365593923301176 0.6916666666666667\n",
      "5002 번째 loss, accuracy:  0.4936413319604516 0.6916666666666667\n",
      "5003 번째 loss, accuracy:  0.4936267281307035 0.6916666666666667\n",
      "5004 번째 loss, accuracy:  0.49361212773854757 0.6916666666666667\n",
      "5005 번째 loss, accuracy:  0.49359753077876617 0.6916666666666667\n",
      "5006 번째 loss, accuracy:  0.4935829372461422 0.6916666666666667\n",
      "5007 번째 loss, accuracy:  0.49356834713546033 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5008 번째 loss, accuracy:  0.4935537604415064 0.6916666666666667\n",
      "5009 번째 loss, accuracy:  0.4935391771590674 0.6916666666666667\n",
      "5010 번째 loss, accuracy:  0.49352459728293224 0.6916666666666667\n",
      "5011 번째 loss, accuracy:  0.49351002080789014 0.6916666666666667\n",
      "5012 번째 loss, accuracy:  0.4934954477287325 0.6916666666666667\n",
      "5013 번째 loss, accuracy:  0.49348087804025137 0.6916666666666667\n",
      "5014 번째 loss, accuracy:  0.4934663117372404 0.6916666666666667\n",
      "5015 번째 loss, accuracy:  0.49345174881449483 0.6916666666666667\n",
      "5016 번째 loss, accuracy:  0.49343718926681013 0.6916666666666667\n",
      "5017 번째 loss, accuracy:  0.49342263308898426 0.6916666666666667\n",
      "5018 번째 loss, accuracy:  0.4934080802758158 0.6916666666666667\n",
      "5019 번째 loss, accuracy:  0.4933935308221045 0.6916666666666667\n",
      "5020 번째 loss, accuracy:  0.49337898472265185 0.6916666666666667\n",
      "5021 번째 loss, accuracy:  0.49336444197226 0.6916666666666667\n",
      "5022 번째 loss, accuracy:  0.49334990256573275 0.6916666666666667\n",
      "5023 번째 loss, accuracy:  0.49333536649787496 0.6916666666666667\n",
      "5024 번째 loss, accuracy:  0.4933208337634928 0.6916666666666667\n",
      "5025 번째 loss, accuracy:  0.4933063043573938 0.6916666666666667\n",
      "5026 번째 loss, accuracy:  0.49329177827438647 0.6916666666666667\n",
      "5027 번째 loss, accuracy:  0.4932772555092806 0.6916666666666667\n",
      "5028 번째 loss, accuracy:  0.49326273605688736 0.6916666666666667\n",
      "5029 번째 loss, accuracy:  0.493248219912019 0.6916666666666667\n",
      "5030 번째 loss, accuracy:  0.4932337070694892 0.6916666666666667\n",
      "5031 번째 loss, accuracy:  0.4932191975241126 0.6916666666666667\n",
      "5032 번째 loss, accuracy:  0.49320469127070504 0.6916666666666667\n",
      "5033 번째 loss, accuracy:  0.49319018830408334 0.6916666666666667\n",
      "5034 번째 loss, accuracy:  0.4931756886190661 0.6916666666666667\n",
      "5035 번째 loss, accuracy:  0.49316119221047305 0.6916666666666667\n",
      "5036 번째 loss, accuracy:  0.4931466990731248 0.6916666666666667\n",
      "5037 번째 loss, accuracy:  0.49313220920184314 0.6916666666666667\n",
      "5038 번째 loss, accuracy:  0.49311772259145115 0.6916666666666667\n",
      "5039 번째 loss, accuracy:  0.4931032392367731 0.6916666666666667\n",
      "5040 번째 loss, accuracy:  0.4930887591326345 0.6916666666666667\n",
      "5041 번째 loss, accuracy:  0.4930742822738619 0.6916666666666667\n",
      "5042 번째 loss, accuracy:  0.49305980865528265 0.6916666666666667\n",
      "5043 번째 loss, accuracy:  0.4930453382717262 0.6916666666666667\n",
      "5044 번째 loss, accuracy:  0.4930308711180223 0.6916666666666667\n",
      "5045 번째 loss, accuracy:  0.4930164071890022 0.6916666666666667\n",
      "5046 번째 loss, accuracy:  0.4930019464794982 0.6916666666666667\n",
      "5047 번째 loss, accuracy:  0.4929874889843442 0.6916666666666667\n",
      "5048 번째 loss, accuracy:  0.4929730346983746 0.6916666666666667\n",
      "5049 번째 loss, accuracy:  0.49295858361642525 0.6916666666666667\n",
      "5050 번째 loss, accuracy:  0.4929441357333331 0.6916666666666667\n",
      "5051 번째 loss, accuracy:  0.49292969104393575 0.6916666666666667\n",
      "5052 번째 loss, accuracy:  0.49291524954307264 0.6916666666666667\n",
      "5053 번째 loss, accuracy:  0.49290081122558416 0.6916666666666667\n",
      "5054 번째 loss, accuracy:  0.49288637608631164 0.6916666666666667\n",
      "5055 번째 loss, accuracy:  0.4928719441200976 0.6916666666666667\n",
      "5056 번째 loss, accuracy:  0.4928575153217858 0.6916666666666667\n",
      "5057 번째 loss, accuracy:  0.49284308968622065 0.6916666666666667\n",
      "5058 번째 loss, accuracy:  0.4928286672082482 0.6916666666666667\n",
      "5059 번째 loss, accuracy:  0.49281424788271516 0.6916666666666667\n",
      "5060 번째 loss, accuracy:  0.4927998317044698 0.6916666666666667\n",
      "5061 번째 loss, accuracy:  0.4927854186683612 0.6916666666666667\n",
      "5062 번째 loss, accuracy:  0.49277100876923957 0.6916666666666667\n",
      "5063 번째 loss, accuracy:  0.4927566020019559 0.6916666666666667\n",
      "5064 번째 loss, accuracy:  0.49274219836136246 0.6916666666666667\n",
      "5065 번째 loss, accuracy:  0.4927277978423129 0.6916666666666667\n",
      "5066 번째 loss, accuracy:  0.4927134004396617 0.6916666666666667\n",
      "5067 번째 loss, accuracy:  0.49269900614826445 0.6916666666666667\n",
      "5068 번째 loss, accuracy:  0.4926846149629778 0.6916666666666667\n",
      "5069 번째 loss, accuracy:  0.49267022687865897 0.6916666666666667\n",
      "5070 번째 loss, accuracy:  0.49265584189016703 0.6916666666666667\n",
      "5071 번째 loss, accuracy:  0.49264145999236164 0.6916666666666667\n",
      "5072 번째 loss, accuracy:  0.49262708118010373 0.6916666666666667\n",
      "5073 번째 loss, accuracy:  0.4926127054482548 0.6916666666666667\n",
      "5074 번째 loss, accuracy:  0.492598332791678 0.6916666666666667\n",
      "5075 번째 loss, accuracy:  0.49258396320523695 0.6916666666666667\n",
      "5076 번째 loss, accuracy:  0.49256959668379674 0.6916666666666667\n",
      "5077 번째 loss, accuracy:  0.4925552332222235 0.6916666666666667\n",
      "5078 번째 loss, accuracy:  0.492540872815384 0.6916666666666667\n",
      "5079 번째 loss, accuracy:  0.49252651545814624 0.6916666666666667\n",
      "5080 번째 loss, accuracy:  0.49251216114537916 0.6916666666666667\n",
      "5081 번째 loss, accuracy:  0.4924978098719529 0.6916666666666667\n",
      "5082 번째 loss, accuracy:  0.49248346163273843 0.6916666666666667\n",
      "5083 번째 loss, accuracy:  0.49246911642260777 0.6916666666666667\n",
      "5084 번째 loss, accuracy:  0.4924547742364338 0.6916666666666667\n",
      "5085 번째 loss, accuracy:  0.4924404350690906 0.6916666666666667\n",
      "5086 번째 loss, accuracy:  0.49242609891545314 0.6916666666666667\n",
      "5087 번째 loss, accuracy:  0.4924117657703974 0.6916666666666667\n",
      "5088 번째 loss, accuracy:  0.49239743562880045 0.6916666666666667\n",
      "5089 번째 loss, accuracy:  0.4923831084855401 0.6916666666666667\n",
      "5090 번째 loss, accuracy:  0.49236878433549525 0.6916666666666667\n",
      "5091 번째 loss, accuracy:  0.49235446317354575 0.6916666666666667\n",
      "5092 번째 loss, accuracy:  0.4923401449945726 0.6916666666666667\n",
      "5093 번째 loss, accuracy:  0.49232582979345746 0.6916666666666667\n",
      "5094 번째 loss, accuracy:  0.49231151756508296 0.6916666666666667\n",
      "5095 번째 loss, accuracy:  0.492297208304333 0.6916666666666667\n",
      "5096 번째 loss, accuracy:  0.49228290200609204 0.6916666666666667\n",
      "5097 번째 loss, accuracy:  0.4922685986652459 0.6916666666666667\n",
      "5098 번째 loss, accuracy:  0.4922542982766812 0.6916666666666667\n",
      "5099 번째 loss, accuracy:  0.492240000835285 0.6916666666666667\n",
      "5100 번째 loss, accuracy:  0.49222570633594626 0.6916666666666667\n",
      "5101 번째 loss, accuracy:  0.49221141477355407 0.6916666666666667\n",
      "5102 번째 loss, accuracy:  0.4921971261429985 0.6916666666666667\n",
      "5103 번째 loss, accuracy:  0.49218284043917104 0.6916666666666667\n",
      "5104 번째 loss, accuracy:  0.4921685576569636 0.6916666666666667\n",
      "5105 번째 loss, accuracy:  0.4921542777912693 0.6916666666666667\n",
      "5106 번째 loss, accuracy:  0.49214000083698195 0.6916666666666667\n",
      "5107 번째 loss, accuracy:  0.49212572678899646 0.6916666666666667\n",
      "5108 번째 loss, accuracy:  0.4921114556422087 0.6916666666666667\n",
      "5109 번째 loss, accuracy:  0.4920971873915152 0.6916666666666667\n",
      "5110 번째 loss, accuracy:  0.49208292203181353 0.6916666666666667\n",
      "5111 번째 loss, accuracy:  0.4920686595580025 0.6916666666666667\n",
      "5112 번째 loss, accuracy:  0.4920543999649808 0.6916666666666667\n",
      "5113 번째 loss, accuracy:  0.49204014324764905 0.6916666666666667\n",
      "5114 번째 loss, accuracy:  0.4920258894009082 0.6916666666666667\n",
      "5115 번째 loss, accuracy:  0.49201163841966034 0.6916666666666667\n",
      "5116 번째 loss, accuracy:  0.4919973902988083 0.6916666666666667\n",
      "5117 번째 loss, accuracy:  0.4919831450332557 0.6916666666666667\n",
      "5118 번째 loss, accuracy:  0.49196890261790677 0.6916666666666667\n",
      "5119 번째 loss, accuracy:  0.4919546630476676 0.6916666666666667\n",
      "5120 번째 loss, accuracy:  0.4919404263174443 0.6916666666666667\n",
      "5121 번째 loss, accuracy:  0.4919261924221436 0.6916666666666667\n",
      "5122 번째 loss, accuracy:  0.4919119613566741 0.6916666666666667\n",
      "5123 번째 loss, accuracy:  0.4918977331159443 0.6916666666666667\n",
      "5124 번째 loss, accuracy:  0.4918835076948638 0.6916666666666667\n",
      "5125 번째 loss, accuracy:  0.49186928508834343 0.6916666666666667\n",
      "5126 번째 loss, accuracy:  0.4918550652912945 0.6916666666666667\n",
      "5127 번째 loss, accuracy:  0.491840848298629 0.6916666666666667\n",
      "5128 번째 loss, accuracy:  0.4918266341052602 0.6916666666666667\n",
      "5129 번째 loss, accuracy:  0.49181242270610187 0.6916666666666667\n",
      "5130 번째 loss, accuracy:  0.49179821409606866 0.6916666666666667\n",
      "5131 번째 loss, accuracy:  0.49178400827007585 0.6916666666666667\n",
      "5132 번째 loss, accuracy:  0.49176980522304015 0.6916666666666667\n",
      "5133 번째 loss, accuracy:  0.4917556049498784 0.6916666666666667\n",
      "5134 번째 loss, accuracy:  0.49174140744550865 0.6916666666666667\n",
      "5135 번째 loss, accuracy:  0.49172721270484937 0.6916666666666667\n",
      "5136 번째 loss, accuracy:  0.49171302072282064 0.6916666666666667\n",
      "5137 번째 loss, accuracy:  0.4916988314943423 0.6916666666666667\n",
      "5138 번째 loss, accuracy:  0.49168464501433556 0.6916666666666667\n",
      "5139 번째 loss, accuracy:  0.4916704612777221 0.6916666666666667\n",
      "5140 번째 loss, accuracy:  0.49165628027942476 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5141 번째 loss, accuracy:  0.49164210201436725 0.6916666666666667\n",
      "5142 번째 loss, accuracy:  0.4916279264774736 0.6916666666666667\n",
      "5143 번째 loss, accuracy:  0.49161375366366883 0.6916666666666667\n",
      "5144 번째 loss, accuracy:  0.49159958356787864 0.6916666666666667\n",
      "5145 번째 loss, accuracy:  0.4915854161850296 0.6916666666666667\n",
      "5146 번째 loss, accuracy:  0.4915712515100491 0.6916666666666667\n",
      "5147 번째 loss, accuracy:  0.49155708953786525 0.6916666666666667\n",
      "5148 번째 loss, accuracy:  0.49154293026340656 0.6916666666666667\n",
      "5149 번째 loss, accuracy:  0.49152877368160286 0.6916666666666667\n",
      "5150 번째 loss, accuracy:  0.4915146197873843 0.6916666666666667\n",
      "5151 번째 loss, accuracy:  0.49150046857568214 0.6916666666666667\n",
      "5152 번째 loss, accuracy:  0.49148632004142806 0.6916666666666667\n",
      "5153 번째 loss, accuracy:  0.49147217417955447 0.6916666666666667\n",
      "5154 번째 loss, accuracy:  0.4914580309849948 0.6916666666666667\n",
      "5155 번째 loss, accuracy:  0.4914438904526832 0.6916666666666667\n",
      "5156 번째 loss, accuracy:  0.4914297525775541 0.6916666666666667\n",
      "5157 번째 loss, accuracy:  0.4914156173545432 0.6916666666666667\n",
      "5158 번째 loss, accuracy:  0.4914014847785862 0.6916666666666667\n",
      "5159 번째 loss, accuracy:  0.4913873548446205 0.6916666666666667\n",
      "5160 번째 loss, accuracy:  0.4913732275475837 0.6916666666666667\n",
      "5161 번째 loss, accuracy:  0.4913591028824136 0.6916666666666667\n",
      "5162 번째 loss, accuracy:  0.49134498084404954 0.6916666666666667\n",
      "5163 번째 loss, accuracy:  0.49133086142743093 0.6916666666666667\n",
      "5164 번째 loss, accuracy:  0.4913167446274986 0.6916666666666667\n",
      "5165 번째 loss, accuracy:  0.4913026304391934 0.6916666666666667\n",
      "5166 번째 loss, accuracy:  0.49128851885745706 0.6916666666666667\n",
      "5167 번째 loss, accuracy:  0.491274409877232 0.6916666666666667\n",
      "5168 번째 loss, accuracy:  0.4912603034934616 0.6916666666666667\n",
      "5169 번째 loss, accuracy:  0.4912461997010895 0.6916666666666667\n",
      "5170 번째 loss, accuracy:  0.4912320984950603 0.6916666666666667\n",
      "5171 번째 loss, accuracy:  0.491217999870319 0.6916666666666667\n",
      "5172 번째 loss, accuracy:  0.49120390382181184 0.6916666666666667\n",
      "5173 번째 loss, accuracy:  0.49118981034448506 0.6916666666666667\n",
      "5174 번째 loss, accuracy:  0.49117571943328603 0.6916666666666667\n",
      "5175 번째 loss, accuracy:  0.4911616310831621 0.6916666666666667\n",
      "5176 번째 loss, accuracy:  0.49114754528906207 0.6916666666666667\n",
      "5177 번째 loss, accuracy:  0.4911334620459351 0.6916666666666667\n",
      "5178 번째 loss, accuracy:  0.4911193813487308 0.6916666666666667\n",
      "5179 번째 loss, accuracy:  0.4911053031923999 0.6916666666666667\n",
      "5180 번째 loss, accuracy:  0.49109122757189316 0.6916666666666667\n",
      "5181 번째 loss, accuracy:  0.4910771544821626 0.6916666666666667\n",
      "5182 번째 loss, accuracy:  0.4910630839181602 0.6916666666666667\n",
      "5183 번째 loss, accuracy:  0.4910490158748391 0.6916666666666667\n",
      "5184 번째 loss, accuracy:  0.49103495034715283 0.6916666666666667\n",
      "5185 번째 loss, accuracy:  0.4910208873300556 0.6916666666666667\n",
      "5186 번째 loss, accuracy:  0.4910068268185024 0.6916666666666667\n",
      "5187 번째 loss, accuracy:  0.4909927688074486 0.6916666666666667\n",
      "5188 번째 loss, accuracy:  0.49097871329185006 0.6916666666666667\n",
      "5189 번째 loss, accuracy:  0.4909646602666638 0.6916666666666667\n",
      "5190 번째 loss, accuracy:  0.49095060972684695 0.6916666666666667\n",
      "5191 번째 loss, accuracy:  0.49093656166735733 0.6916666666666667\n",
      "5192 번째 loss, accuracy:  0.4909225160831533 0.6916666666666667\n",
      "5193 번째 loss, accuracy:  0.4909084729691941 0.6916666666666667\n",
      "5194 번째 loss, accuracy:  0.49089443232043933 0.6916666666666667\n",
      "5195 번째 loss, accuracy:  0.49088039413184925 0.6916666666666667\n",
      "5196 번째 loss, accuracy:  0.4908663583983847 0.6916666666666667\n",
      "5197 번째 loss, accuracy:  0.49085232511500726 0.6916666666666667\n",
      "5198 번째 loss, accuracy:  0.49083829427667874 0.6916666666666667\n",
      "5199 번째 loss, accuracy:  0.49082426587836175 0.6916666666666667\n",
      "5200 번째 loss, accuracy:  0.49081023991501943 0.6916666666666667\n",
      "5201 번째 loss, accuracy:  0.49079621638161547 0.6916666666666667\n",
      "5202 번째 loss, accuracy:  0.4907821952731142 0.6916666666666667\n",
      "5203 번째 loss, accuracy:  0.4907681765844803 0.6916666666666667\n",
      "5204 번째 loss, accuracy:  0.4907541603106794 0.6916666666666667\n",
      "5205 번째 loss, accuracy:  0.4907401464466774 0.6916666666666667\n",
      "5206 번째 loss, accuracy:  0.49072613498744067 0.6916666666666667\n",
      "5207 번째 loss, accuracy:  0.4907121259279363 0.6916666666666667\n",
      "5208 번째 loss, accuracy:  0.49069811926313206 0.6916666666666667\n",
      "5209 번째 loss, accuracy:  0.4906841149879958 0.6916666666666667\n",
      "5210 번째 loss, accuracy:  0.4906701130974962 0.6916666666666667\n",
      "5211 번째 loss, accuracy:  0.49065611358660266 0.6916666666666667\n",
      "5212 번째 loss, accuracy:  0.4906421164502851 0.6916666666666667\n",
      "5213 번째 loss, accuracy:  0.49062812168351344 0.6916666666666667\n",
      "5214 번째 loss, accuracy:  0.49061412928125847 0.6916666666666667\n",
      "5215 번째 loss, accuracy:  0.4906001392384915 0.6916666666666667\n",
      "5216 번째 loss, accuracy:  0.49058615155018437 0.6916666666666667\n",
      "5217 번째 loss, accuracy:  0.4905721662113095 0.6916666666666667\n",
      "5218 번째 loss, accuracy:  0.4905581832168398 0.6916666666666667\n",
      "5219 번째 loss, accuracy:  0.49054420256174847 0.6916666666666667\n",
      "5220 번째 loss, accuracy:  0.49053022424100934 0.6916666666666667\n",
      "5221 번째 loss, accuracy:  0.4905162482495968 0.6916666666666667\n",
      "5222 번째 loss, accuracy:  0.49050227458248596 0.6916666666666667\n",
      "5223 번째 loss, accuracy:  0.49048830323465203 0.6916666666666667\n",
      "5224 번째 loss, accuracy:  0.4904743342010708 0.6916666666666667\n",
      "5225 번째 loss, accuracy:  0.4904603674767184 0.6916666666666667\n",
      "5226 번째 loss, accuracy:  0.4904464030565719 0.6916666666666667\n",
      "5227 번째 loss, accuracy:  0.49043244093560884 0.6916666666666667\n",
      "5228 번째 loss, accuracy:  0.49041848110880637 0.6916666666666667\n",
      "5229 번째 loss, accuracy:  0.4904045235711433 0.6916666666666667\n",
      "5230 번째 loss, accuracy:  0.4903905683175979 0.6916666666666667\n",
      "5231 번째 loss, accuracy:  0.4903766153431496 0.6916666666666667\n",
      "5232 번째 loss, accuracy:  0.4903626646427781 0.6916666666666667\n",
      "5233 번째 loss, accuracy:  0.4903487162114633 0.6916666666666667\n",
      "5234 번째 loss, accuracy:  0.4903347700441861 0.6916666666666667\n",
      "5235 번째 loss, accuracy:  0.49032082613592715 0.6916666666666667\n",
      "5236 번째 loss, accuracy:  0.4903068844816679 0.6916666666666667\n",
      "5237 번째 loss, accuracy:  0.49029294507639054 0.6916666666666667\n",
      "5238 번째 loss, accuracy:  0.4902790079150775 0.6916666666666667\n",
      "5239 번째 loss, accuracy:  0.4902650729927115 0.6916666666666667\n",
      "5240 번째 loss, accuracy:  0.49025114030427575 0.6916666666666667\n",
      "5241 번째 loss, accuracy:  0.490237209844754 0.6916666666666667\n",
      "5242 번째 loss, accuracy:  0.4902232816091302 0.6916666666666667\n",
      "5243 번째 loss, accuracy:  0.49020935559238904 0.6916666666666667\n",
      "5244 번째 loss, accuracy:  0.4901954317895153 0.6916666666666667\n",
      "5245 번째 loss, accuracy:  0.4901815101954946 0.6916666666666667\n",
      "5246 번째 loss, accuracy:  0.49016759080531264 0.6916666666666667\n",
      "5247 번째 loss, accuracy:  0.49015367361395595 0.6916666666666667\n",
      "5248 번째 loss, accuracy:  0.4901397586164108 0.6916666666666667\n",
      "5249 번째 loss, accuracy:  0.49012584580766416 0.6916666666666667\n",
      "5250 번째 loss, accuracy:  0.49011193518270385 0.6916666666666667\n",
      "5251 번째 loss, accuracy:  0.4900980267365174 0.6916666666666667\n",
      "5252 번째 loss, accuracy:  0.4900841204640933 0.6916666666666667\n",
      "5253 번째 loss, accuracy:  0.49007021636042014 0.6916666666666667\n",
      "5254 번째 loss, accuracy:  0.4900563144204871 0.6916666666666667\n",
      "5255 번째 loss, accuracy:  0.49004241463928355 0.6916666666666667\n",
      "5256 번째 loss, accuracy:  0.4900285170117993 0.6916666666666667\n",
      "5257 번째 loss, accuracy:  0.49001462153302433 0.6916666666666667\n",
      "5258 번째 loss, accuracy:  0.49000072819794954 0.6916666666666667\n",
      "5259 번째 loss, accuracy:  0.4899868370015657 0.6916666666666667\n",
      "5260 번째 loss, accuracy:  0.4899729479388643 0.6916666666666667\n",
      "5261 번째 loss, accuracy:  0.48995906100483727 0.6916666666666667\n",
      "5262 번째 loss, accuracy:  0.4899451761944764 0.6916666666666667\n",
      "5263 번째 loss, accuracy:  0.48993129350277426 0.6916666666666667\n",
      "5264 번째 loss, accuracy:  0.4899174129247234 0.6916666666666667\n",
      "5265 번째 loss, accuracy:  0.4899035344553174 0.6916666666666667\n",
      "5266 번째 loss, accuracy:  0.48988965808954976 0.6916666666666667\n",
      "5267 번째 loss, accuracy:  0.4898757838224141 0.6916666666666667\n",
      "5268 번째 loss, accuracy:  0.4898619116489049 0.6916666666666667\n",
      "5269 번째 loss, accuracy:  0.4898480415640166 0.6916666666666667\n",
      "5270 번째 loss, accuracy:  0.48983417356274445 0.6916666666666667\n",
      "5271 번째 loss, accuracy:  0.4898203076400832 0.6916666666666667\n",
      "5272 번째 loss, accuracy:  0.4898064437910287 0.6916666666666667\n",
      "5273 번째 loss, accuracy:  0.489792582010577 0.6916666666666667\n",
      "5274 번째 loss, accuracy:  0.4897787222937243 0.6916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5275 번째 loss, accuracy:  0.48976486463546715 0.6916666666666667\n",
      "5276 번째 loss, accuracy:  0.4897510090308026 0.6916666666666667\n",
      "5277 번째 loss, accuracy:  0.48973715547472796 0.6916666666666667\n",
      "5278 번째 loss, accuracy:  0.48972330396224045 0.6916666666666667\n",
      "5279 번째 loss, accuracy:  0.48970945448833836 0.6916666666666667\n",
      "5280 번째 loss, accuracy:  0.48969560704801973 0.6916666666666667\n",
      "5281 번째 loss, accuracy:  0.489681761636283 0.6916666666666667\n",
      "5282 번째 loss, accuracy:  0.48966791824812694 0.6916666666666667\n",
      "5283 번째 loss, accuracy:  0.4896540768785511 0.6916666666666667\n",
      "5284 번째 loss, accuracy:  0.4896402375225544 0.6916666666666667\n",
      "5285 번째 loss, accuracy:  0.4896264001751367 0.6916666666666667\n",
      "5286 번째 loss, accuracy:  0.48961256483129817 0.6916666666666667\n",
      "5287 번째 loss, accuracy:  0.48959873148603894 0.6916666666666667\n",
      "5288 번째 loss, accuracy:  0.4895849001343598 0.6916666666666667\n",
      "5289 번째 loss, accuracy:  0.4895710707712615 0.6916666666666667\n",
      "5290 번째 loss, accuracy:  0.48955724339174517 0.6916666666666667\n",
      "5291 번째 loss, accuracy:  0.4895434179908125 0.6916666666666667\n",
      "5292 번째 loss, accuracy:  0.48952959456346506 0.6916666666666667\n",
      "5293 번째 loss, accuracy:  0.48951577310470495 0.6916666666666667\n",
      "5294 번째 loss, accuracy:  0.4895019536095344 0.6916666666666667\n",
      "5295 번째 loss, accuracy:  0.48948813607295577 0.6916666666666667\n",
      "5296 번째 loss, accuracy:  0.489474320489972 0.6916666666666667\n",
      "5297 번째 loss, accuracy:  0.4894605068555862 0.6916666666666667\n",
      "5298 번째 loss, accuracy:  0.4894466951648018 0.6916666666666667\n",
      "5299 번째 loss, accuracy:  0.4894328854126222 0.6916666666666667\n",
      "5300 번째 loss, accuracy:  0.4894190775940513 0.6916666666666667\n",
      "5301 번째 loss, accuracy:  0.4894052717040932 0.6916666666666667\n",
      "5302 번째 loss, accuracy:  0.4893914677377523 0.6916666666666667\n",
      "5303 번째 loss, accuracy:  0.4893776656900333 0.6916666666666667\n",
      "5304 번째 loss, accuracy:  0.4893638655559407 0.6916666666666667\n",
      "5305 번째 loss, accuracy:  0.4893500673304797 0.6916666666666667\n",
      "5306 번째 loss, accuracy:  0.4893362710086557 0.6916666666666667\n",
      "5307 번째 loss, accuracy:  0.4893224765854742 0.6916666666666667\n",
      "5308 번째 loss, accuracy:  0.489308684055941 0.6916666666666667\n",
      "5309 번째 loss, accuracy:  0.48929489341506194 0.6916666666666667\n",
      "5310 번째 loss, accuracy:  0.4892811046578432 0.6916666666666667\n",
      "5311 번째 loss, accuracy:  0.4892673177792916 0.6916666666666667\n",
      "5312 번째 loss, accuracy:  0.48925353277441347 0.6916666666666667\n",
      "5313 번째 loss, accuracy:  0.4892397496382158 0.6916666666666667\n",
      "5314 번째 loss, accuracy:  0.4892259683657059 0.6916666666666667\n",
      "5315 번째 loss, accuracy:  0.48921218895189067 0.6916666666666667\n",
      "5316 번째 loss, accuracy:  0.4891984113917777 0.6916666666666667\n",
      "5317 번째 loss, accuracy:  0.4891846356803747 0.6916666666666667\n",
      "5318 번째 loss, accuracy:  0.48917086181268987 0.6916666666666667\n",
      "5319 번째 loss, accuracy:  0.48915708978373107 0.6916666666666667\n",
      "5320 번째 loss, accuracy:  0.4891433195885069 0.6916666666666667\n",
      "5321 번째 loss, accuracy:  0.4891295512220254 0.6916666666666667\n",
      "5322 번째 loss, accuracy:  0.48911578467929556 0.6916666666666667\n",
      "5323 번째 loss, accuracy:  0.48910201995532626 0.6916666666666667\n",
      "5324 번째 loss, accuracy:  0.48908825704512643 0.6916666666666667\n",
      "5325 번째 loss, accuracy:  0.4890744959437053 0.6916666666666667\n",
      "5326 번째 loss, accuracy:  0.48906073664607264 0.6916666666666667\n",
      "5327 번째 loss, accuracy:  0.48904697914723744 0.6916666666666667\n",
      "5328 번째 loss, accuracy:  0.48903322344221006 0.6916666666666667\n",
      "5329 번째 loss, accuracy:  0.4890194695260001 0.6916666666666667\n",
      "5330 번째 loss, accuracy:  0.48900571739361803 0.7\n",
      "5331 번째 loss, accuracy:  0.48899196704007364 0.7\n",
      "5332 번째 loss, accuracy:  0.4889782184603778 0.7\n",
      "5333 번째 loss, accuracy:  0.4889644716495408 0.7\n",
      "5334 번째 loss, accuracy:  0.4889507266025737 0.7\n",
      "5335 번째 loss, accuracy:  0.48893698331448726 0.7\n",
      "5336 번째 loss, accuracy:  0.4889232417802926 0.7\n",
      "5337 번째 loss, accuracy:  0.4889095019950009 0.7\n",
      "5338 번째 loss, accuracy:  0.48889576395362344 0.7\n",
      "5339 번째 loss, accuracy:  0.4888820276511718 0.7\n",
      "5340 번째 loss, accuracy:  0.4888682930826577 0.7\n",
      "5341 번째 loss, accuracy:  0.4888545602430928 0.7\n",
      "5342 번째 loss, accuracy:  0.488840829127489 0.7\n",
      "5343 번째 loss, accuracy:  0.4888270997308586 0.7\n",
      "5344 번째 loss, accuracy:  0.4888133720482133 0.7\n",
      "5345 번째 loss, accuracy:  0.4887996460745657 0.7\n",
      "5346 번째 loss, accuracy:  0.48878592180492836 0.7\n",
      "5347 번째 loss, accuracy:  0.4887721992343136 0.7\n",
      "5348 번째 loss, accuracy:  0.48875847835773406 0.7\n",
      "5349 번째 loss, accuracy:  0.488744759170203 0.7\n",
      "5350 번째 loss, accuracy:  0.4887310416667327 0.7\n",
      "5351 번째 loss, accuracy:  0.48871732584233657 0.7\n",
      "5352 번째 loss, accuracy:  0.4887036116920277 0.7\n",
      "5353 번째 loss, accuracy:  0.48868989921081923 0.7\n",
      "5354 번째 loss, accuracy:  0.48867618839372423 0.7\n",
      "5355 번째 loss, accuracy:  0.48866247923575634 0.7\n",
      "5356 번째 loss, accuracy:  0.48864877173192917 0.7\n",
      "5357 번째 loss, accuracy:  0.4886350658772563 0.7\n",
      "5358 번째 loss, accuracy:  0.48862136166675163 0.7\n",
      "5359 번째 loss, accuracy:  0.4886076590954287 0.7\n",
      "5360 번째 loss, accuracy:  0.4885939581583015 0.7\n",
      "5361 번째 loss, accuracy:  0.48858025885038375 0.7\n",
      "5362 번째 loss, accuracy:  0.48856656116668984 0.7\n",
      "5363 번째 loss, accuracy:  0.4885528651022338 0.7\n",
      "5364 번째 loss, accuracy:  0.4885391706520295 0.7\n",
      "5365 번째 loss, accuracy:  0.48852547781109185 0.7\n",
      "5366 번째 loss, accuracy:  0.4885117865744346 0.7\n",
      "5367 번째 loss, accuracy:  0.48849809693707263 0.7083333333333334\n",
      "5368 번째 loss, accuracy:  0.48848440889402023 0.7083333333333334\n",
      "5369 번째 loss, accuracy:  0.488470722440292 0.7083333333333334\n",
      "5370 번째 loss, accuracy:  0.4884570375709025 0.7083333333333334\n",
      "5371 번째 loss, accuracy:  0.48844335428086627 0.7083333333333334\n",
      "5372 번째 loss, accuracy:  0.4884296725651984 0.7083333333333334\n",
      "5373 번째 loss, accuracy:  0.4884159924189136 0.7083333333333334\n",
      "5374 번째 loss, accuracy:  0.4884023138370264 0.7083333333333334\n",
      "5375 번째 loss, accuracy:  0.488388636814552 0.7083333333333334\n",
      "5376 번째 loss, accuracy:  0.4883749613465048 0.7083333333333334\n",
      "5377 번째 loss, accuracy:  0.4883612874279006 0.7083333333333334\n",
      "5378 번째 loss, accuracy:  0.48834761505375374 0.7083333333333334\n",
      "5379 번째 loss, accuracy:  0.4883339442190796 0.7083333333333334\n",
      "5380 번째 loss, accuracy:  0.488320274918893 0.7083333333333334\n",
      "5381 번째 loss, accuracy:  0.4883066071482092 0.7083333333333334\n",
      "5382 번째 loss, accuracy:  0.48829294090204317 0.7083333333333334\n",
      "5383 번째 loss, accuracy:  0.4882792761754104 0.7083333333333334\n",
      "5384 번째 loss, accuracy:  0.48826561296332593 0.7083333333333334\n",
      "5385 번째 loss, accuracy:  0.488251951260805 0.7083333333333334\n",
      "5386 번째 loss, accuracy:  0.48823829106286276 0.7083333333333334\n",
      "5387 번째 loss, accuracy:  0.4882246323645147 0.7083333333333334\n",
      "5388 번째 loss, accuracy:  0.48821097516077583 0.7083333333333334\n",
      "5389 번째 loss, accuracy:  0.4881973194466614 0.7083333333333334\n",
      "5390 번째 loss, accuracy:  0.488183665217187 0.7083333333333334\n",
      "5391 번째 loss, accuracy:  0.4881700124673676 0.7083333333333334\n",
      "5392 번째 loss, accuracy:  0.4881563611922186 0.7083333333333334\n",
      "5393 번째 loss, accuracy:  0.4881427113867557 0.7083333333333334\n",
      "5394 번째 loss, accuracy:  0.48812906304599396 0.7083333333333334\n",
      "5395 번째 loss, accuracy:  0.48811541616494847 0.7083333333333334\n",
      "5396 번째 loss, accuracy:  0.4881017707386347 0.7083333333333334\n",
      "5397 번째 loss, accuracy:  0.48808812676206775 0.7083333333333334\n",
      "5398 번째 loss, accuracy:  0.4880744842302635 0.7083333333333334\n",
      "5399 번째 loss, accuracy:  0.48806084313823656 0.7083333333333334\n",
      "5400 번째 loss, accuracy:  0.48804720348100283 0.7083333333333334\n",
      "5401 번째 loss, accuracy:  0.48803356525357733 0.7083333333333334\n",
      "5402 번째 loss, accuracy:  0.4880199284509749 0.7083333333333334\n",
      "5403 번째 loss, accuracy:  0.4880062930682111 0.7083333333333334\n",
      "5404 번째 loss, accuracy:  0.48799265910030093 0.7083333333333334\n",
      "5405 번째 loss, accuracy:  0.48797902654225983 0.7083333333333334\n",
      "5406 번째 loss, accuracy:  0.4879653953891027 0.7083333333333334\n",
      "5407 번째 loss, accuracy:  0.4879517656358447 0.7083333333333334\n",
      "5408 번째 loss, accuracy:  0.487938137277501 0.7083333333333334\n",
      "5409 번째 loss, accuracy:  0.48792451030908646 0.7083333333333334\n",
      "5410 번째 loss, accuracy:  0.48791088472561644 0.7083333333333334\n",
      "5411 번째 loss, accuracy:  0.48789726052210547 0.7083333333333334\n",
      "5412 번째 loss, accuracy:  0.4878836376935688 0.7083333333333334\n",
      "5413 번째 loss, accuracy:  0.4878700162350211 0.7083333333333334\n",
      "5414 번째 loss, accuracy:  0.4878563961414772 0.7083333333333334\n",
      "5415 번째 loss, accuracy:  0.4878427774079517 0.7083333333333334\n",
      "5416 번째 loss, accuracy:  0.4878291600294595 0.7083333333333334\n",
      "5417 번째 loss, accuracy:  0.48781554400101534 0.7083333333333334\n",
      "5418 번째 loss, accuracy:  0.4878019293176337 0.7083333333333334\n",
      "5419 번째 loss, accuracy:  0.4877883159743295 0.7083333333333334\n",
      "5420 번째 loss, accuracy:  0.4877747039661166 0.7083333333333334\n",
      "5421 번째 loss, accuracy:  0.48776109328800993 0.7083333333333334\n",
      "5422 번째 loss, accuracy:  0.4877474839350235 0.7083333333333334\n",
      "5423 번째 loss, accuracy:  0.4877338759021718 0.7083333333333334\n",
      "5424 번째 loss, accuracy:  0.4877202691844691 0.7083333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5425 번째 loss, accuracy:  0.48770666377692945 0.7083333333333334\n",
      "5426 번째 loss, accuracy:  0.48769305967456694 0.7083333333333334\n",
      "5427 번째 loss, accuracy:  0.4876794568723954 0.7083333333333334\n",
      "5428 번째 loss, accuracy:  0.487665855365429 0.7083333333333334\n",
      "5429 번째 loss, accuracy:  0.4876522551486816 0.7083333333333334\n",
      "5430 번째 loss, accuracy:  0.4876386562171668 0.7083333333333334\n",
      "5431 번째 loss, accuracy:  0.4876250585658982 0.7083333333333334\n",
      "5432 번째 loss, accuracy:  0.48761146218988977 0.7083333333333334\n",
      "5433 번째 loss, accuracy:  0.48759786708415453 0.7083333333333334\n",
      "5434 번째 loss, accuracy:  0.48758427324370596 0.7083333333333334\n",
      "5435 번째 loss, accuracy:  0.4875706806635575 0.7083333333333334\n",
      "5436 번째 loss, accuracy:  0.4875570893387222 0.7083333333333334\n",
      "5437 번째 loss, accuracy:  0.4875434992642134 0.7083333333333334\n",
      "5438 번째 loss, accuracy:  0.48752991043504407 0.7083333333333334\n",
      "5439 번째 loss, accuracy:  0.48751632284622703 0.7083333333333334\n",
      "5440 번째 loss, accuracy:  0.48750273649277515 0.7083333333333334\n",
      "5441 번째 loss, accuracy:  0.4874891513697007 0.7083333333333334\n",
      "5442 번째 loss, accuracy:  0.487475567472017 0.7083333333333334\n",
      "5443 번째 loss, accuracy:  0.4874619847947359 0.7166666666666667\n",
      "5444 번째 loss, accuracy:  0.48744840333286976 0.7166666666666667\n",
      "5445 번째 loss, accuracy:  0.48743482308143127 0.7166666666666667\n",
      "5446 번째 loss, accuracy:  0.48742124403543213 0.7166666666666667\n",
      "5447 번째 loss, accuracy:  0.48740766618988424 0.7166666666666667\n",
      "5448 번째 loss, accuracy:  0.4873940895397998 0.7166666666666667\n",
      "5449 번째 loss, accuracy:  0.4873805140801904 0.7166666666666667\n",
      "5450 번째 loss, accuracy:  0.48736693980606777 0.7166666666666667\n",
      "5451 번째 loss, accuracy:  0.4873533667124434 0.7166666666666667\n",
      "5452 번째 loss, accuracy:  0.48733979479432843 0.7166666666666667\n",
      "5453 번째 loss, accuracy:  0.4873262240467341 0.7166666666666667\n",
      "5454 번째 loss, accuracy:  0.4873126544646718 0.7166666666666667\n",
      "5455 번째 loss, accuracy:  0.4872990860431519 0.725\n",
      "5456 번째 loss, accuracy:  0.4872855187771858 0.725\n",
      "5457 번째 loss, accuracy:  0.48727195266178386 0.725\n",
      "5458 번째 loss, accuracy:  0.48725838769195673 0.725\n",
      "5459 번째 loss, accuracy:  0.48724482386271456 0.725\n",
      "5460 번째 loss, accuracy:  0.4872312611690676 0.725\n",
      "5461 번째 loss, accuracy:  0.4872176996060264 0.725\n",
      "5462 번째 loss, accuracy:  0.48720413916860017 0.725\n",
      "5463 번째 loss, accuracy:  0.4871905798517991 0.725\n",
      "5464 번째 loss, accuracy:  0.4871770216506325 0.725\n",
      "5465 번째 loss, accuracy:  0.4871634645601103 0.725\n",
      "5466 번째 loss, accuracy:  0.4871499085752414 0.7333333333333333\n",
      "5467 번째 loss, accuracy:  0.4871363536910349 0.7333333333333333\n",
      "5468 번째 loss, accuracy:  0.4871227999024999 0.7333333333333333\n",
      "5469 번째 loss, accuracy:  0.4871092472046453 0.7333333333333333\n",
      "5470 번째 loss, accuracy:  0.4870956955924793 0.7333333333333333\n",
      "5471 번째 loss, accuracy:  0.48708214506101066 0.7333333333333333\n",
      "5472 번째 loss, accuracy:  0.48706859560524784 0.7333333333333333\n",
      "5473 번째 loss, accuracy:  0.4870550472201985 0.7333333333333333\n",
      "5474 번째 loss, accuracy:  0.48704149990087087 0.7333333333333333\n",
      "5475 번째 loss, accuracy:  0.48702795364227264 0.7333333333333333\n",
      "5476 번째 loss, accuracy:  0.4870144084394113 0.7333333333333333\n",
      "5477 번째 loss, accuracy:  0.4870008642872943 0.7333333333333333\n",
      "5478 번째 loss, accuracy:  0.48698732118092886 0.7333333333333333\n",
      "5479 번째 loss, accuracy:  0.486973779115322 0.7333333333333333\n",
      "5480 번째 loss, accuracy:  0.48696023808548017 0.7333333333333333\n",
      "5481 번째 loss, accuracy:  0.4869466980864106 0.7333333333333333\n",
      "5482 번째 loss, accuracy:  0.4869331591131193 0.7333333333333333\n",
      "5483 번째 loss, accuracy:  0.48691962116061266 0.7333333333333333\n",
      "5484 번째 loss, accuracy:  0.4869060842238967 0.7333333333333333\n",
      "5485 번째 loss, accuracy:  0.4868925482979773 0.7416666666666667\n",
      "5486 번째 loss, accuracy:  0.4868790133778599 0.7416666666666667\n",
      "5487 번째 loss, accuracy:  0.48686547945855035 0.7416666666666667\n",
      "5488 번째 loss, accuracy:  0.48685194653505354 0.7416666666666667\n",
      "5489 번째 loss, accuracy:  0.48683841460237437 0.7416666666666667\n",
      "5490 번째 loss, accuracy:  0.48682488365551807 0.7416666666666667\n",
      "5491 번째 loss, accuracy:  0.4868113536894891 0.7416666666666667\n",
      "5492 번째 loss, accuracy:  0.48679782469929145 0.7416666666666667\n",
      "5493 번째 loss, accuracy:  0.48678429667993 0.7416666666666667\n",
      "5494 번째 loss, accuracy:  0.48677076962640836 0.7416666666666667\n",
      "5495 번째 loss, accuracy:  0.4867572435337301 0.7416666666666667\n",
      "5496 번째 loss, accuracy:  0.48674371839689906 0.7416666666666667\n",
      "5497 번째 loss, accuracy:  0.4867301942109187 0.7416666666666667\n",
      "5498 번째 loss, accuracy:  0.48671667097079163 0.7416666666666667\n",
      "5499 번째 loss, accuracy:  0.486703148671521 0.7416666666666667\n",
      "5500 번째 loss, accuracy:  0.4866896273081094 0.7416666666666667\n",
      "5501 번째 loss, accuracy:  0.4866761068755591 0.7416666666666667\n",
      "5502 번째 loss, accuracy:  0.48666258736887247 0.7416666666666667\n",
      "5503 번째 loss, accuracy:  0.4866490687830513 0.7416666666666667\n",
      "5504 번째 loss, accuracy:  0.4866355511130976 0.7416666666666667\n",
      "5505 번째 loss, accuracy:  0.4866220343540124 0.7416666666666667\n",
      "5506 번째 loss, accuracy:  0.48660851850079717 0.7416666666666667\n",
      "5507 번째 loss, accuracy:  0.48659500354845303 0.7416666666666667\n",
      "5508 번째 loss, accuracy:  0.4865814894919803 0.7416666666666667\n",
      "5509 번째 loss, accuracy:  0.4865679763263799 0.7416666666666667\n",
      "5510 번째 loss, accuracy:  0.486554464046652 0.7416666666666667\n",
      "5511 번째 loss, accuracy:  0.4865409526477967 0.75\n",
      "5512 번째 loss, accuracy:  0.4865274421248136 0.75\n",
      "5513 번째 loss, accuracy:  0.48651393247270197 0.75\n",
      "5514 번째 loss, accuracy:  0.4865004236864617 0.75\n",
      "5515 번째 loss, accuracy:  0.4864869157610914 0.75\n",
      "5516 번째 loss, accuracy:  0.48647340869158995 0.75\n",
      "5517 번째 loss, accuracy:  0.4864599024729557 0.75\n",
      "5518 번째 loss, accuracy:  0.486446397100187 0.75\n",
      "5519 번째 loss, accuracy:  0.48643289256828176 0.75\n",
      "5520 번째 loss, accuracy:  0.48641938887223773 0.75\n",
      "5521 번째 loss, accuracy:  0.4864058860070525 0.75\n",
      "5522 번째 loss, accuracy:  0.486392383967723 0.75\n",
      "5523 번째 loss, accuracy:  0.48637888274924623 0.75\n",
      "5524 번째 loss, accuracy:  0.4863653823466189 0.75\n",
      "5525 번째 loss, accuracy:  0.4863518827548373 0.75\n",
      "5526 번째 loss, accuracy:  0.4863383839688977 0.75\n",
      "5527 번째 loss, accuracy:  0.4863248859837957 0.75\n",
      "5528 번째 loss, accuracy:  0.4863113887945271 0.75\n",
      "5529 번째 loss, accuracy:  0.4862978923960871 0.75\n",
      "5530 번째 loss, accuracy:  0.48628439678347063 0.75\n",
      "5531 번째 loss, accuracy:  0.48627090195167216 0.75\n",
      "5532 번째 loss, accuracy:  0.4862574078956864 0.75\n",
      "5533 번째 loss, accuracy:  0.4862439146105075 0.75\n",
      "5534 번째 loss, accuracy:  0.48623042209112943 0.75\n",
      "5535 번째 loss, accuracy:  0.48621693033254554 0.75\n",
      "5536 번째 loss, accuracy:  0.48620343932974913 0.75\n",
      "5537 번째 loss, accuracy:  0.4861899490777333 0.75\n",
      "5538 번째 loss, accuracy:  0.4861764595714906 0.75\n",
      "5539 번째 loss, accuracy:  0.48616297080601356 0.75\n",
      "5540 번째 loss, accuracy:  0.4861494827762941 0.75\n",
      "5541 번째 loss, accuracy:  0.4861359954773242 0.75\n",
      "5542 번째 loss, accuracy:  0.4861225089040955 0.75\n",
      "5543 번째 loss, accuracy:  0.4861090230515991 0.75\n",
      "5544 번째 loss, accuracy:  0.48609553791482596 0.75\n",
      "5545 번째 loss, accuracy:  0.4860820534887662 0.75\n",
      "5546 번째 loss, accuracy:  0.4860685697684107 0.75\n",
      "5547 번째 loss, accuracy:  0.4860550867487492 0.75\n",
      "5548 번째 loss, accuracy:  0.4860416044247715 0.75\n",
      "5549 번째 loss, accuracy:  0.4860281227914668 0.75\n",
      "5550 번째 loss, accuracy:  0.48601464184382437 0.75\n",
      "5551 번째 loss, accuracy:  0.48600116157683276 0.75\n",
      "5552 번째 loss, accuracy:  0.48598768198548054 0.75\n",
      "5553 번째 loss, accuracy:  0.4859742030647558 0.75\n",
      "5554 번째 loss, accuracy:  0.4859607248096462 0.75\n",
      "5555 번째 loss, accuracy:  0.48594724721513954 0.75\n",
      "5556 번째 loss, accuracy:  0.4859337702762226 0.75\n",
      "5557 번째 loss, accuracy:  0.48592029398788245 0.75\n",
      "5558 번째 loss, accuracy:  0.4859068183451055 0.75\n",
      "5559 번째 loss, accuracy:  0.485893343342878 0.75\n",
      "5560 번째 loss, accuracy:  0.48587986897618585 0.75\n",
      "5561 번째 loss, accuracy:  0.48586639524001435 0.75\n",
      "5562 번째 loss, accuracy:  0.4858529221293491 0.75\n",
      "5563 번째 loss, accuracy:  0.48583944963917447 0.75\n",
      "5564 번째 loss, accuracy:  0.48582597776447545 0.75\n",
      "5565 번째 loss, accuracy:  0.48581250650023605 0.75\n",
      "5566 번째 loss, accuracy:  0.48579903584144 0.75\n",
      "5567 번째 loss, accuracy:  0.485785565783071 0.75\n",
      "5568 번째 loss, accuracy:  0.48577209632011226 0.75\n",
      "5569 번째 loss, accuracy:  0.4857586274475467 0.75\n",
      "5570 번째 loss, accuracy:  0.4857451591603566 0.75\n",
      "5571 번째 loss, accuracy:  0.4857316914535243 0.75\n",
      "5572 번째 loss, accuracy:  0.4857182243220315 0.75\n",
      "5573 번째 loss, accuracy:  0.48570475776085975 0.75\n",
      "5574 번째 loss, accuracy:  0.4856912917649903 0.75\n",
      "5575 번째 loss, accuracy:  0.4856778263294037 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5576 번째 loss, accuracy:  0.4856643614490803 0.75\n",
      "5577 번째 loss, accuracy:  0.4856508971190006 0.75\n",
      "5578 번째 loss, accuracy:  0.4856374333341441 0.75\n",
      "5579 번째 loss, accuracy:  0.48562397008949026 0.75\n",
      "5580 번째 loss, accuracy:  0.485610507380018 0.75\n",
      "5581 번째 loss, accuracy:  0.4855970452007059 0.75\n",
      "5582 번째 loss, accuracy:  0.48558358354653247 0.75\n",
      "5583 번째 loss, accuracy:  0.48557012241247555 0.75\n",
      "5584 번째 loss, accuracy:  0.4855566617935129 0.75\n",
      "5585 번째 loss, accuracy:  0.48554320168462145 0.75\n",
      "5586 번째 loss, accuracy:  0.48552974208077837 0.75\n",
      "5587 번째 loss, accuracy:  0.4855162829769598 0.7583333333333333\n",
      "5588 번째 loss, accuracy:  0.48550282436814207 0.7583333333333333\n",
      "5589 번째 loss, accuracy:  0.4854893662493011 0.7583333333333333\n",
      "5590 번째 loss, accuracy:  0.48547590861541184 0.7583333333333333\n",
      "5591 번째 loss, accuracy:  0.48546245146144973 0.7583333333333333\n",
      "5592 번째 loss, accuracy:  0.48544899478238906 0.7583333333333333\n",
      "5593 번째 loss, accuracy:  0.48543553857320443 0.7583333333333333\n",
      "5594 번째 loss, accuracy:  0.4854220828288696 0.7583333333333333\n",
      "5595 번째 loss, accuracy:  0.4854086275443584 0.7583333333333333\n",
      "5596 번째 loss, accuracy:  0.48539517271464355 0.7583333333333333\n",
      "5597 번째 loss, accuracy:  0.48538171833469806 0.7583333333333333\n",
      "5598 번째 loss, accuracy:  0.48536826439949443 0.7583333333333333\n",
      "5599 번째 loss, accuracy:  0.48535481090400434 0.7583333333333333\n",
      "5600 번째 loss, accuracy:  0.4853413578431998 0.7583333333333333\n",
      "5601 번째 loss, accuracy:  0.485327905212052 0.7583333333333333\n",
      "5602 번째 loss, accuracy:  0.4853144530055319 0.7583333333333333\n",
      "5603 번째 loss, accuracy:  0.4853010012186098 0.7583333333333333\n",
      "5604 번째 loss, accuracy:  0.4852875498462557 0.7583333333333333\n",
      "5605 번째 loss, accuracy:  0.4852740988834395 0.7583333333333333\n",
      "5606 번째 loss, accuracy:  0.4852606483251305 0.7583333333333333\n",
      "5607 번째 loss, accuracy:  0.4852471981662975 0.7583333333333333\n",
      "5608 번째 loss, accuracy:  0.4852337484019092 0.7583333333333333\n",
      "5609 번째 loss, accuracy:  0.48522029902693387 0.7583333333333333\n",
      "5610 번째 loss, accuracy:  0.48520685003633895 0.7583333333333333\n",
      "5611 번째 loss, accuracy:  0.4851934014250921 0.7583333333333333\n",
      "5612 번째 loss, accuracy:  0.4851799531881602 0.7583333333333333\n",
      "5613 번째 loss, accuracy:  0.4851665053205099 0.7583333333333333\n",
      "5614 번째 loss, accuracy:  0.4851530578171073 0.7583333333333333\n",
      "5615 번째 loss, accuracy:  0.48513961067291805 0.7583333333333333\n",
      "5616 번째 loss, accuracy:  0.4851261638829078 0.7583333333333333\n",
      "5617 번째 loss, accuracy:  0.4851127174420414 0.7583333333333333\n",
      "5618 번째 loss, accuracy:  0.4850992713452834 0.7583333333333333\n",
      "5619 번째 loss, accuracy:  0.48508582558759794 0.7583333333333333\n",
      "5620 번째 loss, accuracy:  0.4850723801639488 0.7583333333333333\n",
      "5621 번째 loss, accuracy:  0.4850589350692995 0.7583333333333333\n",
      "5622 번째 loss, accuracy:  0.48504549029861266 0.7583333333333333\n",
      "5623 번째 loss, accuracy:  0.4850320458468511 0.7583333333333333\n",
      "5624 번째 loss, accuracy:  0.4850186017089772 0.7583333333333333\n",
      "5625 번째 loss, accuracy:  0.4850051578799524 0.7583333333333333\n",
      "5626 번째 loss, accuracy:  0.4849917143547379 0.7583333333333333\n",
      "5627 번째 loss, accuracy:  0.48497827112829484 0.7583333333333333\n",
      "5628 번째 loss, accuracy:  0.48496482819558384 0.7583333333333333\n",
      "5629 번째 loss, accuracy:  0.4849513855515645 0.7583333333333333\n",
      "5630 번째 loss, accuracy:  0.48493794319119676 0.7583333333333333\n",
      "5631 번째 loss, accuracy:  0.4849245011094399 0.7583333333333333\n",
      "5632 번째 loss, accuracy:  0.4849110593012528 0.7583333333333333\n",
      "5633 번째 loss, accuracy:  0.48489761776159385 0.7583333333333333\n",
      "5634 번째 loss, accuracy:  0.48488417648542087 0.7583333333333333\n",
      "5635 번째 loss, accuracy:  0.48487073546769166 0.7583333333333333\n",
      "5636 번째 loss, accuracy:  0.4848572947033632 0.7583333333333333\n",
      "5637 번째 loss, accuracy:  0.4848438541873923 0.7583333333333333\n",
      "5638 번째 loss, accuracy:  0.4848304139147352 0.7583333333333333\n",
      "5639 번째 loss, accuracy:  0.48481697388034795 0.7583333333333333\n",
      "5640 번째 loss, accuracy:  0.48480353407918564 0.7583333333333333\n",
      "5641 번째 loss, accuracy:  0.48479009450620386 0.7583333333333333\n",
      "5642 번째 loss, accuracy:  0.48477665515635654 0.7583333333333333\n",
      "5643 번째 loss, accuracy:  0.4847632160245983 0.7583333333333333\n",
      "5644 번째 loss, accuracy:  0.4847497771058829 0.7583333333333333\n",
      "5645 번째 loss, accuracy:  0.48473633839516367 0.7583333333333333\n",
      "5646 번째 loss, accuracy:  0.4847228998873933 0.7583333333333333\n",
      "5647 번째 loss, accuracy:  0.4847094615775243 0.7583333333333333\n",
      "5648 번째 loss, accuracy:  0.48469602346050883 0.7583333333333333\n",
      "5649 번째 loss, accuracy:  0.4846825855312984 0.7583333333333333\n",
      "5650 번째 loss, accuracy:  0.48466914778484405 0.7583333333333333\n",
      "5651 번째 loss, accuracy:  0.4846557102160967 0.7583333333333333\n",
      "5652 번째 loss, accuracy:  0.48464227282000644 0.7583333333333333\n",
      "5653 번째 loss, accuracy:  0.4846288355915232 0.7583333333333333\n",
      "5654 번째 loss, accuracy:  0.48461539852559643 0.7583333333333333\n",
      "5655 번째 loss, accuracy:  0.48460196161717517 0.7583333333333333\n",
      "5656 번째 loss, accuracy:  0.4845885248612074 0.7583333333333333\n",
      "5657 번째 loss, accuracy:  0.48457508825264184 0.7583333333333333\n",
      "5658 번째 loss, accuracy:  0.4845616517864258 0.7583333333333333\n",
      "5659 번째 loss, accuracy:  0.48454821545750676 0.7583333333333333\n",
      "5660 번째 loss, accuracy:  0.48453477926083127 0.7583333333333333\n",
      "5661 번째 loss, accuracy:  0.4845213431913456 0.7583333333333333\n",
      "5662 번째 loss, accuracy:  0.4845079072439958 0.7583333333333333\n",
      "5663 번째 loss, accuracy:  0.48449447141372703 0.7583333333333333\n",
      "5664 번째 loss, accuracy:  0.4844810356954843 0.7583333333333333\n",
      "5665 번째 loss, accuracy:  0.4844676000842124 0.7583333333333333\n",
      "5666 번째 loss, accuracy:  0.4844541645748553 0.7583333333333333\n",
      "5667 번째 loss, accuracy:  0.4844407291623565 0.7583333333333333\n",
      "5668 번째 loss, accuracy:  0.4844272938416591 0.7583333333333333\n",
      "5669 번째 loss, accuracy:  0.48441385860770614 0.7583333333333333\n",
      "5670 번째 loss, accuracy:  0.4844004234554398 0.7583333333333333\n",
      "5671 번째 loss, accuracy:  0.48438698837980165 0.7583333333333333\n",
      "5672 번째 loss, accuracy:  0.4843735533757332 0.7583333333333333\n",
      "5673 번째 loss, accuracy:  0.4843601184381754 0.7583333333333333\n",
      "5674 번째 loss, accuracy:  0.4843466835620685 0.7583333333333333\n",
      "5675 번째 loss, accuracy:  0.4843332487423528 0.7583333333333333\n",
      "5676 번째 loss, accuracy:  0.48431981397396767 0.7583333333333333\n",
      "5677 번째 loss, accuracy:  0.4843063792518523 0.7583333333333333\n",
      "5678 번째 loss, accuracy:  0.4842929445709452 0.7583333333333333\n",
      "5679 번째 loss, accuracy:  0.4842795099261845 0.7583333333333333\n",
      "5680 번째 loss, accuracy:  0.4842660753125083 0.7583333333333333\n",
      "5681 번째 loss, accuracy:  0.48425264072485336 0.7583333333333333\n",
      "5682 번째 loss, accuracy:  0.48423920615815663 0.7583333333333333\n",
      "5683 번째 loss, accuracy:  0.48422577160735447 0.7583333333333333\n",
      "5684 번째 loss, accuracy:  0.484212337067383 0.7583333333333333\n",
      "5685 번째 loss, accuracy:  0.48419890253317716 0.7583333333333333\n",
      "5686 번째 loss, accuracy:  0.48418546799967205 0.7583333333333333\n",
      "5687 번째 loss, accuracy:  0.4841720334618022 0.7583333333333333\n",
      "5688 번째 loss, accuracy:  0.48415859891450136 0.7583333333333333\n",
      "5689 번째 loss, accuracy:  0.4841451643527036 0.7583333333333333\n",
      "5690 번째 loss, accuracy:  0.48413172977134145 0.7583333333333333\n",
      "5691 번째 loss, accuracy:  0.4841182951653478 0.7583333333333333\n",
      "5692 번째 loss, accuracy:  0.48410486052965496 0.7583333333333333\n",
      "5693 번째 loss, accuracy:  0.4840914258591944 0.7583333333333333\n",
      "5694 번째 loss, accuracy:  0.48407799114889727 0.7583333333333333\n",
      "5695 번째 loss, accuracy:  0.48406455639369417 0.7583333333333333\n",
      "5696 번째 loss, accuracy:  0.48405112158851554 0.7583333333333333\n",
      "5697 번째 loss, accuracy:  0.48403768672829145 0.7583333333333333\n",
      "5698 번째 loss, accuracy:  0.4840242518079506 0.7583333333333333\n",
      "5699 번째 loss, accuracy:  0.4840108168224223 0.7583333333333333\n",
      "5700 번째 loss, accuracy:  0.48399738176663476 0.7583333333333333\n",
      "5701 번째 loss, accuracy:  0.48398394663551597 0.7583333333333333\n",
      "5702 번째 loss, accuracy:  0.48397051142399333 0.7583333333333333\n",
      "5703 번째 loss, accuracy:  0.48395707612699385 0.75\n",
      "5704 번째 loss, accuracy:  0.48394364073944374 0.75\n",
      "5705 번째 loss, accuracy:  0.48393020525626934 0.75\n",
      "5706 번째 loss, accuracy:  0.483916769672396 0.75\n",
      "5707 번째 loss, accuracy:  0.4839033339827486 0.75\n",
      "5708 번째 loss, accuracy:  0.4838898981822519 0.75\n",
      "5709 번째 loss, accuracy:  0.4838764622658301 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5710 번째 loss, accuracy:  0.48386302622840677 0.75\n",
      "5711 번째 loss, accuracy:  0.483849590064905 0.75\n",
      "5712 번째 loss, accuracy:  0.4838361537702473 0.75\n",
      "5713 번째 loss, accuracy:  0.48382271733935595 0.75\n",
      "5714 번째 loss, accuracy:  0.48380928076715274 0.75\n",
      "5715 번째 loss, accuracy:  0.4837958440485586 0.75\n",
      "5716 번째 loss, accuracy:  0.48378240717849447 0.75\n",
      "5717 번째 loss, accuracy:  0.4837689701518805 0.75\n",
      "5718 번째 loss, accuracy:  0.4837555329636365 0.75\n",
      "5719 번째 loss, accuracy:  0.483742095608682 0.75\n",
      "5720 번째 loss, accuracy:  0.4837286580819355 0.75\n",
      "5721 번째 loss, accuracy:  0.4837152203783153 0.75\n",
      "5722 번째 loss, accuracy:  0.4837017824927393 0.75\n",
      "5723 번째 loss, accuracy:  0.483688344420125 0.75\n",
      "5724 번째 loss, accuracy:  0.48367490615538883 0.75\n",
      "5725 번째 loss, accuracy:  0.48366146769344776 0.75\n",
      "5726 번째 loss, accuracy:  0.48364802902921705 0.75\n",
      "5727 번째 loss, accuracy:  0.4836345901576126 0.75\n",
      "5728 번째 loss, accuracy:  0.483621151073549 0.75\n",
      "5729 번째 loss, accuracy:  0.4836077117719409 0.75\n",
      "5730 번째 loss, accuracy:  0.48359427224770196 0.75\n",
      "5731 번째 loss, accuracy:  0.48358083249574585 0.75\n",
      "5732 번째 loss, accuracy:  0.48356739251098524 0.75\n",
      "5733 번째 loss, accuracy:  0.48355395228833314 0.75\n",
      "5734 번째 loss, accuracy:  0.48354051182270097 0.75\n",
      "5735 번째 loss, accuracy:  0.48352707110900045 0.75\n",
      "5736 번째 loss, accuracy:  0.4835136301421427 0.7583333333333333\n",
      "5737 번째 loss, accuracy:  0.48350018891703833 0.7666666666666667\n",
      "5738 번째 loss, accuracy:  0.48348674742859704 0.7666666666666667\n",
      "5739 번째 loss, accuracy:  0.4834733056717282 0.7666666666666667\n",
      "5740 번째 loss, accuracy:  0.4834598636413414 0.7666666666666667\n",
      "5741 번째 loss, accuracy:  0.4834464213323448 0.7666666666666667\n",
      "5742 번째 loss, accuracy:  0.4834329787396463 0.7666666666666667\n",
      "5743 번째 loss, accuracy:  0.4834195358581538 0.775\n",
      "5744 번째 loss, accuracy:  0.4834060926827741 0.775\n",
      "5745 번째 loss, accuracy:  0.483392649208414 0.775\n",
      "5746 번째 loss, accuracy:  0.4833792054299792 0.775\n",
      "5747 번째 loss, accuracy:  0.4833657613423758 0.775\n",
      "5748 번째 loss, accuracy:  0.48335231694050845 0.775\n",
      "5749 번째 loss, accuracy:  0.48333887221928173 0.775\n",
      "5750 번째 loss, accuracy:  0.48332542717360005 0.775\n",
      "5751 번째 loss, accuracy:  0.48331198179836693 0.775\n",
      "5752 번째 loss, accuracy:  0.4832985360884853 0.775\n",
      "5753 번째 loss, accuracy:  0.48328509003885795 0.775\n",
      "5754 번째 loss, accuracy:  0.48327164364438674 0.775\n",
      "5755 번째 loss, accuracy:  0.4832581968999735 0.775\n",
      "5756 번째 loss, accuracy:  0.4832447498005191 0.775\n",
      "5757 번째 loss, accuracy:  0.4832313023409243 0.775\n",
      "5758 번째 loss, accuracy:  0.48321785451608956 0.775\n",
      "5759 번째 loss, accuracy:  0.48320440632091394 0.775\n",
      "5760 번째 loss, accuracy:  0.48319095775029697 0.775\n",
      "5761 번째 loss, accuracy:  0.48317750879913685 0.775\n",
      "5762 번째 loss, accuracy:  0.48316405946233226 0.775\n",
      "5763 번째 loss, accuracy:  0.4831506097347802 0.775\n",
      "5764 번째 loss, accuracy:  0.4831371596113783 0.775\n",
      "5765 번째 loss, accuracy:  0.4831237090870232 0.775\n",
      "5766 번째 loss, accuracy:  0.4831102581566107 0.775\n",
      "5767 번째 loss, accuracy:  0.4830968068150367 0.775\n",
      "5768 번째 loss, accuracy:  0.48308335505719585 0.775\n",
      "5769 번째 loss, accuracy:  0.48306990287798346 0.775\n",
      "5770 번째 loss, accuracy:  0.4830564502722934 0.775\n",
      "5771 번째 loss, accuracy:  0.483042997235019 0.775\n",
      "5772 번째 loss, accuracy:  0.4830295437610535 0.775\n",
      "5773 번째 loss, accuracy:  0.48301608984528976 0.775\n",
      "5774 번째 loss, accuracy:  0.4830026354826199 0.775\n",
      "5775 번째 loss, accuracy:  0.4829891806679355 0.775\n",
      "5776 번째 loss, accuracy:  0.48297572539612776 0.775\n",
      "5777 번째 loss, accuracy:  0.482962269662087 0.775\n",
      "5778 번째 loss, accuracy:  0.4829488134607036 0.775\n",
      "5779 번째 loss, accuracy:  0.48293535678686733 0.775\n",
      "5780 번째 loss, accuracy:  0.482921899635467 0.775\n",
      "5781 번째 loss, accuracy:  0.4829084420013914 0.775\n",
      "5782 번째 loss, accuracy:  0.48289498387952856 0.775\n",
      "5783 번째 loss, accuracy:  0.482881525264766 0.775\n",
      "5784 번째 loss, accuracy:  0.4828680661519909 0.775\n",
      "5785 번째 loss, accuracy:  0.48285460653609 0.775\n",
      "5786 번째 loss, accuracy:  0.48284114641194953 0.775\n",
      "5787 번째 loss, accuracy:  0.4828276857744548 0.775\n",
      "5788 번째 loss, accuracy:  0.4828142246184911 0.775\n",
      "5789 번째 loss, accuracy:  0.4828007629389429 0.775\n",
      "5790 번째 loss, accuracy:  0.4827873007306946 0.775\n",
      "5791 번째 loss, accuracy:  0.4827738379886294 0.775\n",
      "5792 번째 loss, accuracy:  0.48276037470763067 0.775\n",
      "5793 번째 loss, accuracy:  0.482746910882581 0.775\n",
      "5794 번째 loss, accuracy:  0.48273344650836236 0.775\n",
      "5795 번째 loss, accuracy:  0.48271998157985635 0.775\n",
      "5796 번째 loss, accuracy:  0.48270651609194437 0.775\n",
      "5797 번째 loss, accuracy:  0.48269305003950674 0.775\n",
      "5798 번째 loss, accuracy:  0.48267958341742345 0.775\n",
      "5799 번째 loss, accuracy:  0.4826661162205742 0.775\n",
      "5800 번째 loss, accuracy:  0.4826526484438379 0.775\n",
      "5801 번째 loss, accuracy:  0.48263918008209344 0.775\n",
      "5802 번째 loss, accuracy:  0.48262571113021896 0.775\n",
      "5803 번째 loss, accuracy:  0.48261224158309174 0.775\n",
      "5804 번째 loss, accuracy:  0.4825987714355889 0.775\n",
      "5805 번째 loss, accuracy:  0.48258530068258687 0.775\n",
      "5806 번째 loss, accuracy:  0.4825718293189619 0.775\n",
      "5807 번째 loss, accuracy:  0.48255835733958974 0.775\n",
      "5808 번째 loss, accuracy:  0.48254488473934526 0.775\n",
      "5809 번째 loss, accuracy:  0.48253141151310314 0.775\n",
      "5810 번째 loss, accuracy:  0.48251793765573725 0.775\n",
      "5811 번째 loss, accuracy:  0.4825044631621212 0.775\n",
      "5812 번째 loss, accuracy:  0.48249098802712803 0.775\n",
      "5813 번째 loss, accuracy:  0.4824775122456305 0.775\n",
      "5814 번째 loss, accuracy:  0.48246403581250047 0.775\n",
      "5815 번째 loss, accuracy:  0.48245055872260956 0.775\n",
      "5816 번째 loss, accuracy:  0.48243708097082866 0.775\n",
      "5817 번째 loss, accuracy:  0.48242360255202865 0.775\n",
      "5818 번째 loss, accuracy:  0.48241012346107937 0.775\n",
      "5819 번째 loss, accuracy:  0.48239664369285057 0.775\n",
      "5820 번째 loss, accuracy:  0.4823831632422108 0.775\n",
      "5821 번째 loss, accuracy:  0.482369682104029 0.775\n",
      "5822 번째 loss, accuracy:  0.4823562002731733 0.775\n",
      "5823 번째 loss, accuracy:  0.48234271774451076 0.775\n",
      "5824 번째 loss, accuracy:  0.4823292345129089 0.775\n",
      "5825 번째 loss, accuracy:  0.48231575057323384 0.775\n",
      "5826 번째 loss, accuracy:  0.4823022659203522 0.775\n",
      "5827 번째 loss, accuracy:  0.4822887805491292 0.775\n",
      "5828 번째 loss, accuracy:  0.48227529445442935 0.775\n",
      "5829 번째 loss, accuracy:  0.48226180763111814 0.775\n",
      "5830 번째 loss, accuracy:  0.48224832007405916 0.775\n",
      "5831 번째 loss, accuracy:  0.48223483177811605 0.775\n",
      "5832 번째 loss, accuracy:  0.4822213427381517 0.775\n",
      "5833 번째 loss, accuracy:  0.4822078529490286 0.775\n",
      "5834 번째 loss, accuracy:  0.4821943624056092 0.775\n",
      "5835 번째 loss, accuracy:  0.48218087110275487 0.775\n",
      "5836 번째 loss, accuracy:  0.48216737903532675 0.775\n",
      "5837 번째 loss, accuracy:  0.482153886198185 0.775\n",
      "5838 번째 loss, accuracy:  0.4821403925861899 0.775\n",
      "5839 번째 loss, accuracy:  0.4821268981942012 0.775\n",
      "5840 번째 loss, accuracy:  0.48211340301707784 0.775\n",
      "5841 번째 loss, accuracy:  0.4820999070496782 0.775\n",
      "5842 번째 loss, accuracy:  0.4820864102868604 0.775\n",
      "5843 번째 loss, accuracy:  0.48207291272348224 0.775\n",
      "5844 번째 loss, accuracy:  0.4820594143544007 0.775\n",
      "5845 번째 loss, accuracy:  0.48204591517447215 0.775\n",
      "5846 번째 loss, accuracy:  0.48203241517855294 0.775\n",
      "5847 번째 loss, accuracy:  0.4820189143614984 0.775\n",
      "5848 번째 loss, accuracy:  0.48200541271816383 0.775\n",
      "5849 번째 loss, accuracy:  0.4819919102434039 0.775\n",
      "5850 번째 loss, accuracy:  0.48197840693207256 0.775\n",
      "5851 번째 loss, accuracy:  0.48196490277902354 0.775\n",
      "5852 번째 loss, accuracy:  0.4819513977791097 0.775\n",
      "5853 번째 loss, accuracy:  0.48193789192718384 0.775\n",
      "5854 번째 loss, accuracy:  0.48192438521809805 0.775\n",
      "5855 번째 loss, accuracy:  0.48191087764670404 0.775\n",
      "5856 번째 loss, accuracy:  0.4818973692078529 0.775\n",
      "5857 번째 loss, accuracy:  0.4818838598963954 0.775\n",
      "5858 번째 loss, accuracy:  0.48187034970718123 0.775\n",
      "5859 번째 loss, accuracy:  0.4818568386350607 0.775\n",
      "5860 번째 loss, accuracy:  0.4818433266748829 0.775\n",
      "5861 번째 loss, accuracy:  0.481829813821496 0.775\n",
      "5862 번째 loss, accuracy:  0.4818163000697486 0.775\n",
      "5863 번째 loss, accuracy:  0.48180278541448823 0.775\n",
      "5864 번째 loss, accuracy:  0.4817892698505623 0.7666666666666667\n",
      "5865 번째 loss, accuracy:  0.48177575337281736 0.7666666666666667\n",
      "5866 번째 loss, accuracy:  0.48176223597609974 0.7666666666666667\n",
      "5867 번째 loss, accuracy:  0.4817487176552551 0.7666666666666667\n",
      "5868 번째 loss, accuracy:  0.48173519840512885 0.7666666666666667\n",
      "5869 번째 loss, accuracy:  0.4817216782205655 0.7666666666666667\n",
      "5870 번째 loss, accuracy:  0.48170815709640963 0.7583333333333333\n",
      "5871 번째 loss, accuracy:  0.48169463502750476 0.7583333333333333\n",
      "5872 번째 loss, accuracy:  0.4816811120086945 0.7583333333333333\n",
      "5873 번째 loss, accuracy:  0.4816675880348214 0.7583333333333333\n",
      "5874 번째 loss, accuracy:  0.48165406310072784 0.7583333333333333\n",
      "5875 번째 loss, accuracy:  0.48164053720125577 0.7583333333333333\n",
      "5876 번째 loss, accuracy:  0.48162701033124666 0.7583333333333333\n",
      "5877 번째 loss, accuracy:  0.4816134824855412 0.7583333333333333\n",
      "5878 번째 loss, accuracy:  0.48159995365898 0.7583333333333333\n",
      "5879 번째 loss, accuracy:  0.48158642384640266 0.7583333333333333\n",
      "5880 번째 loss, accuracy:  0.4815728930426489 0.7583333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5881 번째 loss, accuracy:  0.48155936124255744 0.7583333333333333\n",
      "5882 번째 loss, accuracy:  0.481545828440967 0.7583333333333333\n",
      "5883 번째 loss, accuracy:  0.48153229463271535 0.7583333333333333\n",
      "5884 번째 loss, accuracy:  0.4815187598126401 0.7583333333333333\n",
      "5885 번째 loss, accuracy:  0.48150522397557843 0.7583333333333333\n",
      "5886 번째 loss, accuracy:  0.48149168711636653 0.7583333333333333\n",
      "5887 번째 loss, accuracy:  0.4814781492298407 0.7583333333333333\n",
      "5888 번째 loss, accuracy:  0.4814646103108364 0.7583333333333333\n",
      "5889 번째 loss, accuracy:  0.48145107035418905 0.7583333333333333\n",
      "5890 번째 loss, accuracy:  0.48143752935473294 0.7583333333333333\n",
      "5891 번째 loss, accuracy:  0.4814239873073023 0.7583333333333333\n",
      "5892 번째 loss, accuracy:  0.48141044420673074 0.7583333333333333\n",
      "5893 번째 loss, accuracy:  0.4813969000478518 0.7583333333333333\n",
      "5894 번째 loss, accuracy:  0.48138335482549777 0.7583333333333333\n",
      "5895 번째 loss, accuracy:  0.4813698085345012 0.7583333333333333\n",
      "5896 번째 loss, accuracy:  0.48135626116969377 0.7583333333333333\n",
      "5897 번째 loss, accuracy:  0.4813427127259066 0.7583333333333333\n",
      "5898 번째 loss, accuracy:  0.48132916319797076 0.7583333333333333\n",
      "5899 번째 loss, accuracy:  0.4813156125807165 0.7583333333333333\n",
      "5900 번째 loss, accuracy:  0.48130206086897354 0.7583333333333333\n",
      "5901 번째 loss, accuracy:  0.4812885080575717 0.7583333333333333\n",
      "5902 번째 loss, accuracy:  0.48127495414133964 0.7583333333333333\n",
      "5903 번째 loss, accuracy:  0.4812613991151056 0.7583333333333333\n",
      "5904 번째 loss, accuracy:  0.48124784297369794 0.7583333333333333\n",
      "5905 번째 loss, accuracy:  0.4812342857119442 0.7583333333333333\n",
      "5906 번째 loss, accuracy:  0.4812207273246711 0.7583333333333333\n",
      "5907 번째 loss, accuracy:  0.4812071678067055 0.7583333333333333\n",
      "5908 번째 loss, accuracy:  0.4811936071528734 0.7583333333333333\n",
      "5909 번째 loss, accuracy:  0.4811800453580006 0.7583333333333333\n",
      "5910 번째 loss, accuracy:  0.4811664824169121 0.7583333333333333\n",
      "5911 번째 loss, accuracy:  0.4811529183244327 0.7583333333333333\n",
      "5912 번째 loss, accuracy:  0.4811393530753866 0.7583333333333333\n",
      "5913 번째 loss, accuracy:  0.48112578666459777 0.7583333333333333\n",
      "5914 번째 loss, accuracy:  0.48111221908688934 0.7583333333333333\n",
      "5915 번째 loss, accuracy:  0.48109865033708415 0.7583333333333333\n",
      "5916 번째 loss, accuracy:  0.48108508041000475 0.7583333333333333\n",
      "5917 번째 loss, accuracy:  0.4810715093004729 0.7583333333333333\n",
      "5918 번째 loss, accuracy:  0.48105793700331023 0.7583333333333333\n",
      "5919 번째 loss, accuracy:  0.4810443635133378 0.7666666666666667\n",
      "5920 번째 loss, accuracy:  0.48103078882537614 0.7666666666666667\n",
      "5921 번째 loss, accuracy:  0.481017212934245 0.7666666666666667\n",
      "5922 번째 loss, accuracy:  0.48100363583476446 0.775\n",
      "5923 번째 loss, accuracy:  0.48099005752175344 0.775\n",
      "5924 번째 loss, accuracy:  0.48097647799003057 0.775\n",
      "5925 번째 loss, accuracy:  0.48096289723441454 0.775\n",
      "5926 번째 loss, accuracy:  0.4809493152497225 0.775\n",
      "5927 번째 loss, accuracy:  0.48093573203077244 0.775\n",
      "5928 번째 loss, accuracy:  0.48092214757238094 0.775\n",
      "5929 번째 loss, accuracy:  0.4809085618693646 0.775\n",
      "5930 번째 loss, accuracy:  0.48089497491653904 0.775\n",
      "5931 번째 loss, accuracy:  0.4808813867087203 0.775\n",
      "5932 번째 loss, accuracy:  0.48086779724072315 0.775\n",
      "5933 번째 loss, accuracy:  0.48085420650736227 0.775\n",
      "5934 번째 loss, accuracy:  0.4808406145034518 0.775\n",
      "5935 번째 loss, accuracy:  0.4808270212238058 0.775\n",
      "5936 번째 loss, accuracy:  0.48081342666323695 0.775\n",
      "5937 번째 loss, accuracy:  0.48079983081655864 0.775\n",
      "5938 번째 loss, accuracy:  0.48078623367858314 0.775\n",
      "5939 번째 loss, accuracy:  0.48077263524412217 0.775\n",
      "5940 번째 loss, accuracy:  0.4807590355079873 0.775\n",
      "5941 번째 loss, accuracy:  0.48074543446498974 0.775\n",
      "5942 번째 loss, accuracy:  0.4807318321099399 0.775\n",
      "5943 번째 loss, accuracy:  0.48071822843764805 0.775\n",
      "5944 번째 loss, accuracy:  0.480704623442924 0.775\n",
      "5945 번째 loss, accuracy:  0.4806910171205768 0.775\n",
      "5946 번째 loss, accuracy:  0.48067740946541543 0.775\n",
      "5947 번째 loss, accuracy:  0.4806638004722482 0.775\n",
      "5948 번째 loss, accuracy:  0.48065019013588334 0.775\n",
      "5949 번째 loss, accuracy:  0.480636578451128 0.775\n",
      "5950 번째 loss, accuracy:  0.48062296541278954 0.775\n",
      "5951 번째 loss, accuracy:  0.48060935101567454 0.775\n",
      "5952 번째 loss, accuracy:  0.48059573525458915 0.775\n",
      "5953 번째 loss, accuracy:  0.48058211812433893 0.775\n",
      "5954 번째 loss, accuracy:  0.4805684996197295 0.775\n",
      "5955 번째 loss, accuracy:  0.480554879735566 0.775\n",
      "5956 번째 loss, accuracy:  0.48054125846665235 0.775\n",
      "5957 번째 loss, accuracy:  0.48052763580779284 0.775\n",
      "5958 번째 loss, accuracy:  0.4805140117537911 0.775\n",
      "5959 번째 loss, accuracy:  0.4805003862994504 0.775\n",
      "5960 번째 loss, accuracy:  0.4804867594395733 0.775\n",
      "5961 번째 loss, accuracy:  0.48047313116896234 0.775\n",
      "5962 번째 loss, accuracy:  0.4804595014824192 0.775\n",
      "5963 번째 loss, accuracy:  0.48044587037474545 0.775\n",
      "5964 번째 loss, accuracy:  0.48043223784074224 0.775\n",
      "5965 번째 loss, accuracy:  0.48041860387520996 0.775\n",
      "5966 번째 loss, accuracy:  0.48040496847294906 0.775\n",
      "5967 번째 loss, accuracy:  0.4803913316287591 0.775\n",
      "5968 번째 loss, accuracy:  0.48037769333743924 0.775\n",
      "5969 번째 loss, accuracy:  0.48036405359378875 0.775\n",
      "5970 번째 loss, accuracy:  0.480350412392606 0.775\n",
      "5971 번째 loss, accuracy:  0.4803367697286892 0.775\n",
      "5972 번째 loss, accuracy:  0.48032312559683604 0.775\n",
      "5973 번째 loss, accuracy:  0.4803094799918435 0.775\n",
      "5974 번째 loss, accuracy:  0.4802958329085084 0.775\n",
      "5975 번째 loss, accuracy:  0.4802821843416275 0.775\n",
      "5976 번째 loss, accuracy:  0.4802685342859964 0.775\n",
      "5977 번째 loss, accuracy:  0.4802548827364111 0.775\n",
      "5978 번째 loss, accuracy:  0.4802412296876665 0.775\n",
      "5979 번째 loss, accuracy:  0.48022757513455744 0.775\n",
      "5980 번째 loss, accuracy:  0.4802139190718781 0.775\n",
      "5981 번째 loss, accuracy:  0.48020026149442274 0.775\n",
      "5982 번째 loss, accuracy:  0.4801866023969846 0.775\n",
      "5983 번째 loss, accuracy:  0.480172941774357 0.775\n",
      "5984 번째 loss, accuracy:  0.48015927962133254 0.775\n",
      "5985 번째 loss, accuracy:  0.48014561593270355 0.775\n",
      "5986 번째 loss, accuracy:  0.480131950703262 0.775\n",
      "5987 번째 loss, accuracy:  0.4801182839277993 0.775\n",
      "5988 번째 loss, accuracy:  0.48010461560110673 0.775\n",
      "5989 번째 loss, accuracy:  0.48009094571797467 0.775\n",
      "5990 번째 loss, accuracy:  0.4800772742731938 0.775\n",
      "5991 번째 loss, accuracy:  0.4800636012615538 0.775\n",
      "5992 번째 loss, accuracy:  0.4800499266778439 0.775\n",
      "5993 번째 loss, accuracy:  0.4800362505168537 0.775\n",
      "5994 번째 loss, accuracy:  0.4800225727733713 0.775\n",
      "5995 번째 loss, accuracy:  0.48000889344218556 0.775\n",
      "5996 번째 loss, accuracy:  0.479995212518084 0.775\n",
      "5997 번째 loss, accuracy:  0.4799815299958546 0.775\n",
      "5998 번째 loss, accuracy:  0.479967845870284 0.775\n",
      "5999 번째 loss, accuracy:  0.47995416013615905 0.775\n",
      "6000 번째 loss, accuracy:  0.47994047278826624 0.775\n",
      "6001 번째 loss, accuracy:  0.4799267838213915 0.775\n",
      "6002 번째 loss, accuracy:  0.47991309323032 0.775\n",
      "6003 번째 loss, accuracy:  0.47989940100983713 0.775\n",
      "6004 번째 loss, accuracy:  0.47988570715472784 0.775\n",
      "6005 번째 loss, accuracy:  0.4798720116597765 0.775\n",
      "6006 번째 loss, accuracy:  0.479858314519767 0.775\n",
      "6007 번째 loss, accuracy:  0.479844615729483 0.775\n",
      "6008 번째 loss, accuracy:  0.47983091528370775 0.775\n",
      "6009 번째 loss, accuracy:  0.4798172131772239 0.775\n",
      "6010 번째 loss, accuracy:  0.47980350940481437 0.775\n",
      "6011 번째 loss, accuracy:  0.4797898039612608 0.775\n",
      "6012 번째 loss, accuracy:  0.4797760968413452 0.775\n",
      "6013 번째 loss, accuracy:  0.4797623880398488 0.775\n",
      "6014 번째 loss, accuracy:  0.4797486775515524 0.775\n",
      "6015 번째 loss, accuracy:  0.479734965371237 0.775\n",
      "6016 번째 loss, accuracy:  0.4797212514936825 0.775\n",
      "6017 번째 loss, accuracy:  0.47970753591366877 0.775\n",
      "6018 번째 loss, accuracy:  0.4796938186259755 0.775\n",
      "6019 번째 loss, accuracy:  0.4796800996253819 0.775\n",
      "6020 번째 loss, accuracy:  0.47966637890666625 0.775\n",
      "6021 번째 loss, accuracy:  0.479652656464607 0.775\n",
      "6022 번째 loss, accuracy:  0.4796389322939822 0.775\n",
      "6023 번째 loss, accuracy:  0.4796252063895697 0.775\n",
      "6024 번째 loss, accuracy:  0.4796114787461468 0.775\n",
      "6025 번째 loss, accuracy:  0.47959774935848987 0.775\n",
      "6026 번째 loss, accuracy:  0.47958401822137564 0.775\n",
      "6027 번째 loss, accuracy:  0.47957028532958074 0.775\n",
      "6028 번째 loss, accuracy:  0.4795565506778805 0.775\n",
      "6029 번째 loss, accuracy:  0.47954281426105055 0.775\n",
      "6030 번째 loss, accuracy:  0.4795290760738659 0.775\n",
      "6031 번째 loss, accuracy:  0.4795153361111015 0.775\n",
      "6032 번째 loss, accuracy:  0.47950159436753154 0.775\n",
      "6033 번째 loss, accuracy:  0.47948785083793005 0.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6034 번째 loss, accuracy:  0.47947410551707076 0.775\n",
      "6035 번째 loss, accuracy:  0.47946035839972695 0.775\n",
      "6036 번째 loss, accuracy:  0.47944660948067164 0.775\n",
      "6037 번째 loss, accuracy:  0.47943285875467756 0.775\n",
      "6038 번째 loss, accuracy:  0.47941910621651684 0.775\n",
      "6039 번째 loss, accuracy:  0.47940535186096134 0.775\n",
      "6040 번째 loss, accuracy:  0.4793915956827828 0.775\n",
      "6041 번째 loss, accuracy:  0.47937783767675246 0.775\n",
      "6042 번째 loss, accuracy:  0.479364077837641 0.775\n",
      "6043 번째 loss, accuracy:  0.479350316160219 0.775\n",
      "6044 번째 loss, accuracy:  0.4793365526392568 0.775\n",
      "6045 번째 loss, accuracy:  0.4793227872695243 0.775\n",
      "6046 번째 loss, accuracy:  0.47930902004579085 0.775\n",
      "6047 번째 loss, accuracy:  0.4792952509628258 0.775\n",
      "6048 번째 loss, accuracy:  0.4792814800153979 0.775\n",
      "6049 번째 loss, accuracy:  0.4792677071982761 0.775\n",
      "6050 번째 loss, accuracy:  0.4792539325062278 0.775\n",
      "6051 번째 loss, accuracy:  0.4792401559340211 0.775\n",
      "6052 번째 loss, accuracy:  0.4792263774764237 0.775\n",
      "6053 번째 loss, accuracy:  0.4792125971282029 0.775\n",
      "6054 번째 loss, accuracy:  0.47919881488412536 0.775\n",
      "6055 번째 loss, accuracy:  0.47918503073895735 0.775\n",
      "6056 번째 loss, accuracy:  0.47917124468746525 0.775\n",
      "6057 번째 loss, accuracy:  0.47915745672441523 0.775\n",
      "6058 번째 loss, accuracy:  0.4791436668445724 0.775\n",
      "6059 번째 loss, accuracy:  0.4791298750427021 0.775\n",
      "6060 번째 loss, accuracy:  0.4791160813135696 0.775\n",
      "6061 번째 loss, accuracy:  0.479102285651939 0.775\n",
      "6062 번째 loss, accuracy:  0.47908848805257487 0.775\n",
      "6063 번째 loss, accuracy:  0.479074688510241 0.775\n",
      "6064 번째 loss, accuracy:  0.4790608870197011 0.775\n",
      "6065 번째 loss, accuracy:  0.47904708357571846 0.775\n",
      "6066 번째 loss, accuracy:  0.4790332781730562 0.775\n",
      "6067 번째 loss, accuracy:  0.4790194708064768 0.775\n",
      "6068 번째 loss, accuracy:  0.4790056614707427 0.775\n",
      "6069 번째 loss, accuracy:  0.4789918501606157 0.775\n",
      "6070 번째 loss, accuracy:  0.47897803687085805 0.775\n",
      "6071 번째 loss, accuracy:  0.47896422159623075 0.775\n",
      "6072 번째 loss, accuracy:  0.47895040433149527 0.775\n",
      "6073 번째 loss, accuracy:  0.4789365850714122 0.775\n",
      "6074 번째 loss, accuracy:  0.47892276381074195 0.775\n",
      "6075 번째 loss, accuracy:  0.4789089405442455 0.775\n",
      "6076 번째 loss, accuracy:  0.47889511526668194 0.775\n",
      "6077 번째 loss, accuracy:  0.47888128797281104 0.775\n",
      "6078 번째 loss, accuracy:  0.47886745865739255 0.775\n",
      "6079 번째 loss, accuracy:  0.47885362731518505 0.775\n",
      "6080 번째 loss, accuracy:  0.47883979394094744 0.775\n",
      "6081 번째 loss, accuracy:  0.47882595852943827 0.775\n",
      "6082 번째 loss, accuracy:  0.4788121210754156 0.775\n",
      "6083 번째 loss, accuracy:  0.4787982815736373 0.775\n",
      "6084 번째 loss, accuracy:  0.4787844400188606 0.775\n",
      "6085 번째 loss, accuracy:  0.4787705964058431 0.775\n",
      "6086 번째 loss, accuracy:  0.4787567507293417 0.775\n",
      "6087 번째 loss, accuracy:  0.4787429029841133 0.775\n",
      "6088 번째 loss, accuracy:  0.47872905316491426 0.775\n",
      "6089 번째 loss, accuracy:  0.4787152012665003 0.775\n",
      "6090 번째 loss, accuracy:  0.4787013472836276 0.775\n",
      "6091 번째 loss, accuracy:  0.47868749121105164 0.775\n",
      "6092 번째 loss, accuracy:  0.4786736330435276 0.775\n",
      "6093 번째 loss, accuracy:  0.47865977277581057 0.775\n",
      "6094 번째 loss, accuracy:  0.4786459104026554 0.775\n",
      "6095 번째 loss, accuracy:  0.47863204591881636 0.775\n",
      "6096 번째 loss, accuracy:  0.4786181793190476 0.775\n",
      "6097 번째 loss, accuracy:  0.47860431059810343 0.775\n",
      "6098 번째 loss, accuracy:  0.47859043975073706 0.775\n",
      "6099 번째 loss, accuracy:  0.4785765667717019 0.775\n",
      "6100 번째 loss, accuracy:  0.4785626916557509 0.775\n",
      "6101 번째 loss, accuracy:  0.4785488143976373 0.775\n",
      "6102 번째 loss, accuracy:  0.47853493499211347 0.775\n",
      "6103 번째 loss, accuracy:  0.47852105343393153 0.775\n",
      "6104 번째 loss, accuracy:  0.47850716971784363 0.775\n",
      "6105 번째 loss, accuracy:  0.4784932838386016 0.775\n",
      "6106 번째 loss, accuracy:  0.47847939579095683 0.775\n",
      "6107 번째 loss, accuracy:  0.4784655055696605 0.775\n",
      "6108 번째 loss, accuracy:  0.47845161316946355 0.775\n",
      "6109 번째 loss, accuracy:  0.478437718585117 0.775\n",
      "6110 번째 loss, accuracy:  0.47842382181137116 0.775\n",
      "6111 번째 loss, accuracy:  0.47840992284297623 0.775\n",
      "6112 번째 loss, accuracy:  0.47839602167468204 0.775\n",
      "6113 번째 loss, accuracy:  0.4783821183012388 0.775\n",
      "6114 번째 loss, accuracy:  0.4783682127173956 0.775\n",
      "6115 번째 loss, accuracy:  0.47835430491790176 0.775\n",
      "6116 번째 loss, accuracy:  0.4783403948975061 0.775\n",
      "6117 번째 loss, accuracy:  0.4783264826509575 0.775\n",
      "6118 번째 loss, accuracy:  0.4783125681730045 0.775\n",
      "6119 번째 loss, accuracy:  0.4782986514583951 0.775\n",
      "6120 번째 loss, accuracy:  0.4782847325018773 0.775\n",
      "6121 번째 loss, accuracy:  0.4782708112981993 0.775\n",
      "6122 번째 loss, accuracy:  0.478256887842108 0.775\n",
      "6123 번째 loss, accuracy:  0.4782429621283512 0.775\n",
      "6124 번째 loss, accuracy:  0.4782290341516756 0.775\n",
      "6125 번째 loss, accuracy:  0.47821510390682836 0.775\n",
      "6126 번째 loss, accuracy:  0.4782011713885557 0.775\n",
      "6127 번째 loss, accuracy:  0.47818723659160406 0.775\n",
      "6128 번째 loss, accuracy:  0.4781732995107197 0.775\n",
      "6129 번째 loss, accuracy:  0.4781593601406484 0.775\n",
      "6130 번째 loss, accuracy:  0.47814541847613595 0.775\n",
      "6131 번째 loss, accuracy:  0.4781314745119277 0.775\n",
      "6132 번째 loss, accuracy:  0.47811752824276893 0.775\n",
      "6133 번째 loss, accuracy:  0.47810357966340467 0.775\n",
      "6134 번째 loss, accuracy:  0.4780896287685794 0.775\n",
      "6135 번째 loss, accuracy:  0.478075675553038 0.775\n",
      "6136 번째 loss, accuracy:  0.47806172001152486 0.775\n",
      "6137 번째 loss, accuracy:  0.47804776213878397 0.775\n",
      "6138 번째 loss, accuracy:  0.478033801929559 0.775\n",
      "6139 번째 loss, accuracy:  0.47801983937859394 0.775\n",
      "6140 번째 loss, accuracy:  0.4780058744806322 0.775\n",
      "6141 번째 loss, accuracy:  0.4779919072304171 0.775\n",
      "6142 번째 loss, accuracy:  0.4779779376226916 0.775\n",
      "6143 번째 loss, accuracy:  0.4779639656521985 0.775\n",
      "6144 번째 loss, accuracy:  0.47794999131368077 0.775\n",
      "6145 번째 loss, accuracy:  0.47793601460188084 0.775\n",
      "6146 번째 loss, accuracy:  0.4779220355115405 0.775\n",
      "6147 번째 loss, accuracy:  0.47790805403740205 0.775\n",
      "6148 번째 loss, accuracy:  0.4778940701742075 0.775\n",
      "6149 번째 loss, accuracy:  0.47788008391669823 0.775\n",
      "6150 번째 loss, accuracy:  0.47786609525961576 0.775\n",
      "6151 번째 loss, accuracy:  0.4778521041977014 0.775\n",
      "6152 번째 loss, accuracy:  0.4778381107256963 0.775\n",
      "6153 번째 loss, accuracy:  0.4778241148383409 0.775\n",
      "6154 번째 loss, accuracy:  0.4778101165303764 0.775\n",
      "6155 번째 loss, accuracy:  0.47779611579654296 0.775\n",
      "6156 번째 loss, accuracy:  0.47778211263158094 0.775\n",
      "6157 번째 loss, accuracy:  0.4777681070302306 0.775\n",
      "6158 번째 loss, accuracy:  0.47775409898723153 0.775\n",
      "6159 번째 loss, accuracy:  0.47774008849732386 0.775\n",
      "6160 번째 loss, accuracy:  0.477726075555247 0.775\n",
      "6161 번째 loss, accuracy:  0.4777120601557402 0.775\n",
      "6162 번째 loss, accuracy:  0.47769804229354274 0.775\n",
      "6163 번째 loss, accuracy:  0.4776840219633937 0.775\n",
      "6164 번째 loss, accuracy:  0.47766999916003183 0.775\n",
      "6165 번째 loss, accuracy:  0.47765597387819597 0.775\n",
      "6166 번째 loss, accuracy:  0.47764194611262456 0.775\n",
      "6167 번째 loss, accuracy:  0.47762791585805586 0.775\n",
      "6168 번째 loss, accuracy:  0.4776138831092279 0.775\n",
      "6169 번째 loss, accuracy:  0.47759984786087883 0.775\n",
      "6170 번째 loss, accuracy:  0.47758581010774653 0.775\n",
      "6171 번째 loss, accuracy:  0.4775717698445685 0.775\n",
      "6172 번째 loss, accuracy:  0.4775577270660824 0.775\n",
      "6173 번째 loss, accuracy:  0.47754368176702544 0.775\n",
      "6174 번째 loss, accuracy:  0.4775296339421351 0.775\n",
      "6175 번째 loss, accuracy:  0.477515583586148 0.775\n",
      "6176 번째 loss, accuracy:  0.47750153069380125 0.775\n",
      "6177 번째 loss, accuracy:  0.4774874752598315 0.775\n",
      "6178 번째 loss, accuracy:  0.4774734172789749 0.775\n",
      "6179 번째 loss, accuracy:  0.4774593567459687 0.775\n",
      "6180 번째 loss, accuracy:  0.4774452936555483 0.775\n",
      "6181 번째 loss, accuracy:  0.4774312280024501 0.775\n",
      "6182 번째 loss, accuracy:  0.4774171597814101 0.775\n",
      "6183 번째 loss, accuracy:  0.47740308898716394 0.775\n",
      "6184 번째 loss, accuracy:  0.47738901561444747 0.775\n",
      "6185 번째 loss, accuracy:  0.4773749396579961 0.775\n",
      "6186 번째 loss, accuracy:  0.4773608611125452 0.775\n",
      "6187 번째 loss, accuracy:  0.47734677997283015 0.775\n",
      "6188 번째 loss, accuracy:  0.4773326962335859 0.775\n",
      "6189 번째 loss, accuracy:  0.47731860988954733 0.775\n",
      "6190 번째 loss, accuracy:  0.47730452093544934 0.775\n",
      "6191 번째 loss, accuracy:  0.47729042936602667 0.775\n",
      "6192 번째 loss, accuracy:  0.477276335176014 0.775\n",
      "6193 번째 loss, accuracy:  0.4772622383601455 0.775\n",
      "6194 번째 loss, accuracy:  0.4772481389131553 0.775\n",
      "6195 번째 loss, accuracy:  0.4772340368297781 0.775\n",
      "6196 번째 loss, accuracy:  0.47721993210474734 0.775\n",
      "6197 번째 loss, accuracy:  0.4772058247327974 0.775\n",
      "6198 번째 loss, accuracy:  0.4771917147086618 0.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6199 번째 loss, accuracy:  0.4771776020270744 0.775\n",
      "6200 번째 loss, accuracy:  0.4771634866827686 0.775\n",
      "6201 번째 loss, accuracy:  0.47714936867047786 0.775\n",
      "6202 번째 loss, accuracy:  0.47713524798493556 0.775\n",
      "6203 번째 loss, accuracy:  0.4771211246208749 0.775\n",
      "6204 번째 loss, accuracy:  0.4771069985730288 0.775\n",
      "6205 번째 loss, accuracy:  0.47709286983613064 0.7833333333333333\n",
      "6206 번째 loss, accuracy:  0.4770787384049127 0.7833333333333333\n",
      "6207 번째 loss, accuracy:  0.47706460427410813 0.7833333333333333\n",
      "6208 번째 loss, accuracy:  0.47705046743844937 0.7833333333333333\n",
      "6209 번째 loss, accuracy:  0.47703632789266914 0.7833333333333333\n",
      "6210 번째 loss, accuracy:  0.4770221856314997 0.7833333333333333\n",
      "6211 번째 loss, accuracy:  0.4770080406496736 0.7833333333333333\n",
      "6212 번째 loss, accuracy:  0.4769938929419228 0.7833333333333333\n",
      "6213 번째 loss, accuracy:  0.4769797425029797 0.7833333333333333\n",
      "6214 번째 loss, accuracy:  0.4769655893275761 0.7833333333333333\n",
      "6215 번째 loss, accuracy:  0.47695143341044416 0.7833333333333333\n",
      "6216 번째 loss, accuracy:  0.4769372747463157 0.775\n",
      "6217 번째 loss, accuracy:  0.47692311332992243 0.775\n",
      "6218 번째 loss, accuracy:  0.476908949155996 0.775\n",
      "6219 번째 loss, accuracy:  0.47689478221926823 0.775\n",
      "6220 번째 loss, accuracy:  0.47688061251447017 0.775\n",
      "6221 번째 loss, accuracy:  0.4768664400363335 0.775\n",
      "6222 번째 loss, accuracy:  0.47685226477958964 0.775\n",
      "6223 번째 loss, accuracy:  0.4768380867389695 0.775\n",
      "6224 번째 loss, accuracy:  0.4768239059092044 0.775\n",
      "6225 번째 loss, accuracy:  0.47680972228502544 0.775\n",
      "6226 번째 loss, accuracy:  0.4767955358611634 0.775\n",
      "6227 번째 loss, accuracy:  0.4767813466323495 0.775\n",
      "6228 번째 loss, accuracy:  0.47676715459331453 0.775\n",
      "6229 번째 loss, accuracy:  0.4767529597387892 0.775\n",
      "6230 번째 loss, accuracy:  0.47673876206350396 0.775\n",
      "6231 번째 loss, accuracy:  0.4767245615621898 0.775\n",
      "6232 번째 loss, accuracy:  0.47671035822957714 0.775\n",
      "6233 번째 loss, accuracy:  0.47669615206039645 0.7833333333333333\n",
      "6234 번째 loss, accuracy:  0.4766819430493782 0.7833333333333333\n",
      "6235 번째 loss, accuracy:  0.4766677311912526 0.7833333333333333\n",
      "6236 번째 loss, accuracy:  0.4766535164807502 0.7833333333333333\n",
      "6237 번째 loss, accuracy:  0.4766392989126012 0.7833333333333333\n",
      "6238 번째 loss, accuracy:  0.4766250784815355 0.7833333333333333\n",
      "6239 번째 loss, accuracy:  0.4766108551822834 0.7833333333333333\n",
      "6240 번째 loss, accuracy:  0.4765966290095753 0.7833333333333333\n",
      "6241 번째 loss, accuracy:  0.47658239995814095 0.7833333333333333\n",
      "6242 번째 loss, accuracy:  0.4765681680227101 0.7833333333333333\n",
      "6243 번째 loss, accuracy:  0.4765539331980129 0.7833333333333333\n",
      "6244 번째 loss, accuracy:  0.47653969547877917 0.7833333333333333\n",
      "6245 번째 loss, accuracy:  0.4765254548597387 0.7833333333333333\n",
      "6246 번째 loss, accuracy:  0.4765112113356215 0.7833333333333333\n",
      "6247 번째 loss, accuracy:  0.47649696490115695 0.7833333333333333\n",
      "6248 번째 loss, accuracy:  0.47648271555107474 0.7833333333333333\n",
      "6249 번째 loss, accuracy:  0.4764684632801045 0.7833333333333333\n",
      "6250 번째 loss, accuracy:  0.47645420808297606 0.7833333333333333\n",
      "6251 번째 loss, accuracy:  0.47643994995441896 0.7833333333333333\n",
      "6252 번째 loss, accuracy:  0.4764256888891624 0.7833333333333333\n",
      "6253 번째 loss, accuracy:  0.4764114248819362 0.7833333333333333\n",
      "6254 번째 loss, accuracy:  0.4763971579274699 0.7833333333333333\n",
      "6255 번째 loss, accuracy:  0.4763828880204928 0.7833333333333333\n",
      "6256 번째 loss, accuracy:  0.4763686151557342 0.7833333333333333\n",
      "6257 번째 loss, accuracy:  0.4763543393279235 0.7833333333333333\n",
      "6258 번째 loss, accuracy:  0.4763400605317901 0.7833333333333333\n",
      "6259 번째 loss, accuracy:  0.47632577876206333 0.7833333333333333\n",
      "6260 번째 loss, accuracy:  0.4763114940134726 0.7833333333333333\n",
      "6261 번째 loss, accuracy:  0.47629720628074707 0.7833333333333333\n",
      "6262 번째 loss, accuracy:  0.476282915558616 0.7833333333333333\n",
      "6263 번째 loss, accuracy:  0.4762686218418089 0.7833333333333333\n",
      "6264 번째 loss, accuracy:  0.4762543251250546 0.7833333333333333\n",
      "6265 번째 loss, accuracy:  0.47624002540308225 0.7833333333333333\n",
      "6266 번째 loss, accuracy:  0.47622572267062147 0.7833333333333333\n",
      "6267 번째 loss, accuracy:  0.4762114169224013 0.7833333333333333\n",
      "6268 번째 loss, accuracy:  0.4761971081531509 0.7833333333333333\n",
      "6269 번째 loss, accuracy:  0.47618279635759936 0.7833333333333333\n",
      "6270 번째 loss, accuracy:  0.47616848153047575 0.7833333333333333\n",
      "6271 번째 loss, accuracy:  0.4761541636665096 0.7833333333333333\n",
      "6272 번째 loss, accuracy:  0.4761398427604296 0.7833333333333333\n",
      "6273 번째 loss, accuracy:  0.4761255188069654 0.7833333333333333\n",
      "6274 번째 loss, accuracy:  0.47611119180084566 0.7833333333333333\n",
      "6275 번째 loss, accuracy:  0.47609686173679994 0.7833333333333333\n",
      "6276 번째 loss, accuracy:  0.47608252860955697 0.7833333333333333\n",
      "6277 번째 loss, accuracy:  0.4760681924138461 0.7833333333333333\n",
      "6278 번째 loss, accuracy:  0.4760538531443968 0.7833333333333333\n",
      "6279 번째 loss, accuracy:  0.4760395107959379 0.7833333333333333\n",
      "6280 번째 loss, accuracy:  0.47602516536319867 0.7833333333333333\n",
      "6281 번째 loss, accuracy:  0.4760108168409083 0.7833333333333333\n",
      "6282 번째 loss, accuracy:  0.47599646522379613 0.7833333333333333\n",
      "6283 번째 loss, accuracy:  0.4759821105065914 0.7833333333333333\n",
      "6284 번째 loss, accuracy:  0.4759677526840232 0.7833333333333333\n",
      "6285 번째 loss, accuracy:  0.47595339175082096 0.7833333333333333\n",
      "6286 번째 loss, accuracy:  0.4759390277017136 0.7833333333333333\n",
      "6287 번째 loss, accuracy:  0.4759246605314306 0.7833333333333333\n",
      "6288 번째 loss, accuracy:  0.4759102902347016 0.7833333333333333\n",
      "6289 번째 loss, accuracy:  0.47589591680625554 0.7833333333333333\n",
      "6290 번째 loss, accuracy:  0.4758815402408223 0.7833333333333333\n",
      "6291 번째 loss, accuracy:  0.47586716053313083 0.7833333333333333\n",
      "6292 번째 loss, accuracy:  0.4758527776779108 0.7833333333333333\n",
      "6293 번째 loss, accuracy:  0.4758383916698914 0.7833333333333333\n",
      "6294 번째 loss, accuracy:  0.4758240025038025 0.7833333333333333\n",
      "6295 번째 loss, accuracy:  0.47580961017437345 0.7833333333333333\n",
      "6296 번째 loss, accuracy:  0.47579521467633384 0.7833333333333333\n",
      "6297 번째 loss, accuracy:  0.47578081600441313 0.7833333333333333\n",
      "6298 번째 loss, accuracy:  0.4757664141533414 0.7833333333333333\n",
      "6299 번째 loss, accuracy:  0.475752009117848 0.7833333333333333\n",
      "6300 번째 loss, accuracy:  0.4757376008926625 0.7833333333333333\n",
      "6301 번째 loss, accuracy:  0.47572318947251513 0.7833333333333333\n",
      "6302 번째 loss, accuracy:  0.4757087748521355 0.7833333333333333\n",
      "6303 번째 loss, accuracy:  0.47569435702625346 0.7833333333333333\n",
      "6304 번째 loss, accuracy:  0.47567993598959873 0.7833333333333333\n",
      "6305 번째 loss, accuracy:  0.4756655117369018 0.7833333333333333\n",
      "6306 번째 loss, accuracy:  0.47565108426289215 0.7833333333333333\n",
      "6307 번째 loss, accuracy:  0.47563665356230017 0.7833333333333333\n",
      "6308 번째 loss, accuracy:  0.4756222196298562 0.7833333333333333\n",
      "6309 번째 loss, accuracy:  0.47560778246029006 0.7833333333333333\n",
      "6310 번째 loss, accuracy:  0.4755933420483322 0.7833333333333333\n",
      "6311 번째 loss, accuracy:  0.47557889838871287 0.7833333333333333\n",
      "6312 번째 loss, accuracy:  0.4755644514761624 0.7833333333333333\n",
      "6313 번째 loss, accuracy:  0.47555000130541125 0.7833333333333333\n",
      "6314 번째 loss, accuracy:  0.4755355478711901 0.7833333333333333\n",
      "6315 번째 loss, accuracy:  0.4755210911682296 0.7833333333333333\n",
      "6316 번째 loss, accuracy:  0.4755066311912601 0.7833333333333333\n",
      "6317 번째 loss, accuracy:  0.4754921679350124 0.7833333333333333\n",
      "6318 번째 loss, accuracy:  0.4754777013942172 0.7833333333333333\n",
      "6319 번째 loss, accuracy:  0.47546323156360576 0.7833333333333333\n",
      "6320 번째 loss, accuracy:  0.4754487584379086 0.7833333333333333\n",
      "6321 번째 loss, accuracy:  0.47543428201185717 0.7833333333333333\n",
      "6322 번째 loss, accuracy:  0.47541980228018216 0.7833333333333333\n",
      "6323 번째 loss, accuracy:  0.47540531923761464 0.7833333333333333\n",
      "6324 번째 loss, accuracy:  0.4753908328788864 0.7833333333333333\n",
      "6325 번째 loss, accuracy:  0.47537634319872846 0.7833333333333333\n",
      "6326 번째 loss, accuracy:  0.47536185019187227 0.7833333333333333\n",
      "6327 번째 loss, accuracy:  0.47534735385304955 0.7833333333333333\n",
      "6328 번째 loss, accuracy:  0.4753328541769916 0.7833333333333333\n",
      "6329 번째 loss, accuracy:  0.47531835115843063 0.7833333333333333\n",
      "6330 번째 loss, accuracy:  0.4753038447920979 0.7833333333333333\n",
      "6331 번째 loss, accuracy:  0.47528933507272547 0.7833333333333333\n",
      "6332 번째 loss, accuracy:  0.4752748219950452 0.7833333333333333\n",
      "6333 번째 loss, accuracy:  0.47526030555378956 0.7833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6334 번째 loss, accuracy:  0.47524578574369064 0.7833333333333333\n",
      "6335 번째 loss, accuracy:  0.47523126255948045 0.7833333333333333\n",
      "6336 번째 loss, accuracy:  0.4752167359958916 0.7833333333333333\n",
      "6337 번째 loss, accuracy:  0.4752022060476565 0.7833333333333333\n",
      "6338 번째 loss, accuracy:  0.4751876727095076 0.7833333333333333\n",
      "6339 번째 loss, accuracy:  0.4751731359761779 0.7833333333333333\n",
      "6340 번째 loss, accuracy:  0.47515859584239983 0.7833333333333333\n",
      "6341 번째 loss, accuracy:  0.4751440523029068 0.7833333333333333\n",
      "6342 번째 loss, accuracy:  0.47512950535243154 0.7833333333333333\n",
      "6343 번째 loss, accuracy:  0.47511495498570716 0.7833333333333333\n",
      "6344 번째 loss, accuracy:  0.47510040119746727 0.7833333333333333\n",
      "6345 번째 loss, accuracy:  0.4750858439824449 0.7833333333333333\n",
      "6346 번째 loss, accuracy:  0.47507128333537363 0.7833333333333333\n",
      "6347 번째 loss, accuracy:  0.4750567192509871 0.7833333333333333\n",
      "6348 번째 loss, accuracy:  0.4750421517240191 0.7833333333333333\n",
      "6349 번째 loss, accuracy:  0.4750275807492034 0.7833333333333333\n",
      "6350 번째 loss, accuracy:  0.47501300632127424 0.7833333333333333\n",
      "6351 번째 loss, accuracy:  0.4749984284349656 0.7833333333333333\n",
      "6352 번째 loss, accuracy:  0.47498384708501135 0.7833333333333333\n",
      "6353 번째 loss, accuracy:  0.4749692622661463 0.7833333333333333\n",
      "6354 번째 loss, accuracy:  0.47495467397310503 0.7833333333333333\n",
      "6355 번째 loss, accuracy:  0.47494008220062206 0.7833333333333333\n",
      "6356 번째 loss, accuracy:  0.4749254869434322 0.7833333333333333\n",
      "6357 번째 loss, accuracy:  0.4749108881962703 0.7833333333333333\n",
      "6358 번째 loss, accuracy:  0.47489628595387134 0.7833333333333333\n",
      "6359 번째 loss, accuracy:  0.4748816802109707 0.7833333333333333\n",
      "6360 번째 loss, accuracy:  0.4748670709623037 0.7833333333333333\n",
      "6361 번째 loss, accuracy:  0.47485245820260574 0.7833333333333333\n",
      "6362 번째 loss, accuracy:  0.4748378419266126 0.7833333333333333\n",
      "6363 번째 loss, accuracy:  0.4748232221290597 0.7833333333333333\n",
      "6364 번째 loss, accuracy:  0.4748085988046833 0.7833333333333333\n",
      "6365 번째 loss, accuracy:  0.4747939719482195 0.7833333333333333\n",
      "6366 번째 loss, accuracy:  0.47477934155440427 0.7833333333333333\n",
      "6367 번째 loss, accuracy:  0.47476470761797424 0.7833333333333333\n",
      "6368 번째 loss, accuracy:  0.4747500701336657 0.7833333333333333\n",
      "6369 번째 loss, accuracy:  0.4747354290962156 0.7833333333333333\n",
      "6370 번째 loss, accuracy:  0.4747207845003608 0.7833333333333333\n",
      "6371 번째 loss, accuracy:  0.47470613634083814 0.7833333333333333\n",
      "6372 번째 loss, accuracy:  0.4746914846123848 0.7833333333333333\n",
      "6373 번째 loss, accuracy:  0.4746768293097385 0.7833333333333333\n",
      "6374 번째 loss, accuracy:  0.47466217042763625 0.7833333333333333\n",
      "6375 번째 loss, accuracy:  0.474647507960816 0.7833333333333333\n",
      "6376 번째 loss, accuracy:  0.4746328419040153 0.7833333333333333\n",
      "6377 번째 loss, accuracy:  0.4746181722519723 0.7833333333333333\n",
      "6378 번째 loss, accuracy:  0.4746034989994251 0.7833333333333333\n",
      "6379 번째 loss, accuracy:  0.47458882214111237 0.7833333333333333\n",
      "6380 번째 loss, accuracy:  0.4745741416717724 0.7833333333333333\n",
      "6381 번째 loss, accuracy:  0.47455945758614376 0.7833333333333333\n",
      "6382 번째 loss, accuracy:  0.47454476987896566 0.7833333333333333\n",
      "6383 번째 loss, accuracy:  0.4745300785449769 0.7833333333333333\n",
      "6384 번째 loss, accuracy:  0.47451538357891665 0.7833333333333333\n",
      "6385 번째 loss, accuracy:  0.47450068497552483 0.7833333333333333\n",
      "6386 번째 loss, accuracy:  0.4744859827295407 0.7916666666666666\n",
      "6387 번째 loss, accuracy:  0.47447127683570406 0.7916666666666666\n",
      "6388 번째 loss, accuracy:  0.4744565672887549 0.7916666666666666\n",
      "6389 번째 loss, accuracy:  0.47444185408343337 0.7916666666666666\n",
      "6390 번째 loss, accuracy:  0.4744271372144798 0.7916666666666666\n",
      "6391 번째 loss, accuracy:  0.474412416676635 0.7916666666666666\n",
      "6392 번째 loss, accuracy:  0.47439769246463936 0.7916666666666666\n",
      "6393 번째 loss, accuracy:  0.47438296457323414 0.7916666666666666\n",
      "6394 번째 loss, accuracy:  0.4743682329971603 0.7916666666666666\n",
      "6395 번째 loss, accuracy:  0.47435349773115926 0.7916666666666666\n",
      "6396 번째 loss, accuracy:  0.47433875876997267 0.7916666666666666\n",
      "6397 번째 loss, accuracy:  0.4743240161083419 0.7916666666666666\n",
      "6398 번째 loss, accuracy:  0.4743092697410091 0.7916666666666666\n",
      "6399 번째 loss, accuracy:  0.47429451966271674 0.7916666666666666\n",
      "6400 번째 loss, accuracy:  0.47427976586820686 0.7916666666666666\n",
      "6401 번째 loss, accuracy:  0.4742650083522221 0.7916666666666666\n",
      "6402 번째 loss, accuracy:  0.47425024710950525 0.7916666666666666\n",
      "6403 번째 loss, accuracy:  0.4742354821347993 0.7916666666666666\n",
      "6404 번째 loss, accuracy:  0.47422071342284766 0.7916666666666666\n",
      "6405 번째 loss, accuracy:  0.47420594096839336 0.7833333333333333\n",
      "6406 번째 loss, accuracy:  0.47419116476618034 0.7833333333333333\n",
      "6407 번째 loss, accuracy:  0.4741763848109523 0.7833333333333333\n",
      "6408 번째 loss, accuracy:  0.4741616010974534 0.7833333333333333\n",
      "6409 번째 loss, accuracy:  0.47414681362042793 0.7833333333333333\n",
      "6410 번째 loss, accuracy:  0.4741320223746205 0.7833333333333333\n",
      "6411 번째 loss, accuracy:  0.4741172273547757 0.7833333333333333\n",
      "6412 번째 loss, accuracy:  0.4741024285556385 0.7833333333333333\n",
      "6413 번째 loss, accuracy:  0.4740876259719542 0.7833333333333333\n",
      "6414 번째 loss, accuracy:  0.4740728195984686 0.7833333333333333\n",
      "6415 번째 loss, accuracy:  0.47405800942992665 0.7833333333333333\n",
      "6416 번째 loss, accuracy:  0.47404319546107465 0.7833333333333333\n",
      "6417 번째 loss, accuracy:  0.4740283776866587 0.7833333333333333\n",
      "6418 번째 loss, accuracy:  0.474013556101425 0.7833333333333333\n",
      "6419 번째 loss, accuracy:  0.47399873070012055 0.7833333333333333\n",
      "6420 번째 loss, accuracy:  0.47398390147749175 0.7833333333333333\n",
      "6421 번째 loss, accuracy:  0.4739690684282862 0.7833333333333333\n",
      "6422 번째 loss, accuracy:  0.47395423154725075 0.7833333333333333\n",
      "6423 번째 loss, accuracy:  0.4739393908291332 0.7833333333333333\n",
      "6424 번째 loss, accuracy:  0.47392454626868136 0.7833333333333333\n",
      "6425 번째 loss, accuracy:  0.47390969786064346 0.7833333333333333\n",
      "6426 번째 loss, accuracy:  0.4738948455997675 0.7833333333333333\n",
      "6427 번째 loss, accuracy:  0.473879989480802 0.7833333333333333\n",
      "6428 번째 loss, accuracy:  0.47386512949849624 0.7833333333333333\n",
      "6429 번째 loss, accuracy:  0.4738502656475987 0.7833333333333333\n",
      "6430 번째 loss, accuracy:  0.4738353979228592 0.7833333333333333\n",
      "6431 번째 loss, accuracy:  0.4738205263190274 0.7833333333333333\n",
      "6432 번째 loss, accuracy:  0.4738056508308527 0.7833333333333333\n",
      "6433 번째 loss, accuracy:  0.4737907714530854 0.7833333333333333\n",
      "6434 번째 loss, accuracy:  0.4737758881804759 0.7833333333333333\n",
      "6435 번째 loss, accuracy:  0.47376100100777485 0.7833333333333333\n",
      "6436 번째 loss, accuracy:  0.4737461099297331 0.7833333333333333\n",
      "6437 번째 loss, accuracy:  0.47373121494110193 0.7833333333333333\n",
      "6438 번째 loss, accuracy:  0.4737163160366325 0.7833333333333333\n",
      "6439 번째 loss, accuracy:  0.47370141321107667 0.7833333333333333\n",
      "6440 번째 loss, accuracy:  0.47368650645918653 0.7833333333333333\n",
      "6441 번째 loss, accuracy:  0.4736715957757143 0.7833333333333333\n",
      "6442 번째 loss, accuracy:  0.47365668115541243 0.7833333333333333\n",
      "6443 번째 loss, accuracy:  0.4736417625930337 0.7833333333333333\n",
      "6444 번째 loss, accuracy:  0.4736268400833312 0.7833333333333333\n",
      "6445 번째 loss, accuracy:  0.4736119136210584 0.7833333333333333\n",
      "6446 번째 loss, accuracy:  0.47359698320096905 0.7833333333333333\n",
      "6447 번째 loss, accuracy:  0.47358204881781646 0.7833333333333333\n",
      "6448 번째 loss, accuracy:  0.47356711046635563 0.7833333333333333\n",
      "6449 번째 loss, accuracy:  0.4735521681413405 0.7833333333333333\n",
      "6450 번째 loss, accuracy:  0.47353722183752567 0.775\n",
      "6451 번째 loss, accuracy:  0.47352227154966686 0.775\n",
      "6452 번째 loss, accuracy:  0.47350731727251916 0.775\n",
      "6453 번째 loss, accuracy:  0.47349235900083786 0.775\n",
      "6454 번째 loss, accuracy:  0.47347739672937916 0.775\n",
      "6455 번째 loss, accuracy:  0.4734624304528995 0.775\n",
      "6456 번째 loss, accuracy:  0.4734474601661551 0.775\n",
      "6457 번째 loss, accuracy:  0.47343248586390285 0.775\n",
      "6458 번째 loss, accuracy:  0.47341750754090023 0.775\n",
      "6459 번째 loss, accuracy:  0.47340252519190446 0.775\n",
      "6460 번째 loss, accuracy:  0.47338753881167295 0.775\n",
      "6461 번째 loss, accuracy:  0.4733725483949641 0.775\n",
      "6462 번째 loss, accuracy:  0.47335755393653617 0.775\n",
      "6463 번째 loss, accuracy:  0.473342555431148 0.775\n",
      "6464 번째 loss, accuracy:  0.4733275528735581 0.775\n",
      "6465 번째 loss, accuracy:  0.4733125462585258 0.775\n",
      "6466 번째 loss, accuracy:  0.47329753558081095 0.775\n",
      "6467 번째 loss, accuracy:  0.4732825208351736 0.7833333333333333\n",
      "6468 번째 loss, accuracy:  0.4732675020163738 0.7833333333333333\n",
      "6469 번째 loss, accuracy:  0.473252479119172 0.7833333333333333\n",
      "6470 번째 loss, accuracy:  0.47323745213832896 0.7833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6471 번째 loss, accuracy:  0.4732224210686062 0.7833333333333333\n",
      "6472 번째 loss, accuracy:  0.47320738590476474 0.7833333333333333\n",
      "6473 번째 loss, accuracy:  0.4731923466415663 0.7833333333333333\n",
      "6474 번째 loss, accuracy:  0.4731773032737735 0.7833333333333333\n",
      "6475 번째 loss, accuracy:  0.4731622557961486 0.7833333333333333\n",
      "6476 번째 loss, accuracy:  0.47314720420345463 0.7833333333333333\n",
      "6477 번째 loss, accuracy:  0.4731321484904542 0.7833333333333333\n",
      "6478 번째 loss, accuracy:  0.47311708865191127 0.7833333333333333\n",
      "6479 번째 loss, accuracy:  0.47310202468258955 0.7833333333333333\n",
      "6480 번째 loss, accuracy:  0.4730869565772528 0.7833333333333333\n",
      "6481 번째 loss, accuracy:  0.4730718843306657 0.7833333333333333\n",
      "6482 번째 loss, accuracy:  0.47305680793759314 0.7833333333333333\n",
      "6483 번째 loss, accuracy:  0.4730417273928 0.7833333333333333\n",
      "6484 번째 loss, accuracy:  0.47302664269105205 0.7833333333333333\n",
      "6485 번째 loss, accuracy:  0.473011553827115 0.7833333333333333\n",
      "6486 번째 loss, accuracy:  0.47299646079575486 0.7833333333333333\n",
      "6487 번째 loss, accuracy:  0.4729813635917385 0.7833333333333333\n",
      "6488 번째 loss, accuracy:  0.4729662622098323 0.7833333333333333\n",
      "6489 번째 loss, accuracy:  0.4729511566448039 0.7833333333333333\n",
      "6490 번째 loss, accuracy:  0.4729360468914205 0.7833333333333333\n",
      "6491 번째 loss, accuracy:  0.4729209329444498 0.7833333333333333\n",
      "6492 번째 loss, accuracy:  0.4729058147986606 0.7833333333333333\n",
      "6493 번째 loss, accuracy:  0.4728906924488213 0.7833333333333333\n",
      "6494 번째 loss, accuracy:  0.47287556588970076 0.7833333333333333\n",
      "6495 번째 loss, accuracy:  0.47286043511606823 0.7833333333333333\n",
      "6496 번째 loss, accuracy:  0.4728453001226936 0.7833333333333333\n",
      "6497 번째 loss, accuracy:  0.4728301609043469 0.7833333333333333\n",
      "6498 번째 loss, accuracy:  0.4728150174557982 0.7833333333333333\n",
      "6499 번째 loss, accuracy:  0.4727998697718183 0.7833333333333333\n",
      "6500 번째 loss, accuracy:  0.47278471784717874 0.7833333333333333\n",
      "6501 번째 loss, accuracy:  0.47276956167665063 0.7833333333333333\n",
      "6502 번째 loss, accuracy:  0.472754401255006 0.7833333333333333\n",
      "6503 번째 loss, accuracy:  0.47273923657701694 0.7833333333333333\n",
      "6504 번째 loss, accuracy:  0.4727240676374562 0.7833333333333333\n",
      "6505 번째 loss, accuracy:  0.4727088944310965 0.7833333333333333\n",
      "6506 번째 loss, accuracy:  0.4726937169527114 0.7833333333333333\n",
      "6507 번째 loss, accuracy:  0.4726785351970749 0.7833333333333333\n",
      "6508 번째 loss, accuracy:  0.4726633491589606 0.7833333333333333\n",
      "6509 번째 loss, accuracy:  0.47264815883314326 0.7833333333333333\n",
      "6510 번째 loss, accuracy:  0.4726329642143974 0.7833333333333333\n",
      "6511 번째 loss, accuracy:  0.4726177652974985 0.7833333333333333\n",
      "6512 번째 loss, accuracy:  0.47260256207722207 0.7833333333333333\n",
      "6513 번째 loss, accuracy:  0.47258735454834416 0.7833333333333333\n",
      "6514 번째 loss, accuracy:  0.47257214270564124 0.7833333333333333\n",
      "6515 번째 loss, accuracy:  0.4725569265438902 0.7833333333333333\n",
      "6516 번째 loss, accuracy:  0.47254170605786794 0.7833333333333333\n",
      "6517 번째 loss, accuracy:  0.47252648124235236 0.7833333333333333\n",
      "6518 번째 loss, accuracy:  0.47251125209212114 0.7833333333333333\n",
      "6519 번째 loss, accuracy:  0.4724960186019523 0.7833333333333333\n",
      "6520 번째 loss, accuracy:  0.4724807807666252 0.7833333333333333\n",
      "6521 번째 loss, accuracy:  0.47246553858091855 0.7833333333333333\n",
      "6522 번째 loss, accuracy:  0.4724502920396121 0.7833333333333333\n",
      "6523 번째 loss, accuracy:  0.4724350411374857 0.7833333333333333\n",
      "6524 번째 loss, accuracy:  0.4724197858693195 0.7833333333333333\n",
      "6525 번째 loss, accuracy:  0.4724045262298945 0.7833333333333333\n",
      "6526 번째 loss, accuracy:  0.4723892622139917 0.7833333333333333\n",
      "6527 번째 loss, accuracy:  0.4723739938163927 0.7833333333333333\n",
      "6528 번째 loss, accuracy:  0.4723587210318792 0.7833333333333333\n",
      "6529 번째 loss, accuracy:  0.47234344385523397 0.7833333333333333\n",
      "6530 번째 loss, accuracy:  0.47232816228123975 0.7833333333333333\n",
      "6531 번째 loss, accuracy:  0.4723128763046793 0.7833333333333333\n",
      "6532 번째 loss, accuracy:  0.4722975859203365 0.7833333333333333\n",
      "6533 번째 loss, accuracy:  0.47228229112299547 0.7833333333333333\n",
      "6534 번째 loss, accuracy:  0.47226699190744037 0.7833333333333333\n",
      "6535 번째 loss, accuracy:  0.47225168826845626 0.7833333333333333\n",
      "6536 번째 loss, accuracy:  0.4722363802008282 0.7833333333333333\n",
      "6537 번째 loss, accuracy:  0.47222106769934186 0.7833333333333333\n",
      "6538 번째 loss, accuracy:  0.4722057507587836 0.7833333333333333\n",
      "6539 번째 loss, accuracy:  0.4721904293739396 0.7833333333333333\n",
      "6540 번째 loss, accuracy:  0.4721751035395972 0.7916666666666666\n",
      "6541 번째 loss, accuracy:  0.47215977325054337 0.7916666666666666\n",
      "6542 번째 loss, accuracy:  0.4721444385015662 0.7916666666666666\n",
      "6543 번째 loss, accuracy:  0.4721290992874537 0.7916666666666666\n",
      "6544 번째 loss, accuracy:  0.4721137556029947 0.7916666666666666\n",
      "6545 번째 loss, accuracy:  0.47209840744297815 0.7916666666666666\n",
      "6546 번째 loss, accuracy:  0.4720830548021935 0.7916666666666666\n",
      "6547 번째 loss, accuracy:  0.4720676976754312 0.7916666666666666\n",
      "6548 번째 loss, accuracy:  0.47205233605748137 0.7916666666666666\n",
      "6549 번째 loss, accuracy:  0.4720369699431348 0.7916666666666666\n",
      "6550 번째 loss, accuracy:  0.47202159932718285 0.7916666666666666\n",
      "6551 번째 loss, accuracy:  0.47200622420441707 0.7916666666666666\n",
      "6552 번째 loss, accuracy:  0.47199084456962964 0.7916666666666666\n",
      "6553 번째 loss, accuracy:  0.47197546041761324 0.7916666666666666\n",
      "6554 번째 loss, accuracy:  0.47196007174316074 0.7916666666666666\n",
      "6555 번째 loss, accuracy:  0.4719446785410662 0.7916666666666666\n",
      "6556 번째 loss, accuracy:  0.471929280806123 0.7916666666666666\n",
      "6557 번째 loss, accuracy:  0.47191387853312583 0.7916666666666666\n",
      "6558 번째 loss, accuracy:  0.47189847171686927 0.7916666666666666\n",
      "6559 번째 loss, accuracy:  0.47188306035214883 0.7916666666666666\n",
      "6560 번째 loss, accuracy:  0.47186764443376 0.7916666666666666\n",
      "6561 번째 loss, accuracy:  0.4718522239564995 0.7916666666666666\n",
      "6562 번째 loss, accuracy:  0.47183679891516345 0.8\n",
      "6563 번째 loss, accuracy:  0.4718213693045493 0.8\n",
      "6564 번째 loss, accuracy:  0.47180593511945457 0.8\n",
      "6565 번째 loss, accuracy:  0.47179049635467707 0.8\n",
      "6566 번째 loss, accuracy:  0.47177505300501577 0.8\n",
      "6567 번째 loss, accuracy:  0.47175960506526937 0.8\n",
      "6568 번째 loss, accuracy:  0.47174415253023727 0.8\n",
      "6569 번째 loss, accuracy:  0.4717286953947194 0.8\n",
      "6570 번째 loss, accuracy:  0.47171323365351636 0.8\n",
      "6571 번째 loss, accuracy:  0.47169776730142854 0.8\n",
      "6572 번째 loss, accuracy:  0.4716822963332577 0.8\n",
      "6573 번째 loss, accuracy:  0.47166682074380517 0.8\n",
      "6574 번째 loss, accuracy:  0.4716513405278737 0.8\n",
      "6575 번째 loss, accuracy:  0.47163585568026567 0.8\n",
      "6576 번째 loss, accuracy:  0.47162036619578457 0.8\n",
      "6577 번째 loss, accuracy:  0.47160487206923396 0.8\n",
      "6578 번째 loss, accuracy:  0.47158937329541784 0.8\n",
      "6579 번째 loss, accuracy:  0.4715738698691414 0.8\n",
      "6580 번째 loss, accuracy:  0.471558361785209 0.8\n",
      "6581 번째 loss, accuracy:  0.4715428490384271 0.8\n",
      "6582 번째 loss, accuracy:  0.4715273316236014 0.8\n",
      "6583 번째 loss, accuracy:  0.4715118095355384 0.8\n",
      "6584 번째 loss, accuracy:  0.47149628276904537 0.8\n",
      "6585 번째 loss, accuracy:  0.4714807513189298 0.8\n",
      "6586 번째 loss, accuracy:  0.4714652151799999 0.8\n",
      "6587 번째 loss, accuracy:  0.47144967434706386 0.8\n",
      "6588 번째 loss, accuracy:  0.47143412881493113 0.8\n",
      "6589 번째 loss, accuracy:  0.4714185785784111 0.8\n",
      "6590 번째 loss, accuracy:  0.471403023632314 0.8\n",
      "6591 번째 loss, accuracy:  0.4713874639714503 0.8\n",
      "6592 번째 loss, accuracy:  0.47137189959063086 0.8\n",
      "6593 번째 loss, accuracy:  0.47135633048466763 0.8\n",
      "6594 번째 loss, accuracy:  0.47134075664837216 0.8\n",
      "6595 번째 loss, accuracy:  0.4713251780765572 0.8\n",
      "6596 번째 loss, accuracy:  0.471309594764036 0.8\n",
      "6597 번째 loss, accuracy:  0.47129400670562205 0.8\n",
      "6598 번째 loss, accuracy:  0.47127841389612934 0.8\n",
      "6599 번째 loss, accuracy:  0.4712628163303725 0.8\n",
      "6600 번째 loss, accuracy:  0.4712472140031666 0.8\n",
      "6601 번째 loss, accuracy:  0.47123160690932747 0.8\n",
      "6602 번째 loss, accuracy:  0.47121599504367107 0.8\n",
      "6603 번째 loss, accuracy:  0.47120037840101386 0.8\n",
      "6604 번째 loss, accuracy:  0.47118475697617335 0.8\n",
      "6605 번째 loss, accuracy:  0.47116913076396705 0.8\n",
      "6606 번째 loss, accuracy:  0.47115349975921333 0.8\n",
      "6607 번째 loss, accuracy:  0.47113786395673085 0.8\n",
      "6608 번째 loss, accuracy:  0.4711222233513387 0.8\n",
      "6609 번째 loss, accuracy:  0.4711065779378568 0.8\n",
      "6610 번째 loss, accuracy:  0.4710909277111052 0.8\n",
      "6611 번째 loss, accuracy:  0.47107527266590526 0.8\n",
      "6612 번째 loss, accuracy:  0.4710596127970779 0.8\n",
      "6613 번째 loss, accuracy:  0.4710439480994452 0.8\n",
      "6614 번째 loss, accuracy:  0.47102827856782953 0.8\n",
      "6615 번째 loss, accuracy:  0.47101260419705365 0.8\n",
      "6616 번째 loss, accuracy:  0.4709969249819413 0.8\n",
      "6617 번째 loss, accuracy:  0.4709812409173165 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6618 번째 loss, accuracy:  0.4709655519980037 0.8\n",
      "6619 번째 loss, accuracy:  0.4709498582188279 0.8\n",
      "6620 번째 loss, accuracy:  0.4709341595746151 0.8\n",
      "6621 번째 loss, accuracy:  0.4709184560601913 0.8\n",
      "6622 번째 loss, accuracy:  0.470902747670383 0.8\n",
      "6623 번째 loss, accuracy:  0.4708870344000176 0.8\n",
      "6624 번째 loss, accuracy:  0.4708713162439229 0.8\n",
      "6625 번째 loss, accuracy:  0.4708555931969275 0.8\n",
      "6626 번째 loss, accuracy:  0.47083986525385996 0.8\n",
      "6627 번째 loss, accuracy:  0.47082413240954973 0.8\n",
      "6628 번째 loss, accuracy:  0.47080839465882723 0.8\n",
      "6629 번째 loss, accuracy:  0.4707926519965229 0.8083333333333333\n",
      "6630 번째 loss, accuracy:  0.47077690441746756 0.8083333333333333\n",
      "6631 번째 loss, accuracy:  0.4707611519164929 0.8083333333333333\n",
      "6632 번째 loss, accuracy:  0.4707453944884315 0.8083333333333333\n",
      "6633 번째 loss, accuracy:  0.47072963212811586 0.8083333333333333\n",
      "6634 번째 loss, accuracy:  0.47071386483037947 0.8083333333333333\n",
      "6635 번째 loss, accuracy:  0.4706980925900562 0.8083333333333333\n",
      "6636 번째 loss, accuracy:  0.47068231540198024 0.8083333333333333\n",
      "6637 번째 loss, accuracy:  0.4706665332609872 0.8083333333333333\n",
      "6638 번째 loss, accuracy:  0.4706507461619123 0.8083333333333333\n",
      "6639 번째 loss, accuracy:  0.4706349540995917 0.8083333333333333\n",
      "6640 번째 loss, accuracy:  0.47061915706886237 0.8083333333333333\n",
      "6641 번째 loss, accuracy:  0.4706033550645613 0.8083333333333333\n",
      "6642 번째 loss, accuracy:  0.4705875480815266 0.8083333333333333\n",
      "6643 번째 loss, accuracy:  0.47057173611459646 0.8083333333333333\n",
      "6644 번째 loss, accuracy:  0.47055591915861034 0.8083333333333333\n",
      "6645 번째 loss, accuracy:  0.47054009720840734 0.8083333333333333\n",
      "6646 번째 loss, accuracy:  0.4705242702588277 0.8083333333333333\n",
      "6647 번째 loss, accuracy:  0.47050843830471256 0.8083333333333333\n",
      "6648 번째 loss, accuracy:  0.47049260134090276 0.8083333333333333\n",
      "6649 번째 loss, accuracy:  0.4704767593622403 0.8083333333333333\n",
      "6650 번째 loss, accuracy:  0.4704609123635679 0.8083333333333333\n",
      "6651 번째 loss, accuracy:  0.4704450603397286 0.8083333333333333\n",
      "6652 번째 loss, accuracy:  0.4704292032855657 0.8083333333333333\n",
      "6653 번째 loss, accuracy:  0.47041334119592393 0.8083333333333333\n",
      "6654 번째 loss, accuracy:  0.4703974740656477 0.8083333333333333\n",
      "6655 번째 loss, accuracy:  0.47038160188958283 0.8083333333333333\n",
      "6656 번째 loss, accuracy:  0.47036572466257504 0.8083333333333333\n",
      "6657 번째 loss, accuracy:  0.47034984237947103 0.8083333333333333\n",
      "6658 번째 loss, accuracy:  0.4703339550351179 0.8083333333333333\n",
      "6659 번째 loss, accuracy:  0.4703180626243635 0.8083333333333333\n",
      "6660 번째 loss, accuracy:  0.4703021651420562 0.8083333333333333\n",
      "6661 번째 loss, accuracy:  0.47028626258304485 0.8083333333333333\n",
      "6662 번째 loss, accuracy:  0.4702703549421792 0.8083333333333333\n",
      "6663 번째 loss, accuracy:  0.4702544422143094 0.8083333333333333\n",
      "6664 번째 loss, accuracy:  0.4702385243942859 0.8083333333333333\n",
      "6665 번째 loss, accuracy:  0.47022260147696066 0.8083333333333333\n",
      "6666 번째 loss, accuracy:  0.4702066734571852 0.8083333333333333\n",
      "6667 번째 loss, accuracy:  0.4701907403298123 0.8083333333333333\n",
      "6668 번째 loss, accuracy:  0.47017480208969514 0.8083333333333333\n",
      "6669 번째 loss, accuracy:  0.4701588587316874 0.8083333333333333\n",
      "6670 번째 loss, accuracy:  0.4701429102506437 0.8083333333333333\n",
      "6671 번째 loss, accuracy:  0.4701269566414189 0.8083333333333333\n",
      "6672 번째 loss, accuracy:  0.47011099789886873 0.8083333333333333\n",
      "6673 번째 loss, accuracy:  0.47009503401784936 0.8083333333333333\n",
      "6674 번째 loss, accuracy:  0.4700790649932177 0.8083333333333333\n",
      "6675 번째 loss, accuracy:  0.47006309081983133 0.8083333333333333\n",
      "6676 번째 loss, accuracy:  0.4700471114925478 0.8083333333333333\n",
      "6677 번째 loss, accuracy:  0.47003112700622646 0.8083333333333333\n",
      "6678 번째 loss, accuracy:  0.47001513735572636 0.8083333333333333\n",
      "6679 번째 loss, accuracy:  0.4699991425359074 0.8083333333333333\n",
      "6680 번째 loss, accuracy:  0.46998314254163026 0.8083333333333333\n",
      "6681 번째 loss, accuracy:  0.46996713736775625 0.8083333333333333\n",
      "6682 번째 loss, accuracy:  0.469951127009147 0.8083333333333333\n",
      "6683 번째 loss, accuracy:  0.4699351114606649 0.8083333333333333\n",
      "6684 번째 loss, accuracy:  0.4699190907171733 0.8083333333333333\n",
      "6685 번째 loss, accuracy:  0.46990306477353566 0.8083333333333333\n",
      "6686 번째 loss, accuracy:  0.4698870336246163 0.8083333333333333\n",
      "6687 번째 loss, accuracy:  0.46987099726528037 0.8083333333333333\n",
      "6688 번째 loss, accuracy:  0.46985495569039337 0.8083333333333333\n",
      "6689 번째 loss, accuracy:  0.4698389088948217 0.8083333333333333\n",
      "6690 번째 loss, accuracy:  0.46982285687343217 0.8083333333333333\n",
      "6691 번째 loss, accuracy:  0.46980679962109195 0.8083333333333333\n",
      "6692 번째 loss, accuracy:  0.4697907371326695 0.8083333333333333\n",
      "6693 번째 loss, accuracy:  0.4697746694030336 0.8083333333333333\n",
      "6694 번째 loss, accuracy:  0.4697585964270536 0.8083333333333333\n",
      "6695 번째 loss, accuracy:  0.4697425181995999 0.8083333333333333\n",
      "6696 번째 loss, accuracy:  0.4697264347155427 0.8083333333333333\n",
      "6697 번째 loss, accuracy:  0.469710345969754 0.8083333333333333\n",
      "6698 번째 loss, accuracy:  0.4696942519571051 0.8083333333333333\n",
      "6699 번째 loss, accuracy:  0.469678152672469 0.8083333333333333\n",
      "6700 번째 loss, accuracy:  0.46966204811071904 0.8083333333333333\n",
      "6701 번째 loss, accuracy:  0.469645938266729 0.8083333333333333\n",
      "6702 번째 loss, accuracy:  0.4696298231353738 0.8083333333333333\n",
      "6703 번째 loss, accuracy:  0.4696137027115287 0.8083333333333333\n",
      "6704 번째 loss, accuracy:  0.46959757699006943 0.8083333333333333\n",
      "6705 번째 loss, accuracy:  0.46958144596587265 0.8083333333333333\n",
      "6706 번째 loss, accuracy:  0.46956530963381543 0.8083333333333333\n",
      "6707 번째 loss, accuracy:  0.4695491679887758 0.8083333333333333\n",
      "6708 번째 loss, accuracy:  0.4695330210256323 0.8083333333333333\n",
      "6709 번째 loss, accuracy:  0.4695168687392645 0.8083333333333333\n",
      "6710 번째 loss, accuracy:  0.4695007111245518 0.8083333333333333\n",
      "6711 번째 loss, accuracy:  0.46948454817637475 0.8083333333333333\n",
      "6712 번째 loss, accuracy:  0.4694683798896149 0.8083333333333333\n",
      "6713 번째 loss, accuracy:  0.46945220625915385 0.825\n",
      "6714 번째 loss, accuracy:  0.4694360272798743 0.825\n",
      "6715 번째 loss, accuracy:  0.46941984294665945 0.825\n",
      "6716 번째 loss, accuracy:  0.46940365325439326 0.825\n",
      "6717 번째 loss, accuracy:  0.46938745819795996 0.825\n",
      "6718 번째 loss, accuracy:  0.4693712577722451 0.825\n",
      "6719 번째 loss, accuracy:  0.4693550519721344 0.825\n",
      "6720 번째 loss, accuracy:  0.4693388407925146 0.825\n",
      "6721 번째 loss, accuracy:  0.46932262422827287 0.825\n",
      "6722 번째 loss, accuracy:  0.4693064022742974 0.825\n",
      "6723 번째 loss, accuracy:  0.4692901749254766 0.825\n",
      "6724 번째 loss, accuracy:  0.46927394217669965 0.825\n",
      "6725 번째 loss, accuracy:  0.4692577040228568 0.825\n",
      "6726 번째 loss, accuracy:  0.4692414604588388 0.825\n",
      "6727 번째 loss, accuracy:  0.46922521147953683 0.825\n",
      "6728 번째 loss, accuracy:  0.4692089570798427 0.825\n",
      "6729 번째 loss, accuracy:  0.46919269725464974 0.825\n",
      "6730 번째 loss, accuracy:  0.46917643199885084 0.825\n",
      "6731 번째 loss, accuracy:  0.46916016130734023 0.825\n",
      "6732 번째 loss, accuracy:  0.46914388517501315 0.8333333333333334\n",
      "6733 번째 loss, accuracy:  0.46912760359676464 0.8333333333333334\n",
      "6734 번째 loss, accuracy:  0.46911131656749083 0.8333333333333334\n",
      "6735 번째 loss, accuracy:  0.469095024082089 0.8333333333333334\n",
      "6736 번째 loss, accuracy:  0.4690787261354567 0.8333333333333334\n",
      "6737 번째 loss, accuracy:  0.4690624227224921 0.8333333333333334\n",
      "6738 번째 loss, accuracy:  0.4690461138380941 0.8333333333333334\n",
      "6739 번째 loss, accuracy:  0.4690297994771626 0.8333333333333334\n",
      "6740 번째 loss, accuracy:  0.4690134796345981 0.8333333333333334\n",
      "6741 번째 loss, accuracy:  0.46899715430530137 0.8333333333333334\n",
      "6742 번째 loss, accuracy:  0.4689808234841743 0.8333333333333334\n",
      "6743 번째 loss, accuracy:  0.4689644871661196 0.8333333333333334\n",
      "6744 번째 loss, accuracy:  0.46894814534604046 0.8333333333333334\n",
      "6745 번째 loss, accuracy:  0.46893179801884094 0.8333333333333334\n",
      "6746 번째 loss, accuracy:  0.46891544517942535 0.8333333333333334\n",
      "6747 번째 loss, accuracy:  0.4688990868226991 0.8333333333333334\n",
      "6748 번째 loss, accuracy:  0.4688827229435685 0.8333333333333334\n",
      "6749 번째 loss, accuracy:  0.4688663535369403 0.8333333333333334\n",
      "6750 번째 loss, accuracy:  0.46884997859772176 0.8333333333333334\n",
      "6751 번째 loss, accuracy:  0.46883359812082126 0.8333333333333334\n",
      "6752 번째 loss, accuracy:  0.46881721210114785 0.8333333333333334\n",
      "6753 번째 loss, accuracy:  0.46880082053361133 0.8333333333333334\n",
      "6754 번째 loss, accuracy:  0.46878442341312176 0.8333333333333334\n",
      "6755 번째 loss, accuracy:  0.4687680207345903 0.8333333333333334\n",
      "6756 번째 loss, accuracy:  0.46875161249292885 0.8333333333333334\n",
      "6757 번째 loss, accuracy:  0.46873519868305014 0.8333333333333334\n",
      "6758 번째 loss, accuracy:  0.4687187792998671 0.8333333333333334\n",
      "6759 번째 loss, accuracy:  0.4687023543382943 0.8333333333333334\n",
      "6760 번째 loss, accuracy:  0.4686859237932462 0.8333333333333334\n",
      "6761 번째 loss, accuracy:  0.4686694876596384 0.8333333333333334\n",
      "6762 번째 loss, accuracy:  0.46865304593238677 0.8333333333333334\n",
      "6763 번째 loss, accuracy:  0.4686365986064086 0.8333333333333334\n",
      "6764 번째 loss, accuracy:  0.4686201456766213 0.8333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6765 번째 loss, accuracy:  0.4686036871379435 0.8333333333333334\n",
      "6766 번째 loss, accuracy:  0.4685872229852943 0.8333333333333334\n",
      "6767 번째 loss, accuracy:  0.4685707532135937 0.8333333333333334\n",
      "6768 번째 loss, accuracy:  0.46855427781776215 0.8333333333333334\n",
      "6769 번째 loss, accuracy:  0.4685377967927213 0.8333333333333334\n",
      "6770 번째 loss, accuracy:  0.46852131013339327 0.8333333333333334\n",
      "6771 번째 loss, accuracy:  0.4685048178347004 0.8333333333333334\n",
      "6772 번째 loss, accuracy:  0.468488319891567 0.8333333333333334\n",
      "6773 번째 loss, accuracy:  0.46847181629891715 0.8333333333333334\n",
      "6774 번째 loss, accuracy:  0.468455307051676 0.8333333333333334\n",
      "6775 번째 loss, accuracy:  0.4684387921447692 0.8333333333333334\n",
      "6776 번째 loss, accuracy:  0.46842227157312344 0.8333333333333334\n",
      "6777 번째 loss, accuracy:  0.4684057453316664 0.8333333333333334\n",
      "6778 번째 loss, accuracy:  0.46838921341532597 0.8333333333333334\n",
      "6779 번째 loss, accuracy:  0.4683726758190309 0.8333333333333334\n",
      "6780 번째 loss, accuracy:  0.4683561325377113 0.8333333333333334\n",
      "6781 번째 loss, accuracy:  0.46833958356629696 0.8333333333333334\n",
      "6782 번째 loss, accuracy:  0.46832302889971955 0.8333333333333334\n",
      "6783 번째 loss, accuracy:  0.46830646853291075 0.8333333333333334\n",
      "6784 번째 loss, accuracy:  0.46828990246080315 0.8333333333333334\n",
      "6785 번째 loss, accuracy:  0.46827333067833027 0.8333333333333334\n",
      "6786 번째 loss, accuracy:  0.46825675318042653 0.8333333333333334\n",
      "6787 번째 loss, accuracy:  0.46824016996202666 0.8333333333333334\n",
      "6788 번째 loss, accuracy:  0.46822358101806644 0.8333333333333334\n",
      "6789 번째 loss, accuracy:  0.4682069863434826 0.8333333333333334\n",
      "6790 번째 loss, accuracy:  0.46819038593321216 0.8333333333333334\n",
      "6791 번째 loss, accuracy:  0.4681737797821931 0.8333333333333334\n",
      "6792 번째 loss, accuracy:  0.4681571678853644 0.8333333333333334\n",
      "6793 번째 loss, accuracy:  0.46814055023766554 0.8333333333333334\n",
      "6794 번째 loss, accuracy:  0.46812392683403714 0.8333333333333334\n",
      "6795 번째 loss, accuracy:  0.46810729766942033 0.8333333333333334\n",
      "6796 번째 loss, accuracy:  0.4680906627387567 0.8333333333333334\n",
      "6797 번째 loss, accuracy:  0.4680740220369894 0.8333333333333334\n",
      "6798 번째 loss, accuracy:  0.46805737555906163 0.8333333333333334\n",
      "6799 번째 loss, accuracy:  0.46804072329991775 0.8333333333333334\n",
      "6800 번째 loss, accuracy:  0.4680240652545025 0.8333333333333334\n",
      "6801 번째 loss, accuracy:  0.46800740141776237 0.8333333333333334\n",
      "6802 번째 loss, accuracy:  0.4679907317846436 0.8333333333333334\n",
      "6803 번째 loss, accuracy:  0.46797405635009365 0.8333333333333334\n",
      "6804 번째 loss, accuracy:  0.46795737510906077 0.8333333333333334\n",
      "6805 번째 loss, accuracy:  0.467940688056494 0.8333333333333334\n",
      "6806 번째 loss, accuracy:  0.467923995187343 0.8333333333333334\n",
      "6807 번째 loss, accuracy:  0.4679072964965582 0.8333333333333334\n",
      "6808 번째 loss, accuracy:  0.4678905919790913 0.8333333333333334\n",
      "6809 번째 loss, accuracy:  0.46787388162989413 0.8333333333333334\n",
      "6810 번째 loss, accuracy:  0.4678571654439197 0.8333333333333334\n",
      "6811 번째 loss, accuracy:  0.46784044341612224 0.8333333333333334\n",
      "6812 번째 loss, accuracy:  0.4678237155414559 0.8333333333333334\n",
      "6813 번째 loss, accuracy:  0.46780698181487623 0.8333333333333334\n",
      "6814 번째 loss, accuracy:  0.4677902422313395 0.8333333333333334\n",
      "6815 번째 loss, accuracy:  0.4677734967858024 0.8333333333333334\n",
      "6816 번째 loss, accuracy:  0.46775674547322255 0.8333333333333334\n",
      "6817 번째 loss, accuracy:  0.46773998828855906 0.8333333333333334\n",
      "6818 번째 loss, accuracy:  0.46772322522677084 0.8333333333333334\n",
      "6819 번째 loss, accuracy:  0.46770645628281843 0.8333333333333334\n",
      "6820 번째 loss, accuracy:  0.467689681451663 0.8333333333333334\n",
      "6821 번째 loss, accuracy:  0.4676729007282659 0.8333333333333334\n",
      "6822 번째 loss, accuracy:  0.46765611410758995 0.8333333333333334\n",
      "6823 번째 loss, accuracy:  0.4676393215845986 0.8333333333333334\n",
      "6824 번째 loss, accuracy:  0.46762252315425623 0.8333333333333334\n",
      "6825 번째 loss, accuracy:  0.4676057188115277 0.8333333333333334\n",
      "6826 번째 loss, accuracy:  0.46758890855137936 0.8333333333333334\n",
      "6827 번째 loss, accuracy:  0.4675720923687775 0.8333333333333334\n",
      "6828 번째 loss, accuracy:  0.46755527025868976 0.8333333333333334\n",
      "6829 번째 loss, accuracy:  0.4675384422160845 0.8333333333333334\n",
      "6830 번째 loss, accuracy:  0.4675216082359312 0.8333333333333334\n",
      "6831 번째 loss, accuracy:  0.46750476831319954 0.8333333333333334\n",
      "6832 번째 loss, accuracy:  0.4674879224428604 0.8333333333333334\n",
      "6833 번째 loss, accuracy:  0.46747107061988563 0.8333333333333334\n",
      "6834 번째 loss, accuracy:  0.46745421283924754 0.8333333333333334\n",
      "6835 번째 loss, accuracy:  0.46743734909591966 0.8333333333333334\n",
      "6836 번째 loss, accuracy:  0.46742047938487585 0.8333333333333334\n",
      "6837 번째 loss, accuracy:  0.46740360370109146 0.8333333333333334\n",
      "6838 번째 loss, accuracy:  0.467386722039542 0.8333333333333334\n",
      "6839 번째 loss, accuracy:  0.4673698343952044 0.8333333333333334\n",
      "6840 번째 loss, accuracy:  0.46735294076305606 0.8333333333333334\n",
      "6841 번째 loss, accuracy:  0.46733604113807553 0.8333333333333334\n",
      "6842 번째 loss, accuracy:  0.4673191355152415 0.8333333333333334\n",
      "6843 번째 loss, accuracy:  0.46730222388953446 0.8333333333333334\n",
      "6844 번째 loss, accuracy:  0.467285306255935 0.8333333333333334\n",
      "6845 번째 loss, accuracy:  0.4672683826094252 0.8333333333333334\n",
      "6846 번째 loss, accuracy:  0.4672514529449874 0.8333333333333334\n",
      "6847 번째 loss, accuracy:  0.467234517257605 0.8333333333333334\n",
      "6848 번째 loss, accuracy:  0.4672175755422623 0.8333333333333334\n",
      "6849 번째 loss, accuracy:  0.4672006277939443 0.8333333333333334\n",
      "6850 번째 loss, accuracy:  0.4671836740076372 0.8333333333333334\n",
      "6851 번째 loss, accuracy:  0.46716671417832756 0.8333333333333334\n",
      "6852 번째 loss, accuracy:  0.4671497483010033 0.8333333333333334\n",
      "6853 번째 loss, accuracy:  0.46713277637065265 0.8333333333333334\n",
      "6854 번째 loss, accuracy:  0.46711579838226513 0.8333333333333334\n",
      "6855 번째 loss, accuracy:  0.46709881433083095 0.8333333333333334\n",
      "6856 번째 loss, accuracy:  0.46708182421134126 0.8333333333333334\n",
      "6857 번째 loss, accuracy:  0.46706482801878824 0.8333333333333334\n",
      "6858 번째 loss, accuracy:  0.4670478257481643 0.8333333333333334\n",
      "6859 번째 loss, accuracy:  0.46703081739446295 0.8333333333333334\n",
      "6860 번째 loss, accuracy:  0.4670138029526794 0.8333333333333334\n",
      "6861 번째 loss, accuracy:  0.46699678241780873 0.8333333333333334\n",
      "6862 번째 loss, accuracy:  0.46697975578484724 0.8333333333333334\n",
      "6863 번째 loss, accuracy:  0.466962723048792 0.8333333333333334\n",
      "6864 번째 loss, accuracy:  0.4669456842046413 0.8333333333333334\n",
      "6865 번째 loss, accuracy:  0.4669286392473938 0.8333333333333334\n",
      "6866 번째 loss, accuracy:  0.4669115881720493 0.8333333333333334\n",
      "6867 번째 loss, accuracy:  0.46689453097360845 0.8333333333333334\n",
      "6868 번째 loss, accuracy:  0.46687746764707294 0.8333333333333334\n",
      "6869 번째 loss, accuracy:  0.46686039818744474 0.8333333333333334\n",
      "6870 번째 loss, accuracy:  0.4668433225897273 0.8333333333333334\n",
      "6871 번째 loss, accuracy:  0.46682624084892493 0.8333333333333334\n",
      "6872 번째 loss, accuracy:  0.4668091529600428 0.8333333333333334\n",
      "6873 번째 loss, accuracy:  0.4667920589180865 0.8333333333333334\n",
      "6874 번째 loss, accuracy:  0.466774958718063 0.8333333333333334\n",
      "6875 번째 loss, accuracy:  0.46675785235497996 0.8333333333333334\n",
      "6876 번째 loss, accuracy:  0.4667407398238461 0.8333333333333334\n",
      "6877 번째 loss, accuracy:  0.46672362111967064 0.8333333333333334\n",
      "6878 번째 loss, accuracy:  0.46670649623746435 0.8333333333333334\n",
      "6879 번째 loss, accuracy:  0.4666893651722381 0.8333333333333334\n",
      "6880 번째 loss, accuracy:  0.466672227919004 0.8333333333333334\n",
      "6881 번째 loss, accuracy:  0.4666550844727754 0.8333333333333334\n",
      "6882 번째 loss, accuracy:  0.4666379348285656 0.8333333333333334\n",
      "6883 번째 loss, accuracy:  0.4666207789813898 0.8333333333333334\n",
      "6884 번째 loss, accuracy:  0.46660361692626406 0.8333333333333334\n",
      "6885 번째 loss, accuracy:  0.46658644865820464 0.8333333333333334\n",
      "6886 번째 loss, accuracy:  0.4665692741722293 0.8333333333333334\n",
      "6887 번째 loss, accuracy:  0.46655209346335613 0.8333333333333334\n",
      "6888 번째 loss, accuracy:  0.46653490652660456 0.8333333333333334\n",
      "6889 번째 loss, accuracy:  0.466517713356995 0.8333333333333334\n",
      "6890 번째 loss, accuracy:  0.46650051394954856 0.8333333333333334\n",
      "6891 번째 loss, accuracy:  0.4664833082992874 0.8333333333333334\n",
      "6892 번째 loss, accuracy:  0.46646609640123404 0.8333333333333334\n",
      "6893 번째 loss, accuracy:  0.4664488782504129 0.8333333333333334\n",
      "6894 번째 loss, accuracy:  0.46643165384184826 0.8333333333333334\n",
      "6895 번째 loss, accuracy:  0.4664144231705662 0.8333333333333334\n",
      "6896 번째 loss, accuracy:  0.4663971862315931 0.8333333333333334\n",
      "6897 번째 loss, accuracy:  0.4663799430199564 0.8333333333333334\n",
      "6898 번째 loss, accuracy:  0.466362693530685 0.8333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6899 번째 loss, accuracy:  0.46634543775880805 0.8333333333333334\n",
      "6900 번째 loss, accuracy:  0.46632817569935564 0.8333333333333334\n",
      "6901 번째 loss, accuracy:  0.4663109073473593 0.8333333333333334\n",
      "6902 번째 loss, accuracy:  0.4662936326978509 0.8333333333333334\n",
      "6903 번째 loss, accuracy:  0.46627635174586357 0.8333333333333334\n",
      "6904 번째 loss, accuracy:  0.46625906448643134 0.8333333333333334\n",
      "6905 번째 loss, accuracy:  0.46624177091458907 0.8333333333333334\n",
      "6906 번째 loss, accuracy:  0.46622447102537284 0.8333333333333334\n",
      "6907 번째 loss, accuracy:  0.4662071648138189 0.8333333333333334\n",
      "6908 번째 loss, accuracy:  0.46618985227496523 0.8333333333333334\n",
      "6909 번째 loss, accuracy:  0.46617253340385056 0.8333333333333334\n",
      "6910 번째 loss, accuracy:  0.4661552081955147 0.8333333333333334\n",
      "6911 번째 loss, accuracy:  0.4661378766449977 0.8333333333333334\n",
      "6912 번째 loss, accuracy:  0.46612053874734116 0.8333333333333334\n",
      "6913 번째 loss, accuracy:  0.46610319449758747 0.8333333333333334\n",
      "6914 번째 loss, accuracy:  0.46608584389077995 0.8333333333333334\n",
      "6915 번째 loss, accuracy:  0.46606848692196295 0.8333333333333334\n",
      "6916 번째 loss, accuracy:  0.4660511235861815 0.8333333333333334\n",
      "6917 번째 loss, accuracy:  0.46603375387848206 0.8333333333333334\n",
      "6918 번째 loss, accuracy:  0.46601637779391153 0.8333333333333334\n",
      "6919 번째 loss, accuracy:  0.46599899532751793 0.8333333333333334\n",
      "6920 번째 loss, accuracy:  0.46598160647435044 0.8333333333333334\n",
      "6921 번째 loss, accuracy:  0.4659642112294589 0.8333333333333334\n",
      "6922 번째 loss, accuracy:  0.4659468095878942 0.8333333333333334\n",
      "6923 번째 loss, accuracy:  0.46592940154470824 0.8333333333333334\n",
      "6924 번째 loss, accuracy:  0.4659119870949537 0.8333333333333334\n",
      "6925 번째 loss, accuracy:  0.46589456623368464 0.8333333333333334\n",
      "6926 번째 loss, accuracy:  0.46587713895595556 0.8333333333333334\n",
      "6927 번째 loss, accuracy:  0.4658597052568221 0.8333333333333334\n",
      "6928 번째 loss, accuracy:  0.46584226513134086 0.8333333333333334\n",
      "6929 번째 loss, accuracy:  0.46582481857457 0.8333333333333334\n",
      "6930 번째 loss, accuracy:  0.4658073655815673 0.8333333333333334\n",
      "6931 번째 loss, accuracy:  0.4657899061473931 0.8333333333333334\n",
      "6932 번째 loss, accuracy:  0.4657724402671072 0.8333333333333334\n",
      "6933 번째 loss, accuracy:  0.4657549679357714 0.8333333333333334\n",
      "6934 번째 loss, accuracy:  0.4657374891484484 0.8333333333333334\n",
      "6935 번째 loss, accuracy:  0.465720003900201 0.8333333333333334\n",
      "6936 번째 loss, accuracy:  0.46570251218609393 0.8333333333333334\n",
      "6937 번째 loss, accuracy:  0.46568501400119255 0.8333333333333334\n",
      "6938 번째 loss, accuracy:  0.46566750934056317 0.8333333333333334\n",
      "6939 번째 loss, accuracy:  0.4656499981992729 0.8333333333333334\n",
      "6940 번째 loss, accuracy:  0.46563248057239026 0.8333333333333334\n",
      "6941 번째 loss, accuracy:  0.46561495645498474 0.8333333333333334\n",
      "6942 번째 loss, accuracy:  0.4655974258421263 0.8333333333333334\n",
      "6943 번째 loss, accuracy:  0.46557988872888617 0.8333333333333334\n",
      "6944 번째 loss, accuracy:  0.4655623451103365 0.8333333333333334\n",
      "6945 번째 loss, accuracy:  0.4655447949815508 0.8333333333333334\n",
      "6946 번째 loss, accuracy:  0.46552723833760284 0.8333333333333334\n",
      "6947 번째 loss, accuracy:  0.46550967517356834 0.8333333333333334\n",
      "6948 번째 loss, accuracy:  0.4654921054845231 0.8333333333333334\n",
      "6949 번째 loss, accuracy:  0.46547452926554445 0.8333333333333334\n",
      "6950 번째 loss, accuracy:  0.46545694651171016 0.8333333333333334\n",
      "6951 번째 loss, accuracy:  0.4654393572180994 0.8333333333333334\n",
      "6952 번째 loss, accuracy:  0.465421761379793 0.8333333333333334\n",
      "6953 번째 loss, accuracy:  0.46540415899187143 0.8333333333333334\n",
      "6954 번째 loss, accuracy:  0.46538655004941704 0.8333333333333334\n",
      "6955 번째 loss, accuracy:  0.4653689345475131 0.8333333333333334\n",
      "6956 번째 loss, accuracy:  0.4653513124812438 0.8333333333333334\n",
      "6957 번째 loss, accuracy:  0.46533368384569407 0.8333333333333334\n",
      "6958 번째 loss, accuracy:  0.4653160486359501 0.8333333333333334\n",
      "6959 번째 loss, accuracy:  0.46529840684709906 0.8333333333333334\n",
      "6960 번째 loss, accuracy:  0.46528075847422906 0.8333333333333334\n",
      "6961 번째 loss, accuracy:  0.4652631035124293 0.8333333333333334\n",
      "6962 번째 loss, accuracy:  0.46524544195679013 0.8333333333333334\n",
      "6963 번째 loss, accuracy:  0.4652277738024027 0.8333333333333334\n",
      "6964 번째 loss, accuracy:  0.46521009904435895 0.8333333333333334\n",
      "6965 번째 loss, accuracy:  0.4651924176777523 0.8333333333333334\n",
      "6966 번째 loss, accuracy:  0.4651747296976771 0.8333333333333334\n",
      "6967 번째 loss, accuracy:  0.4651570350992284 0.8333333333333334\n",
      "6968 번째 loss, accuracy:  0.4651393338775026 0.8333333333333334\n",
      "6969 번째 loss, accuracy:  0.4651216260275971 0.8333333333333334\n",
      "6970 번째 loss, accuracy:  0.46510391154460995 0.8333333333333334\n",
      "6971 번째 loss, accuracy:  0.46508619042364086 0.8333333333333334\n",
      "6972 번째 loss, accuracy:  0.4650684626597899 0.8333333333333334\n",
      "6973 번째 loss, accuracy:  0.46505072824815863 0.8333333333333334\n",
      "6974 번째 loss, accuracy:  0.46503298718384944 0.8333333333333334\n",
      "6975 번째 loss, accuracy:  0.46501523946196577 0.8333333333333334\n",
      "6976 번째 loss, accuracy:  0.464997485077612 0.8333333333333334\n",
      "6977 번째 loss, accuracy:  0.464979724025894 0.8333333333333334\n",
      "6978 번째 loss, accuracy:  0.46496195630191794 0.8333333333333334\n",
      "6979 번째 loss, accuracy:  0.4649441819007916 0.8333333333333334\n",
      "6980 번째 loss, accuracy:  0.46492640081762376 0.8333333333333334\n",
      "6981 번째 loss, accuracy:  0.4649086130475238 0.8333333333333334\n",
      "6982 번째 loss, accuracy:  0.4648908185856025 0.8333333333333334\n",
      "6983 번째 loss, accuracy:  0.4648730174269719 0.8333333333333334\n",
      "6984 번째 loss, accuracy:  0.46485520956674453 0.8333333333333334\n",
      "6985 번째 loss, accuracy:  0.4648373950000344 0.8333333333333334\n",
      "6986 번째 loss, accuracy:  0.4648195737219564 0.8333333333333334\n",
      "6987 번째 loss, accuracy:  0.4648017457276264 0.8333333333333334\n",
      "6988 번째 loss, accuracy:  0.46478391101216127 0.8333333333333334\n",
      "6989 번째 loss, accuracy:  0.4647660695706792 0.8333333333333334\n",
      "6990 번째 loss, accuracy:  0.4647482213982993 0.8333333333333334\n",
      "6991 번째 loss, accuracy:  0.46473036649014166 0.8333333333333334\n",
      "6992 번째 loss, accuracy:  0.4647125048413275 0.8333333333333334\n",
      "6993 번째 loss, accuracy:  0.4646946364469792 0.8333333333333334\n",
      "6994 번째 loss, accuracy:  0.46467676130222 0.8333333333333334\n",
      "6995 번째 loss, accuracy:  0.4646588794021744 0.8333333333333334\n",
      "6996 번째 loss, accuracy:  0.46464099074196774 0.8333333333333334\n",
      "6997 번째 loss, accuracy:  0.46462309531672635 0.8333333333333334\n",
      "6998 번째 loss, accuracy:  0.4646051931215781 0.8333333333333334\n",
      "6999 번째 loss, accuracy:  0.4645872841516515 0.8333333333333334\n",
      "7000 번째 loss, accuracy:  0.46456936840207635 0.8333333333333334\n",
      "7001 번째 loss, accuracy:  0.46455144586798347 0.8333333333333334\n",
      "7002 번째 loss, accuracy:  0.4645335165445047 0.8333333333333334\n",
      "7003 번째 loss, accuracy:  0.4645155804267728 0.8333333333333334\n",
      "7004 번째 loss, accuracy:  0.46449763750992185 0.8333333333333334\n",
      "7005 번째 loss, accuracy:  0.4644796877890871 0.8333333333333334\n",
      "7006 번째 loss, accuracy:  0.4644617312594047 0.8333333333333334\n",
      "7007 번째 loss, accuracy:  0.46444376791601183 0.8333333333333334\n",
      "7008 번째 loss, accuracy:  0.46442579775404685 0.8333333333333334\n",
      "7009 번째 loss, accuracy:  0.46440782076864895 0.8333333333333334\n",
      "7010 번째 loss, accuracy:  0.4643898369549589 0.8333333333333334\n",
      "7011 번째 loss, accuracy:  0.46437184630811806 0.8333333333333334\n",
      "7012 번째 loss, accuracy:  0.4643538488232694 0.8333333333333334\n",
      "7013 번째 loss, accuracy:  0.4643358444955563 0.8333333333333334\n",
      "7014 번째 loss, accuracy:  0.46431783332012366 0.8333333333333334\n",
      "7015 번째 loss, accuracy:  0.46429981529211767 0.8333333333333334\n",
      "7016 번째 loss, accuracy:  0.4642817904066854 0.8333333333333334\n",
      "7017 번째 loss, accuracy:  0.46426375865897473 0.8333333333333334\n",
      "7018 번째 loss, accuracy:  0.4642457200441348 0.8333333333333334\n",
      "7019 번째 loss, accuracy:  0.4642276745573163 0.8333333333333334\n",
      "7020 번째 loss, accuracy:  0.4642096221936703 0.8333333333333334\n",
      "7021 번째 loss, accuracy:  0.4641915629483497 0.8333333333333334\n",
      "7022 번째 loss, accuracy:  0.4641734968165078 0.8333333333333334\n",
      "7023 번째 loss, accuracy:  0.46415542379329977 0.8333333333333334\n",
      "7024 번째 loss, accuracy:  0.46413734387388084 0.8333333333333334\n",
      "7025 번째 loss, accuracy:  0.4641192570534088 0.8333333333333334\n",
      "7026 번째 loss, accuracy:  0.4641011633270408 0.8333333333333334\n",
      "7027 번째 loss, accuracy:  0.4640830626899363 0.8333333333333334\n",
      "7028 번째 loss, accuracy:  0.46406495513725593 0.8333333333333334\n",
      "7029 번째 loss, accuracy:  0.46404684066416085 0.8333333333333334\n",
      "7030 번째 loss, accuracy:  0.46402871926581324 0.8333333333333334\n",
      "7031 번째 loss, accuracy:  0.4640105909373775 0.8333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7032 번째 loss, accuracy:  0.4639924556740178 0.8333333333333334\n",
      "7033 번째 loss, accuracy:  0.4639743134709002 0.8333333333333334\n",
      "7034 번째 loss, accuracy:  0.4639561643231918 0.8333333333333334\n",
      "7035 번째 loss, accuracy:  0.4639380082260606 0.8333333333333334\n",
      "7036 번째 loss, accuracy:  0.4639198451746759 0.8333333333333334\n",
      "7037 번째 loss, accuracy:  0.46390167516420794 0.8333333333333334\n",
      "7038 번째 loss, accuracy:  0.4638834981898283 0.8333333333333334\n",
      "7039 번째 loss, accuracy:  0.4638653142467098 0.8333333333333334\n",
      "7040 번째 loss, accuracy:  0.46384712333002615 0.8333333333333334\n",
      "7041 번째 loss, accuracy:  0.463828925434952 0.8333333333333334\n",
      "7042 번째 loss, accuracy:  0.46381072055666356 0.8333333333333334\n",
      "7043 번째 loss, accuracy:  0.4637925086903381 0.8333333333333334\n",
      "7044 번째 loss, accuracy:  0.463774289831154 0.8333333333333334\n",
      "7045 번째 loss, accuracy:  0.4637560639742905 0.8333333333333334\n",
      "7046 번째 loss, accuracy:  0.4637378311149282 0.8333333333333334\n",
      "7047 번째 loss, accuracy:  0.463719591248249 0.8333333333333334\n",
      "7048 번째 loss, accuracy:  0.46370134436943594 0.8333333333333334\n",
      "7049 번째 loss, accuracy:  0.46368309047367257 0.8333333333333334\n",
      "7050 번째 loss, accuracy:  0.4636648295561443 0.8333333333333334\n",
      "7051 번째 loss, accuracy:  0.46364656161203777 0.8333333333333334\n",
      "7052 번째 loss, accuracy:  0.46362828663654043 0.8333333333333334\n",
      "7053 번째 loss, accuracy:  0.46361000462484075 0.8333333333333334\n",
      "7054 번째 loss, accuracy:  0.4635917155721282 0.8333333333333334\n",
      "7055 번째 loss, accuracy:  0.46357341947359443 0.8333333333333334\n",
      "7056 번째 loss, accuracy:  0.46355511632443125 0.8333333333333334\n",
      "7057 번째 loss, accuracy:  0.46353680611983195 0.8333333333333334\n",
      "7058 번째 loss, accuracy:  0.4635184888549908 0.8333333333333334\n",
      "7059 번째 loss, accuracy:  0.4635001645251034 0.8333333333333334\n",
      "7060 번째 loss, accuracy:  0.4634818331253669 0.8333333333333334\n",
      "7061 번째 loss, accuracy:  0.46346349465097886 0.8333333333333334\n",
      "7062 번째 loss, accuracy:  0.4634451490971385 0.8333333333333334\n",
      "7063 번째 loss, accuracy:  0.4634267964590463 0.8333333333333334\n",
      "7064 번째 loss, accuracy:  0.46340843673190346 0.8333333333333334\n",
      "7065 번째 loss, accuracy:  0.463390069910913 0.8333333333333334\n",
      "7066 번째 loss, accuracy:  0.4633716959912784 0.8333333333333334\n",
      "7067 번째 loss, accuracy:  0.4633533149682047 0.8333333333333334\n",
      "7068 번째 loss, accuracy:  0.46333492683689786 0.8333333333333334\n",
      "7069 번째 loss, accuracy:  0.46331653159256575 0.8333333333333334\n",
      "7070 번째 loss, accuracy:  0.4632981292304166 0.8333333333333334\n",
      "7071 번째 loss, accuracy:  0.4632797197456599 0.8333333333333334\n",
      "7072 번째 loss, accuracy:  0.4632613031335069 0.8333333333333334\n",
      "7073 번째 loss, accuracy:  0.4632428793891695 0.8333333333333334\n",
      "7074 번째 loss, accuracy:  0.4632244485078612 0.8333333333333334\n",
      "7075 번째 loss, accuracy:  0.4632060104847961 0.8333333333333334\n",
      "7076 번째 loss, accuracy:  0.46318756531519045 0.8333333333333334\n",
      "7077 번째 loss, accuracy:  0.4631691129942607 0.8333333333333334\n",
      "7078 번째 loss, accuracy:  0.46315065351722473 0.8333333333333334\n",
      "7079 번째 loss, accuracy:  0.4631321868793021 0.8333333333333334\n",
      "7080 번째 loss, accuracy:  0.4631137130757132 0.8333333333333334\n",
      "7081 번째 loss, accuracy:  0.4630952321016798 0.8333333333333334\n",
      "7082 번째 loss, accuracy:  0.46307674395242443 0.8333333333333334\n",
      "7083 번째 loss, accuracy:  0.46305824862317135 0.8333333333333334\n",
      "7084 번째 loss, accuracy:  0.46303974610914583 0.8333333333333334\n",
      "7085 번째 loss, accuracy:  0.46302123640557447 0.8333333333333334\n",
      "7086 번째 loss, accuracy:  0.4630027195076848 0.8333333333333334\n",
      "7087 번째 loss, accuracy:  0.46298419541070573 0.8333333333333334\n",
      "7088 번째 loss, accuracy:  0.46296566410986745 0.8333333333333334\n",
      "7089 번째 loss, accuracy:  0.46294712560040124 0.8333333333333334\n",
      "7090 번째 loss, accuracy:  0.4629285798775396 0.8333333333333334\n",
      "7091 번째 loss, accuracy:  0.4629100269365167 0.8333333333333334\n",
      "7092 번째 loss, accuracy:  0.46289146677256693 0.8333333333333334\n",
      "7093 번째 loss, accuracy:  0.4628728993809267 0.8333333333333334\n",
      "7094 번째 loss, accuracy:  0.4628543247568337 0.8333333333333334\n",
      "7095 번째 loss, accuracy:  0.4628357428955264 0.8333333333333334\n",
      "7096 번째 loss, accuracy:  0.4628171537922446 0.8333333333333334\n",
      "7097 번째 loss, accuracy:  0.46279855744222964 0.8333333333333334\n",
      "7098 번째 loss, accuracy:  0.4627799538407238 0.8333333333333334\n",
      "7099 번째 loss, accuracy:  0.46276134298297045 0.8333333333333334\n",
      "7100 번째 loss, accuracy:  0.46274272486421497 0.8333333333333334\n",
      "7101 번째 loss, accuracy:  0.4627240994797029 0.8333333333333334\n",
      "7102 번째 loss, accuracy:  0.46270546682468167 0.8333333333333334\n",
      "7103 번째 loss, accuracy:  0.46268682689439955 0.8333333333333334\n",
      "7104 번째 loss, accuracy:  0.4626681796841068 0.8333333333333334\n",
      "7105 번째 loss, accuracy:  0.4626495251890544 0.8333333333333334\n",
      "7106 번째 loss, accuracy:  0.4626308634044944 0.8333333333333334\n",
      "7107 번째 loss, accuracy:  0.46261219432568024 0.8333333333333334\n",
      "7108 번째 loss, accuracy:  0.46259351794786696 0.8333333333333334\n",
      "7109 번째 loss, accuracy:  0.46257483426631035 0.8333333333333334\n",
      "7110 번째 loss, accuracy:  0.4625561432762681 0.8333333333333334\n",
      "7111 번째 loss, accuracy:  0.4625374449729982 0.8333333333333334\n",
      "7112 번째 loss, accuracy:  0.46251873935176074 0.8333333333333334\n",
      "7113 번째 loss, accuracy:  0.46250002640781673 0.8333333333333334\n",
      "7114 번째 loss, accuracy:  0.4624813061364283 0.8333333333333334\n",
      "7115 번째 loss, accuracy:  0.46246257853285905 0.8333333333333334\n",
      "7116 번째 loss, accuracy:  0.46244384359237395 0.8333333333333334\n",
      "7117 번째 loss, accuracy:  0.4624251013102391 0.8333333333333334\n",
      "7118 번째 loss, accuracy:  0.46240635168172173 0.8333333333333334\n",
      "7119 번째 loss, accuracy:  0.46238759470209073 0.8333333333333334\n",
      "7120 번째 loss, accuracy:  0.46236883036661575 0.8333333333333334\n",
      "7121 번째 loss, accuracy:  0.462350058670568 0.8333333333333334\n",
      "7122 번째 loss, accuracy:  0.4623312796092201 0.8333333333333334\n",
      "7123 번째 loss, accuracy:  0.46231249317784545 0.8333333333333334\n",
      "7124 번째 loss, accuracy:  0.46229369937171944 0.8333333333333334\n",
      "7125 번째 loss, accuracy:  0.4622748981861182 0.8333333333333334\n",
      "7126 번째 loss, accuracy:  0.462256089616319 0.8333333333333334\n",
      "7127 번째 loss, accuracy:  0.46223727365760087 0.8333333333333334\n",
      "7128 번째 loss, accuracy:  0.4622184503052444 0.8333333333333334\n",
      "7129 번째 loss, accuracy:  0.46219961955453026 0.8333333333333334\n",
      "7130 번째 loss, accuracy:  0.462180781400742 0.8333333333333334\n",
      "7131 번째 loss, accuracy:  0.4621619358391629 0.8333333333333334\n",
      "7132 번째 loss, accuracy:  0.46214308286507844 0.8333333333333334\n",
      "7133 번째 loss, accuracy:  0.4621242224737753 0.8333333333333334\n",
      "7134 번째 loss, accuracy:  0.46210535466054137 0.8333333333333334\n",
      "7135 번째 loss, accuracy:  0.46208647942066566 0.8333333333333334\n",
      "7136 번째 loss, accuracy:  0.46206759674943887 0.8333333333333334\n",
      "7137 번째 loss, accuracy:  0.4620487066421531 0.8333333333333334\n",
      "7138 번째 loss, accuracy:  0.46202980909410074 0.8333333333333334\n",
      "7139 번째 loss, accuracy:  0.46201090410057677 0.8333333333333334\n",
      "7140 번째 loss, accuracy:  0.46199199165687654 0.8333333333333334\n",
      "7141 번째 loss, accuracy:  0.4619730717582972 0.8333333333333334\n",
      "7142 번째 loss, accuracy:  0.46195414440013705 0.8333333333333334\n",
      "7143 번째 loss, accuracy:  0.4619352095776962 0.8333333333333334\n",
      "7144 번째 loss, accuracy:  0.461916267286275 0.8333333333333334\n",
      "7145 번째 loss, accuracy:  0.4618973175211758 0.8333333333333334\n",
      "7146 번째 loss, accuracy:  0.46187836027770235 0.8333333333333334\n",
      "7147 번째 loss, accuracy:  0.4618593955511597 0.8333333333333334\n",
      "7148 번째 loss, accuracy:  0.4618404233368537 0.8333333333333334\n",
      "7149 번째 loss, accuracy:  0.46182144363009237 0.8333333333333334\n",
      "7150 번째 loss, accuracy:  0.4618024564261842 0.8333333333333334\n",
      "7151 번째 loss, accuracy:  0.46178346172043955 0.8333333333333334\n",
      "7152 번째 loss, accuracy:  0.46176445950816997 0.8333333333333334\n",
      "7153 번째 loss, accuracy:  0.46174544978468857 0.8333333333333334\n",
      "7154 번째 loss, accuracy:  0.4617264325453094 0.8333333333333334\n",
      "7155 번째 loss, accuracy:  0.4617074077853477 0.8333333333333334\n",
      "7156 번째 loss, accuracy:  0.46168837550012065 0.8333333333333334\n",
      "7157 번째 loss, accuracy:  0.46166933568494684 0.8333333333333334\n",
      "7158 번째 loss, accuracy:  0.4616502883351455 0.8333333333333334\n",
      "7159 번째 loss, accuracy:  0.46163123344603724 0.8333333333333334\n",
      "7160 번째 loss, accuracy:  0.46161217101294494 0.8333333333333334\n",
      "7161 번째 loss, accuracy:  0.46159310103119183 0.8333333333333334\n",
      "7162 번째 loss, accuracy:  0.46157402349610294 0.8333333333333334\n",
      "7163 번째 loss, accuracy:  0.4615549384030048 0.8333333333333334\n",
      "7164 번째 loss, accuracy:  0.4615358457472247 0.8333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7165 번째 loss, accuracy:  0.4615167455240918 0.8333333333333334\n",
      "7166 번째 loss, accuracy:  0.46149763772893676 0.8333333333333334\n",
      "7167 번째 loss, accuracy:  0.46147852235709125 0.8333333333333334\n",
      "7168 번째 loss, accuracy:  0.4614593994038882 0.8333333333333334\n",
      "7169 번째 loss, accuracy:  0.46144026886466205 0.8333333333333334\n",
      "7170 번째 loss, accuracy:  0.4614211307347487 0.8333333333333334\n",
      "7171 번째 loss, accuracy:  0.46140198500948526 0.8333333333333334\n",
      "7172 번째 loss, accuracy:  0.4613828316842105 0.8333333333333334\n",
      "7173 번째 loss, accuracy:  0.46136367075426415 0.8333333333333334\n",
      "7174 번째 loss, accuracy:  0.46134450221498785 0.8333333333333334\n",
      "7175 번째 loss, accuracy:  0.46132532606172405 0.8333333333333334\n",
      "7176 번째 loss, accuracy:  0.46130614228981687 0.8333333333333334\n",
      "7177 번째 loss, accuracy:  0.46128695089461175 0.8333333333333334\n",
      "7178 번째 loss, accuracy:  0.4612677518714556 0.8333333333333334\n",
      "7179 번째 loss, accuracy:  0.4612485452156964 0.8333333333333334\n",
      "7180 번째 loss, accuracy:  0.46122933092268437 0.8333333333333334\n",
      "7181 번째 loss, accuracy:  0.4612101089877696 0.8333333333333334\n",
      "7182 번째 loss, accuracy:  0.46119087940630477 0.8333333333333334\n",
      "7183 번째 loss, accuracy:  0.4611716421736439 0.8333333333333334\n",
      "7184 번째 loss, accuracy:  0.46115239728514223 0.8333333333333334\n",
      "7185 번째 loss, accuracy:  0.46113314473615596 0.8333333333333334\n",
      "7186 번째 loss, accuracy:  0.46111388452204327 0.8333333333333334\n",
      "7187 번째 loss, accuracy:  0.4610946166381634 0.8333333333333334\n",
      "7188 번째 loss, accuracy:  0.4610753410798771 0.8333333333333334\n",
      "7189 번째 loss, accuracy:  0.4610560578425465 0.8333333333333334\n",
      "7190 번째 loss, accuracy:  0.4610367669215351 0.8333333333333334\n",
      "7191 번째 loss, accuracy:  0.4610174683122081 0.8333333333333334\n",
      "7192 번째 loss, accuracy:  0.46099816200993177 0.8333333333333334\n",
      "7193 번째 loss, accuracy:  0.4609788480100738 0.8333333333333334\n",
      "7194 번째 loss, accuracy:  0.4609595263080036 0.8333333333333334\n",
      "7195 번째 loss, accuracy:  0.46094019689909144 0.8333333333333334\n",
      "7196 번째 loss, accuracy:  0.4609208597787097 0.8333333333333334\n",
      "7197 번째 loss, accuracy:  0.4609015149422317 0.8333333333333334\n",
      "7198 번째 loss, accuracy:  0.46088216238503216 0.8333333333333334\n",
      "7199 번째 loss, accuracy:  0.4608628021024878 0.8333333333333334\n",
      "7200 번째 loss, accuracy:  0.46084343408997613 0.8333333333333334\n",
      "7201 번째 loss, accuracy:  0.460824058342876 0.8333333333333334\n",
      "7202 번째 loss, accuracy:  0.4608046748565682 0.8333333333333334\n",
      "7203 번째 loss, accuracy:  0.46078528362643495 0.8333333333333334\n",
      "7204 번째 loss, accuracy:  0.4607658846478594 0.8333333333333334\n",
      "7205 번째 loss, accuracy:  0.46074647791622636 0.8333333333333334\n",
      "7206 번째 loss, accuracy:  0.4607270634269224 0.8333333333333334\n",
      "7207 번째 loss, accuracy:  0.46070764117533497 0.8333333333333334\n",
      "7208 번째 loss, accuracy:  0.4606882111568536 0.8333333333333334\n",
      "7209 번째 loss, accuracy:  0.4606687733668688 0.8333333333333334\n",
      "7210 번째 loss, accuracy:  0.46064932780077267 0.8333333333333334\n",
      "7211 번째 loss, accuracy:  0.4606298744539589 0.8333333333333334\n",
      "7212 번째 loss, accuracy:  0.4606104133218222 0.8333333333333334\n",
      "7213 번째 loss, accuracy:  0.46059094439975906 0.8333333333333334\n",
      "7214 번째 loss, accuracy:  0.46057146768316753 0.8333333333333334\n",
      "7215 번째 loss, accuracy:  0.46055198316744694 0.8333333333333334\n",
      "7216 번째 loss, accuracy:  0.46053249084799786 0.8333333333333334\n",
      "7217 번째 loss, accuracy:  0.4605129907202226 0.8333333333333334\n",
      "7218 번째 loss, accuracy:  0.46049348277952507 0.8333333333333334\n",
      "7219 번째 loss, accuracy:  0.46047396702131044 0.8333333333333334\n",
      "7220 번째 loss, accuracy:  0.46045444344098496 0.8333333333333334\n",
      "7221 번째 loss, accuracy:  0.46043491203395726 0.8333333333333334\n",
      "7222 번째 loss, accuracy:  0.4604153727956369 0.8333333333333334\n",
      "7223 번째 loss, accuracy:  0.4603958257214348 0.8333333333333334\n",
      "7224 번째 loss, accuracy:  0.4603762708067633 0.8333333333333334\n",
      "7225 번째 loss, accuracy:  0.4603567080470369 0.8333333333333334\n",
      "7226 번째 loss, accuracy:  0.46033713743767074 0.8333333333333334\n",
      "7227 번째 loss, accuracy:  0.46031755897408183 0.8333333333333334\n",
      "7228 번째 loss, accuracy:  0.46029797265168876 0.8333333333333334\n",
      "7229 번째 loss, accuracy:  0.4602783784659116 0.8333333333333334\n",
      "7230 번째 loss, accuracy:  0.4602587764121715 0.8333333333333334\n",
      "7231 번째 loss, accuracy:  0.46023916648589136 0.8333333333333334\n",
      "7232 번째 loss, accuracy:  0.460219548682496 0.8333333333333334\n",
      "7233 번째 loss, accuracy:  0.4601999229974107 0.8333333333333334\n",
      "7234 번째 loss, accuracy:  0.46018028942606326 0.8333333333333334\n",
      "7235 번째 loss, accuracy:  0.4601606479638826 0.8333333333333334\n",
      "7236 번째 loss, accuracy:  0.4601409986062992 0.8333333333333334\n",
      "7237 번째 loss, accuracy:  0.460121341348745 0.8333333333333334\n",
      "7238 번째 loss, accuracy:  0.46010167618665326 0.8333333333333334\n",
      "7239 번째 loss, accuracy:  0.4600820031154587 0.8333333333333334\n",
      "7240 번째 loss, accuracy:  0.46006232213059833 0.8333333333333334\n",
      "7241 번째 loss, accuracy:  0.4600426332275095 0.8333333333333334\n",
      "7242 번째 loss, accuracy:  0.460022936401632 0.8333333333333334\n",
      "7243 번째 loss, accuracy:  0.4600032316484066 0.8333333333333334\n",
      "7244 번째 loss, accuracy:  0.4599835189632759 0.8333333333333334\n",
      "7245 번째 loss, accuracy:  0.4599637983416836 0.8333333333333334\n",
      "7246 번째 loss, accuracy:  0.4599440697790758 0.8333333333333334\n",
      "7247 번째 loss, accuracy:  0.4599243332708994 0.8333333333333334\n",
      "7248 번째 loss, accuracy:  0.4599045888126025 0.8333333333333334\n",
      "7249 번째 loss, accuracy:  0.4598848363996357 0.8333333333333334\n",
      "7250 번째 loss, accuracy:  0.4598650760274506 0.8333333333333334\n",
      "7251 번째 loss, accuracy:  0.45984530769150017 0.8333333333333334\n",
      "7252 번째 loss, accuracy:  0.4598255313872393 0.8333333333333334\n",
      "7253 번째 loss, accuracy:  0.45980574711012434 0.8333333333333334\n",
      "7254 번째 loss, accuracy:  0.4597859548556127 0.8333333333333334\n",
      "7255 번째 loss, accuracy:  0.45976615461916404 0.8333333333333334\n",
      "7256 번째 loss, accuracy:  0.4597463463962391 0.8333333333333334\n",
      "7257 번째 loss, accuracy:  0.4597265301823004 0.8333333333333334\n",
      "7258 번째 loss, accuracy:  0.4597067059728114 0.8333333333333334\n",
      "7259 번째 loss, accuracy:  0.4596868737632383 0.8333333333333334\n",
      "7260 번째 loss, accuracy:  0.45966703354904775 0.8416666666666667\n",
      "7261 번째 loss, accuracy:  0.4596471853257083 0.8416666666666667\n",
      "7262 번째 loss, accuracy:  0.4596273290886905 0.8416666666666667\n",
      "7263 번째 loss, accuracy:  0.4596074648334657 0.8416666666666667\n",
      "7264 번째 loss, accuracy:  0.4595875925555074 0.8416666666666667\n",
      "7265 번째 loss, accuracy:  0.4595677122502906 0.8416666666666667\n",
      "7266 번째 loss, accuracy:  0.45954782391329135 0.8416666666666667\n",
      "7267 번째 loss, accuracy:  0.459527927539988 0.8416666666666667\n",
      "7268 번째 loss, accuracy:  0.4595080231258599 0.8416666666666667\n",
      "7269 번째 loss, accuracy:  0.4594881106663884 0.8416666666666667\n",
      "7270 번째 loss, accuracy:  0.4594681901570562 0.8416666666666667\n",
      "7271 번째 loss, accuracy:  0.4594482615933471 0.8416666666666667\n",
      "7272 번째 loss, accuracy:  0.4594283249707475 0.8416666666666667\n",
      "7273 번째 loss, accuracy:  0.45940838028474446 0.8416666666666667\n",
      "7274 번째 loss, accuracy:  0.4593884275308274 0.8416666666666667\n",
      "7275 번째 loss, accuracy:  0.45936846670448667 0.8416666666666667\n",
      "7276 번째 loss, accuracy:  0.45934849780121473 0.8416666666666667\n",
      "7277 번째 loss, accuracy:  0.45932852081650494 0.8416666666666667\n",
      "7278 번째 loss, accuracy:  0.459308535745853 0.8416666666666667\n",
      "7279 번째 loss, accuracy:  0.45928854258475577 0.8416666666666667\n",
      "7280 번째 loss, accuracy:  0.4592685413287121 0.8416666666666667\n",
      "7281 번째 loss, accuracy:  0.4592485319732219 0.8416666666666667\n",
      "7282 번째 loss, accuracy:  0.45922851451378693 0.8416666666666667\n",
      "7283 번째 loss, accuracy:  0.45920848894591076 0.8416666666666667\n",
      "7284 번째 loss, accuracy:  0.45918845526509816 0.8416666666666667\n",
      "7285 번째 loss, accuracy:  0.45916841346685605 0.8416666666666667\n",
      "7286 번째 loss, accuracy:  0.4591483635466923 0.8416666666666667\n",
      "7287 번째 loss, accuracy:  0.4591283055001171 0.8416666666666667\n",
      "7288 번째 loss, accuracy:  0.45910823932264166 0.8416666666666667\n",
      "7289 번째 loss, accuracy:  0.4590881650097789 0.8416666666666667\n",
      "7290 번째 loss, accuracy:  0.45906808255704346 0.8416666666666667\n",
      "7291 번째 loss, accuracy:  0.4590479919599521 0.8416666666666667\n",
      "7292 번째 loss, accuracy:  0.4590278932140224 0.8416666666666667\n",
      "7293 번째 loss, accuracy:  0.45900778631477407 0.8416666666666667\n",
      "7294 번째 loss, accuracy:  0.4589876712577281 0.8416666666666667\n",
      "7295 번째 loss, accuracy:  0.45896754803840756 0.8416666666666667\n",
      "7296 번째 loss, accuracy:  0.4589474166523368 0.8416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7297 번째 loss, accuracy:  0.45892727709504155 0.8416666666666667\n",
      "7298 번째 loss, accuracy:  0.45890712936204986 0.8416666666666667\n",
      "7299 번째 loss, accuracy:  0.45888697344889123 0.8416666666666667\n",
      "7300 번째 loss, accuracy:  0.45886680935109647 0.8416666666666667\n",
      "7301 번째 loss, accuracy:  0.45884663706419804 0.8416666666666667\n",
      "7302 번째 loss, accuracy:  0.4588264565837305 0.8416666666666667\n",
      "7303 번째 loss, accuracy:  0.45880626790522966 0.8416666666666667\n",
      "7304 번째 loss, accuracy:  0.4587860710242333 0.8416666666666667\n",
      "7305 번째 loss, accuracy:  0.45876586593628044 0.8416666666666667\n",
      "7306 번째 loss, accuracy:  0.45874565263691214 0.8416666666666667\n",
      "7307 번째 loss, accuracy:  0.45872543112167097 0.8416666666666667\n",
      "7308 번째 loss, accuracy:  0.45870520138610116 0.8416666666666667\n",
      "7309 번째 loss, accuracy:  0.45868496342574866 0.8416666666666667\n",
      "7310 번째 loss, accuracy:  0.4586647172361609 0.8416666666666667\n",
      "7311 번째 loss, accuracy:  0.45864446281288723 0.8416666666666667\n",
      "7312 번째 loss, accuracy:  0.4586242001514783 0.8416666666666667\n",
      "7313 번째 loss, accuracy:  0.4586039292474868 0.8416666666666667\n",
      "7314 번째 loss, accuracy:  0.4585836500964671 0.8416666666666667\n",
      "7315 번째 loss, accuracy:  0.45856336269397496 0.8416666666666667\n",
      "7316 번째 loss, accuracy:  0.4585430670355683 0.8416666666666667\n",
      "7317 번째 loss, accuracy:  0.45852276311680634 0.8416666666666667\n",
      "7318 번째 loss, accuracy:  0.4585024509332498 0.8416666666666667\n",
      "7319 번째 loss, accuracy:  0.4584821304804614 0.8416666666666667\n",
      "7320 번째 loss, accuracy:  0.45846180175400575 0.8416666666666667\n",
      "7321 번째 loss, accuracy:  0.45844146474944847 0.8416666666666667\n",
      "7322 번째 loss, accuracy:  0.45842111946235786 0.8416666666666667\n",
      "7323 번째 loss, accuracy:  0.4584007658883028 0.8416666666666667\n",
      "7324 번째 loss, accuracy:  0.4583804040228548 0.8416666666666667\n",
      "7325 번째 loss, accuracy:  0.4583600338615863 0.8416666666666667\n",
      "7326 번째 loss, accuracy:  0.4583396554000724 0.8416666666666667\n",
      "7327 번째 loss, accuracy:  0.4583192686338891 0.8416666666666667\n",
      "7328 번째 loss, accuracy:  0.4582988735586145 0.8416666666666667\n",
      "7329 번째 loss, accuracy:  0.45827847016982776 0.8416666666666667\n",
      "7330 번째 loss, accuracy:  0.4582580584631107 0.8416666666666667\n",
      "7331 번째 loss, accuracy:  0.45823763843404636 0.8416666666666667\n",
      "7332 번째 loss, accuracy:  0.45821721007821964 0.8416666666666667\n",
      "7333 번째 loss, accuracy:  0.4581967733912167 0.8416666666666667\n",
      "7334 번째 loss, accuracy:  0.4581763283686263 0.8416666666666667\n",
      "7335 번째 loss, accuracy:  0.4581558750060382 0.8416666666666667\n",
      "7336 번째 loss, accuracy:  0.4581354132990442 0.8416666666666667\n",
      "7337 번째 loss, accuracy:  0.45811494324323776 0.8416666666666667\n",
      "7338 번째 loss, accuracy:  0.45809446483421407 0.8416666666666667\n",
      "7339 번째 loss, accuracy:  0.45807397806757 0.8416666666666667\n",
      "7340 번째 loss, accuracy:  0.45805348293890413 0.8416666666666667\n",
      "7341 번째 loss, accuracy:  0.4580329794438168 0.8416666666666667\n",
      "7342 번째 loss, accuracy:  0.4580124675779106 0.8416666666666667\n",
      "7343 번째 loss, accuracy:  0.457991947336789 0.8416666666666667\n",
      "7344 번째 loss, accuracy:  0.4579714187160578 0.8416666666666667\n",
      "7345 번째 loss, accuracy:  0.4579508817113243 0.8416666666666667\n",
      "7346 번째 loss, accuracy:  0.45793033631819763 0.8416666666666667\n",
      "7347 번째 loss, accuracy:  0.45790978253228876 0.8416666666666667\n",
      "7348 번째 loss, accuracy:  0.4578892203492104 0.8416666666666667\n",
      "7349 번째 loss, accuracy:  0.45786864976457686 0.8416666666666667\n",
      "7350 번째 loss, accuracy:  0.4578480707740044 0.8416666666666667\n",
      "7351 번째 loss, accuracy:  0.4578274833731108 0.8416666666666667\n",
      "7352 번째 loss, accuracy:  0.457806887557516 0.8416666666666667\n",
      "7353 번째 loss, accuracy:  0.4577862833228413 0.8416666666666667\n",
      "7354 번째 loss, accuracy:  0.45776567066471024 0.8416666666666667\n",
      "7355 번째 loss, accuracy:  0.45774504957874734 0.8416666666666667\n",
      "7356 번째 loss, accuracy:  0.4577244200605801 0.8416666666666667\n",
      "7357 번째 loss, accuracy:  0.45770378210583657 0.8416666666666667\n",
      "7358 번째 loss, accuracy:  0.4576831357101471 0.8416666666666667\n",
      "7359 번째 loss, accuracy:  0.457662480869144 0.8416666666666667\n",
      "7360 번째 loss, accuracy:  0.4576418175784615 0.8416666666666667\n",
      "7361 번째 loss, accuracy:  0.45762114583373503 0.8416666666666667\n",
      "7362 번째 loss, accuracy:  0.4576004656306022 0.8416666666666667\n",
      "7363 번째 loss, accuracy:  0.45757977696470237 0.8416666666666667\n",
      "7364 번째 loss, accuracy:  0.45755907983167654 0.8416666666666667\n",
      "7365 번째 loss, accuracy:  0.4575383742271676 0.8416666666666667\n",
      "7366 번째 loss, accuracy:  0.45751766014682016 0.85\n",
      "7367 번째 loss, accuracy:  0.45749693758628107 0.85\n",
      "7368 번째 loss, accuracy:  0.45747620654119836 0.85\n",
      "7369 번째 loss, accuracy:  0.45745546700722234 0.85\n",
      "7370 번째 loss, accuracy:  0.4574347189800051 0.85\n",
      "7371 번째 loss, accuracy:  0.4574139624552004 0.85\n",
      "7372 번째 loss, accuracy:  0.4573931974284637 0.85\n",
      "7373 번째 loss, accuracy:  0.45737242389545235 0.85\n",
      "7374 번째 loss, accuracy:  0.45735164185182586 0.85\n",
      "7375 번째 loss, accuracy:  0.45733085129324474 0.85\n",
      "7376 번째 loss, accuracy:  0.4573100522153725 0.85\n",
      "7377 번째 loss, accuracy:  0.45728924461387377 0.85\n",
      "7378 번째 loss, accuracy:  0.4572684284844148 0.85\n",
      "7379 번째 loss, accuracy:  0.45724760382266433 0.85\n",
      "7380 번째 loss, accuracy:  0.45722677062429234 0.85\n",
      "7381 번째 loss, accuracy:  0.4572059288849706 0.85\n",
      "7382 번째 loss, accuracy:  0.4571850786003734 0.85\n",
      "7383 번째 loss, accuracy:  0.4571642197661767 0.85\n",
      "7384 번째 loss, accuracy:  0.4571433523780577 0.85\n",
      "7385 번째 loss, accuracy:  0.4571224764316962 0.85\n",
      "7386 번째 loss, accuracy:  0.4571015919227733 0.85\n",
      "7387 번째 loss, accuracy:  0.45708069884697217 0.85\n",
      "7388 번째 loss, accuracy:  0.4570597971999778 0.85\n",
      "7389 번째 loss, accuracy:  0.4570388869774774 0.85\n",
      "7390 번째 loss, accuracy:  0.45701796817515944 0.85\n",
      "7391 번째 loss, accuracy:  0.45699704078871445 0.85\n",
      "7392 번째 loss, accuracy:  0.4569761048138351 0.85\n",
      "7393 번째 loss, accuracy:  0.4569551602462158 0.85\n",
      "7394 번째 loss, accuracy:  0.4569342070815525 0.85\n",
      "7395 번째 loss, accuracy:  0.45691324531554367 0.85\n",
      "7396 번째 loss, accuracy:  0.4568922749438891 0.85\n",
      "7397 번째 loss, accuracy:  0.4568712959622908 0.85\n",
      "7398 번째 loss, accuracy:  0.4568503083664524 0.85\n",
      "7399 번째 loss, accuracy:  0.45682931215207956 0.85\n",
      "7400 번째 loss, accuracy:  0.45680830731487976 0.85\n",
      "7401 번째 loss, accuracy:  0.4567872938505627 0.85\n",
      "7402 번째 loss, accuracy:  0.45676627175483947 0.85\n",
      "7403 번째 loss, accuracy:  0.4567452410234233 0.85\n",
      "7404 번째 loss, accuracy:  0.4567242016520293 0.85\n",
      "7405 번째 loss, accuracy:  0.45670315363637476 0.85\n",
      "7406 번째 loss, accuracy:  0.4566820969721783 0.85\n",
      "7407 번째 loss, accuracy:  0.45666103165516103 0.85\n",
      "7408 번째 loss, accuracy:  0.4566399576810455 0.85\n",
      "7409 번째 loss, accuracy:  0.45661887504555615 0.85\n",
      "7410 번째 loss, accuracy:  0.45659778374442 0.85\n",
      "7411 번째 loss, accuracy:  0.45657668377336535 0.85\n",
      "7412 번째 loss, accuracy:  0.4565555751281229 0.85\n",
      "7413 번째 loss, accuracy:  0.4565344578044247 0.85\n",
      "7414 번째 loss, accuracy:  0.45651333179800496 0.85\n",
      "7415 번째 loss, accuracy:  0.4564921971046002 0.85\n",
      "7416 번째 loss, accuracy:  0.45647105371994834 0.85\n",
      "7417 번째 loss, accuracy:  0.4564499016397896 0.85\n",
      "7418 번째 loss, accuracy:  0.4564287408598658 0.85\n",
      "7419 번째 loss, accuracy:  0.45640757137592103 0.85\n",
      "7420 번째 loss, accuracy:  0.4563863931837011 0.85\n",
      "7421 번째 loss, accuracy:  0.456365206278954 0.85\n",
      "7422 번째 loss, accuracy:  0.45634401065742924 0.85\n",
      "7423 번째 loss, accuracy:  0.4563228063148788 0.85\n",
      "7424 번째 loss, accuracy:  0.4563015932470564 0.85\n",
      "7425 번째 loss, accuracy:  0.4562803714497177 0.85\n",
      "7426 번째 loss, accuracy:  0.45625914091862035 0.85\n",
      "7427 번째 loss, accuracy:  0.45623790164952355 0.85\n",
      "7428 번째 loss, accuracy:  0.456216653638189 0.85\n",
      "7429 번째 loss, accuracy:  0.45619539688038024 0.85\n",
      "7430 번째 loss, accuracy:  0.45617413137186275 0.85\n",
      "7431 번째 loss, accuracy:  0.4561528571084041 0.85\n",
      "7432 번째 loss, accuracy:  0.45613157408577387 0.85\n",
      "7433 번째 loss, accuracy:  0.4561102822997428 0.85\n",
      "7434 번째 loss, accuracy:  0.45608898174608503 0.85\n",
      "7435 번째 loss, accuracy:  0.45606767242057583 0.85\n",
      "7436 번째 loss, accuracy:  0.45604635431899204 0.85\n",
      "7437 번째 loss, accuracy:  0.4560250274371133 0.85\n",
      "7438 번째 loss, accuracy:  0.4560036917707208 0.85\n",
      "7439 번째 loss, accuracy:  0.4559823473155982 0.85\n",
      "7440 번째 loss, accuracy:  0.4559609940675306 0.85\n",
      "7441 번째 loss, accuracy:  0.4559396320223054 0.85\n",
      "7442 번째 loss, accuracy:  0.45591826117571177 0.85\n",
      "7443 번째 loss, accuracy:  0.45589688152354124 0.8416666666666667\n",
      "7444 번째 loss, accuracy:  0.45587549306158714 0.8416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7445 번째 loss, accuracy:  0.4558540957856446 0.8416666666666667\n",
      "7446 번째 loss, accuracy:  0.45583268969151114 0.8416666666666667\n",
      "7447 번째 loss, accuracy:  0.45581127477498623 0.8416666666666667\n",
      "7448 번째 loss, accuracy:  0.4557898510318712 0.8416666666666667\n",
      "7449 번째 loss, accuracy:  0.4557684184579696 0.8416666666666667\n",
      "7450 번째 loss, accuracy:  0.4557469770490865 0.8416666666666667\n",
      "7451 번째 loss, accuracy:  0.45572552680102957 0.8416666666666667\n",
      "7452 번째 loss, accuracy:  0.45570406770960853 0.8416666666666667\n",
      "7453 번째 loss, accuracy:  0.45568259977063463 0.8416666666666667\n",
      "7454 번째 loss, accuracy:  0.45566112297992145 0.8416666666666667\n",
      "7455 번째 loss, accuracy:  0.455639637333285 0.8416666666666667\n",
      "7456 번째 loss, accuracy:  0.45561814282654267 0.8416666666666667\n",
      "7457 번째 loss, accuracy:  0.45559663945551415 0.8416666666666667\n",
      "7458 번째 loss, accuracy:  0.4555751272160211 0.8416666666666667\n",
      "7459 번째 loss, accuracy:  0.4555536061038873 0.8416666666666667\n",
      "7460 번째 loss, accuracy:  0.455532076114939 0.8416666666666667\n",
      "7461 번째 loss, accuracy:  0.4555105372450036 0.8416666666666667\n",
      "7462 번째 loss, accuracy:  0.45548898948991146 0.8416666666666667\n",
      "7463 번째 loss, accuracy:  0.45546743284549435 0.8416666666666667\n",
      "7464 번째 loss, accuracy:  0.4554458673075866 0.8416666666666667\n",
      "7465 번째 loss, accuracy:  0.45542429287202413 0.8416666666666667\n",
      "7466 번째 loss, accuracy:  0.45540270953464523 0.8416666666666667\n",
      "7467 번째 loss, accuracy:  0.45538111729129016 0.8416666666666667\n",
      "7468 번째 loss, accuracy:  0.4553595161378015 0.8416666666666667\n",
      "7469 번째 loss, accuracy:  0.4553379060700236 0.8416666666666667\n",
      "7470 번째 loss, accuracy:  0.455316287083803 0.8416666666666667\n",
      "7471 번째 loss, accuracy:  0.4552946591749881 0.8416666666666667\n",
      "7472 번째 loss, accuracy:  0.4552730223394299 0.8416666666666667\n",
      "7473 번째 loss, accuracy:  0.45525137657298104 0.8416666666666667\n",
      "7474 번째 loss, accuracy:  0.4552297218714963 0.8416666666666667\n",
      "7475 번째 loss, accuracy:  0.45520805823083293 0.8416666666666667\n",
      "7476 번째 loss, accuracy:  0.45518638564684977 0.8416666666666667\n",
      "7477 번째 loss, accuracy:  0.45516470411540827 0.8416666666666667\n",
      "7478 번째 loss, accuracy:  0.45514301363237153 0.8416666666666667\n",
      "7479 번째 loss, accuracy:  0.4551213141936051 0.8416666666666667\n",
      "7480 번째 loss, accuracy:  0.455099605794976 0.8416666666666667\n",
      "7481 번째 loss, accuracy:  0.4550778884323543 0.8416666666666667\n",
      "7482 번째 loss, accuracy:  0.45505616210161154 0.8416666666666667\n",
      "7483 번째 loss, accuracy:  0.45503442679862166 0.8416666666666667\n",
      "7484 번째 loss, accuracy:  0.4550126825192604 0.8416666666666667\n",
      "7485 번째 loss, accuracy:  0.454990929259406 0.8416666666666667\n",
      "7486 번째 loss, accuracy:  0.45496916701493884 0.8416666666666667\n",
      "7487 번째 loss, accuracy:  0.45494739578174115 0.8416666666666667\n",
      "7488 번째 loss, accuracy:  0.4549256155556974 0.8416666666666667\n",
      "7489 번째 loss, accuracy:  0.45490382633269383 0.8416666666666667\n",
      "7490 번째 loss, accuracy:  0.4548820281086196 0.8416666666666667\n",
      "7491 번째 loss, accuracy:  0.4548602208793656 0.8416666666666667\n",
      "7492 번째 loss, accuracy:  0.4548384046408246 0.8416666666666667\n",
      "7493 번째 loss, accuracy:  0.45481657938889225 0.8416666666666667\n",
      "7494 번째 loss, accuracy:  0.4547947451194654 0.8416666666666667\n",
      "7495 번째 loss, accuracy:  0.4547729018284437 0.8416666666666667\n",
      "7496 번째 loss, accuracy:  0.4547510495117286 0.8416666666666667\n",
      "7497 번째 loss, accuracy:  0.45472918816522406 0.8416666666666667\n",
      "7498 번째 loss, accuracy:  0.45470731778483614 0.8416666666666667\n",
      "7499 번째 loss, accuracy:  0.45468543836647285 0.8416666666666667\n",
      "7500 번째 loss, accuracy:  0.4546635499060445 0.8416666666666667\n",
      "7501 번째 loss, accuracy:  0.4546416523994636 0.8416666666666667\n",
      "7502 번째 loss, accuracy:  0.4546197458426447 0.8416666666666667\n",
      "7503 번째 loss, accuracy:  0.45459783023150446 0.8416666666666667\n",
      "7504 번째 loss, accuracy:  0.4545759055619619 0.8416666666666667\n",
      "7505 번째 loss, accuracy:  0.4545539718299384 0.8416666666666667\n",
      "7506 번째 loss, accuracy:  0.45453202903135687 0.8416666666666667\n",
      "7507 번째 loss, accuracy:  0.45451007716214326 0.8416666666666667\n",
      "7508 번째 loss, accuracy:  0.4544881162182251 0.8416666666666667\n",
      "7509 번째 loss, accuracy:  0.45446614619553244 0.8416666666666667\n",
      "7510 번째 loss, accuracy:  0.45444416708999763 0.8416666666666667\n",
      "7511 번째 loss, accuracy:  0.4544221788975545 0.8416666666666667\n",
      "7512 번째 loss, accuracy:  0.4544001816141394 0.8416666666666667\n",
      "7513 번째 loss, accuracy:  0.45437817523569174 0.8416666666666667\n",
      "7514 번째 loss, accuracy:  0.4543561597581519 0.8416666666666667\n",
      "7515 번째 loss, accuracy:  0.4543341351774633 0.8416666666666667\n",
      "7516 번째 loss, accuracy:  0.4543121014895711 0.8416666666666667\n",
      "7517 번째 loss, accuracy:  0.4542900586904227 0.8416666666666667\n",
      "7518 번째 loss, accuracy:  0.4542680067759683 0.8416666666666667\n",
      "7519 번째 loss, accuracy:  0.45424594574215976 0.8416666666666667\n",
      "7520 번째 loss, accuracy:  0.45422387558495153 0.8416666666666667\n",
      "7521 번째 loss, accuracy:  0.45420179630029966 0.8416666666666667\n",
      "7522 번째 loss, accuracy:  0.454179707884163 0.8416666666666667\n",
      "7523 번째 loss, accuracy:  0.4541576103325024 0.8416666666666667\n",
      "7524 번째 loss, accuracy:  0.45413550364128125 0.8416666666666667\n",
      "7525 번째 loss, accuracy:  0.45411338780646465 0.8416666666666667\n",
      "7526 번째 loss, accuracy:  0.4540912628240204 0.8416666666666667\n",
      "7527 번째 loss, accuracy:  0.45406912868991844 0.8416666666666667\n",
      "7528 번째 loss, accuracy:  0.454046985400131 0.8416666666666667\n",
      "7529 번째 loss, accuracy:  0.4540248329506323 0.8416666666666667\n",
      "7530 번째 loss, accuracy:  0.454002671337399 0.8416666666666667\n",
      "7531 번째 loss, accuracy:  0.4539805005564103 0.8416666666666667\n",
      "7532 번째 loss, accuracy:  0.45395832060364705 0.8416666666666667\n",
      "7533 번째 loss, accuracy:  0.4539361314750926 0.8416666666666667\n",
      "7534 번째 loss, accuracy:  0.4539139331667329 0.8416666666666667\n",
      "7535 번째 loss, accuracy:  0.4538917256745557 0.8416666666666667\n",
      "7536 번째 loss, accuracy:  0.45386950899455153 0.8416666666666667\n",
      "7537 번째 loss, accuracy:  0.4538472831227126 0.8416666666666667\n",
      "7538 번째 loss, accuracy:  0.4538250480550338 0.8416666666666667\n",
      "7539 번째 loss, accuracy:  0.4538028037875125 0.8416666666666667\n",
      "7540 번째 loss, accuracy:  0.45378055031614745 0.8416666666666667\n",
      "7541 번째 loss, accuracy:  0.4537582876369411 0.8416666666666667\n",
      "7542 번째 loss, accuracy:  0.4537360157458969 0.8416666666666667\n",
      "7543 번째 loss, accuracy:  0.4537137346390212 0.8416666666666667\n",
      "7544 번째 loss, accuracy:  0.4536914443123225 0.8416666666666667\n",
      "7545 번째 loss, accuracy:  0.4536691447618119 0.8416666666666667\n",
      "7546 번째 loss, accuracy:  0.4536468359835023 0.8416666666666667\n",
      "7547 번째 loss, accuracy:  0.4536245179734092 0.8416666666666667\n",
      "7548 번째 loss, accuracy:  0.4536021907275502 0.8416666666666667\n",
      "7549 번째 loss, accuracy:  0.45357985424194563 0.8416666666666667\n",
      "7550 번째 loss, accuracy:  0.45355750851261756 0.8416666666666667\n",
      "7551 번째 loss, accuracy:  0.4535351535355909 0.8416666666666667\n",
      "7552 번째 loss, accuracy:  0.4535127893068923 0.8416666666666667\n",
      "7553 번째 loss, accuracy:  0.4534904158225518 0.8416666666666667\n",
      "7554 번째 loss, accuracy:  0.4534680330786007 0.8416666666666667\n",
      "7555 번째 loss, accuracy:  0.4534456410710731 0.8416666666666667\n",
      "7556 번째 loss, accuracy:  0.4534232397960053 0.8416666666666667\n",
      "7557 번째 loss, accuracy:  0.45340082924943587 0.8416666666666667\n",
      "7558 번째 loss, accuracy:  0.4533784094274062 0.8416666666666667\n",
      "7559 번째 loss, accuracy:  0.4533559803259595 0.8416666666666667\n",
      "7560 번째 loss, accuracy:  0.45333354194114117 0.8416666666666667\n",
      "7561 번째 loss, accuracy:  0.4533110942689994 0.8416666666666667\n",
      "7562 번째 loss, accuracy:  0.453288637305585 0.8416666666666667\n",
      "7563 번째 loss, accuracy:  0.45326617104695044 0.8416666666666667\n",
      "7564 번째 loss, accuracy:  0.45324369548915105 0.8416666666666667\n",
      "7565 번째 loss, accuracy:  0.4532212106282439 0.8416666666666667\n",
      "7566 번째 loss, accuracy:  0.4531987164602891 0.8416666666666667\n",
      "7567 번째 loss, accuracy:  0.45317621298134897 0.8416666666666667\n",
      "7568 번째 loss, accuracy:  0.4531537001874876 0.8416666666666667\n",
      "7569 번째 loss, accuracy:  0.4531311780747724 0.8416666666666667\n",
      "7570 번째 loss, accuracy:  0.4531086466392728 0.8416666666666667\n",
      "7571 번째 loss, accuracy:  0.45308610587706044 0.8416666666666667\n",
      "7572 번째 loss, accuracy:  0.4530635557842094 0.8416666666666667\n",
      "7573 번째 loss, accuracy:  0.4530409963567961 0.8416666666666667\n",
      "7574 번째 loss, accuracy:  0.4530184275908994 0.8416666666666667\n",
      "7575 번째 loss, accuracy:  0.45299584948260035 0.8416666666666667\n",
      "7576 번째 loss, accuracy:  0.45297326202798355 0.8416666666666667\n",
      "7577 번째 loss, accuracy:  0.45295066522313393 0.8416666666666667\n",
      "7578 번째 loss, accuracy:  0.4529280590641406 0.8416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7579 번째 loss, accuracy:  0.45290544354709433 0.8416666666666667\n",
      "7580 번째 loss, accuracy:  0.4528828186680886 0.8416666666666667\n",
      "7581 번째 loss, accuracy:  0.45286018442321885 0.8416666666666667\n",
      "7582 번째 loss, accuracy:  0.4528375408085831 0.8416666666666667\n",
      "7583 번째 loss, accuracy:  0.452814887820282 0.8416666666666667\n",
      "7584 번째 loss, accuracy:  0.4527922254544187 0.8416666666666667\n",
      "7585 번째 loss, accuracy:  0.45276955370709815 0.8416666666666667\n",
      "7586 번째 loss, accuracy:  0.45274687257442875 0.8416666666666667\n",
      "7587 번째 loss, accuracy:  0.45272418205252 0.8416666666666667\n",
      "7588 번째 loss, accuracy:  0.45270148213748523 0.8416666666666667\n",
      "7589 번째 loss, accuracy:  0.45267877282543895 0.8416666666666667\n",
      "7590 번째 loss, accuracy:  0.45265605411249926 0.8416666666666667\n",
      "7591 번째 loss, accuracy:  0.45263332599478573 0.8416666666666667\n",
      "7592 번째 loss, accuracy:  0.4526105884684209 0.8416666666666667\n",
      "7593 번째 loss, accuracy:  0.4525878415295298 0.8416666666666667\n",
      "7594 번째 loss, accuracy:  0.45256508517423943 0.8416666666666667\n",
      "7595 번째 loss, accuracy:  0.4525423193986802 0.8416666666666667\n",
      "7596 번째 loss, accuracy:  0.45251954419898405 0.8416666666666667\n",
      "7597 번째 loss, accuracy:  0.4524967595712854 0.8416666666666667\n",
      "7598 번째 loss, accuracy:  0.4524739655117216 0.8416666666666667\n",
      "7599 번째 loss, accuracy:  0.4524511620164321 0.8416666666666667\n",
      "7600 번째 loss, accuracy:  0.4524283490815595 0.8416666666666667\n",
      "7601 번째 loss, accuracy:  0.4524055267032479 0.8416666666666667\n",
      "7602 번째 loss, accuracy:  0.45238269487764454 0.8416666666666667\n",
      "7603 번째 loss, accuracy:  0.4523598536008992 0.8416666666666667\n",
      "7604 번째 loss, accuracy:  0.4523370028691636 0.8416666666666667\n",
      "7605 번째 loss, accuracy:  0.4523141426785926 0.8416666666666667\n",
      "7606 번째 loss, accuracy:  0.45229127302534294 0.8416666666666667\n",
      "7607 번째 loss, accuracy:  0.4522683939055741 0.8416666666666667\n",
      "7608 번째 loss, accuracy:  0.4522455053154482 0.8416666666666667\n",
      "7609 번째 loss, accuracy:  0.4522226072511292 0.8416666666666667\n",
      "7610 번째 loss, accuracy:  0.4521996997087849 0.8416666666666667\n",
      "7611 번째 loss, accuracy:  0.45217678268458433 0.8416666666666667\n",
      "7612 번째 loss, accuracy:  0.4521538561746998 0.8416666666666667\n",
      "7613 번째 loss, accuracy:  0.45213092017530543 0.8416666666666667\n",
      "7614 번째 loss, accuracy:  0.45210797468257885 0.8416666666666667\n",
      "7615 번째 loss, accuracy:  0.4520850196926991 0.8416666666666667\n",
      "7616 번째 loss, accuracy:  0.45206205520184833 0.8416666666666667\n",
      "7617 번째 loss, accuracy:  0.4520390812062111 0.8416666666666667\n",
      "7618 번째 loss, accuracy:  0.45201609770197515 0.8416666666666667\n",
      "7619 번째 loss, accuracy:  0.45199310468532955 0.8416666666666667\n",
      "7620 번째 loss, accuracy:  0.4519701021524666 0.8416666666666667\n",
      "7621 번째 loss, accuracy:  0.4519470900995813 0.8416666666666667\n",
      "7622 번째 loss, accuracy:  0.4519240685228706 0.8416666666666667\n",
      "7623 번째 loss, accuracy:  0.45190103741853427 0.8416666666666667\n",
      "7624 번째 loss, accuracy:  0.4518779967827751 0.8416666666666667\n",
      "7625 번째 loss, accuracy:  0.45185494661179776 0.8416666666666667\n",
      "7626 번째 loss, accuracy:  0.45183188690180975 0.8416666666666667\n",
      "7627 번째 loss, accuracy:  0.4518088176490213 0.8416666666666667\n",
      "7628 번째 loss, accuracy:  0.4517857388496448 0.8416666666666667\n",
      "7629 번째 loss, accuracy:  0.4517626504998955 0.8416666666666667\n",
      "7630 번째 loss, accuracy:  0.45173955259599136 0.8416666666666667\n",
      "7631 번째 loss, accuracy:  0.4517164451341522 0.8416666666666667\n",
      "7632 번째 loss, accuracy:  0.4516933281106012 0.8416666666666667\n",
      "7633 번째 loss, accuracy:  0.451670201521564 0.8416666666666667\n",
      "7634 번째 loss, accuracy:  0.45164706536326815 0.8416666666666667\n",
      "7635 번째 loss, accuracy:  0.45162391963194476 0.8416666666666667\n",
      "7636 번째 loss, accuracy:  0.45160076432382645 0.8416666666666667\n",
      "7637 번째 loss, accuracy:  0.4515775994351497 0.8416666666666667\n",
      "7638 번째 loss, accuracy:  0.4515544249621525 0.8416666666666667\n",
      "7639 번째 loss, accuracy:  0.4515312409010761 0.8416666666666667\n",
      "7640 번째 loss, accuracy:  0.4515080472481638 0.8416666666666667\n",
      "7641 번째 loss, accuracy:  0.45148484399966204 0.8416666666666667\n",
      "7642 번째 loss, accuracy:  0.4514616311518194 0.8416666666666667\n",
      "7643 번째 loss, accuracy:  0.4514384087008875 0.8416666666666667\n",
      "7644 번째 loss, accuracy:  0.4514151766431202 0.8416666666666667\n",
      "7645 번째 loss, accuracy:  0.4513919349747742 0.8416666666666667\n",
      "7646 번째 loss, accuracy:  0.451368683692109 0.8416666666666667\n",
      "7647 번째 loss, accuracy:  0.451345422791386 0.8416666666666667\n",
      "7648 번째 loss, accuracy:  0.45132215226887035 0.8416666666666667\n",
      "7649 번째 loss, accuracy:  0.45129887212082853 0.8416666666666667\n",
      "7650 번째 loss, accuracy:  0.4512755823435306 0.8416666666666667\n",
      "7651 번째 loss, accuracy:  0.4512522829332491 0.8416666666666667\n",
      "7652 번째 loss, accuracy:  0.4512289738862588 0.8416666666666667\n",
      "7653 번째 loss, accuracy:  0.4512056551988376 0.8416666666666667\n",
      "7654 번째 loss, accuracy:  0.45118232686726584 0.8416666666666667\n",
      "7655 번째 loss, accuracy:  0.4511589888878266 0.8416666666666667\n",
      "7656 번째 loss, accuracy:  0.45113564125680516 0.8416666666666667\n",
      "7657 번째 loss, accuracy:  0.45111228397048986 0.8416666666666667\n",
      "7658 번째 loss, accuracy:  0.4510889170251723 0.8416666666666667\n",
      "7659 번째 loss, accuracy:  0.4510655404171454 0.8416666666666667\n",
      "7660 번째 loss, accuracy:  0.45104215414270565 0.8416666666666667\n",
      "7661 번째 loss, accuracy:  0.4510187581981523 0.8416666666666667\n",
      "7662 번째 loss, accuracy:  0.4509953525797867 0.8416666666666667\n",
      "7663 번째 loss, accuracy:  0.45097193728391305 0.8416666666666667\n",
      "7664 번째 loss, accuracy:  0.4509485123068388 0.8416666666666667\n",
      "7665 번째 loss, accuracy:  0.45092507764487294 0.8416666666666667\n",
      "7666 번째 loss, accuracy:  0.45090163329432814 0.8416666666666667\n",
      "7667 번째 loss, accuracy:  0.4508781792515194 0.8416666666666667\n",
      "7668 번째 loss, accuracy:  0.4508547155127648 0.8416666666666667\n",
      "7669 번째 loss, accuracy:  0.45083124207438435 0.8416666666666667\n",
      "7670 번째 loss, accuracy:  0.45080775893270136 0.8416666666666667\n",
      "7671 번째 loss, accuracy:  0.4507842660840417 0.8416666666666667\n",
      "7672 번째 loss, accuracy:  0.45076076352473393 0.8416666666666667\n",
      "7673 번째 loss, accuracy:  0.45073725125110925 0.8416666666666667\n",
      "7674 번째 loss, accuracy:  0.4507137292595017 0.8416666666666667\n",
      "7675 번째 loss, accuracy:  0.4506901975462476 0.8416666666666667\n",
      "7676 번째 loss, accuracy:  0.4506666561076867 0.8416666666666667\n",
      "7677 번째 loss, accuracy:  0.45064310494016113 0.8416666666666667\n",
      "7678 번째 loss, accuracy:  0.45061954404001564 0.8416666666666667\n",
      "7679 번째 loss, accuracy:  0.45059597340359786 0.8416666666666667\n",
      "7680 번째 loss, accuracy:  0.45057239302725804 0.8416666666666667\n",
      "7681 번째 loss, accuracy:  0.4505488029073491 0.8416666666666667\n",
      "7682 번째 loss, accuracy:  0.45052520304022714 0.8416666666666667\n",
      "7683 번째 loss, accuracy:  0.45050159342225043 0.8416666666666667\n",
      "7684 번째 loss, accuracy:  0.45047797404978035 0.8416666666666667\n",
      "7685 번째 loss, accuracy:  0.45045434491918096 0.8416666666666667\n",
      "7686 번째 loss, accuracy:  0.45043070602681917 0.8416666666666667\n",
      "7687 번째 loss, accuracy:  0.4504070573690643 0.8416666666666667\n",
      "7688 번째 loss, accuracy:  0.4503833989422888 0.8416666666666667\n",
      "7689 번째 loss, accuracy:  0.4503597307428676 0.8416666666666667\n",
      "7690 번째 loss, accuracy:  0.45033605276717864 0.8416666666666667\n",
      "7691 번째 loss, accuracy:  0.4503123650116025 0.8416666666666667\n",
      "7692 번째 loss, accuracy:  0.45028866747252244 0.8416666666666667\n",
      "7693 번째 loss, accuracy:  0.45026496014632467 0.8416666666666667\n",
      "7694 번째 loss, accuracy:  0.4502412430293979 0.8416666666666667\n",
      "7695 번째 loss, accuracy:  0.45021751611813415 0.8416666666666667\n",
      "7696 번째 loss, accuracy:  0.45019377940892774 0.8416666666666667\n",
      "7697 번째 loss, accuracy:  0.4501700328981761 0.8416666666666667\n",
      "7698 번째 loss, accuracy:  0.4501462765822795 0.8416666666666667\n",
      "7699 번째 loss, accuracy:  0.45012251045764046 0.8416666666666667\n",
      "7700 번째 loss, accuracy:  0.4500987345206649 0.8416666666666667\n",
      "7701 번째 loss, accuracy:  0.4500749487677611 0.8416666666666667\n",
      "7702 번째 loss, accuracy:  0.45005115319534034 0.8416666666666667\n",
      "7703 번째 loss, accuracy:  0.45002734779981696 0.8416666666666667\n",
      "7704 번째 loss, accuracy:  0.4500035325776078 0.8416666666666667\n",
      "7705 번째 loss, accuracy:  0.44997970752513233 0.8416666666666667\n",
      "7706 번째 loss, accuracy:  0.44995587263881354 0.8416666666666667\n",
      "7707 번째 loss, accuracy:  0.44993202791507664 0.8416666666666667\n",
      "7708 번째 loss, accuracy:  0.4499081733503498 0.8416666666666667\n",
      "7709 번째 loss, accuracy:  0.449884308941064 0.8416666666666667\n",
      "7710 번째 loss, accuracy:  0.44986043468365317 0.8416666666666667\n",
      "7711 번째 loss, accuracy:  0.4498365505745542 0.8416666666666667\n",
      "7712 번째 loss, accuracy:  0.44981265661020614 0.8416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7713 번째 loss, accuracy:  0.44978875278705177 0.8416666666666667\n",
      "7714 번째 loss, accuracy:  0.44976483910153675 0.8416666666666667\n",
      "7715 번째 loss, accuracy:  0.44974091555010837 0.8416666666666667\n",
      "7716 번째 loss, accuracy:  0.4497169821292183 0.8416666666666667\n",
      "7717 번째 loss, accuracy:  0.4496930388353198 0.8416666666666667\n",
      "7718 번째 loss, accuracy:  0.44966908566487007 0.8416666666666667\n",
      "7719 번째 loss, accuracy:  0.4496451226143282 0.8416666666666667\n",
      "7720 번째 loss, accuracy:  0.4496211496801569 0.8416666666666667\n",
      "7721 번째 loss, accuracy:  0.4495971668588215 0.8416666666666667\n",
      "7722 번째 loss, accuracy:  0.4495731741467897 0.8416666666666667\n",
      "7723 번째 loss, accuracy:  0.4495491715405331 0.8416666666666667\n",
      "7724 번째 loss, accuracy:  0.4495251590365254 0.8416666666666667\n",
      "7725 번째 loss, accuracy:  0.4495011366312434 0.8416666666666667\n",
      "7726 번째 loss, accuracy:  0.44947710432116683 0.8416666666666667\n",
      "7727 번째 loss, accuracy:  0.44945306210277813 0.8416666666666667\n",
      "7728 번째 loss, accuracy:  0.449429009972563 0.8416666666666667\n",
      "7729 번째 loss, accuracy:  0.4494049479270098 0.8416666666666667\n",
      "7730 번째 loss, accuracy:  0.4493808759626097 0.8416666666666667\n",
      "7731 번째 loss, accuracy:  0.44935679407585705 0.8416666666666667\n",
      "7732 번째 loss, accuracy:  0.4493327022632489 0.8416666666666667\n",
      "7733 번째 loss, accuracy:  0.4493086005212856 0.8416666666666667\n",
      "7734 번째 loss, accuracy:  0.44928448884646965 0.8416666666666667\n",
      "7735 번째 loss, accuracy:  0.4492603672353072 0.8416666666666667\n",
      "7736 번째 loss, accuracy:  0.44923623568430693 0.8416666666666667\n",
      "7737 번째 loss, accuracy:  0.4492120941899807 0.8333333333333334\n",
      "7738 번째 loss, accuracy:  0.4491879427488427 0.8333333333333334\n",
      "7739 번째 loss, accuracy:  0.4491637813574111 0.8333333333333334\n",
      "7740 번째 loss, accuracy:  0.449139610012206 0.8333333333333334\n",
      "7741 번째 loss, accuracy:  0.4491154287097511 0.8333333333333334\n",
      "7742 번째 loss, accuracy:  0.4490912374465731 0.8333333333333334\n",
      "7743 번째 loss, accuracy:  0.4490670362192011 0.8333333333333334\n",
      "7744 번째 loss, accuracy:  0.4490428250241672 0.8333333333333334\n",
      "7745 번째 loss, accuracy:  0.44901860385800696 0.8333333333333334\n",
      "7746 번째 loss, accuracy:  0.44899437271725856 0.8333333333333334\n",
      "7747 번째 loss, accuracy:  0.4489701315984629 0.8333333333333334\n",
      "7748 번째 loss, accuracy:  0.44894588049816453 0.8333333333333334\n",
      "7749 번째 loss, accuracy:  0.44892161941291076 0.8333333333333334\n",
      "7750 번째 loss, accuracy:  0.4488973483392513 0.8333333333333334\n",
      "7751 번째 loss, accuracy:  0.4488730672737394 0.8333333333333334\n",
      "7752 번째 loss, accuracy:  0.44884877621293107 0.8333333333333334\n",
      "7753 번째 loss, accuracy:  0.4488244751533854 0.8333333333333334\n",
      "7754 번째 loss, accuracy:  0.44880016409166446 0.8333333333333334\n",
      "7755 번째 loss, accuracy:  0.44877584302433315 0.8333333333333334\n",
      "7756 번째 loss, accuracy:  0.4487515119479596 0.8333333333333334\n",
      "7757 번째 loss, accuracy:  0.4487271708591152 0.8333333333333334\n",
      "7758 번째 loss, accuracy:  0.44870281975437315 0.8333333333333334\n",
      "7759 번째 loss, accuracy:  0.44867845863031125 0.8333333333333334\n",
      "7760 번째 loss, accuracy:  0.4486540874835091 0.8333333333333334\n",
      "7761 번째 loss, accuracy:  0.4486297063105501 0.8333333333333334\n",
      "7762 번째 loss, accuracy:  0.44860531510801976 0.8333333333333334\n",
      "7763 번째 loss, accuracy:  0.44858091387250776 0.8333333333333334\n",
      "7764 번째 loss, accuracy:  0.4485565026006061 0.8333333333333334\n",
      "7765 번째 loss, accuracy:  0.44853208128890965 0.8333333333333334\n",
      "7766 번째 loss, accuracy:  0.4485076499340168 0.8333333333333334\n",
      "7767 번째 loss, accuracy:  0.4484832085325287 0.8333333333333334\n",
      "7768 번째 loss, accuracy:  0.4484587570810495 0.8333333333333334\n",
      "7769 번째 loss, accuracy:  0.44843429557618664 0.8333333333333334\n",
      "7770 번째 loss, accuracy:  0.44840982401455015 0.8333333333333334\n",
      "7771 번째 loss, accuracy:  0.4483853423927541 0.8333333333333334\n",
      "7772 번째 loss, accuracy:  0.44836085070741455 0.8333333333333334\n",
      "7773 번째 loss, accuracy:  0.4483363489551505 0.8333333333333334\n",
      "7774 번째 loss, accuracy:  0.4483118371325852 0.8333333333333334\n",
      "7775 번째 loss, accuracy:  0.4482873152363436 0.8333333333333334\n",
      "7776 번째 loss, accuracy:  0.44826278326305496 0.8333333333333334\n",
      "7777 번째 loss, accuracy:  0.44823824120935074 0.8333333333333334\n",
      "7778 번째 loss, accuracy:  0.44821368907186565 0.8333333333333334\n",
      "7779 번째 loss, accuracy:  0.44818912684723766 0.8333333333333334\n",
      "7780 번째 loss, accuracy:  0.44816455453210785 0.8333333333333334\n",
      "7781 번째 loss, accuracy:  0.44813997212312034 0.8333333333333334\n",
      "7782 번째 loss, accuracy:  0.4481153796169222 0.8333333333333334\n",
      "7783 번째 loss, accuracy:  0.4480907770101634 0.8333333333333334\n",
      "7784 번째 loss, accuracy:  0.4480661642994974 0.8333333333333334\n",
      "7785 번째 loss, accuracy:  0.44804154148158043 0.8333333333333334\n",
      "7786 번째 loss, accuracy:  0.44801690855307236 0.8333333333333334\n",
      "7787 번째 loss, accuracy:  0.4479922655106356 0.8333333333333334\n",
      "7788 번째 loss, accuracy:  0.44796761235093613 0.8333333333333334\n",
      "7789 번째 loss, accuracy:  0.44794294907064264 0.8333333333333334\n",
      "7790 번째 loss, accuracy:  0.447918275666427 0.8333333333333334\n",
      "7791 번째 loss, accuracy:  0.44789359213496455 0.8333333333333334\n",
      "7792 번째 loss, accuracy:  0.44786889847293326 0.8333333333333334\n",
      "7793 번째 loss, accuracy:  0.4478441946770147 0.8333333333333334\n",
      "7794 번째 loss, accuracy:  0.44781948074389316 0.8333333333333334\n",
      "7795 번째 loss, accuracy:  0.4477947566702561 0.8333333333333334\n",
      "7796 번째 loss, accuracy:  0.44777002245279457 0.8333333333333334\n",
      "7797 번째 loss, accuracy:  0.44774527808820214 0.8333333333333334\n",
      "7798 번째 loss, accuracy:  0.44772052357317577 0.8333333333333334\n",
      "7799 번째 loss, accuracy:  0.4476957589044159 0.8333333333333334\n",
      "7800 번째 loss, accuracy:  0.4476709840786259 0.8333333333333334\n",
      "7801 번째 loss, accuracy:  0.44764619909251185 0.8333333333333334\n",
      "7802 번째 loss, accuracy:  0.4476214039427834 0.8333333333333334\n",
      "7803 번째 loss, accuracy:  0.4475965986261539 0.8333333333333334\n",
      "7804 번째 loss, accuracy:  0.44757178313933893 0.8333333333333334\n",
      "7805 번째 loss, accuracy:  0.4475469574790578 0.8333333333333334\n",
      "7806 번째 loss, accuracy:  0.4475221216420324 0.8333333333333334\n",
      "7807 번째 loss, accuracy:  0.44749727562498864 0.8333333333333334\n",
      "7808 번째 loss, accuracy:  0.4474724194246546 0.8333333333333334\n",
      "7809 번째 loss, accuracy:  0.44744755303776285 0.8333333333333334\n",
      "7810 번째 loss, accuracy:  0.4474226764610479 0.8333333333333334\n",
      "7811 번째 loss, accuracy:  0.447397789691248 0.8333333333333334\n",
      "7812 번째 loss, accuracy:  0.4473728927251048 0.8333333333333334\n",
      "7813 번째 loss, accuracy:  0.44734798555936295 0.8333333333333334\n",
      "7814 번째 loss, accuracy:  0.44732306819076995 0.8333333333333334\n",
      "7815 번째 loss, accuracy:  0.44729814061607687 0.8333333333333334\n",
      "7816 번째 loss, accuracy:  0.4472732028320384 0.8333333333333334\n",
      "7817 번째 loss, accuracy:  0.44724825483541153 0.8333333333333334\n",
      "7818 번째 loss, accuracy:  0.4472232966229572 0.8333333333333334\n",
      "7819 번째 loss, accuracy:  0.44719832819143895 0.8333333333333334\n",
      "7820 번째 loss, accuracy:  0.44717334953762405 0.8333333333333334\n",
      "7821 번째 loss, accuracy:  0.44714836065828295 0.8333333333333334\n",
      "7822 번째 loss, accuracy:  0.44712336155018895 0.8333333333333334\n",
      "7823 번째 loss, accuracy:  0.4470983522101192 0.8333333333333334\n",
      "7824 번째 loss, accuracy:  0.4470733326348532 0.8333333333333334\n",
      "7825 번째 loss, accuracy:  0.44704830282117464 0.8333333333333334\n",
      "7826 번째 loss, accuracy:  0.44702326276587023 0.8333333333333334\n",
      "7827 번째 loss, accuracy:  0.4469982124657293 0.8333333333333334\n",
      "7828 번째 loss, accuracy:  0.44697315191754516 0.8333333333333334\n",
      "7829 번째 loss, accuracy:  0.446948081118114 0.8333333333333334\n",
      "7830 번째 loss, accuracy:  0.4469230000642353 0.8333333333333334\n",
      "7831 번째 loss, accuracy:  0.44689790875271174 0.8333333333333334\n",
      "7832 번째 loss, accuracy:  0.44687280718034966 0.8333333333333334\n",
      "7833 번째 loss, accuracy:  0.44684769534395835 0.8333333333333334\n",
      "7834 번째 loss, accuracy:  0.4468225732403502 0.8333333333333334\n",
      "7835 번째 loss, accuracy:  0.4467974408663412 0.8333333333333334\n",
      "7836 번째 loss, accuracy:  0.4467722982187508 0.8333333333333334\n",
      "7837 번째 loss, accuracy:  0.44674714529440107 0.8333333333333334\n",
      "7838 번째 loss, accuracy:  0.44672198209011804 0.8333333333333334\n",
      "7839 번째 loss, accuracy:  0.44669680860273064 0.8333333333333334\n",
      "7840 번째 loss, accuracy:  0.44667162482907113 0.8333333333333334\n",
      "7841 번째 loss, accuracy:  0.4466464307659752 0.8333333333333334\n",
      "7842 번째 loss, accuracy:  0.44662122641028196 0.8333333333333334\n",
      "7843 번째 loss, accuracy:  0.44659601175883334 0.8333333333333334\n",
      "7844 번째 loss, accuracy:  0.44657078680847545 0.8333333333333334\n",
      "7845 번째 loss, accuracy:  0.4465455515560566 0.8333333333333334\n",
      "7846 번째 loss, accuracy:  0.44652030599842896 0.8333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7847 번째 loss, accuracy:  0.4464950501324488 0.8333333333333334\n",
      "7848 번째 loss, accuracy:  0.446469783954974 0.8333333333333334\n",
      "7849 번째 loss, accuracy:  0.44644450746286746 0.8333333333333334\n",
      "7850 번째 loss, accuracy:  0.44641922065299444 0.8333333333333334\n",
      "7851 번째 loss, accuracy:  0.4463939235222238 0.8333333333333334\n",
      "7852 번째 loss, accuracy:  0.4463686160674278 0.8333333333333334\n",
      "7853 번째 loss, accuracy:  0.44634329828548186 0.8333333333333334\n",
      "7854 번째 loss, accuracy:  0.4463179701732646 0.8333333333333334\n",
      "7855 번째 loss, accuracy:  0.44629263172765893 0.8333333333333334\n",
      "7856 번째 loss, accuracy:  0.4462672829455498 0.8333333333333334\n",
      "7857 번째 loss, accuracy:  0.4462419238238264 0.8333333333333334\n",
      "7858 번째 loss, accuracy:  0.446216554359381 0.8333333333333334\n",
      "7859 번째 loss, accuracy:  0.4461911745491092 0.8333333333333334\n",
      "7860 번째 loss, accuracy:  0.44616578438991017 0.8333333333333334\n",
      "7861 번째 loss, accuracy:  0.4461403838786866 0.8333333333333334\n",
      "7862 번째 loss, accuracy:  0.44611497301234343 0.8333333333333334\n",
      "7863 번째 loss, accuracy:  0.4460895517877907 0.8333333333333334\n",
      "7864 번째 loss, accuracy:  0.44606412020194075 0.8333333333333334\n",
      "7865 번째 loss, accuracy:  0.4460386782517094 0.8333333333333334\n",
      "7866 번째 loss, accuracy:  0.446013225934016 0.8416666666666667\n",
      "7867 번째 loss, accuracy:  0.44598776324578326 0.8416666666666667\n",
      "7868 번째 loss, accuracy:  0.4459622901839373 0.8416666666666667\n",
      "7869 번째 loss, accuracy:  0.4459368067454078 0.8416666666666667\n",
      "7870 번째 loss, accuracy:  0.44591131292712777 0.8416666666666667\n",
      "7871 번째 loss, accuracy:  0.4458858087260333 0.8416666666666667\n",
      "7872 번째 loss, accuracy:  0.44586029413906425 0.8416666666666667\n",
      "7873 번째 loss, accuracy:  0.4458347691631639 0.8416666666666667\n",
      "7874 번째 loss, accuracy:  0.445809233795279 0.8416666666666667\n",
      "7875 번째 loss, accuracy:  0.4457836880323592 0.8416666666666667\n",
      "7876 번째 loss, accuracy:  0.4457581318713582 0.8416666666666667\n",
      "7877 번째 loss, accuracy:  0.44573256530923305 0.8416666666666667\n",
      "7878 번째 loss, accuracy:  0.4457069883429438 0.8416666666666667\n",
      "7879 번째 loss, accuracy:  0.4456814009694542 0.8416666666666667\n",
      "7880 번째 loss, accuracy:  0.4456558031857314 0.8416666666666667\n",
      "7881 번째 loss, accuracy:  0.44563019498874645 0.8416666666666667\n",
      "7882 번째 loss, accuracy:  0.4456045763754733 0.8416666666666667\n",
      "7883 번째 loss, accuracy:  0.44557894734288983 0.8416666666666667\n",
      "7884 번째 loss, accuracy:  0.4455533078879766 0.8416666666666667\n",
      "7885 번째 loss, accuracy:  0.44552765800771804 0.8416666666666667\n",
      "7886 번째 loss, accuracy:  0.44550199769910276 0.8416666666666667\n",
      "7887 번째 loss, accuracy:  0.4454763269591216 0.8416666666666667\n",
      "7888 번째 loss, accuracy:  0.4454506457847696 0.8416666666666667\n",
      "7889 번째 loss, accuracy:  0.4454249541730452 0.8416666666666667\n",
      "7890 번째 loss, accuracy:  0.4453992521209501 0.8416666666666667\n",
      "7891 번째 loss, accuracy:  0.44537353962548953 0.8416666666666667\n",
      "7892 번째 loss, accuracy:  0.44534781668367257 0.8416666666666667\n",
      "7893 번째 loss, accuracy:  0.4453220832925118 0.8416666666666667\n",
      "7894 번째 loss, accuracy:  0.4452963394490229 0.8416666666666667\n",
      "7895 번째 loss, accuracy:  0.4452705851502252 0.8416666666666667\n",
      "7896 번째 loss, accuracy:  0.44524482039314145 0.8416666666666667\n",
      "7897 번째 loss, accuracy:  0.4452190451747979 0.8416666666666667\n",
      "7898 번째 loss, accuracy:  0.4451932594922247 0.8416666666666667\n",
      "7899 번째 loss, accuracy:  0.4451674633424546 0.8416666666666667\n",
      "7900 번째 loss, accuracy:  0.44514165672252476 0.8416666666666667\n",
      "7901 번째 loss, accuracy:  0.4451158396294758 0.8416666666666667\n",
      "7902 번째 loss, accuracy:  0.44509001206035176 0.8416666666666667\n",
      "7903 번째 loss, accuracy:  0.4450641740121996 0.8416666666666667\n",
      "7904 번째 loss, accuracy:  0.4450383254820705 0.8416666666666667\n",
      "7905 번째 loss, accuracy:  0.44501246646701964 0.8416666666666667\n",
      "7906 번째 loss, accuracy:  0.4449865969641041 0.8416666666666667\n",
      "7907 번째 loss, accuracy:  0.44496071697038625 0.8416666666666667\n",
      "7908 번째 loss, accuracy:  0.44493482648293076 0.8416666666666667\n",
      "7909 번째 loss, accuracy:  0.44490892549880656 0.8416666666666667\n",
      "7910 번째 loss, accuracy:  0.4448830140150856 0.8416666666666667\n",
      "7911 번째 loss, accuracy:  0.4448570920288439 0.8416666666666667\n",
      "7912 번째 loss, accuracy:  0.444831159537161 0.8416666666666667\n",
      "7913 번째 loss, accuracy:  0.44480521653711985 0.8416666666666667\n",
      "7914 번째 loss, accuracy:  0.4447792630258069 0.8416666666666667\n",
      "7915 번째 loss, accuracy:  0.4447532990003123 0.8416666666666667\n",
      "7916 번째 loss, accuracy:  0.4447273244577298 0.8416666666666667\n",
      "7917 번째 loss, accuracy:  0.44470133939515655 0.8416666666666667\n",
      "7918 번째 loss, accuracy:  0.44467534380969354 0.8416666666666667\n",
      "7919 번째 loss, accuracy:  0.4446493376984448 0.8416666666666667\n",
      "7920 번째 loss, accuracy:  0.4446233210585189 0.8416666666666667\n",
      "7921 번째 loss, accuracy:  0.44459729388702696 0.8416666666666667\n",
      "7922 번째 loss, accuracy:  0.44457125618108484 0.8416666666666667\n",
      "7923 번째 loss, accuracy:  0.4445452079378106 0.8416666666666667\n",
      "7924 번째 loss, accuracy:  0.4445191491543273 0.8416666666666667\n",
      "7925 번째 loss, accuracy:  0.44449307982776076 0.8416666666666667\n",
      "7926 번째 loss, accuracy:  0.4444669999552406 0.8416666666666667\n",
      "7927 번째 loss, accuracy:  0.4444409095339002 0.8416666666666667\n",
      "7928 번째 loss, accuracy:  0.4444148085608768 0.8416666666666667\n",
      "7929 번째 loss, accuracy:  0.44438869703331046 0.8416666666666667\n",
      "7930 번째 loss, accuracy:  0.4443625749483457 0.8416666666666667\n",
      "7931 번째 loss, accuracy:  0.44433644230313 0.8416666666666667\n",
      "7932 번째 loss, accuracy:  0.4443102990948152 0.8416666666666667\n",
      "7933 번째 loss, accuracy:  0.4442841453205559 0.8416666666666667\n",
      "7934 번째 loss, accuracy:  0.44425798097751107 0.8416666666666667\n",
      "7935 번째 loss, accuracy:  0.4442318060628429 0.8416666666666667\n",
      "7936 번째 loss, accuracy:  0.4442056205737179 0.8416666666666667\n",
      "7937 번째 loss, accuracy:  0.4441794245073055 0.8416666666666667\n",
      "7938 번째 loss, accuracy:  0.4441532178607788 0.8416666666666667\n",
      "7939 번째 loss, accuracy:  0.4441270006313154 0.8416666666666667\n",
      "7940 번째 loss, accuracy:  0.4441007728160955 0.85\n",
      "7941 번째 loss, accuracy:  0.4440745344123036 0.85\n",
      "7942 번째 loss, accuracy:  0.4440482854171277 0.85\n",
      "7943 번째 loss, accuracy:  0.44402202582775935 0.85\n",
      "7944 번째 loss, accuracy:  0.4439957556413946 0.85\n",
      "7945 번째 loss, accuracy:  0.4439694748552319 0.85\n",
      "7946 번째 loss, accuracy:  0.4439431834664744 0.85\n",
      "7947 번째 loss, accuracy:  0.44391688147232816 0.85\n",
      "7948 번째 loss, accuracy:  0.44389056887000417 0.85\n",
      "7949 번째 loss, accuracy:  0.44386424565671506 0.85\n",
      "7950 번째 loss, accuracy:  0.4438379118296792 0.85\n",
      "7951 번째 loss, accuracy:  0.4438115673861179 0.85\n",
      "7952 번째 loss, accuracy:  0.4437852123232561 0.85\n",
      "7953 번째 loss, accuracy:  0.4437588466383224 0.85\n",
      "7954 번째 loss, accuracy:  0.4437324703285494 0.85\n",
      "7955 번째 loss, accuracy:  0.4437060833911732 0.85\n",
      "7956 번째 loss, accuracy:  0.4436796858234334 0.85\n",
      "7957 번째 loss, accuracy:  0.44365327762257406 0.85\n",
      "7958 번째 loss, accuracy:  0.4436268587858422 0.85\n",
      "7959 번째 loss, accuracy:  0.4436004293104892 0.85\n",
      "7960 번째 loss, accuracy:  0.4435739891937699 0.85\n",
      "7961 번째 loss, accuracy:  0.4435475384329427 0.85\n",
      "7962 번째 loss, accuracy:  0.4435210770252703 0.85\n",
      "7963 번째 loss, accuracy:  0.44349460496801857 0.85\n",
      "7964 번째 loss, accuracy:  0.4434681222584572 0.85\n",
      "7965 번째 loss, accuracy:  0.4434416288938603 0.85\n",
      "7966 번째 loss, accuracy:  0.4434151248715047 0.85\n",
      "7967 번째 loss, accuracy:  0.4433886101886716 0.85\n",
      "7968 번째 loss, accuracy:  0.44336208484264644 0.85\n",
      "7969 번째 loss, accuracy:  0.4433355488307177 0.85\n",
      "7970 번째 loss, accuracy:  0.44330900215017766 0.85\n",
      "7971 번째 loss, accuracy:  0.4432824447983229 0.85\n",
      "7972 번째 loss, accuracy:  0.44325587677245337 0.85\n",
      "7973 번째 loss, accuracy:  0.44322929806987293 0.85\n",
      "7974 번째 loss, accuracy:  0.4432027086878891 0.85\n",
      "7975 번째 loss, accuracy:  0.4431761086238136 0.85\n",
      "7976 번째 loss, accuracy:  0.44314949787496155 0.85\n",
      "7977 번째 loss, accuracy:  0.44312287643865217 0.85\n",
      "7978 번째 loss, accuracy:  0.4430962443122082 0.85\n",
      "7979 번째 loss, accuracy:  0.44306960149295677 0.85\n",
      "7980 번째 loss, accuracy:  0.4430429479782276 0.85\n",
      "7981 번째 loss, accuracy:  0.4430162837653556 0.85\n",
      "7982 번째 loss, accuracy:  0.44298960885167865 0.85\n",
      "7983 번째 loss, accuracy:  0.442962923234539 0.85\n",
      "7984 번째 loss, accuracy:  0.4429362269112824 0.85\n",
      "7985 번째 loss, accuracy:  0.4429095198792587 0.85\n",
      "7986 번째 loss, accuracy:  0.44288280213582143 0.85\n",
      "7987 번째 loss, accuracy:  0.44285607367832763 0.85\n",
      "7988 번째 loss, accuracy:  0.4428293345041389 0.85\n",
      "7989 번째 loss, accuracy:  0.44280258461062005 0.85\n",
      "7990 번째 loss, accuracy:  0.44277582399514015 0.85\n",
      "7991 번째 loss, accuracy:  0.44274905265507214 0.85\n",
      "7992 번째 loss, accuracy:  0.4427222705877923 0.85\n",
      "7993 번째 loss, accuracy:  0.44269547779068125 0.85\n",
      "7994 번째 loss, accuracy:  0.4426686742611237 0.85\n",
      "7995 번째 loss, accuracy:  0.44264185999650746 0.85\n",
      "7996 번째 loss, accuracy:  0.4426150349942249 0.85\n",
      "7997 번째 loss, accuracy:  0.4425881992516723 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7998 번째 loss, accuracy:  0.4425613527662494 0.85\n",
      "7999 번째 loss, accuracy:  0.44253449553536 0.85\n",
      "8000 번째 loss, accuracy:  0.4425076275564119 0.85\n",
      "8001 번째 loss, accuracy:  0.4424807488268165 0.85\n",
      "8002 번째 loss, accuracy:  0.4424538593439895 0.85\n",
      "8003 번째 loss, accuracy:  0.4424269591053503 0.85\n",
      "8004 번째 loss, accuracy:  0.44240004810832195 0.85\n",
      "8005 번째 loss, accuracy:  0.44237312635033227 0.85\n",
      "8006 번째 loss, accuracy:  0.44234619382881224 0.85\n",
      "8007 번째 loss, accuracy:  0.44231925054119686 0.85\n",
      "8008 번째 loss, accuracy:  0.44229229648492513 0.85\n",
      "8009 번째 loss, accuracy:  0.44226533165744 0.85\n",
      "8010 번째 loss, accuracy:  0.44223835605618844 0.85\n",
      "8011 번째 loss, accuracy:  0.44221136967862135 0.85\n",
      "8012 번째 loss, accuracy:  0.4421843725221934 0.85\n",
      "8013 번째 loss, accuracy:  0.4421573645843632 0.85\n",
      "8014 번째 loss, accuracy:  0.4421303458625934 0.85\n",
      "8015 번째 loss, accuracy:  0.4421033163543511 0.85\n",
      "8016 번째 loss, accuracy:  0.4420762760571062 0.85\n",
      "8017 번째 loss, accuracy:  0.4420492249683338 0.85\n",
      "8018 번째 loss, accuracy:  0.44202216308551207 0.85\n",
      "8019 번째 loss, accuracy:  0.4419950904061233 0.85\n",
      "8020 번째 loss, accuracy:  0.44196800692765476 0.85\n",
      "8021 번째 loss, accuracy:  0.4419409126475957 0.85\n",
      "8022 번째 loss, accuracy:  0.4419138075634413 0.85\n",
      "8023 번째 loss, accuracy:  0.4418866916726895 0.85\n",
      "8024 번째 loss, accuracy:  0.441859564972843 0.85\n",
      "8025 번째 loss, accuracy:  0.44183242746140816 0.85\n",
      "8026 번째 loss, accuracy:  0.44180527913589507 0.85\n",
      "8027 번째 loss, accuracy:  0.4417781199938183 0.85\n",
      "8028 번째 loss, accuracy:  0.4417509500326957 0.85\n",
      "8029 번째 loss, accuracy:  0.4417237692500503 0.85\n",
      "8030 번째 loss, accuracy:  0.44169657764340803 0.85\n",
      "8031 번째 loss, accuracy:  0.44166937521029936 0.85\n",
      "8032 번째 loss, accuracy:  0.4416421619482591 0.85\n",
      "8033 번째 loss, accuracy:  0.44161493785482503 0.85\n",
      "8034 번째 loss, accuracy:  0.44158770292753957 0.85\n",
      "8035 번째 loss, accuracy:  0.44156045716394987 0.85\n",
      "8036 번째 loss, accuracy:  0.44153320056160617 0.85\n",
      "8037 번째 loss, accuracy:  0.44150593311806285 0.85\n",
      "8038 번째 loss, accuracy:  0.4414786548308784 0.85\n",
      "8039 번째 loss, accuracy:  0.4414513656976157 0.85\n",
      "8040 번째 loss, accuracy:  0.44142406571584136 0.85\n",
      "8041 번째 loss, accuracy:  0.44139675488312596 0.85\n",
      "8042 번째 loss, accuracy:  0.4413694331970442 0.85\n",
      "8043 번째 loss, accuracy:  0.4413421006551753 0.85\n",
      "8044 번째 loss, accuracy:  0.4413147572551017 0.85\n",
      "8045 번째 loss, accuracy:  0.44128740299441127 0.85\n",
      "8046 번째 loss, accuracy:  0.4412600378706941 0.85\n",
      "8047 번째 loss, accuracy:  0.4412326618815456 0.85\n",
      "8048 번째 loss, accuracy:  0.44120527502456525 0.85\n",
      "8049 번째 loss, accuracy:  0.4411778772973555 0.85\n",
      "8050 번째 loss, accuracy:  0.44115046869752483 0.85\n",
      "8051 번째 loss, accuracy:  0.44112304922268397 0.85\n",
      "8052 번째 loss, accuracy:  0.44109561887044874 0.85\n",
      "8053 번째 loss, accuracy:  0.44106817763843864 0.85\n",
      "8054 번째 loss, accuracy:  0.4410407255242776 0.85\n",
      "8055 번째 loss, accuracy:  0.44101326252559386 0.85\n",
      "8056 번째 loss, accuracy:  0.4409857886400186 0.85\n",
      "8057 번째 loss, accuracy:  0.44095830386518803 0.8583333333333333\n",
      "8058 번째 loss, accuracy:  0.4409308081987426 0.8583333333333333\n",
      "8059 번째 loss, accuracy:  0.4409033016383263 0.8583333333333333\n",
      "8060 번째 loss, accuracy:  0.44087578418158807 0.8583333333333333\n",
      "8061 번째 loss, accuracy:  0.44084825582618037 0.8583333333333333\n",
      "8062 번째 loss, accuracy:  0.44082071656975974 0.8583333333333333\n",
      "8063 번째 loss, accuracy:  0.44079316640998706 0.8583333333333333\n",
      "8064 번째 loss, accuracy:  0.4407656053445272 0.8583333333333333\n",
      "8065 번째 loss, accuracy:  0.4407380333710495 0.8583333333333333\n",
      "8066 번째 loss, accuracy:  0.44071045048722707 0.8583333333333333\n",
      "8067 번째 loss, accuracy:  0.4406828566907374 0.8583333333333333\n",
      "8068 번째 loss, accuracy:  0.4406552519792617 0.8583333333333333\n",
      "8069 번째 loss, accuracy:  0.4406276363504861 0.8583333333333333\n",
      "8070 번째 loss, accuracy:  0.44060000980210057 0.8583333333333333\n",
      "8071 번째 loss, accuracy:  0.4405723723317992 0.8583333333333333\n",
      "8072 번째 loss, accuracy:  0.4405447239372798 0.8583333333333333\n",
      "8073 번째 loss, accuracy:  0.4405170646162451 0.8583333333333333\n",
      "8074 번째 loss, accuracy:  0.4404893943664015 0.8583333333333333\n",
      "8075 번째 loss, accuracy:  0.4404617131854599 0.8583333333333333\n",
      "8076 번째 loss, accuracy:  0.4404340210711354 0.8583333333333333\n",
      "8077 번째 loss, accuracy:  0.4404063180211469 0.8583333333333333\n",
      "8078 번째 loss, accuracy:  0.44037860403321777 0.8583333333333333\n",
      "8079 번째 loss, accuracy:  0.4403508791050755 0.8583333333333333\n",
      "8080 번째 loss, accuracy:  0.4403231432344517 0.8583333333333333\n",
      "8081 번째 loss, accuracy:  0.44029539641908283 0.8583333333333333\n",
      "8082 번째 loss, accuracy:  0.44026763865670887 0.8583333333333333\n",
      "8083 번째 loss, accuracy:  0.44023986994507375 0.8583333333333333\n",
      "8084 번째 loss, accuracy:  0.4402120902819264 0.8583333333333333\n",
      "8085 번째 loss, accuracy:  0.4401842996650194 0.8583333333333333\n",
      "8086 번째 loss, accuracy:  0.44015649809211 0.8583333333333333\n",
      "8087 번째 loss, accuracy:  0.44012868556095947 0.8583333333333333\n",
      "8088 번째 loss, accuracy:  0.44010086206933335 0.8583333333333333\n",
      "8089 번째 loss, accuracy:  0.4400730276150007 0.8583333333333333\n",
      "8090 번째 loss, accuracy:  0.440045182195736 0.8583333333333333\n",
      "8091 번째 loss, accuracy:  0.4400173258093177 0.8583333333333333\n",
      "8092 번째 loss, accuracy:  0.4399894584535277 0.8583333333333333\n",
      "8093 번째 loss, accuracy:  0.43996158012615294 0.8583333333333333\n",
      "8094 번째 loss, accuracy:  0.43993369082498446 0.8583333333333333\n",
      "8095 번째 loss, accuracy:  0.4399057905478171 0.8583333333333333\n",
      "8096 번째 loss, accuracy:  0.4398778792924505 0.8583333333333333\n",
      "8097 번째 loss, accuracy:  0.43984995705668856 0.8583333333333333\n",
      "8098 번째 loss, accuracy:  0.4398220238383389 0.8583333333333333\n",
      "8099 번째 loss, accuracy:  0.4397940796352143 0.8583333333333333\n",
      "8100 번째 loss, accuracy:  0.439766124445131 0.8583333333333333\n",
      "8101 번째 loss, accuracy:  0.4397381582659098 0.8583333333333333\n",
      "8102 번째 loss, accuracy:  0.4397101810953759 0.8583333333333333\n",
      "8103 번째 loss, accuracy:  0.43968219293135863 0.8583333333333333\n",
      "8104 번째 loss, accuracy:  0.43965419377169196 0.8583333333333333\n",
      "8105 번째 loss, accuracy:  0.43962618361421363 0.8583333333333333\n",
      "8106 번째 loss, accuracy:  0.43959816245676625 0.8583333333333333\n",
      "8107 번째 loss, accuracy:  0.4395701302971957 0.8583333333333333\n",
      "8108 번째 loss, accuracy:  0.43954208713335347 0.8583333333333333\n",
      "8109 번째 loss, accuracy:  0.439514032963095 0.8583333333333333\n",
      "8110 번째 loss, accuracy:  0.4394859677842788 0.8583333333333333\n",
      "8111 번째 loss, accuracy:  0.4394578915947693 0.8583333333333333\n",
      "8112 번째 loss, accuracy:  0.4394298043924349 0.8583333333333333\n",
      "8113 번째 loss, accuracy:  0.4394017061751479 0.8583333333333333\n",
      "8114 번째 loss, accuracy:  0.4393735969407852 0.8583333333333333\n",
      "8115 번째 loss, accuracy:  0.439345476687228 0.8583333333333333\n",
      "8116 번째 loss, accuracy:  0.4393173454123616 0.8583333333333333\n",
      "8117 번째 loss, accuracy:  0.439289203114076 0.8583333333333333\n",
      "8118 번째 loss, accuracy:  0.4392610497902652 0.8583333333333333\n",
      "8119 번째 loss, accuracy:  0.4392328854388279 0.8583333333333333\n",
      "8120 번째 loss, accuracy:  0.4392047100576671 0.8583333333333333\n",
      "8121 번째 loss, accuracy:  0.43917652364468934 0.8583333333333333\n",
      "8122 번째 loss, accuracy:  0.439148326197807 0.8583333333333333\n",
      "8123 번째 loss, accuracy:  0.43912011771493586 0.8583333333333333\n",
      "8124 번째 loss, accuracy:  0.43909189819399663 0.8583333333333333\n",
      "8125 번째 loss, accuracy:  0.43906366763291327 0.8583333333333333\n",
      "8126 번째 loss, accuracy:  0.43903542602961537 0.8583333333333333\n",
      "8127 번째 loss, accuracy:  0.43900717338203604 0.8583333333333333\n",
      "8128 번째 loss, accuracy:  0.43897890968811326 0.8583333333333333\n",
      "8129 번째 loss, accuracy:  0.4389506349457892 0.8583333333333333\n",
      "8130 번째 loss, accuracy:  0.43892234915301054 0.8583333333333333\n",
      "8131 번째 loss, accuracy:  0.43889405230772854 0.8583333333333333\n",
      "8132 번째 loss, accuracy:  0.4388657444078985 0.8583333333333333\n",
      "8133 번째 loss, accuracy:  0.4388374254514799 0.8583333333333333\n",
      "8134 번째 loss, accuracy:  0.4388090954364375 0.8583333333333333\n",
      "8135 번째 loss, accuracy:  0.43878075436073977 0.8583333333333333\n",
      "8136 번째 loss, accuracy:  0.43875240222235956 0.8583333333333333\n",
      "8137 번째 loss, accuracy:  0.4387240390192744 0.8583333333333333\n",
      "8138 번째 loss, accuracy:  0.43869566474946625 0.8583333333333333\n",
      "8139 번째 loss, accuracy:  0.4386672794109213 0.8583333333333333\n",
      "8140 번째 loss, accuracy:  0.4386388830016306 0.8583333333333333\n",
      "8141 번째 loss, accuracy:  0.43861047551958887 0.8583333333333333\n",
      "8142 번째 loss, accuracy:  0.4385820569627963 0.8583333333333333\n",
      "8143 번째 loss, accuracy:  0.43855362732925657 0.8583333333333333\n",
      "8144 번째 loss, accuracy:  0.43852518661697826 0.8583333333333333\n",
      "8145 번째 loss, accuracy:  0.43849673482397417 0.8583333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8146 번째 loss, accuracy:  0.43846827194826155 0.8583333333333333\n",
      "8147 번째 loss, accuracy:  0.4384397979878629 0.8583333333333333\n",
      "8148 번째 loss, accuracy:  0.43841131294080404 0.8583333333333333\n",
      "8149 번째 loss, accuracy:  0.43838281680511576 0.8583333333333333\n",
      "8150 번째 loss, accuracy:  0.4383543095788334 0.8583333333333333\n",
      "8151 번째 loss, accuracy:  0.43832579125999677 0.8583333333333333\n",
      "8152 번째 loss, accuracy:  0.43829726184664974 0.8583333333333333\n",
      "8153 번째 loss, accuracy:  0.4382687213368416 0.8583333333333333\n",
      "8154 번째 loss, accuracy:  0.43824016972862484 0.8583333333333333\n",
      "8155 번째 loss, accuracy:  0.43821160702005735 0.8583333333333333\n",
      "8156 번째 loss, accuracy:  0.4381830332092013 0.8583333333333333\n",
      "8157 번째 loss, accuracy:  0.4381544482941233 0.8583333333333333\n",
      "8158 번째 loss, accuracy:  0.4381258522728943 0.8583333333333333\n",
      "8159 번째 loss, accuracy:  0.43809724514358994 0.8583333333333333\n",
      "8160 번째 loss, accuracy:  0.4380686269042903 0.8583333333333333\n",
      "8161 번째 loss, accuracy:  0.43803999755308 0.8583333333333333\n",
      "8162 번째 loss, accuracy:  0.4380113570880482 0.8583333333333333\n",
      "8163 번째 loss, accuracy:  0.43798270550728896 0.8583333333333333\n",
      "8164 번째 loss, accuracy:  0.4379540428088999 0.8583333333333333\n",
      "8165 번째 loss, accuracy:  0.43792536899098417 0.8583333333333333\n",
      "8166 번째 loss, accuracy:  0.43789668405164844 0.8583333333333333\n",
      "8167 번째 loss, accuracy:  0.43786798798900495 0.8583333333333333\n",
      "8168 번째 loss, accuracy:  0.4378392808011698 0.8583333333333333\n",
      "8169 번째 loss, accuracy:  0.43781056248626365 0.8583333333333333\n",
      "8170 번째 loss, accuracy:  0.4377818330424122 0.8583333333333333\n",
      "8171 번째 loss, accuracy:  0.43775309246774524 0.8583333333333333\n",
      "8172 번째 loss, accuracy:  0.4377243407603971 0.8583333333333333\n",
      "8173 번째 loss, accuracy:  0.4376955779185067 0.8583333333333333\n",
      "8174 번째 loss, accuracy:  0.43766680394021795 0.8583333333333333\n",
      "8175 번째 loss, accuracy:  0.4376380188236791 0.8583333333333333\n",
      "8176 번째 loss, accuracy:  0.43760922256704243 0.8583333333333333\n",
      "8177 번째 loss, accuracy:  0.43758041516846524 0.8583333333333333\n",
      "8178 번째 loss, accuracy:  0.4375515966261092 0.8583333333333333\n",
      "8179 번째 loss, accuracy:  0.43752276693814124 0.8583333333333333\n",
      "8180 번째 loss, accuracy:  0.4374939261027321 0.8583333333333333\n",
      "8181 번째 loss, accuracy:  0.43746507411805713 0.8583333333333333\n",
      "8182 번째 loss, accuracy:  0.43743621098229707 0.8583333333333333\n",
      "8183 번째 loss, accuracy:  0.43740733669363613 0.8583333333333333\n",
      "8184 번째 loss, accuracy:  0.4373784512502642 0.8583333333333333\n",
      "8185 번째 loss, accuracy:  0.4373495546503747 0.8583333333333333\n",
      "8186 번째 loss, accuracy:  0.4373206468921664 0.8583333333333333\n",
      "8187 번째 loss, accuracy:  0.43729172797384225 0.8583333333333333\n",
      "8188 번째 loss, accuracy:  0.4372627978936104 0.8583333333333333\n",
      "8189 번째 loss, accuracy:  0.4372338566496828 0.8583333333333333\n",
      "8190 번째 loss, accuracy:  0.4372049042402768 0.8583333333333333\n",
      "8191 번째 loss, accuracy:  0.43717594066361404 0.8583333333333333\n",
      "8192 번째 loss, accuracy:  0.43714696591792046 0.8583333333333333\n",
      "8193 번째 loss, accuracy:  0.4371179800014275 0.8583333333333333\n",
      "8194 번째 loss, accuracy:  0.43708898291237 0.8583333333333333\n",
      "8195 번째 loss, accuracy:  0.4370599746489881 0.8583333333333333\n",
      "8196 번째 loss, accuracy:  0.4370309552095272 0.8583333333333333\n",
      "8197 번째 loss, accuracy:  0.43700192459223614 0.8583333333333333\n",
      "8198 번째 loss, accuracy:  0.4369728827953691 0.8583333333333333\n",
      "8199 번째 loss, accuracy:  0.43694382981718494 0.8583333333333333\n",
      "8200 번째 loss, accuracy:  0.43691476565594695 0.8583333333333333\n",
      "8201 번째 loss, accuracy:  0.4368856903099231 0.8583333333333333\n",
      "8202 번째 loss, accuracy:  0.43685660377738617 0.8583333333333333\n",
      "8203 번째 loss, accuracy:  0.43682750605661397 0.8583333333333333\n",
      "8204 번째 loss, accuracy:  0.4367983971458879 0.8583333333333333\n",
      "8205 번째 loss, accuracy:  0.4367692770434948 0.8583333333333333\n",
      "8206 번째 loss, accuracy:  0.4367401457477261 0.8583333333333333\n",
      "8207 번째 loss, accuracy:  0.43671100325687784 0.8583333333333333\n",
      "8208 번째 loss, accuracy:  0.43668184956925055 0.8583333333333333\n",
      "8209 번째 loss, accuracy:  0.4366526846831499 0.8583333333333333\n",
      "8210 번째 loss, accuracy:  0.43662350859688637 0.8583333333333333\n",
      "8211 번째 loss, accuracy:  0.436594321308774 0.8583333333333333\n",
      "8212 번째 loss, accuracy:  0.43656512281713317 0.8583333333333333\n",
      "8213 번째 loss, accuracy:  0.43653591312028717 0.8583333333333333\n",
      "8214 번째 loss, accuracy:  0.4365066922165656 0.8583333333333333\n",
      "8215 번째 loss, accuracy:  0.4364774601043023 0.8583333333333333\n",
      "8216 번째 loss, accuracy:  0.4364482167818347 0.8583333333333333\n",
      "8217 번째 loss, accuracy:  0.4364189622475068 0.8583333333333333\n",
      "8218 번째 loss, accuracy:  0.4363896964996657 0.8583333333333333\n",
      "8219 번째 loss, accuracy:  0.4363604195366641 0.8583333333333333\n",
      "8220 번째 loss, accuracy:  0.43633113135685964 0.8583333333333333\n",
      "8221 번째 loss, accuracy:  0.43630183195861366 0.8583333333333333\n",
      "8222 번째 loss, accuracy:  0.43627252134029343 0.8583333333333333\n",
      "8223 번째 loss, accuracy:  0.4362431995002702 0.8583333333333333\n",
      "8224 번째 loss, accuracy:  0.4362138664369201 0.8583333333333333\n",
      "8225 번째 loss, accuracy:  0.436184522148624 0.8583333333333333\n",
      "8226 번째 loss, accuracy:  0.43615516663376774 0.8583333333333333\n",
      "8227 번째 loss, accuracy:  0.43612579989074146 0.8583333333333333\n",
      "8228 번째 loss, accuracy:  0.43609642191794085 0.8583333333333333\n",
      "8229 번째 loss, accuracy:  0.43606703271376585 0.8583333333333333\n",
      "8230 번째 loss, accuracy:  0.43603763227662085 0.8583333333333333\n",
      "8231 번째 loss, accuracy:  0.43600822060491556 0.8583333333333333\n",
      "8232 번째 loss, accuracy:  0.43597879769706444 0.8583333333333333\n",
      "8233 번째 loss, accuracy:  0.4359493635514861 0.8583333333333333\n",
      "8234 번째 loss, accuracy:  0.43591991816660447 0.8583333333333333\n",
      "8235 번째 loss, accuracy:  0.43589046154084843 0.8583333333333333\n",
      "8236 번째 loss, accuracy:  0.4358609936726514 0.8583333333333333\n",
      "8237 번째 loss, accuracy:  0.4358315145604512 0.8583333333333333\n",
      "8238 번째 loss, accuracy:  0.4358020242026913 0.8583333333333333\n",
      "8239 번째 loss, accuracy:  0.4357725225978191 0.8583333333333333\n",
      "8240 번째 loss, accuracy:  0.43574300974428737 0.8583333333333333\n",
      "8241 번째 loss, accuracy:  0.4357134856405536 0.8583333333333333\n",
      "8242 번째 loss, accuracy:  0.4356839502850798 0.8583333333333333\n",
      "8243 번째 loss, accuracy:  0.43565440367633335 0.8583333333333333\n",
      "8244 번째 loss, accuracy:  0.4356248458127856 0.8583333333333333\n",
      "8245 번째 loss, accuracy:  0.43559527669291337 0.8583333333333333\n",
      "8246 번째 loss, accuracy:  0.4355656963151981 0.8583333333333333\n",
      "8247 번째 loss, accuracy:  0.4355361046781263 0.8583333333333333\n",
      "8248 번째 loss, accuracy:  0.4355065017801891 0.8583333333333333\n",
      "8249 번째 loss, accuracy:  0.43547688761988257 0.8583333333333333\n",
      "8250 번째 loss, accuracy:  0.43544726219570706 0.8583333333333333\n",
      "8251 번째 loss, accuracy:  0.4354176255061687 0.8583333333333333\n",
      "8252 번째 loss, accuracy:  0.43538797754977776 0.8583333333333333\n",
      "8253 번째 loss, accuracy:  0.4353583183250498 0.8583333333333333\n",
      "8254 번째 loss, accuracy:  0.435328647830505 0.8583333333333333\n",
      "8255 번째 loss, accuracy:  0.4352989660646684 0.8583333333333333\n",
      "8256 번째 loss, accuracy:  0.4352692730260699 0.8583333333333333\n",
      "8257 번째 loss, accuracy:  0.4352395687132443 0.8583333333333333\n",
      "8258 번째 loss, accuracy:  0.4352098531247314 0.8583333333333333\n",
      "8259 번째 loss, accuracy:  0.4351801262590757 0.8583333333333333\n",
      "8260 번째 loss, accuracy:  0.4351503881148263 0.8583333333333333\n",
      "8261 번째 loss, accuracy:  0.43512063869053785 0.8583333333333333\n",
      "8262 번째 loss, accuracy:  0.4350908779847696 0.8583333333333333\n",
      "8263 번째 loss, accuracy:  0.4350611059960852 0.8583333333333333\n",
      "8264 번째 loss, accuracy:  0.43503132272305395 0.8666666666666667\n",
      "8265 번째 loss, accuracy:  0.43500152816424964 0.8666666666666667\n",
      "8266 번째 loss, accuracy:  0.43497172231825104 0.8666666666666667\n",
      "8267 번째 loss, accuracy:  0.4349419051836417 0.8666666666666667\n",
      "8268 번째 loss, accuracy:  0.4349120767590101 0.8666666666666667\n",
      "8269 번째 loss, accuracy:  0.43488223704294976 0.8666666666666667\n",
      "8270 번째 loss, accuracy:  0.4348523860340593 0.8666666666666667\n",
      "8271 번째 loss, accuracy:  0.4348225237309416 0.8666666666666667\n",
      "8272 번째 loss, accuracy:  0.4347926501322052 0.8666666666666667\n",
      "8273 번째 loss, accuracy:  0.4347627652364627 0.8666666666666667\n",
      "8274 번째 loss, accuracy:  0.4347328690423327 0.8666666666666667\n",
      "8275 번째 loss, accuracy:  0.43470296154843846 0.8666666666666667\n",
      "8276 번째 loss, accuracy:  0.43467304275340696 0.8666666666666667\n",
      "8277 번째 loss, accuracy:  0.43464311265587174 0.8666666666666667\n",
      "8278 번째 loss, accuracy:  0.4346131712544711 0.8666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8279 번째 loss, accuracy:  0.4345832185478466 0.8666666666666667\n",
      "8280 번째 loss, accuracy:  0.43455325453464677 0.8666666666666667\n",
      "8281 번째 loss, accuracy:  0.43452327921352385 0.8666666666666667\n",
      "8282 번째 loss, accuracy:  0.4344932925831355 0.8666666666666667\n",
      "8283 번째 loss, accuracy:  0.4344632946421444 0.8666666666666667\n",
      "8284 번째 loss, accuracy:  0.434433285389218 0.8666666666666667\n",
      "8285 번째 loss, accuracy:  0.43440326482302877 0.8666666666666667\n",
      "8286 번째 loss, accuracy:  0.43437323294225433 0.8666666666666667\n",
      "8287 번째 loss, accuracy:  0.4343431897455771 0.8666666666666667\n",
      "8288 번째 loss, accuracy:  0.4343131352316842 0.8666666666666667\n",
      "8289 번째 loss, accuracy:  0.43428306939926814 0.8666666666666667\n",
      "8290 번째 loss, accuracy:  0.43425299224702635 0.8666666666666667\n",
      "8291 번째 loss, accuracy:  0.4342229037736612 0.8666666666666667\n",
      "8292 번째 loss, accuracy:  0.4341928039778803 0.8666666666666667\n",
      "8293 번째 loss, accuracy:  0.4341626928583958 0.8666666666666667\n",
      "8294 번째 loss, accuracy:  0.43413257041392467 0.8666666666666667\n",
      "8295 번째 loss, accuracy:  0.43410243664318954 0.8666666666666667\n",
      "8296 번째 loss, accuracy:  0.4340722915449179 0.8666666666666667\n",
      "8297 번째 loss, accuracy:  0.434042135117842 0.8666666666666667\n",
      "8298 번째 loss, accuracy:  0.4340119673606993 0.8666666666666667\n",
      "8299 번째 loss, accuracy:  0.43398178827223205 0.8666666666666667\n",
      "8300 번째 loss, accuracy:  0.43395159785118775 0.8666666666666667\n",
      "8301 번째 loss, accuracy:  0.433921396096319 0.8666666666666667\n",
      "8302 번째 loss, accuracy:  0.433891183006383 0.8666666666666667\n",
      "8303 번째 loss, accuracy:  0.4338609585801423 0.8666666666666667\n",
      "8304 번째 loss, accuracy:  0.43383072281636464 0.8666666666666667\n",
      "8305 번째 loss, accuracy:  0.4338004757138222 0.8666666666666667\n",
      "8306 번째 loss, accuracy:  0.4337702172712928 0.8666666666666667\n",
      "8307 번째 loss, accuracy:  0.4337399474875594 0.8666666666666667\n",
      "8308 번째 loss, accuracy:  0.4337096663614094 0.8666666666666667\n",
      "8309 번째 loss, accuracy:  0.4336793738916355 0.8666666666666667\n",
      "8310 번째 loss, accuracy:  0.4336490700770355 0.8666666666666667\n",
      "8311 번째 loss, accuracy:  0.4336187549164123 0.8666666666666667\n",
      "8312 번째 loss, accuracy:  0.43358842840857387 0.8666666666666667\n",
      "8313 번째 loss, accuracy:  0.4335580905523332 0.8666666666666667\n",
      "8314 번째 loss, accuracy:  0.4335277413465083 0.8666666666666667\n",
      "8315 번째 loss, accuracy:  0.4334973807899223 0.8666666666666667\n",
      "8316 번째 loss, accuracy:  0.43346700888140394 0.8666666666666667\n",
      "8317 번째 loss, accuracy:  0.43343662561978535 0.8666666666666667\n",
      "8318 번째 loss, accuracy:  0.433406231003906 0.8666666666666667\n",
      "8319 번째 loss, accuracy:  0.4333758250326092 0.8666666666666667\n",
      "8320 번째 loss, accuracy:  0.43334540770474317 0.8666666666666667\n",
      "8321 번째 loss, accuracy:  0.433314979019162 0.8666666666666667\n",
      "8322 번째 loss, accuracy:  0.4332845389747238 0.8666666666666667\n",
      "8323 번째 loss, accuracy:  0.43325408757029255 0.8666666666666667\n",
      "8324 번째 loss, accuracy:  0.43322362480473764 0.8666666666666667\n",
      "8325 번째 loss, accuracy:  0.43319315067693315 0.8666666666666667\n",
      "8326 번째 loss, accuracy:  0.43316266518575774 0.8666666666666667\n",
      "8327 번째 loss, accuracy:  0.4331321683300961 0.8666666666666667\n",
      "8328 번째 loss, accuracy:  0.43310166010883744 0.8666666666666667\n",
      "8329 번째 loss, accuracy:  0.4330711405208764 0.8666666666666667\n",
      "8330 번째 loss, accuracy:  0.4330406095651128 0.8666666666666667\n",
      "8331 번째 loss, accuracy:  0.4330100672404511 0.8666666666666667\n",
      "8332 번째 loss, accuracy:  0.43297951354580155 0.8666666666666667\n",
      "8333 번째 loss, accuracy:  0.43294894848007914 0.8666666666666667\n",
      "8334 번째 loss, accuracy:  0.4329183720422038 0.8666666666666667\n",
      "8335 번째 loss, accuracy:  0.43288778423110075 0.8666666666666667\n",
      "8336 번째 loss, accuracy:  0.4328571850457011 0.8666666666666667\n",
      "8337 번째 loss, accuracy:  0.4328265744849401 0.8666666666666667\n",
      "8338 번째 loss, accuracy:  0.4327959525477588 0.8666666666666667\n",
      "8339 번째 loss, accuracy:  0.4327653192331031 0.8666666666666667\n",
      "8340 번째 loss, accuracy:  0.432734674539924 0.8666666666666667\n",
      "8341 번째 loss, accuracy:  0.43270401846717754 0.8666666666666667\n",
      "8342 번째 loss, accuracy:  0.4326733510138254 0.8666666666666667\n",
      "8343 번째 loss, accuracy:  0.43264267217883423 0.8666666666666667\n",
      "8344 번째 loss, accuracy:  0.432611981961176 0.8666666666666667\n",
      "8345 번째 loss, accuracy:  0.4325812803598273 0.8666666666666667\n",
      "8346 번째 loss, accuracy:  0.4325505673737702 0.8666666666666667\n",
      "8347 번째 loss, accuracy:  0.4325198430019926 0.8666666666666667\n",
      "8348 번째 loss, accuracy:  0.4324891072434864 0.8666666666666667\n",
      "8349 번째 loss, accuracy:  0.4324583600972497 0.8666666666666667\n",
      "8350 번째 loss, accuracy:  0.4324276015622857 0.8666666666666667\n",
      "8351 번째 loss, accuracy:  0.4323968316376018 0.8666666666666667\n",
      "8352 번째 loss, accuracy:  0.4323660503222121 0.8666666666666667\n",
      "8353 번째 loss, accuracy:  0.43233525761513436 0.8666666666666667\n",
      "8354 번째 loss, accuracy:  0.4323044535153929 0.8666666666666667\n",
      "8355 번째 loss, accuracy:  0.43227363802201624 0.8666666666666667\n",
      "8356 번째 loss, accuracy:  0.4322428111340386 0.8666666666666667\n",
      "8357 번째 loss, accuracy:  0.4322119728504994 0.8666666666666667\n",
      "8358 번째 loss, accuracy:  0.4321811231704435 0.8666666666666667\n",
      "8359 번째 loss, accuracy:  0.4321502620929205 0.8666666666666667\n",
      "8360 번째 loss, accuracy:  0.4321193896169852 0.8666666666666667\n",
      "8361 번째 loss, accuracy:  0.4320885057416984 0.8666666666666667\n",
      "8362 번째 loss, accuracy:  0.4320576104661254 0.8666666666666667\n",
      "8363 번째 loss, accuracy:  0.43202670378933694 0.8666666666666667\n",
      "8364 번째 loss, accuracy:  0.4319957857104091 0.8666666666666667\n",
      "8365 번째 loss, accuracy:  0.4319648562284232 0.8666666666666667\n",
      "8366 번째 loss, accuracy:  0.4319339153424657 0.8666666666666667\n",
      "8367 번째 loss, accuracy:  0.43190296305162834 0.8666666666666667\n",
      "8368 번째 loss, accuracy:  0.43187199935500786 0.8666666666666667\n",
      "8369 번째 loss, accuracy:  0.43184102425170706 0.8666666666666667\n",
      "8370 번째 loss, accuracy:  0.4318100377408334 0.8666666666666667\n",
      "8371 번째 loss, accuracy:  0.4317790398214993 0.8666666666666667\n",
      "8372 번째 loss, accuracy:  0.431748030492823 0.8666666666666667\n",
      "8373 번째 loss, accuracy:  0.4317170097539279 0.8666666666666667\n",
      "8374 번째 loss, accuracy:  0.43168597760394267 0.8666666666666667\n",
      "8375 번째 loss, accuracy:  0.4316549340420011 0.8666666666666667\n",
      "8376 번째 loss, accuracy:  0.4316238790672427 0.8666666666666667\n",
      "8377 번째 loss, accuracy:  0.43159281267881155 0.8666666666666667\n",
      "8378 번째 loss, accuracy:  0.43156173487585786 0.8666666666666667\n",
      "8379 번째 loss, accuracy:  0.43153064565753624 0.8666666666666667\n",
      "8380 번째 loss, accuracy:  0.4314995450230074 0.8666666666666667\n",
      "8381 번째 loss, accuracy:  0.431468432971437 0.8666666666666667\n",
      "8382 번째 loss, accuracy:  0.4314373095019956 0.8666666666666667\n",
      "8383 번째 loss, accuracy:  0.43140617461386 0.8666666666666667\n",
      "8384 번째 loss, accuracy:  0.43137502830621177 0.8666666666666667\n",
      "8385 번째 loss, accuracy:  0.4313438705782373 0.8666666666666667\n",
      "8386 번째 loss, accuracy:  0.4313127014291294 0.8666666666666667\n",
      "8387 번째 loss, accuracy:  0.4312815208580853 0.8666666666666667\n",
      "8388 번째 loss, accuracy:  0.4312503288643081 0.8666666666666667\n",
      "8389 번째 loss, accuracy:  0.4312191254470056 0.8666666666666667\n",
      "8390 번째 loss, accuracy:  0.431187910605392 0.8666666666666667\n",
      "8391 번째 loss, accuracy:  0.43115668433868576 0.8666666666666667\n",
      "8392 번째 loss, accuracy:  0.4311254466461109 0.8666666666666667\n",
      "8393 번째 loss, accuracy:  0.4310941975268972 0.8666666666666667\n",
      "8394 번째 loss, accuracy:  0.4310629369802793 0.8666666666666667\n",
      "8395 번째 loss, accuracy:  0.4310316650054975 0.8666666666666667\n",
      "8396 번째 loss, accuracy:  0.43100038160179804 0.8666666666666667\n",
      "8397 번째 loss, accuracy:  0.4309690867684314 0.8666666666666667\n",
      "8398 번째 loss, accuracy:  0.4309377805046536 0.8666666666666667\n",
      "8399 번째 loss, accuracy:  0.4309064628097266 0.8666666666666667\n",
      "8400 번째 loss, accuracy:  0.4308751336829173 0.8666666666666667\n",
      "8401 번째 loss, accuracy:  0.43084379312349813 0.8666666666666667\n",
      "8402 번째 loss, accuracy:  0.43081244113074696 0.8666666666666667\n",
      "8403 번째 loss, accuracy:  0.43078107770394697 0.8666666666666667\n",
      "8404 번째 loss, accuracy:  0.43074970284238673 0.8666666666666667\n",
      "8405 번째 loss, accuracy:  0.43071831654536 0.8666666666666667\n",
      "8406 번째 loss, accuracy:  0.430686918812166 0.8666666666666667\n",
      "8407 번째 loss, accuracy:  0.43065550964210975 0.8666666666666667\n",
      "8408 번째 loss, accuracy:  0.43062408903450095 0.8666666666666667\n",
      "8409 번째 loss, accuracy:  0.43059265698865506 0.8666666666666667\n",
      "8410 번째 loss, accuracy:  0.4305612135038929 0.8666666666666667\n",
      "8411 번째 loss, accuracy:  0.430529758579541 0.8666666666666667\n",
      "8412 번째 loss, accuracy:  0.4304982922149308 0.8666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8413 번째 loss, accuracy:  0.4304668144093996 0.8666666666666667\n",
      "8414 번째 loss, accuracy:  0.43043532516228955 0.8666666666666667\n",
      "8415 번째 loss, accuracy:  0.4304038244729493 0.8666666666666667\n",
      "8416 번째 loss, accuracy:  0.43037231234073114 0.8666666666666667\n",
      "8417 번째 loss, accuracy:  0.43034078876499465 0.8666666666666667\n",
      "8418 번째 loss, accuracy:  0.43030925374510337 0.8666666666666667\n",
      "8419 번째 loss, accuracy:  0.4302777072804272 0.8666666666666667\n",
      "8420 번째 loss, accuracy:  0.43024614937034084 0.8666666666666667\n",
      "8421 번째 loss, accuracy:  0.43021458001422525 0.8666666666666667\n",
      "8422 번째 loss, accuracy:  0.4301829992114661 0.8666666666666667\n",
      "8423 번째 loss, accuracy:  0.43015140696145443 0.8666666666666667\n",
      "8424 번째 loss, accuracy:  0.4301198032635873 0.8666666666666667\n",
      "8425 번째 loss, accuracy:  0.4300881881172669 0.8666666666666667\n",
      "8426 번째 loss, accuracy:  0.43005656152190064 0.8666666666666667\n",
      "8427 번째 loss, accuracy:  0.4300249234769022 0.8666666666666667\n",
      "8428 번째 loss, accuracy:  0.42999327398168957 0.8666666666666667\n",
      "8429 번째 loss, accuracy:  0.4299616130356873 0.8666666666666667\n",
      "8430 번째 loss, accuracy:  0.42992994063832435 0.8666666666666667\n",
      "8431 번째 loss, accuracy:  0.42989825678903615 0.8666666666666667\n",
      "8432 번째 loss, accuracy:  0.4298665614872628 0.8666666666666667\n",
      "8433 번째 loss, accuracy:  0.42983485473245026 0.8666666666666667\n",
      "8434 번째 loss, accuracy:  0.42980313652404983 0.8666666666666667\n",
      "8435 번째 loss, accuracy:  0.4297714068615186 0.8666666666666667\n",
      "8436 번째 loss, accuracy:  0.42973966574431877 0.8666666666666667\n",
      "8437 번째 loss, accuracy:  0.42970791317191825 0.8666666666666667\n",
      "8438 번째 loss, accuracy:  0.4296761491437902 0.8666666666666667\n",
      "8439 번째 loss, accuracy:  0.42964437365941366 0.8666666666666667\n",
      "8440 번째 loss, accuracy:  0.4296125867182726 0.8666666666666667\n",
      "8441 번째 loss, accuracy:  0.4295807883198573 0.8666666666666667\n",
      "8442 번째 loss, accuracy:  0.4295489784636626 0.8666666666666667\n",
      "8443 번째 loss, accuracy:  0.4295171571491893 0.8666666666666667\n",
      "8444 번째 loss, accuracy:  0.42948532437594383 0.8666666666666667\n",
      "8445 번째 loss, accuracy:  0.4294534801434379 0.8666666666666667\n",
      "8446 번째 loss, accuracy:  0.42942162445118925 0.8666666666666667\n",
      "8447 번째 loss, accuracy:  0.4293897572987203 0.8666666666666667\n",
      "8448 번째 loss, accuracy:  0.42935787868555975 0.8666666666666667\n",
      "8449 번째 loss, accuracy:  0.42932598861124105 0.8666666666666667\n",
      "8450 번째 loss, accuracy:  0.42929408707530387 0.8666666666666667\n",
      "8451 번째 loss, accuracy:  0.4292621740772934 0.8666666666666667\n",
      "8452 번째 loss, accuracy:  0.4292302496167598 0.8666666666666667\n",
      "8453 번째 loss, accuracy:  0.42919831369325917 0.8666666666666667\n",
      "8454 번째 loss, accuracy:  0.42916636630635324 0.8666666666666667\n",
      "8455 번째 loss, accuracy:  0.4291344074556086 0.8666666666666667\n",
      "8456 번째 loss, accuracy:  0.4291024371405981 0.8666666666666667\n",
      "8457 번째 loss, accuracy:  0.4290704553609001 0.8666666666666667\n",
      "8458 번째 loss, accuracy:  0.4290384621160984 0.8666666666666667\n",
      "8459 번째 loss, accuracy:  0.429006457405782 0.8666666666666667\n",
      "8460 번째 loss, accuracy:  0.4289744412295459 0.8666666666666667\n",
      "8461 번째 loss, accuracy:  0.42894241358699065 0.8666666666666667\n",
      "8462 번째 loss, accuracy:  0.42891037447772207 0.8666666666666667\n",
      "8463 번째 loss, accuracy:  0.42887832390135167 0.8666666666666667\n",
      "8464 번째 loss, accuracy:  0.4288462618574967 0.8666666666666667\n",
      "8465 번째 loss, accuracy:  0.42881418834577983 0.8666666666666667\n",
      "8466 번째 loss, accuracy:  0.42878210336582917 0.8666666666666667\n",
      "8467 번째 loss, accuracy:  0.42875000691727844 0.8666666666666667\n",
      "8468 번째 loss, accuracy:  0.4287178989997676 0.8666666666666667\n",
      "8469 번째 loss, accuracy:  0.4286857796129412 0.8666666666666667\n",
      "8470 번째 loss, accuracy:  0.42865364875644996 0.8666666666666667\n",
      "8471 번째 loss, accuracy:  0.42862150642995006 0.8666666666666667\n",
      "8472 번째 loss, accuracy:  0.4285893526331032 0.8666666666666667\n",
      "8473 번째 loss, accuracy:  0.4285571873655771 0.8666666666666667\n",
      "8474 번째 loss, accuracy:  0.4285250106270445 0.8666666666666667\n",
      "8475 번째 loss, accuracy:  0.4284928224171837 0.8666666666666667\n",
      "8476 번째 loss, accuracy:  0.4284606227356792 0.8666666666666667\n",
      "8477 번째 loss, accuracy:  0.4284284115822208 0.8666666666666667\n",
      "8478 번째 loss, accuracy:  0.4283961889565037 0.8666666666666667\n",
      "8479 번째 loss, accuracy:  0.4283639548582295 0.8666666666666667\n",
      "8480 번째 loss, accuracy:  0.42833170928710396 0.8666666666666667\n",
      "8481 번째 loss, accuracy:  0.4282994522428398 0.8666666666666667\n",
      "8482 번째 loss, accuracy:  0.4282671837251551 0.8666666666666667\n",
      "8483 번째 loss, accuracy:  0.4282349037337735 0.8666666666666667\n",
      "8484 번째 loss, accuracy:  0.42820261226842365 0.8666666666666667\n",
      "8485 번째 loss, accuracy:  0.4281703093288405 0.8666666666666667\n",
      "8486 번째 loss, accuracy:  0.4281379949147644 0.8666666666666667\n",
      "8487 번째 loss, accuracy:  0.42810566902594166 0.8666666666666667\n",
      "8488 번째 loss, accuracy:  0.428073331662124 0.8666666666666667\n",
      "8489 번째 loss, accuracy:  0.4280409828230686 0.8666666666666667\n",
      "8490 번째 loss, accuracy:  0.42800862250853855 0.8666666666666667\n",
      "8491 번째 loss, accuracy:  0.4279762507183025 0.8666666666666667\n",
      "8492 번째 loss, accuracy:  0.4279438674521346 0.8666666666666667\n",
      "8493 번째 loss, accuracy:  0.4279114727098151 0.8666666666666667\n",
      "8494 번째 loss, accuracy:  0.4278790664911296 0.8666666666666667\n",
      "8495 번째 loss, accuracy:  0.4278466487958692 0.8666666666666667\n",
      "8496 번째 loss, accuracy:  0.4278142196238311 0.8666666666666667\n",
      "8497 번째 loss, accuracy:  0.42778177897481734 0.8666666666666667\n",
      "8498 번째 loss, accuracy:  0.42774932684863703 0.8666666666666667\n",
      "8499 번째 loss, accuracy:  0.42771686324510383 0.8666666666666667\n",
      "8500 번째 loss, accuracy:  0.4276843881640372 0.8666666666666667\n",
      "8501 번째 loss, accuracy:  0.42765190160526273 0.8666666666666667\n",
      "8502 번째 loss, accuracy:  0.42761940356861144 0.8666666666666667\n",
      "8503 번째 loss, accuracy:  0.4275868940539199 0.8666666666666667\n",
      "8504 번째 loss, accuracy:  0.42755437306103056 0.8666666666666667\n",
      "8505 번째 loss, accuracy:  0.4275218405897915 0.8666666666666667\n",
      "8506 번째 loss, accuracy:  0.4274892966400566 0.8666666666666667\n",
      "8507 번째 loss, accuracy:  0.4274567412116853 0.8666666666666667\n",
      "8508 번째 loss, accuracy:  0.42742417430454277 0.8666666666666667\n",
      "8509 번째 loss, accuracy:  0.4273915959184998 0.8666666666666667\n",
      "8510 번째 loss, accuracy:  0.42735900605343324 0.8666666666666667\n",
      "8511 번째 loss, accuracy:  0.42732640470922534 0.8666666666666667\n",
      "8512 번째 loss, accuracy:  0.4272937918857641 0.8666666666666667\n",
      "8513 번째 loss, accuracy:  0.42726116758294325 0.8666666666666667\n",
      "8514 번째 loss, accuracy:  0.4272285318006623 0.8666666666666667\n",
      "8515 번째 loss, accuracy:  0.4271958845388261 0.8666666666666667\n",
      "8516 번째 loss, accuracy:  0.4271632257973465 0.8666666666666667\n",
      "8517 번째 loss, accuracy:  0.42713055557613927 0.8666666666666667\n",
      "8518 번째 loss, accuracy:  0.42709787387512727 0.8666666666666667\n",
      "8519 번째 loss, accuracy:  0.4270651806942384 0.8666666666666667\n",
      "8520 번째 loss, accuracy:  0.4270324760334065 0.8666666666666667\n",
      "8521 번째 loss, accuracy:  0.42699975989257094 0.8666666666666667\n",
      "8522 번째 loss, accuracy:  0.42696703227167754 0.8666666666666667\n",
      "8523 번째 loss, accuracy:  0.42693429317067744 0.8666666666666667\n",
      "8524 번째 loss, accuracy:  0.4269015425895269 0.8666666666666667\n",
      "8525 번째 loss, accuracy:  0.4268687805281889 0.8666666666666667\n",
      "8526 번째 loss, accuracy:  0.4268360069866315 0.8666666666666667\n",
      "8527 번째 loss, accuracy:  0.4268032219648291 0.8666666666666667\n",
      "8528 번째 loss, accuracy:  0.4267704254627612 0.8666666666666667\n",
      "8529 번째 loss, accuracy:  0.4267376174804139 0.8666666666666667\n",
      "8530 번째 loss, accuracy:  0.4267047980177783 0.8666666666666667\n",
      "8531 번째 loss, accuracy:  0.4266719670748517 0.8666666666666667\n",
      "8532 번째 loss, accuracy:  0.42663912465163684 0.8666666666666667\n",
      "8533 번째 loss, accuracy:  0.4266062707481422 0.8666666666666667\n",
      "8534 번째 loss, accuracy:  0.42657340536438254 0.8666666666666667\n",
      "8535 번째 loss, accuracy:  0.4265405285003784 0.8666666666666667\n",
      "8536 번째 loss, accuracy:  0.42650764015615555 0.8666666666666667\n",
      "8537 번째 loss, accuracy:  0.42647474033174587 0.8666666666666667\n",
      "8538 번째 loss, accuracy:  0.42644182902718647 0.8666666666666667\n",
      "8539 번째 loss, accuracy:  0.42640890624252165 0.8666666666666667\n",
      "8540 번째 loss, accuracy:  0.4263759719778 0.8666666666666667\n",
      "8541 번째 loss, accuracy:  0.4263430262330765 0.8666666666666667\n",
      "8542 번째 loss, accuracy:  0.42631006900841206 0.8666666666666667\n",
      "8543 번째 loss, accuracy:  0.42627710030387356 0.8666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544 번째 loss, accuracy:  0.4262441201195331 0.8666666666666667\n",
      "8545 번째 loss, accuracy:  0.42621112845546877 0.8666666666666667\n",
      "8546 번째 loss, accuracy:  0.4261781253117649 0.8666666666666667\n",
      "8547 번째 loss, accuracy:  0.42614511068851113 0.8666666666666667\n",
      "8548 번째 loss, accuracy:  0.42611208458580313 0.8666666666666667\n",
      "8549 번째 loss, accuracy:  0.42607904700374244 0.8666666666666667\n",
      "8550 번째 loss, accuracy:  0.42604599794243636 0.8666666666666667\n",
      "8551 번째 loss, accuracy:  0.4260129374019978 0.8666666666666667\n",
      "8552 번째 loss, accuracy:  0.42597986538254606 0.8666666666666667\n",
      "8553 번째 loss, accuracy:  0.42594678188420587 0.8666666666666667\n",
      "8554 번째 loss, accuracy:  0.42591368690710746 0.8666666666666667\n",
      "8555 번째 loss, accuracy:  0.42588058045138755 0.8666666666666667\n",
      "8556 번째 loss, accuracy:  0.42584746251718825 0.8666666666666667\n",
      "8557 번째 loss, accuracy:  0.4258143331046579 0.8666666666666667\n",
      "8558 번째 loss, accuracy:  0.4257811922139503 0.8666666666666667\n",
      "8559 번째 loss, accuracy:  0.4257480398452252 0.8666666666666667\n",
      "8560 번째 loss, accuracy:  0.4257148759986484 0.8666666666666667\n",
      "8561 번째 loss, accuracy:  0.4256817006743915 0.8666666666666667\n",
      "8562 번째 loss, accuracy:  0.4256485138726314 0.8666666666666667\n",
      "8563 번째 loss, accuracy:  0.4256153155935519 0.8666666666666667\n",
      "8564 번째 loss, accuracy:  0.42558210583734185 0.8666666666666667\n",
      "8565 번째 loss, accuracy:  0.4255488846041963 0.8666666666666667\n",
      "8566 번째 loss, accuracy:  0.42551565189431584 0.8666666666666667\n",
      "8567 번째 loss, accuracy:  0.4254824077079072 0.8666666666666667\n",
      "8568 번째 loss, accuracy:  0.4254491520451829 0.8666666666666667\n",
      "8569 번째 loss, accuracy:  0.4254158849063613 0.8666666666666667\n",
      "8570 번째 loss, accuracy:  0.4253826062916669 0.8666666666666667\n",
      "8571 번째 loss, accuracy:  0.4253493162013299 0.8666666666666667\n",
      "8572 번째 loss, accuracy:  0.425316014635586 0.8666666666666667\n",
      "8573 번째 loss, accuracy:  0.42528270159467724 0.8666666666666667\n",
      "8574 번째 loss, accuracy:  0.42524937707885174 0.8666666666666667\n",
      "8575 번째 loss, accuracy:  0.4252160410883628 0.8666666666666667\n",
      "8576 번째 loss, accuracy:  0.4251826936234707 0.8666666666666667\n",
      "8577 번째 loss, accuracy:  0.42514933468444044 0.8666666666666667\n",
      "8578 번째 loss, accuracy:  0.42511596427154325 0.8666666666666667\n",
      "8579 번째 loss, accuracy:  0.42508258238505675 0.8666666666666667\n",
      "8580 번째 loss, accuracy:  0.4250491890252642 0.8666666666666667\n",
      "8581 번째 loss, accuracy:  0.42501578419245406 0.8666666666666667\n",
      "8582 번째 loss, accuracy:  0.42498236788692195 0.8666666666666667\n",
      "8583 번째 loss, accuracy:  0.4249489401089687 0.8666666666666667\n",
      "8584 번째 loss, accuracy:  0.4249155008589014 0.8666666666666667\n",
      "8585 번째 loss, accuracy:  0.4248820501370323 0.8666666666666667\n",
      "8586 번째 loss, accuracy:  0.4248485879436803 0.8666666666666667\n",
      "8587 번째 loss, accuracy:  0.4248151142791695 0.8666666666666667\n",
      "8588 번째 loss, accuracy:  0.42478162914383105 0.8666666666666667\n",
      "8589 번째 loss, accuracy:  0.42474813253800114 0.8666666666666667\n",
      "8590 번째 loss, accuracy:  0.4247146244620222 0.8666666666666667\n",
      "8591 번째 loss, accuracy:  0.42468110491624267 0.8666666666666667\n",
      "8592 번째 loss, accuracy:  0.42464757390101593 0.8666666666666667\n",
      "8593 번째 loss, accuracy:  0.4246140314167033 0.8666666666666667\n",
      "8594 번째 loss, accuracy:  0.4245804774636702 0.8666666666666667\n",
      "8595 번째 loss, accuracy:  0.4245469120422887 0.8666666666666667\n",
      "8596 번째 loss, accuracy:  0.4245133351529367 0.8666666666666667\n",
      "8597 번째 loss, accuracy:  0.4244797467959985 0.8666666666666667\n",
      "8598 번째 loss, accuracy:  0.4244461469718638 0.8666666666666667\n",
      "8599 번째 loss, accuracy:  0.42441253568092824 0.8666666666666667\n",
      "8600 번째 loss, accuracy:  0.42437891292359387 0.8666666666666667\n",
      "8601 번째 loss, accuracy:  0.4243452787002682 0.8666666666666667\n",
      "8602 번째 loss, accuracy:  0.42431163301136543 0.8666666666666667\n",
      "8603 번째 loss, accuracy:  0.4242779758573043 0.8666666666666667\n",
      "8604 번째 loss, accuracy:  0.4242443072385111 0.8666666666666667\n",
      "8605 번째 loss, accuracy:  0.4242106271554171 0.8666666666666667\n",
      "8606 번째 loss, accuracy:  0.42417693560845987 0.8666666666666667\n",
      "8607 번째 loss, accuracy:  0.4241432325980832 0.8666666666666667\n",
      "8608 번째 loss, accuracy:  0.42410951812473613 0.8666666666666667\n",
      "8609 번째 loss, accuracy:  0.4240757921888745 0.8666666666666667\n",
      "8610 번째 loss, accuracy:  0.4240420547909596 0.8666666666666667\n",
      "8611 번째 loss, accuracy:  0.42400830593145916 0.8666666666666667\n",
      "8612 번째 loss, accuracy:  0.42397454561084635 0.8666666666666667\n",
      "8613 번째 loss, accuracy:  0.4239407738296002 0.8666666666666667\n",
      "8614 번째 loss, accuracy:  0.42390699058820663 0.8666666666666667\n",
      "8615 번째 loss, accuracy:  0.42387319588715683 0.8666666666666667\n",
      "8616 번째 loss, accuracy:  0.42383938972694823 0.8666666666666667\n",
      "8617 번째 loss, accuracy:  0.4238055721080842 0.8666666666666667\n",
      "8618 번째 loss, accuracy:  0.4237717430310738 0.8666666666666667\n",
      "8619 번째 loss, accuracy:  0.4237379024964327 0.8666666666666667\n",
      "8620 번째 loss, accuracy:  0.4237040505046821 0.8666666666666667\n",
      "8621 번째 loss, accuracy:  0.4236701870563494 0.8666666666666667\n",
      "8622 번째 loss, accuracy:  0.423636312151968 0.8666666666666667\n",
      "8623 번째 loss, accuracy:  0.423602425792077 0.8666666666666667\n",
      "8624 번째 loss, accuracy:  0.4235685279772221 0.8666666666666667\n",
      "8625 번째 loss, accuracy:  0.42353461870795467 0.8666666666666667\n",
      "8626 번째 loss, accuracy:  0.4235006979848324 0.8666666666666667\n",
      "8627 번째 loss, accuracy:  0.4234667658084181 0.8666666666666667\n",
      "8628 번째 loss, accuracy:  0.42343282217928163 0.8666666666666667\n",
      "8629 번째 loss, accuracy:  0.42339886709799823 0.8666666666666667\n",
      "8630 번째 loss, accuracy:  0.4233649005651499 0.8666666666666667\n",
      "8631 번째 loss, accuracy:  0.4233309225813238 0.8666666666666667\n",
      "8632 번째 loss, accuracy:  0.4232969331471136 0.8666666666666667\n",
      "8633 번째 loss, accuracy:  0.4232629322631187 0.8666666666666667\n",
      "8634 번째 loss, accuracy:  0.42322891992994477 0.8666666666666667\n",
      "8635 번째 loss, accuracy:  0.4231948961482036 0.8666666666666667\n",
      "8636 번째 loss, accuracy:  0.423160860918513 0.8666666666666667\n",
      "8637 번째 loss, accuracy:  0.42312681424149673 0.8666666666666667\n",
      "8638 번째 loss, accuracy:  0.4230927561177848 0.8666666666666667\n",
      "8639 번째 loss, accuracy:  0.42305868654801254 0.8666666666666667\n",
      "8640 번째 loss, accuracy:  0.4230246055328222 0.8666666666666667\n",
      "8641 번째 loss, accuracy:  0.4229905130728613 0.8666666666666667\n",
      "8642 번째 loss, accuracy:  0.42295640916878435 0.8666666666666667\n",
      "8643 번째 loss, accuracy:  0.4229222938212513 0.8666666666666667\n",
      "8644 번째 loss, accuracy:  0.4228881670309282 0.8666666666666667\n",
      "8645 번째 loss, accuracy:  0.4228540287984875 0.8666666666666667\n",
      "8646 번째 loss, accuracy:  0.422819879124607 0.8666666666666667\n",
      "8647 번째 loss, accuracy:  0.4227857180099714 0.8666666666666667\n",
      "8648 번째 loss, accuracy:  0.42275154545527066 0.8666666666666667\n",
      "8649 번째 loss, accuracy:  0.42271736146120137 0.8666666666666667\n",
      "8650 번째 loss, accuracy:  0.4226831660284664 0.8666666666666667\n",
      "8651 번째 loss, accuracy:  0.42264895915777373 0.8666666666666667\n",
      "8652 번째 loss, accuracy:  0.4226147408498383 0.8666666666666667\n",
      "8653 번째 loss, accuracy:  0.42258051110538114 0.8666666666666667\n",
      "8654 번째 loss, accuracy:  0.4225462699251287 0.8666666666666667\n",
      "8655 번째 loss, accuracy:  0.4225120173098143 0.8666666666666667\n",
      "8656 번째 loss, accuracy:  0.42247775326017645 0.8666666666666667\n",
      "8657 번째 loss, accuracy:  0.4224434777769608 0.8666666666666667\n",
      "8658 번째 loss, accuracy:  0.4224091908609182 0.8666666666666667\n",
      "8659 번째 loss, accuracy:  0.4223748925128055 0.8666666666666667\n",
      "8660 번째 loss, accuracy:  0.4223405827333869 0.8666666666666667\n",
      "8661 번째 loss, accuracy:  0.4223062615234314 0.8666666666666667\n",
      "8662 번째 loss, accuracy:  0.42227192888371473 0.8666666666666667\n",
      "8663 번째 loss, accuracy:  0.4222375848150183 0.8666666666666667\n",
      "8664 번째 loss, accuracy:  0.42220322931813004 0.8666666666666667\n",
      "8665 번째 loss, accuracy:  0.4221688623938433 0.8666666666666667\n",
      "8666 번째 loss, accuracy:  0.4221344840429592 0.8666666666666667\n",
      "8667 번째 loss, accuracy:  0.4221000942662831 0.8666666666666667\n",
      "8668 번째 loss, accuracy:  0.4220656930646271 0.8666666666666667\n",
      "8669 번째 loss, accuracy:  0.42203128043880983 0.8666666666666667\n",
      "8670 번째 loss, accuracy:  0.42199685638965545 0.8666666666666667\n",
      "8671 번째 loss, accuracy:  0.4219624209179949 0.8666666666666667\n",
      "8672 번째 loss, accuracy:  0.4219279740246643 0.8666666666666667\n",
      "8673 번째 loss, accuracy:  0.4218935157105069 0.8666666666666667\n",
      "8674 번째 loss, accuracy:  0.4218590459763715 0.8666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8675 번째 loss, accuracy:  0.4218245648231127 0.875\n",
      "8676 번째 loss, accuracy:  0.4217900722515922 0.875\n",
      "8677 번째 loss, accuracy:  0.4217555682626774 0.875\n",
      "8678 번째 loss, accuracy:  0.42172105285724115 0.875\n",
      "8679 번째 loss, accuracy:  0.42168652603616336 0.875\n",
      "8680 번째 loss, accuracy:  0.4216519878003298 0.875\n",
      "8681 번째 loss, accuracy:  0.4216174381506322 0.875\n",
      "8682 번째 loss, accuracy:  0.42158287708796854 0.875\n",
      "8683 번째 loss, accuracy:  0.42154830461324305 0.875\n",
      "8684 번째 loss, accuracy:  0.42151372072736576 0.875\n",
      "8685 번째 loss, accuracy:  0.42147912543125315 0.875\n",
      "8686 번째 loss, accuracy:  0.4214445187258279 0.875\n",
      "8687 번째 loss, accuracy:  0.42140990061201883 0.875\n",
      "8688 번째 loss, accuracy:  0.4213752710907605 0.875\n",
      "8689 번째 loss, accuracy:  0.4213406301629942 0.875\n",
      "8690 번째 loss, accuracy:  0.42130597782966733 0.875\n",
      "8691 번째 loss, accuracy:  0.4212713140917327 0.875\n",
      "8692 번째 loss, accuracy:  0.4212366389501503 0.875\n",
      "8693 번째 loss, accuracy:  0.4212019524058853 0.875\n",
      "8694 번째 loss, accuracy:  0.42116725445991027 0.875\n",
      "8695 번째 loss, accuracy:  0.4211325451132023 0.875\n",
      "8696 번째 loss, accuracy:  0.42109782436674625 0.875\n",
      "8697 번째 loss, accuracy:  0.4210630922215322 0.875\n",
      "8698 번째 loss, accuracy:  0.4210283486785568 0.875\n",
      "8699 번째 loss, accuracy:  0.4209935937388225 0.875\n",
      "8700 번째 loss, accuracy:  0.4209588274033382 0.875\n",
      "8701 번째 loss, accuracy:  0.42092404967311936 0.875\n",
      "8702 번째 loss, accuracy:  0.42088926054918674 0.875\n",
      "8703 번째 loss, accuracy:  0.42085446003256793 0.875\n",
      "8704 번째 loss, accuracy:  0.4208196481242965 0.875\n",
      "8705 번째 loss, accuracy:  0.4207848248254123 0.875\n",
      "8706 번째 loss, accuracy:  0.4207499901369614 0.875\n",
      "8707 번째 loss, accuracy:  0.42071514405999577 0.875\n",
      "8708 번째 loss, accuracy:  0.4206802865955742 0.875\n",
      "8709 번째 loss, accuracy:  0.4206454177447607 0.875\n",
      "8710 번째 loss, accuracy:  0.4206105375086262 0.875\n",
      "8711 번째 loss, accuracy:  0.42057564588824736 0.875\n",
      "8712 번째 loss, accuracy:  0.42054074288470794 0.8833333333333333\n",
      "8713 번째 loss, accuracy:  0.42050582849909707 0.8833333333333333\n",
      "8714 번째 loss, accuracy:  0.4204709027325099 0.8833333333333333\n",
      "8715 번째 loss, accuracy:  0.4204359655860485 0.8833333333333333\n",
      "8716 번째 loss, accuracy:  0.4204010170608209 0.8833333333333333\n",
      "8717 번째 loss, accuracy:  0.4203660571579416 0.8833333333333333\n",
      "8718 번째 loss, accuracy:  0.4203310858785307 0.8833333333333333\n",
      "8719 번째 loss, accuracy:  0.4202961032237148 0.8833333333333333\n",
      "8720 번째 loss, accuracy:  0.42026110919462656 0.8833333333333333\n",
      "8721 번째 loss, accuracy:  0.42022610379240494 0.8833333333333333\n",
      "8722 번째 loss, accuracy:  0.4201910870181957 0.8833333333333333\n",
      "8723 번째 loss, accuracy:  0.4201560588731502 0.8833333333333333\n",
      "8724 번째 loss, accuracy:  0.42012101935842583 0.8833333333333333\n",
      "8725 번째 loss, accuracy:  0.42008596847518687 0.8833333333333333\n",
      "8726 번째 loss, accuracy:  0.42005090622460284 0.8833333333333333\n",
      "8727 번째 loss, accuracy:  0.42001583260785086 0.8833333333333333\n",
      "8728 번째 loss, accuracy:  0.41998074762611337 0.8833333333333333\n",
      "8729 번째 loss, accuracy:  0.419945651280579 0.8833333333333333\n",
      "8730 번째 loss, accuracy:  0.41991054357244323 0.8833333333333333\n",
      "8731 번째 loss, accuracy:  0.41987542450290694 0.8833333333333333\n",
      "8732 번째 loss, accuracy:  0.41984029407317786 0.8833333333333333\n",
      "8733 번째 loss, accuracy:  0.4198051522844697 0.8833333333333333\n",
      "8734 번째 loss, accuracy:  0.4197699991380024 0.8833333333333333\n",
      "8735 번째 loss, accuracy:  0.4197348346350028 0.8833333333333333\n",
      "8736 번째 loss, accuracy:  0.41969965877670273 0.8833333333333333\n",
      "8737 번째 loss, accuracy:  0.4196644715643412 0.8833333333333333\n",
      "8738 번째 loss, accuracy:  0.4196292729991632 0.8833333333333333\n",
      "8739 번째 loss, accuracy:  0.41959406308242014 0.8833333333333333\n",
      "8740 번째 loss, accuracy:  0.4195588418153695 0.8833333333333333\n",
      "8741 번째 loss, accuracy:  0.41952360919927495 0.8833333333333333\n",
      "8742 번째 loss, accuracy:  0.4194883652354064 0.8833333333333333\n",
      "8743 번째 loss, accuracy:  0.4194531099250404 0.8833333333333333\n",
      "8744 번째 loss, accuracy:  0.41941784326945913 0.8833333333333333\n",
      "8745 번째 loss, accuracy:  0.41938256526995155 0.8833333333333333\n",
      "8746 번째 loss, accuracy:  0.41934727592781307 0.8833333333333333\n",
      "8747 번째 loss, accuracy:  0.4193119752443446 0.8833333333333333\n",
      "8748 번째 loss, accuracy:  0.4192766632208536 0.8833333333333333\n",
      "8749 번째 loss, accuracy:  0.41924133985865447 0.8833333333333333\n",
      "8750 번째 loss, accuracy:  0.4192060051590669 0.8833333333333333\n",
      "8751 번째 loss, accuracy:  0.41917065912341733 0.8833333333333333\n",
      "8752 번째 loss, accuracy:  0.41913530175303854 0.8833333333333333\n",
      "8753 번째 loss, accuracy:  0.4190999330492694 0.8833333333333333\n",
      "8754 번째 loss, accuracy:  0.4190645530134551 0.8833333333333333\n",
      "8755 번째 loss, accuracy:  0.4190291616469472 0.8833333333333333\n",
      "8756 번째 loss, accuracy:  0.4189937589511036 0.8833333333333333\n",
      "8757 번째 loss, accuracy:  0.41895834492728784 0.8833333333333333\n",
      "8758 번째 loss, accuracy:  0.41892291957687094 0.8833333333333333\n",
      "8759 번째 loss, accuracy:  0.4188874829012288 0.8833333333333333\n",
      "8760 번째 loss, accuracy:  0.4188520349017445 0.8833333333333333\n",
      "8761 번째 loss, accuracy:  0.4188165755798075 0.8833333333333333\n",
      "8762 번째 loss, accuracy:  0.4187811049368128 0.8833333333333333\n",
      "8763 번째 loss, accuracy:  0.4187456229741628 0.8833333333333333\n",
      "8764 번째 loss, accuracy:  0.41871012969326504 0.8833333333333333\n",
      "8765 번째 loss, accuracy:  0.41867462509553394 0.8833333333333333\n",
      "8766 번째 loss, accuracy:  0.4186391091823901 0.8833333333333333\n",
      "8767 번째 loss, accuracy:  0.41860358195526054 0.8833333333333333\n",
      "8768 번째 loss, accuracy:  0.41856804341557824 0.8833333333333333\n",
      "8769 번째 loss, accuracy:  0.41853249356478306 0.8833333333333333\n",
      "8770 번째 loss, accuracy:  0.418496932404321 0.8833333333333333\n",
      "8771 번째 loss, accuracy:  0.41846135993564365 0.8833333333333333\n",
      "8772 번째 loss, accuracy:  0.41842577616020965 0.8833333333333333\n",
      "8773 번째 loss, accuracy:  0.4183901810794837 0.8833333333333333\n",
      "8774 번째 loss, accuracy:  0.4183545746949368 0.8833333333333333\n",
      "8775 번째 loss, accuracy:  0.4183189570080464 0.8833333333333333\n",
      "8776 번째 loss, accuracy:  0.418283328020296 0.8833333333333333\n",
      "8777 번째 loss, accuracy:  0.41824768773317583 0.8833333333333333\n",
      "8778 번째 loss, accuracy:  0.4182120361481818 0.8833333333333333\n",
      "8779 번째 loss, accuracy:  0.4181763732668166 0.8833333333333333\n",
      "8780 번째 loss, accuracy:  0.4181406990905891 0.8833333333333333\n",
      "8781 번째 loss, accuracy:  0.4181050136210146 0.8833333333333333\n",
      "8782 번째 loss, accuracy:  0.4180693168596147 0.8833333333333333\n",
      "8783 번째 loss, accuracy:  0.4180336088079171 0.8833333333333333\n",
      "8784 번째 loss, accuracy:  0.417997889467456 0.8833333333333333\n",
      "8785 번째 loss, accuracy:  0.417962158839772 0.8833333333333333\n",
      "8786 번째 loss, accuracy:  0.41792641692641147 0.8833333333333333\n",
      "8787 번째 loss, accuracy:  0.41789066372892847 0.8833333333333333\n",
      "8788 번째 loss, accuracy:  0.41785489924888164 0.8833333333333333\n",
      "8789 번째 loss, accuracy:  0.4178191234878372 0.8833333333333333\n",
      "8790 번째 loss, accuracy:  0.41778333644736687 0.8833333333333333\n",
      "8791 번째 loss, accuracy:  0.4177475381290497 0.8833333333333333\n",
      "8792 번째 loss, accuracy:  0.4177117285344698 0.8833333333333333\n",
      "8793 번째 loss, accuracy:  0.4176759076652186 0.8833333333333333\n",
      "8794 번째 loss, accuracy:  0.4176400755228936 0.8833333333333333\n",
      "8795 번째 loss, accuracy:  0.4176042321090987 0.8833333333333333\n",
      "8796 번째 loss, accuracy:  0.4175683774254439 0.8833333333333333\n",
      "8797 번째 loss, accuracy:  0.4175325114735454 0.8833333333333333\n",
      "8798 번째 loss, accuracy:  0.4174966342550267 0.8833333333333333\n",
      "8799 번째 loss, accuracy:  0.41746074577151643 0.8833333333333333\n",
      "8800 번째 loss, accuracy:  0.4174248460246498 0.8833333333333333\n",
      "8801 번째 loss, accuracy:  0.4173889350160692 0.8833333333333333\n",
      "8802 번째 loss, accuracy:  0.4173530127474226 0.8833333333333333\n",
      "8803 번째 loss, accuracy:  0.4173170792203642 0.8833333333333333\n",
      "8804 번째 loss, accuracy:  0.41728113443655557 0.8833333333333333\n",
      "8805 번째 loss, accuracy:  0.41724517839766323 0.8833333333333333\n",
      "8806 번째 loss, accuracy:  0.41720921110536097 0.8833333333333333\n",
      "8807 번째 loss, accuracy:  0.41717323256132904 0.8833333333333333\n",
      "8808 번째 loss, accuracy:  0.41713724276725317 0.8833333333333333\n",
      "8809 번째 loss, accuracy:  0.4171012417248264 0.8833333333333333\n",
      "8810 번째 loss, accuracy:  0.4170652294357476 0.8833333333333333\n",
      "8811 번째 loss, accuracy:  0.41702920590172227 0.8833333333333333\n",
      "8812 번째 loss, accuracy:  0.4169931711244619 0.8833333333333333\n",
      "8813 번째 loss, accuracy:  0.41695712510568456 0.8833333333333333\n",
      "8814 번째 loss, accuracy:  0.4169210678471146 0.8833333333333333\n",
      "8815 번째 loss, accuracy:  0.4168849993504825 0.8833333333333333\n",
      "8816 번째 loss, accuracy:  0.4168489196175262 0.8833333333333333\n",
      "8817 번째 loss, accuracy:  0.41681282864998853 0.8833333333333333\n",
      "8818 번째 loss, accuracy:  0.41677672644961977 0.8833333333333333\n",
      "8819 번째 loss, accuracy:  0.41674061301817583 0.8833333333333333\n",
      "8820 번째 loss, accuracy:  0.4167044883574201 0.8833333333333333\n",
      "8821 번째 loss, accuracy:  0.4166683524691204 0.8833333333333333\n",
      "8822 번째 loss, accuracy:  0.416632205355053 0.8833333333333333\n",
      "8823 번째 loss, accuracy:  0.4165960470169993 0.8833333333333333\n",
      "8824 번째 loss, accuracy:  0.4165598774567472 0.8833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8825 번째 loss, accuracy:  0.4165236966760915 0.8833333333333333\n",
      "8826 번째 loss, accuracy:  0.41648750467683254 0.8833333333333333\n",
      "8827 번째 loss, accuracy:  0.41645130146077763 0.8833333333333333\n",
      "8828 번째 loss, accuracy:  0.4164150870297409 0.8833333333333333\n",
      "8829 번째 loss, accuracy:  0.41637886138554187 0.8833333333333333\n",
      "8830 번째 loss, accuracy:  0.4163426245300071 0.8833333333333333\n",
      "8831 번째 loss, accuracy:  0.416306376464969 0.8833333333333333\n",
      "8832 번째 loss, accuracy:  0.41627011719226703 0.8833333333333333\n",
      "8833 번째 loss, accuracy:  0.4162338467137466 0.8833333333333333\n",
      "8834 번째 loss, accuracy:  0.4161975650312596 0.8833333333333333\n",
      "8835 번째 loss, accuracy:  0.41616127214666393 0.8833333333333333\n",
      "8836 번째 loss, accuracy:  0.4161249680618244 0.8833333333333333\n",
      "8837 번째 loss, accuracy:  0.4160886527786126 0.8833333333333333\n",
      "8838 번째 loss, accuracy:  0.4160523262989052 0.8833333333333333\n",
      "8839 번째 loss, accuracy:  0.41601598862458644 0.8833333333333333\n",
      "8840 번째 loss, accuracy:  0.4159796397575466 0.8833333333333333\n",
      "8841 번째 loss, accuracy:  0.41594327969968165 0.8833333333333333\n",
      "8842 번째 loss, accuracy:  0.41590690845289513 0.8833333333333333\n",
      "8843 번째 loss, accuracy:  0.41587052601909635 0.8833333333333333\n",
      "8844 번째 loss, accuracy:  0.4158341324002008 0.8833333333333333\n",
      "8845 번째 loss, accuracy:  0.4157977275981311 0.8833333333333333\n",
      "8846 번째 loss, accuracy:  0.41576131161481533 0.8833333333333333\n",
      "8847 번째 loss, accuracy:  0.4157248844521889 0.8833333333333333\n",
      "8848 번째 loss, accuracy:  0.41568844611219263 0.8833333333333333\n",
      "8849 번째 loss, accuracy:  0.41565199659677476 0.8833333333333333\n",
      "8850 번째 loss, accuracy:  0.4156155359078889 0.8833333333333333\n",
      "8851 번째 loss, accuracy:  0.415579064047496 0.8833333333333333\n",
      "8852 번째 loss, accuracy:  0.41554258101756325 0.8833333333333333\n",
      "8853 번째 loss, accuracy:  0.4155060868200638 0.8833333333333333\n",
      "8854 번째 loss, accuracy:  0.41546958145697716 0.8833333333333333\n",
      "8855 번째 loss, accuracy:  0.4154330649302894 0.8833333333333333\n",
      "8856 번째 loss, accuracy:  0.41539653724199355 0.8833333333333333\n",
      "8857 번째 loss, accuracy:  0.4153599983940885 0.8833333333333333\n",
      "8858 번째 loss, accuracy:  0.4153234483885795 0.8833333333333333\n",
      "8859 번째 loss, accuracy:  0.41528688722747814 0.8833333333333333\n",
      "8860 번째 loss, accuracy:  0.4152503149128035 0.8833333333333333\n",
      "8861 번째 loss, accuracy:  0.41521373144657947 0.8833333333333333\n",
      "8862 번째 loss, accuracy:  0.4151771368308373 0.8833333333333333\n",
      "8863 번째 loss, accuracy:  0.41514053106761406 0.8833333333333333\n",
      "8864 번째 loss, accuracy:  0.415103914158954 0.8833333333333333\n",
      "8865 번째 loss, accuracy:  0.41506728610690724 0.8833333333333333\n",
      "8866 번째 loss, accuracy:  0.41503064691353064 0.8833333333333333\n",
      "8867 번째 loss, accuracy:  0.41499399658088726 0.8833333333333333\n",
      "8868 번째 loss, accuracy:  0.41495733511104615 0.8833333333333333\n",
      "8869 번째 loss, accuracy:  0.41492066250608367 0.8833333333333333\n",
      "8870 번째 loss, accuracy:  0.4148839787680824 0.8833333333333333\n",
      "8871 번째 loss, accuracy:  0.41484728389913056 0.8833333333333333\n",
      "8872 번째 loss, accuracy:  0.41481057790132353 0.8833333333333333\n",
      "8873 번째 loss, accuracy:  0.4147738607767631 0.8833333333333333\n",
      "8874 번째 loss, accuracy:  0.414737132527557 0.8833333333333333\n",
      "8875 번째 loss, accuracy:  0.41470039315582 0.8833333333333333\n",
      "8876 번째 loss, accuracy:  0.41466364266367284 0.8833333333333333\n",
      "8877 번째 loss, accuracy:  0.4146268810532428 0.8833333333333333\n",
      "8878 번째 loss, accuracy:  0.41459010832666354 0.8833333333333333\n",
      "8879 번째 loss, accuracy:  0.4145533244860757 0.8833333333333333\n",
      "8880 번째 loss, accuracy:  0.41451652953362494 0.8833333333333333\n",
      "8881 번째 loss, accuracy:  0.4144797234714646 0.8833333333333333\n",
      "8882 번째 loss, accuracy:  0.41444290630175434 0.8833333333333333\n",
      "8883 번째 loss, accuracy:  0.41440607802665996 0.8833333333333333\n",
      "8884 번째 loss, accuracy:  0.4143692386483538 0.8833333333333333\n",
      "8885 번째 loss, accuracy:  0.4143323881690147 0.8833333333333333\n",
      "8886 번째 loss, accuracy:  0.4142955265908275 0.8833333333333333\n",
      "8887 번째 loss, accuracy:  0.4142586539159839 0.8833333333333333\n",
      "8888 번째 loss, accuracy:  0.4142217701466818 0.8833333333333333\n",
      "8889 번째 loss, accuracy:  0.4141848752851261 0.8833333333333333\n",
      "8890 번째 loss, accuracy:  0.41414796933352743 0.8833333333333333\n",
      "8891 번째 loss, accuracy:  0.4141110522941029 0.8833333333333333\n",
      "8892 번째 loss, accuracy:  0.41407412416907646 0.8833333333333333\n",
      "8893 번째 loss, accuracy:  0.414037184960678 0.8833333333333333\n",
      "8894 번째 loss, accuracy:  0.41400023467114444 0.8833333333333333\n",
      "8895 번째 loss, accuracy:  0.4139632733027188 0.8833333333333333\n",
      "8896 번째 loss, accuracy:  0.4139263008576504 0.8833333333333333\n",
      "8897 번째 loss, accuracy:  0.4138893173381954 0.8833333333333333\n",
      "8898 번째 loss, accuracy:  0.4138523227466158 0.8833333333333333\n",
      "8899 번째 loss, accuracy:  0.41381531708518104 0.8833333333333333\n",
      "8900 번째 loss, accuracy:  0.41377830035616536 0.8833333333333333\n",
      "8901 번째 loss, accuracy:  0.4137412725618514 0.8833333333333333\n",
      "8902 번째 loss, accuracy:  0.41370423370452675 0.8833333333333333\n",
      "8903 번째 loss, accuracy:  0.4136671837864865 0.8833333333333333\n",
      "8904 번째 loss, accuracy:  0.41363012281003114 0.8833333333333333\n",
      "8905 번째 loss, accuracy:  0.4135930507774684 0.8833333333333333\n",
      "8906 번째 loss, accuracy:  0.4135559676911117 0.8833333333333333\n",
      "8907 번째 loss, accuracy:  0.41351887355328193 0.8833333333333333\n",
      "8908 번째 loss, accuracy:  0.41348176836630574 0.8833333333333333\n",
      "8909 번째 loss, accuracy:  0.4134446521325165 0.8833333333333333\n",
      "8910 번째 loss, accuracy:  0.4134075248542537 0.8833333333333333\n",
      "8911 번째 loss, accuracy:  0.41337038653386327 0.8833333333333333\n",
      "8912 번째 loss, accuracy:  0.4133332371736979 0.8833333333333333\n",
      "8913 번째 loss, accuracy:  0.4132960767761169 0.8916666666666667\n",
      "8914 번째 loss, accuracy:  0.41325890534348564 0.8916666666666667\n",
      "8915 번째 loss, accuracy:  0.41322172287817566 0.8916666666666667\n",
      "8916 번째 loss, accuracy:  0.4131845293825657 0.8916666666666667\n",
      "8917 번째 loss, accuracy:  0.4131473248590404 0.8916666666666667\n",
      "8918 번째 loss, accuracy:  0.41311010930999104 0.8916666666666667\n",
      "8919 번째 loss, accuracy:  0.41307288273781523 0.8916666666666667\n",
      "8920 번째 loss, accuracy:  0.4130356451449172 0.8916666666666667\n",
      "8921 번째 loss, accuracy:  0.41299839653370757 0.8916666666666667\n",
      "8922 번째 loss, accuracy:  0.4129611369066034 0.8916666666666667\n",
      "8923 번째 loss, accuracy:  0.41292386626602806 0.8916666666666667\n",
      "8924 번째 loss, accuracy:  0.4128865846144119 0.8916666666666667\n",
      "8925 번째 loss, accuracy:  0.412849291954191 0.8916666666666667\n",
      "8926 번째 loss, accuracy:  0.41281198828780813 0.8916666666666667\n",
      "8927 번째 loss, accuracy:  0.41277467361771253 0.8916666666666667\n",
      "8928 번째 loss, accuracy:  0.41273734794636047 0.8916666666666667\n",
      "8929 번째 loss, accuracy:  0.41270001127621386 0.8916666666666667\n",
      "8930 번째 loss, accuracy:  0.41266266360974185 0.8916666666666667\n",
      "8931 번째 loss, accuracy:  0.41262530494941907 0.8916666666666667\n",
      "8932 번째 loss, accuracy:  0.4125879352977272 0.8916666666666667\n",
      "8933 번째 loss, accuracy:  0.4125505546571541 0.8916666666666667\n",
      "8934 번째 loss, accuracy:  0.41251316303019453 0.8916666666666667\n",
      "8935 번째 loss, accuracy:  0.4124757604193495 0.8916666666666667\n",
      "8936 번째 loss, accuracy:  0.4124383468271264 0.8916666666666667\n",
      "8937 번째 loss, accuracy:  0.4124009222560388 0.8916666666666667\n",
      "8938 번째 loss, accuracy:  0.41236348670860734 0.8916666666666667\n",
      "8939 번째 loss, accuracy:  0.41232604018735863 0.8916666666666667\n",
      "8940 번째 loss, accuracy:  0.4122885826948258 0.8916666666666667\n",
      "8941 번째 loss, accuracy:  0.41225111423354893 0.8916666666666667\n",
      "8942 번째 loss, accuracy:  0.412213634806074 0.8916666666666667\n",
      "8943 번째 loss, accuracy:  0.41217614441495365 0.8916666666666667\n",
      "8944 번째 loss, accuracy:  0.4121386430627467 0.8916666666666667\n",
      "8945 번째 loss, accuracy:  0.41210113075201915 0.8916666666666667\n",
      "8946 번째 loss, accuracy:  0.41206360748534293 0.8916666666666667\n",
      "8947 번째 loss, accuracy:  0.4120260732652961 0.8916666666666667\n",
      "8948 번째 loss, accuracy:  0.4119885280944641 0.8916666666666667\n",
      "8949 번째 loss, accuracy:  0.41195097197543784 0.8916666666666667\n",
      "8950 번째 loss, accuracy:  0.41191340491081585 0.8916666666666667\n",
      "8951 번째 loss, accuracy:  0.4118758269032016 0.8916666666666667\n",
      "8952 번째 loss, accuracy:  0.41183823795520613 0.8916666666666667\n",
      "8953 번째 loss, accuracy:  0.41180063806944633 0.8916666666666667\n",
      "8954 번째 loss, accuracy:  0.4117630272485464 0.8916666666666667\n",
      "8955 번째 loss, accuracy:  0.4117254054951365 0.8916666666666667\n",
      "8956 번째 loss, accuracy:  0.41168777281185254 0.8916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8957 번째 loss, accuracy:  0.4116501292013385 0.8916666666666667\n",
      "8958 번째 loss, accuracy:  0.4116124746662434 0.8916666666666667\n",
      "8959 번째 loss, accuracy:  0.41157480920922324 0.8916666666666667\n",
      "8960 번째 loss, accuracy:  0.41153713283294086 0.8916666666666667\n",
      "8961 번째 loss, accuracy:  0.41149944554006496 0.8916666666666667\n",
      "8962 번째 loss, accuracy:  0.41146174733327073 0.8916666666666667\n",
      "8963 번째 loss, accuracy:  0.4114240382152406 0.8916666666666667\n",
      "8964 번째 loss, accuracy:  0.4113863181886618 0.8916666666666667\n",
      "8965 번째 loss, accuracy:  0.4113485872562297 0.8916666666666667\n",
      "8966 번째 loss, accuracy:  0.4113108454206455 0.8916666666666667\n",
      "8967 번째 loss, accuracy:  0.4112730926846169 0.8916666666666667\n",
      "8968 번째 loss, accuracy:  0.41123532905085786 0.8916666666666667\n",
      "8969 번째 loss, accuracy:  0.4111975545220892 0.8916666666666667\n",
      "8970 번째 loss, accuracy:  0.4111597691010382 0.8916666666666667\n",
      "8971 번째 loss, accuracy:  0.4111219727904383 0.8916666666666667\n",
      "8972 번째 loss, accuracy:  0.41108416559302924 0.8916666666666667\n",
      "8973 번째 loss, accuracy:  0.4110463475115575 0.8916666666666667\n",
      "8974 번째 loss, accuracy:  0.4110085185487763 0.8916666666666667\n",
      "8975 번째 loss, accuracy:  0.4109706787074451 0.8916666666666667\n",
      "8976 번째 loss, accuracy:  0.4109328279903295 0.8916666666666667\n",
      "8977 번째 loss, accuracy:  0.4108949664002017 0.8916666666666667\n",
      "8978 번째 loss, accuracy:  0.41085709393984066 0.8916666666666667\n",
      "8979 번째 loss, accuracy:  0.4108192106120316 0.8916666666666667\n",
      "8980 번째 loss, accuracy:  0.4107813164195663 0.8916666666666667\n",
      "8981 번째 loss, accuracy:  0.4107434113652431 0.8916666666666667\n",
      "8982 번째 loss, accuracy:  0.41070549545186635 0.8916666666666667\n",
      "8983 번째 loss, accuracy:  0.4106675686822473 0.8916666666666667\n",
      "8984 번째 loss, accuracy:  0.4106296310592032 0.8916666666666667\n",
      "8985 번째 loss, accuracy:  0.4105916825855588 0.8916666666666667\n",
      "8986 번째 loss, accuracy:  0.4105537232641436 0.8916666666666667\n",
      "8987 번째 loss, accuracy:  0.4105157530977953 0.8916666666666667\n",
      "8988 번째 loss, accuracy:  0.41047777208935704 0.8916666666666667\n",
      "8989 번째 loss, accuracy:  0.41043978024167893 0.8916666666666667\n",
      "8990 번째 loss, accuracy:  0.410401777557617 0.8916666666666667\n",
      "8991 번째 loss, accuracy:  0.4103637640400341 0.8916666666666667\n",
      "8992 번째 loss, accuracy:  0.41032573969179953 0.8916666666666667\n",
      "8993 번째 loss, accuracy:  0.4102877045157892 0.8916666666666667\n",
      "8994 번째 loss, accuracy:  0.4102496585148851 0.8916666666666667\n",
      "8995 번째 loss, accuracy:  0.41021160169197624 0.8916666666666667\n",
      "8996 번째 loss, accuracy:  0.4101735340499572 0.8916666666666667\n",
      "8997 번째 loss, accuracy:  0.4101354555917301 0.8916666666666667\n",
      "8998 번째 loss, accuracy:  0.4100973663202024 0.8916666666666667\n",
      "8999 번째 loss, accuracy:  0.4100592662382892 0.8916666666666667\n",
      "9000 번째 loss, accuracy:  0.41002115534891115 0.8916666666666667\n",
      "9001 번째 loss, accuracy:  0.4099830336549958 0.8916666666666667\n",
      "9002 번째 loss, accuracy:  0.40994490115947674 0.8916666666666667\n",
      "9003 번째 loss, accuracy:  0.40990675786529446 0.8916666666666667\n",
      "9004 번째 loss, accuracy:  0.4098686037753956 0.8916666666666667\n",
      "9005 번째 loss, accuracy:  0.4098304388927341 0.8916666666666667\n",
      "9006 번째 loss, accuracy:  0.4097922632202691 0.8916666666666667\n",
      "9007 번째 loss, accuracy:  0.40975407676096676 0.8916666666666667\n",
      "9008 번째 loss, accuracy:  0.40971587951780003 0.8916666666666667\n",
      "9009 번째 loss, accuracy:  0.40967767149374784 0.8916666666666667\n",
      "9010 번째 loss, accuracy:  0.4096394526917958 0.8916666666666667\n",
      "9011 번째 loss, accuracy:  0.40960122311493624 0.8916666666666667\n",
      "9012 번째 loss, accuracy:  0.40956298276616715 0.8916666666666667\n",
      "9013 번째 loss, accuracy:  0.4095247316484935 0.8916666666666667\n",
      "9014 번째 loss, accuracy:  0.409486469764927 0.8916666666666667\n",
      "9015 번째 loss, accuracy:  0.4094481971184856 0.8916666666666667\n",
      "9016 번째 loss, accuracy:  0.4094099137121931 0.8916666666666667\n",
      "9017 번째 loss, accuracy:  0.40937161954908063 0.8916666666666667\n",
      "9018 번째 loss, accuracy:  0.4093333146321855 0.8916666666666667\n",
      "9019 번째 loss, accuracy:  0.409294998964551 0.8916666666666667\n",
      "9020 번째 loss, accuracy:  0.4092566725492273 0.8916666666666667\n",
      "9021 번째 loss, accuracy:  0.4092183353892716 0.8916666666666667\n",
      "9022 번째 loss, accuracy:  0.4091799874877464 0.8916666666666667\n",
      "9023 번째 loss, accuracy:  0.4091416288477213 0.8916666666666667\n",
      "9024 번째 loss, accuracy:  0.40910325947227233 0.8916666666666667\n",
      "9025 번째 loss, accuracy:  0.4090648793644818 0.8916666666666667\n",
      "9026 번째 loss, accuracy:  0.40902648852743867 0.8916666666666667\n",
      "9027 번째 loss, accuracy:  0.4089880869642382 0.8916666666666667\n",
      "9028 번째 loss, accuracy:  0.40894967467798243 0.8916666666666667\n",
      "9029 번째 loss, accuracy:  0.4089112516717795 0.8916666666666667\n",
      "9030 번째 loss, accuracy:  0.408872817948744 0.8916666666666667\n",
      "9031 번째 loss, accuracy:  0.4088343735119969 0.8916666666666667\n",
      "9032 번째 loss, accuracy:  0.40879591836466606 0.8916666666666667\n",
      "9033 번째 loss, accuracy:  0.40875745250988516 0.8916666666666667\n",
      "9034 번째 loss, accuracy:  0.4087189759507949 0.8916666666666667\n",
      "9035 번째 loss, accuracy:  0.40868048869054235 0.8916666666666667\n",
      "9036 번째 loss, accuracy:  0.40864199073228075 0.8916666666666667\n",
      "9037 번째 loss, accuracy:  0.40860348207917013 0.8916666666666667\n",
      "9038 번째 loss, accuracy:  0.40856496273437676 0.8916666666666667\n",
      "9039 번째 loss, accuracy:  0.4085264327010733 0.8916666666666667\n",
      "9040 번째 loss, accuracy:  0.40848789198243857 0.8916666666666667\n",
      "9041 번째 loss, accuracy:  0.40844934058165855 0.8916666666666667\n",
      "9042 번째 loss, accuracy:  0.40841077850192525 0.8916666666666667\n",
      "9043 번째 loss, accuracy:  0.40837220574643723 0.8916666666666667\n",
      "9044 번째 loss, accuracy:  0.4083336223183994 0.8916666666666667\n",
      "9045 번째 loss, accuracy:  0.4082950282210234 0.8916666666666667\n",
      "9046 번째 loss, accuracy:  0.40825642345752655 0.8916666666666667\n",
      "9047 번째 loss, accuracy:  0.40821780803113356 0.8916666666666667\n",
      "9048 번째 loss, accuracy:  0.408179181945075 0.8916666666666667\n",
      "9049 번째 loss, accuracy:  0.40814054520258813 0.8916666666666667\n",
      "9050 번째 loss, accuracy:  0.40810189780691636 0.8916666666666667\n",
      "9051 번째 loss, accuracy:  0.4080632397613101 0.8916666666666667\n",
      "9052 번째 loss, accuracy:  0.4080245710690261 0.8916666666666667\n",
      "9053 번째 loss, accuracy:  0.4079858917333266 0.8916666666666667\n",
      "9054 번째 loss, accuracy:  0.4079472017574813 0.8916666666666667\n",
      "9055 번째 loss, accuracy:  0.40790850114476584 0.8916666666666667\n",
      "9056 번째 loss, accuracy:  0.407869789898463 0.8916666666666667\n",
      "9057 번째 loss, accuracy:  0.40783106802186114 0.8916666666666667\n",
      "9058 번째 loss, accuracy:  0.4077923355182554 0.8916666666666667\n",
      "9059 번째 loss, accuracy:  0.40775359239094705 0.8916666666666667\n",
      "9060 번째 loss, accuracy:  0.4077148386432446 0.8916666666666667\n",
      "9061 번째 loss, accuracy:  0.4076760742784623 0.8916666666666667\n",
      "9062 번째 loss, accuracy:  0.40763729929992143 0.8916666666666667\n",
      "9063 번째 loss, accuracy:  0.4075985137109485 0.8916666666666667\n",
      "9064 번째 loss, accuracy:  0.4075597175148779 0.8916666666666667\n",
      "9065 번째 loss, accuracy:  0.40752091071504953 0.8916666666666667\n",
      "9066 번째 loss, accuracy:  0.4074820933148099 0.8916666666666667\n",
      "9067 번째 loss, accuracy:  0.4074432653175124 0.8916666666666667\n",
      "9068 번째 loss, accuracy:  0.4074044267265163 0.8916666666666667\n",
      "9069 번째 loss, accuracy:  0.4073655775451873 0.8916666666666667\n",
      "9070 번째 loss, accuracy:  0.40732671777689805 0.8916666666666667\n",
      "9071 번째 loss, accuracy:  0.40728784742502716 0.8916666666666667\n",
      "9072 번째 loss, accuracy:  0.4072489664929597 0.8916666666666667\n",
      "9073 번째 loss, accuracy:  0.40721007498408757 0.8916666666666667\n",
      "9074 번째 loss, accuracy:  0.40717117290180854 0.8916666666666667\n",
      "9075 번째 loss, accuracy:  0.4071322602495272 0.8916666666666667\n",
      "9076 번째 loss, accuracy:  0.4070933370306545 0.8916666666666667\n",
      "9077 번째 loss, accuracy:  0.4070544032486077 0.8916666666666667\n",
      "9078 번째 loss, accuracy:  0.40701545890681007 0.8916666666666667\n",
      "9079 번째 loss, accuracy:  0.4069765040086923 0.8916666666666667\n",
      "9080 번째 loss, accuracy:  0.40693753855769094 0.8916666666666667\n",
      "9081 번째 loss, accuracy:  0.40689856255724866 0.8916666666666667\n",
      "9082 번째 loss, accuracy:  0.4068595760108155 0.8916666666666667\n",
      "9083 번째 loss, accuracy:  0.4068205789218464 0.8916666666666667\n",
      "9084 번째 loss, accuracy:  0.40678157129380427 0.8916666666666667\n",
      "9085 번째 loss, accuracy:  0.4067425531301574 0.8916666666666667\n",
      "9086 번째 loss, accuracy:  0.4067035244343813 0.8916666666666667\n",
      "9087 번째 loss, accuracy:  0.4066644852099569 0.8916666666666667\n",
      "9088 번째 loss, accuracy:  0.4066254354603724 0.8916666666666667\n",
      "9089 번째 loss, accuracy:  0.40658637518912216 0.8916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9090 번째 loss, accuracy:  0.40654730439970643 0.8916666666666667\n",
      "9091 번째 loss, accuracy:  0.40650822309563317 0.8916666666666667\n",
      "9092 번째 loss, accuracy:  0.4064691312804153 0.8916666666666667\n",
      "9093 번째 loss, accuracy:  0.406430028957573 0.8916666666666667\n",
      "9094 번째 loss, accuracy:  0.4063909161306325 0.8916666666666667\n",
      "9095 번째 loss, accuracy:  0.4063517928031264 0.8916666666666667\n",
      "9096 번째 loss, accuracy:  0.40631265897859437 0.8916666666666667\n",
      "9097 번째 loss, accuracy:  0.4062735146605817 0.8916666666666667\n",
      "9098 번째 loss, accuracy:  0.40623435985264017 0.8916666666666667\n",
      "9099 번째 loss, accuracy:  0.40619519455832875 0.8916666666666667\n",
      "9100 번째 loss, accuracy:  0.4061560187812115 0.8916666666666667\n",
      "9101 번째 loss, accuracy:  0.4061168325248604 0.8916666666666667\n",
      "9102 번째 loss, accuracy:  0.40607763579285266 0.8916666666666667\n",
      "9103 번째 loss, accuracy:  0.4060384285887718 0.8916666666666667\n",
      "9104 번째 loss, accuracy:  0.40599921091620855 0.8916666666666667\n",
      "9105 번째 loss, accuracy:  0.4059599827787601 0.8916666666666667\n",
      "9106 번째 loss, accuracy:  0.4059207441800288 0.8916666666666667\n",
      "9107 번째 loss, accuracy:  0.40588149512362504 0.8916666666666667\n",
      "9108 번째 loss, accuracy:  0.40584223561316435 0.8916666666666667\n",
      "9109 번째 loss, accuracy:  0.40580296565226937 0.8916666666666667\n",
      "9110 번째 loss, accuracy:  0.40576368524456824 0.8916666666666667\n",
      "9111 번째 loss, accuracy:  0.4057243943936968 0.8916666666666667\n",
      "9112 번째 loss, accuracy:  0.4056850931032963 0.8916666666666667\n",
      "9113 번째 loss, accuracy:  0.4056457813770143 0.8916666666666667\n",
      "9114 번째 loss, accuracy:  0.40560645921850547 0.8916666666666667\n",
      "9115 번째 loss, accuracy:  0.40556712663143035 0.8916666666666667\n",
      "9116 번째 loss, accuracy:  0.405527783619456 0.8916666666666667\n",
      "9117 번째 loss, accuracy:  0.4054884301862559 0.8916666666666667\n",
      "9118 번째 loss, accuracy:  0.40544906633551003 0.8916666666666667\n",
      "9119 번째 loss, accuracy:  0.40540969207090444 0.8916666666666667\n",
      "9120 번째 loss, accuracy:  0.4053703073961317 0.8916666666666667\n",
      "9121 번째 loss, accuracy:  0.40533091231489105 0.8916666666666667\n",
      "9122 번째 loss, accuracy:  0.4052915068308874 0.8916666666666667\n",
      "9123 번째 loss, accuracy:  0.4052520909478329 0.8916666666666667\n",
      "9124 번째 loss, accuracy:  0.4052126646694456 0.8916666666666667\n",
      "9125 번째 loss, accuracy:  0.4051732279994497 0.8916666666666667\n",
      "9126 번째 loss, accuracy:  0.40513378094157615 0.8916666666666667\n",
      "9127 번째 loss, accuracy:  0.4050943234995622 0.8916666666666667\n",
      "9128 번째 loss, accuracy:  0.4050548556771513 0.8916666666666667\n",
      "9129 번째 loss, accuracy:  0.4050153774780937 0.8916666666666667\n",
      "9130 번째 loss, accuracy:  0.40497588890614494 0.8916666666666667\n",
      "9131 번째 loss, accuracy:  0.40493638996506875 0.8916666666666667\n",
      "9132 번째 loss, accuracy:  0.404896880658634 0.8916666666666667\n",
      "9133 번째 loss, accuracy:  0.40485736099061537 0.8916666666666667\n",
      "9134 번째 loss, accuracy:  0.4048178309647952 0.8916666666666667\n",
      "9135 번째 loss, accuracy:  0.40477829058496134 0.8916666666666667\n",
      "9136 번째 loss, accuracy:  0.40473873985490866 0.8916666666666667\n",
      "9137 번째 loss, accuracy:  0.4046991787784376 0.8916666666666667\n",
      "9138 번째 loss, accuracy:  0.40465960735935563 0.8916666666666667\n",
      "9139 번째 loss, accuracy:  0.40462002560147675 0.8916666666666667\n",
      "9140 번째 loss, accuracy:  0.40458043350861966 0.8916666666666667\n",
      "9141 번째 loss, accuracy:  0.4045408310846118 0.8916666666666667\n",
      "9142 번째 loss, accuracy:  0.4045012183332857 0.8916666666666667\n",
      "9143 번째 loss, accuracy:  0.40446159525847974 0.8916666666666667\n",
      "9144 번째 loss, accuracy:  0.4044219618640394 0.8916666666666667\n",
      "9145 번째 loss, accuracy:  0.40438231815381626 0.8916666666666667\n",
      "9146 번째 loss, accuracy:  0.40434266413166875 0.8916666666666667\n",
      "9147 번째 loss, accuracy:  0.404302999801461 0.8916666666666667\n",
      "9148 번째 loss, accuracy:  0.4042633251670637 0.8916666666666667\n",
      "9149 번째 loss, accuracy:  0.40422364023235374 0.8916666666666667\n",
      "9150 번째 loss, accuracy:  0.40418394500121513 0.8916666666666667\n",
      "9151 번째 loss, accuracy:  0.40414423947753686 0.8916666666666667\n",
      "9152 번째 loss, accuracy:  0.40410452366521493 0.8916666666666667\n",
      "9153 번째 loss, accuracy:  0.40406479756815217 0.8916666666666667\n",
      "9154 번째 loss, accuracy:  0.4040250611902573 0.8916666666666667\n",
      "9155 번째 loss, accuracy:  0.40398531453544506 0.8916666666666667\n",
      "9156 번째 loss, accuracy:  0.40394555760763734 0.8916666666666667\n",
      "9157 번째 loss, accuracy:  0.4039057904107616 0.8916666666666667\n",
      "9158 번째 loss, accuracy:  0.40386601294875174 0.8916666666666667\n",
      "9159 번째 loss, accuracy:  0.4038262252255484 0.8916666666666667\n",
      "9160 번째 loss, accuracy:  0.40378642724509806 0.8916666666666667\n",
      "9161 번째 loss, accuracy:  0.4037466190113537 0.8916666666666667\n",
      "9162 번째 loss, accuracy:  0.4037068005282747 0.8916666666666667\n",
      "9163 번째 loss, accuracy:  0.403666971799827 0.8916666666666667\n",
      "9164 번째 loss, accuracy:  0.4036271328299826 0.8916666666666667\n",
      "9165 번째 loss, accuracy:  0.40358728362271895 0.8916666666666667\n",
      "9166 번째 loss, accuracy:  0.40354742418202166 0.8916666666666667\n",
      "9167 번째 loss, accuracy:  0.40350755451188125 0.8916666666666667\n",
      "9168 번째 loss, accuracy:  0.4034676746162953 0.8916666666666667\n",
      "9169 번째 loss, accuracy:  0.40342778449926714 0.8916666666666667\n",
      "9170 번째 loss, accuracy:  0.4033878841648065 0.8916666666666667\n",
      "9171 번째 loss, accuracy:  0.40334797361692953 0.8916666666666667\n",
      "9172 번째 loss, accuracy:  0.403308052859659 0.8916666666666667\n",
      "9173 번째 loss, accuracy:  0.40326812189702305 0.8916666666666667\n",
      "9174 번째 loss, accuracy:  0.40322818073305755 0.8916666666666667\n",
      "9175 번째 loss, accuracy:  0.4031882293718033 0.8916666666666667\n",
      "9176 번째 loss, accuracy:  0.40314826781730856 0.8916666666666667\n",
      "9177 번째 loss, accuracy:  0.4031082960736271 0.8916666666666667\n",
      "9178 번째 loss, accuracy:  0.40306831414481875 0.8916666666666667\n",
      "9179 번째 loss, accuracy:  0.40302832203495065 0.8916666666666667\n",
      "9180 번째 loss, accuracy:  0.40298831974809535 0.8916666666666667\n",
      "9181 번째 loss, accuracy:  0.40294830728833186 0.8916666666666667\n",
      "9182 번째 loss, accuracy:  0.40290828465974626 0.8916666666666667\n",
      "9183 번째 loss, accuracy:  0.4028682518664297 0.8916666666666667\n",
      "9184 번째 loss, accuracy:  0.40282820891248045 0.8916666666666667\n",
      "9185 번째 loss, accuracy:  0.40278815580200295 0.8916666666666667\n",
      "9186 번째 loss, accuracy:  0.4027480925391072 0.8916666666666667\n",
      "9187 번째 loss, accuracy:  0.40270801912791065 0.8916666666666667\n",
      "9188 번째 loss, accuracy:  0.4026679355725361 0.8916666666666667\n",
      "9189 번째 loss, accuracy:  0.402627841877113 0.8916666666666667\n",
      "9190 번째 loss, accuracy:  0.4025877380457775 0.8916666666666667\n",
      "9191 번째 loss, accuracy:  0.40254762408267125 0.8916666666666667\n",
      "9192 번째 loss, accuracy:  0.40250749999194224 0.8916666666666667\n",
      "9193 번째 loss, accuracy:  0.4024673657777452 0.8916666666666667\n",
      "9194 번째 loss, accuracy:  0.40242722144424087 0.8916666666666667\n",
      "9195 번째 loss, accuracy:  0.4023870669955963 0.8916666666666667\n",
      "9196 번째 loss, accuracy:  0.4023469024359849 0.8916666666666667\n",
      "9197 번째 loss, accuracy:  0.40230672776958604 0.8916666666666667\n",
      "9198 번째 loss, accuracy:  0.40226654300058584 0.8916666666666667\n",
      "9199 번째 loss, accuracy:  0.40222634813317587 0.8916666666666667\n",
      "9200 번째 loss, accuracy:  0.40218614317155515 0.8916666666666667\n",
      "9201 번째 loss, accuracy:  0.4021459281199278 0.8916666666666667\n",
      "9202 번째 loss, accuracy:  0.4021057029825045 0.8916666666666667\n",
      "9203 번째 loss, accuracy:  0.40206546776350294 0.8916666666666667\n",
      "9204 번째 loss, accuracy:  0.40202522246714595 0.8916666666666667\n",
      "9205 번째 loss, accuracy:  0.40198496709766385 0.8916666666666667\n",
      "9206 번째 loss, accuracy:  0.40194470165929164 0.8916666666666667\n",
      "9207 번째 loss, accuracy:  0.4019044261562717 0.8916666666666667\n",
      "9208 번째 loss, accuracy:  0.40186414059285236 0.8916666666666667\n",
      "9209 번째 loss, accuracy:  0.40182384497328827 0.8916666666666667\n",
      "9210 번째 loss, accuracy:  0.40178353930184035 0.8916666666666667\n",
      "9211 번째 loss, accuracy:  0.4017432235827752 0.8916666666666667\n",
      "9212 번째 loss, accuracy:  0.40170289782036644 0.8916666666666667\n",
      "9213 번째 loss, accuracy:  0.4016625620188938 0.8916666666666667\n",
      "9214 번째 loss, accuracy:  0.40162221618264266 0.8916666666666667\n",
      "9215 번째 loss, accuracy:  0.40158186031590487 0.8916666666666667\n",
      "9216 번째 loss, accuracy:  0.4015414944229788 0.8916666666666667\n",
      "9217 번째 loss, accuracy:  0.4015011185081686 0.8916666666666667\n",
      "9218 번째 loss, accuracy:  0.4014607325757852 0.8916666666666667\n",
      "9219 번째 loss, accuracy:  0.4014203366301457 0.8916666666666667\n",
      "9220 번째 loss, accuracy:  0.4013799306755725 0.8916666666666667\n",
      "9221 번째 loss, accuracy:  0.40133951471639534 0.8916666666666667\n",
      "9222 번째 loss, accuracy:  0.40129908875694975 0.8916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9223 번째 loss, accuracy:  0.4012586528015772 0.8916666666666667\n",
      "9224 번째 loss, accuracy:  0.40121820685462567 0.8916666666666667\n",
      "9225 번째 loss, accuracy:  0.40117775092044916 0.8916666666666667\n",
      "9226 번째 loss, accuracy:  0.40113728500340806 0.8916666666666667\n",
      "9227 번째 loss, accuracy:  0.401096809107869 0.8916666666666667\n",
      "9228 번째 loss, accuracy:  0.40105632323820495 0.8916666666666667\n",
      "9229 번째 loss, accuracy:  0.40101582739879427 0.8916666666666667\n",
      "9230 번째 loss, accuracy:  0.40097532159402244 0.8916666666666667\n",
      "9231 번째 loss, accuracy:  0.40093480582828034 0.8916666666666667\n",
      "9232 번째 loss, accuracy:  0.40089428010596584 0.8916666666666667\n",
      "9233 번째 loss, accuracy:  0.4008537444314829 0.8916666666666667\n",
      "9234 번째 loss, accuracy:  0.400813198809241 0.8916666666666667\n",
      "9235 번째 loss, accuracy:  0.4007726432436562 0.8916666666666667\n",
      "9236 번째 loss, accuracy:  0.40073207773915104 0.8916666666666667\n",
      "9237 번째 loss, accuracy:  0.40069150230015377 0.8916666666666667\n",
      "9238 번째 loss, accuracy:  0.40065091693109894 0.8916666666666667\n",
      "9239 번째 loss, accuracy:  0.40061032163642746 0.8916666666666667\n",
      "9240 번째 loss, accuracy:  0.40056971642058653 0.8916666666666667\n",
      "9241 번째 loss, accuracy:  0.4005291012880286 0.8916666666666667\n",
      "9242 번째 loss, accuracy:  0.4004884762432131 0.8916666666666667\n",
      "9243 번째 loss, accuracy:  0.4004478412906061 0.8916666666666667\n",
      "9244 번째 loss, accuracy:  0.40040719643467876 0.8916666666666667\n",
      "9245 번째 loss, accuracy:  0.400366541679909 0.8916666666666667\n",
      "9246 번째 loss, accuracy:  0.4003258770307809 0.8916666666666667\n",
      "9247 번째 loss, accuracy:  0.40028520249178395 0.8916666666666667\n",
      "9248 번째 loss, accuracy:  0.40024451806741534 0.8916666666666667\n",
      "9249 번째 loss, accuracy:  0.40020382376217684 0.8916666666666667\n",
      "9250 번째 loss, accuracy:  0.40016311958057743 0.8916666666666667\n",
      "9251 번째 loss, accuracy:  0.40012240552713163 0.8916666666666667\n",
      "9252 번째 loss, accuracy:  0.4000816816063603 0.8916666666666667\n",
      "9253 번째 loss, accuracy:  0.40004094782279037 0.8916666666666667\n",
      "9254 번째 loss, accuracy:  0.40000020418095505 0.8916666666666667\n",
      "9255 번째 loss, accuracy:  0.39995945068539374 0.8916666666666667\n",
      "9256 번째 loss, accuracy:  0.3999186873406516 0.8916666666666667\n",
      "9257 번째 loss, accuracy:  0.3998779141512807 0.8916666666666667\n",
      "9258 번째 loss, accuracy:  0.3998371311218382 0.8916666666666667\n",
      "9259 번째 loss, accuracy:  0.39979633825688826 0.8916666666666667\n",
      "9260 번째 loss, accuracy:  0.39975553556100096 0.8916666666666667\n",
      "9261 번째 loss, accuracy:  0.3997147230387522 0.8916666666666667\n",
      "9262 번째 loss, accuracy:  0.3996739006947242 0.8916666666666667\n",
      "9263 번째 loss, accuracy:  0.399633068533505 0.8916666666666667\n",
      "9264 번째 loss, accuracy:  0.39959222655968935 0.8916666666666667\n",
      "9265 번째 loss, accuracy:  0.3995513747778779 0.8916666666666667\n",
      "9266 번째 loss, accuracy:  0.3995105131926772 0.8916666666666667\n",
      "9267 번째 loss, accuracy:  0.39946964180870015 0.8916666666666667\n",
      "9268 번째 loss, accuracy:  0.3994287606305651 0.8916666666666667\n",
      "9269 번째 loss, accuracy:  0.3993878696628977 0.8916666666666667\n",
      "9270 번째 loss, accuracy:  0.3993469689103285 0.8916666666666667\n",
      "9271 번째 loss, accuracy:  0.3993060583774951 0.8916666666666667\n",
      "9272 번째 loss, accuracy:  0.3992651380690408 0.8916666666666667\n",
      "9273 번째 loss, accuracy:  0.3992242079896149 0.8916666666666667\n",
      "9274 번째 loss, accuracy:  0.3991832681438729 0.8916666666666667\n",
      "9275 번째 loss, accuracy:  0.39914231853647614 0.8916666666666667\n",
      "9276 번째 loss, accuracy:  0.39910135917209233 0.8916666666666667\n",
      "9277 번째 loss, accuracy:  0.39906039005539545 0.8916666666666667\n",
      "9278 번째 loss, accuracy:  0.39901941119106527 0.8916666666666667\n",
      "9279 번째 loss, accuracy:  0.3989784225837878 0.8916666666666667\n",
      "9280 번째 loss, accuracy:  0.3989374242382547 0.8916666666666667\n",
      "9281 번째 loss, accuracy:  0.39889641615916444 0.8916666666666667\n",
      "9282 번째 loss, accuracy:  0.39885539835122075 0.8916666666666667\n",
      "9283 번째 loss, accuracy:  0.3988143708191342 0.8916666666666667\n",
      "9284 번째 loss, accuracy:  0.3987733335676205 0.8916666666666667\n",
      "9285 번째 loss, accuracy:  0.39873228660140286 0.8916666666666667\n",
      "9286 번째 loss, accuracy:  0.39869122992520906 0.8916666666666667\n",
      "9287 번째 loss, accuracy:  0.39865016354377397 0.8916666666666667\n",
      "9288 번째 loss, accuracy:  0.39860908746183765 0.8916666666666667\n",
      "9289 번째 loss, accuracy:  0.3985680016841466 0.8916666666666667\n",
      "9290 번째 loss, accuracy:  0.39852690621545395 0.8916666666666667\n",
      "9291 번째 loss, accuracy:  0.3984858010605181 0.8916666666666667\n",
      "9292 번째 loss, accuracy:  0.39844468622410356 0.8916666666666667\n",
      "9293 번째 loss, accuracy:  0.3984035617109815 0.8916666666666667\n",
      "9294 번째 loss, accuracy:  0.39836242752592893 0.8916666666666667\n",
      "9295 번째 loss, accuracy:  0.39832128367372804 0.8916666666666667\n",
      "9296 번째 loss, accuracy:  0.398280130159168 0.8916666666666667\n",
      "9297 번째 loss, accuracy:  0.3982389669870435 0.8916666666666667\n",
      "9298 번째 loss, accuracy:  0.39819779416215606 0.8916666666666667\n",
      "9299 번째 loss, accuracy:  0.39815661168931193 0.8916666666666667\n",
      "9300 번째 loss, accuracy:  0.3981154195733244 0.8916666666666667\n",
      "9301 번째 loss, accuracy:  0.3980742178190121 0.8916666666666667\n",
      "9302 번째 loss, accuracy:  0.39803300643120104 0.8916666666666667\n",
      "9303 번째 loss, accuracy:  0.3979917854147213 0.8916666666666667\n",
      "9304 번째 loss, accuracy:  0.39795055477441027 0.8916666666666667\n",
      "9305 번째 loss, accuracy:  0.3979093145151109 0.8916666666666667\n",
      "9306 번째 loss, accuracy:  0.39786806464167257 0.8916666666666667\n",
      "9307 번째 loss, accuracy:  0.39782680515895 0.8916666666666667\n",
      "9308 번째 loss, accuracy:  0.39778553607180456 0.8916666666666667\n",
      "9309 번째 loss, accuracy:  0.3977442573851032 0.8916666666666667\n",
      "9310 번째 loss, accuracy:  0.3977029691037188 0.8916666666666667\n",
      "9311 번째 loss, accuracy:  0.39766167123253077 0.8916666666666667\n",
      "9312 번째 loss, accuracy:  0.39762036377642374 0.8916666666666667\n",
      "9313 번째 loss, accuracy:  0.397579046740289 0.8916666666666667\n",
      "9314 번째 loss, accuracy:  0.3975377201290235 0.8916666666666667\n",
      "9315 번째 loss, accuracy:  0.39749638394753056 0.8916666666666667\n",
      "9316 번째 loss, accuracy:  0.39745503820071887 0.8916666666666667\n",
      "9317 번째 loss, accuracy:  0.39741368289350354 0.8916666666666667\n",
      "9318 번째 loss, accuracy:  0.3973723180308057 0.8916666666666667\n",
      "9319 번째 loss, accuracy:  0.39733094361755167 0.8916666666666667\n",
      "9320 번째 loss, accuracy:  0.3972895596586749 0.8916666666666667\n",
      "9321 번째 loss, accuracy:  0.39724816615911396 0.8916666666666667\n",
      "9322 번째 loss, accuracy:  0.39720676312381364 0.8916666666666667\n",
      "9323 번째 loss, accuracy:  0.3971653505577244 0.8916666666666667\n",
      "9324 번째 loss, accuracy:  0.3971239284658035 0.8916666666666667\n",
      "9325 번째 loss, accuracy:  0.3970824968530134 0.8916666666666667\n",
      "9326 번째 loss, accuracy:  0.39704105572432263 0.9\n",
      "9327 번째 loss, accuracy:  0.39699960508470566 0.9\n",
      "9328 번째 loss, accuracy:  0.39695814493914294 0.9\n",
      "9329 번째 loss, accuracy:  0.3969166752926211 0.9\n",
      "9330 번째 loss, accuracy:  0.39687519615013245 0.9\n",
      "9331 번째 loss, accuracy:  0.3968337075166757 0.9\n",
      "9332 번째 loss, accuracy:  0.39679220939725474 0.9\n",
      "9333 번째 loss, accuracy:  0.39675070179687993 0.9\n",
      "9334 번째 loss, accuracy:  0.396709184720567 0.9\n",
      "9335 번째 loss, accuracy:  0.3966676581733382 0.9\n",
      "9336 번째 loss, accuracy:  0.3966261221602217 0.9\n",
      "9337 번째 loss, accuracy:  0.39658457668625113 0.9\n",
      "9338 번째 loss, accuracy:  0.3965430217564664 0.9\n",
      "9339 번째 loss, accuracy:  0.39650145737591286 0.9\n",
      "9340 번째 loss, accuracy:  0.39645988354964234 0.9\n",
      "9341 번째 loss, accuracy:  0.39641830028271247 0.9\n",
      "9342 번째 loss, accuracy:  0.3963767075801861 0.9\n",
      "9343 번째 loss, accuracy:  0.39633510544713296 0.9\n",
      "9344 번째 loss, accuracy:  0.3962934938886281 0.9\n",
      "9345 번째 loss, accuracy:  0.3962518729097528 0.9\n",
      "9346 번째 loss, accuracy:  0.39621024251559406 0.9\n",
      "9347 번째 loss, accuracy:  0.39616860271124427 0.9\n",
      "9348 번째 loss, accuracy:  0.39612695350180266 0.9\n",
      "9349 번째 loss, accuracy:  0.3960852948923733 0.9\n",
      "9350 번째 loss, accuracy:  0.39604362688806743 0.9\n",
      "9351 번째 loss, accuracy:  0.3960019494940007 0.9\n",
      "9352 번째 loss, accuracy:  0.3959602627152955 0.9\n",
      "9353 번째 loss, accuracy:  0.39591856655708 0.9\n",
      "9354 번째 loss, accuracy:  0.3958768610244882 0.9\n",
      "9355 번째 loss, accuracy:  0.3958351461226597 0.9\n",
      "9356 번째 loss, accuracy:  0.3957934218567408 0.9\n",
      "9357 번째 loss, accuracy:  0.39575168823188217 0.9\n",
      "9358 번째 loss, accuracy:  0.39570994525324166 0.9\n",
      "9359 번째 loss, accuracy:  0.39566819292598226 0.9\n",
      "9360 번째 loss, accuracy:  0.3956264312552734 0.9\n",
      "9361 번째 loss, accuracy:  0.3955846602462893 0.9\n",
      "9362 번째 loss, accuracy:  0.3955428799042113 0.9\n",
      "9363 번째 loss, accuracy:  0.39550109023422614 0.9\n",
      "9364 번째 loss, accuracy:  0.3954592912415257 0.9\n",
      "9365 번째 loss, accuracy:  0.39541748293130813 0.9\n",
      "9366 번째 loss, accuracy:  0.395375665308778 0.9\n",
      "9367 번째 loss, accuracy:  0.3953338383791446 0.9\n",
      "9368 번째 loss, accuracy:  0.39529200214762383 0.9\n",
      "9369 번째 loss, accuracy:  0.39525015661943735 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9370 번째 loss, accuracy:  0.39520830179981237 0.9\n",
      "9371 번째 loss, accuracy:  0.3951664376939822 0.9\n",
      "9372 번째 loss, accuracy:  0.3951245643071855 0.9\n",
      "9373 번째 loss, accuracy:  0.39508268164466703 0.9\n",
      "9374 번째 loss, accuracy:  0.395040789711677 0.9\n",
      "9375 번째 loss, accuracy:  0.3949988885134725 0.9\n",
      "9376 번째 loss, accuracy:  0.3949569780553148 0.9\n",
      "9377 번째 loss, accuracy:  0.39491505834247176 0.9\n",
      "9378 번째 loss, accuracy:  0.3948731293802179 0.9\n",
      "9379 번째 loss, accuracy:  0.3948311911738319 0.9\n",
      "9380 번째 loss, accuracy:  0.3947892437285992 0.9\n",
      "9381 번째 loss, accuracy:  0.394747287049811 0.9\n",
      "9382 번째 loss, accuracy:  0.3947053211427638 0.9\n",
      "9383 번째 loss, accuracy:  0.3946633460127602 0.9\n",
      "9384 번째 loss, accuracy:  0.3946213616651086 0.9\n",
      "9385 번째 loss, accuracy:  0.3945793681051227 0.9\n",
      "9386 번째 loss, accuracy:  0.39453736533812234 0.9\n",
      "9387 번째 loss, accuracy:  0.39449535336943387 0.9\n",
      "9388 번째 loss, accuracy:  0.39445333220438783 0.9\n",
      "9389 번째 loss, accuracy:  0.3944113018483211 0.9\n",
      "9390 번째 loss, accuracy:  0.39436926230657676 0.9\n",
      "9391 번째 loss, accuracy:  0.3943272135845032 0.9\n",
      "9392 번째 loss, accuracy:  0.3942851556874547 0.9\n",
      "9393 번째 loss, accuracy:  0.39424308862079144 0.9\n",
      "9394 번째 loss, accuracy:  0.3942010123898789 0.9\n",
      "9395 번째 loss, accuracy:  0.3941589270000888 0.9\n",
      "9396 번째 loss, accuracy:  0.3941168324567979 0.9\n",
      "9397 번째 loss, accuracy:  0.3940747287653893 0.9\n",
      "9398 번째 loss, accuracy:  0.3940326159312516 0.9\n",
      "9399 번째 loss, accuracy:  0.3939904939597794 0.9\n",
      "9400 번째 loss, accuracy:  0.3939483628563718 0.9\n",
      "9401 번째 loss, accuracy:  0.393906222626435 0.9\n",
      "9402 번째 loss, accuracy:  0.3938640732753806 0.9\n",
      "9403 번째 loss, accuracy:  0.39382191480862544 0.9\n",
      "9404 번째 loss, accuracy:  0.39377974723159226 0.9\n",
      "9405 번째 loss, accuracy:  0.39373757054970965 0.9\n",
      "9406 번째 loss, accuracy:  0.3936953847684118 0.9\n",
      "9407 번째 loss, accuracy:  0.39365318989313813 0.9\n",
      "9408 번째 loss, accuracy:  0.39361098592933497 0.9\n",
      "9409 번째 loss, accuracy:  0.3935687728824527 0.9\n",
      "9410 번째 loss, accuracy:  0.39352655075794823 0.9\n",
      "9411 번째 loss, accuracy:  0.39348431956128455 0.9\n",
      "9412 번째 loss, accuracy:  0.3934420792979293 0.9\n",
      "9413 번째 loss, accuracy:  0.39339982997335654 0.9\n",
      "9414 번째 loss, accuracy:  0.3933575715930459 0.9\n",
      "9415 번째 loss, accuracy:  0.3933153041624822 0.9\n",
      "9416 번째 loss, accuracy:  0.39327302768715655 0.9\n",
      "9417 번째 loss, accuracy:  0.39323074217256515 0.9\n",
      "9418 번째 loss, accuracy:  0.3931884476242101 0.9\n",
      "9419 번째 loss, accuracy:  0.39314614404759884 0.9\n",
      "9420 번째 loss, accuracy:  0.3931038314482448 0.9\n",
      "9421 번째 loss, accuracy:  0.3930615098316672 0.9\n",
      "9422 번째 loss, accuracy:  0.39301917920339047 0.9\n",
      "9423 번째 loss, accuracy:  0.3929768395689449 0.9\n",
      "9424 번째 loss, accuracy:  0.39293449093386607 0.9\n",
      "9425 번째 loss, accuracy:  0.39289213330369555 0.9\n",
      "9426 번째 loss, accuracy:  0.3928497666839801 0.9\n",
      "9427 번째 loss, accuracy:  0.39280739108027246 0.9\n",
      "9428 번째 loss, accuracy:  0.39276500649813106 0.9\n",
      "9429 번째 loss, accuracy:  0.3927226129431196 0.9\n",
      "9430 번째 loss, accuracy:  0.3926802104208073 0.9\n",
      "9431 번째 loss, accuracy:  0.39263779893676987 0.9\n",
      "9432 번째 loss, accuracy:  0.3925953784965872 0.9\n",
      "9433 번째 loss, accuracy:  0.39255294910584576 0.9\n",
      "9434 번째 loss, accuracy:  0.3925105107701371 0.9\n",
      "9435 번째 loss, accuracy:  0.39246806349505886 0.9\n",
      "9436 번째 loss, accuracy:  0.3924256072862138 0.9\n",
      "9437 번째 loss, accuracy:  0.3923831421492101 0.9\n",
      "9438 번째 loss, accuracy:  0.39234066808966245 0.9\n",
      "9439 번째 loss, accuracy:  0.3922981851131894 0.9\n",
      "9440 번째 loss, accuracy:  0.39225569322541687 0.9\n",
      "9441 번째 loss, accuracy:  0.3922131924319752 0.9\n",
      "9442 번째 loss, accuracy:  0.39217068273850086 0.9\n",
      "9443 번째 loss, accuracy:  0.3921281641506358 0.9\n",
      "9444 번째 loss, accuracy:  0.3920856366740268 0.9\n",
      "9445 번째 loss, accuracy:  0.3920431003143268 0.9\n",
      "9446 번째 loss, accuracy:  0.39200055507719445 0.9\n",
      "9447 번째 loss, accuracy:  0.39195800096829353 0.9\n",
      "9448 번째 loss, accuracy:  0.39191543799329337 0.9\n",
      "9449 번째 loss, accuracy:  0.3918728661578687 0.9\n",
      "9450 번째 loss, accuracy:  0.39183028546770066 0.9\n",
      "9451 번째 loss, accuracy:  0.3917876959284746 0.9\n",
      "9452 번째 loss, accuracy:  0.3917450975458824 0.9\n",
      "9453 번째 loss, accuracy:  0.39170249032562054 0.9\n",
      "9454 번째 loss, accuracy:  0.39165987427339183 0.9\n",
      "9455 번째 loss, accuracy:  0.3916172493949039 0.9\n",
      "9456 번째 loss, accuracy:  0.39157461569587043 0.9\n",
      "9457 번째 loss, accuracy:  0.3915319731820109 0.9\n",
      "9458 번째 loss, accuracy:  0.39148932185904883 0.9\n",
      "9459 번째 loss, accuracy:  0.39144666173271453 0.9\n",
      "9460 번째 loss, accuracy:  0.39140399280874344 0.9\n",
      "9461 번째 loss, accuracy:  0.39136131509287597 0.9\n",
      "9462 번째 loss, accuracy:  0.3913186285908593 0.9\n",
      "9463 번째 loss, accuracy:  0.3912759333084439 0.9\n",
      "9464 번째 loss, accuracy:  0.39123322925138765 0.9\n",
      "9465 번째 loss, accuracy:  0.39119051642545377 0.9\n",
      "9466 번째 loss, accuracy:  0.39114779483640943 0.9\n",
      "9467 번째 loss, accuracy:  0.3911050644900287 0.9\n",
      "9468 번째 loss, accuracy:  0.3910623253920908 0.9\n",
      "9469 번째 loss, accuracy:  0.3910195775483799 0.9\n",
      "9470 번째 loss, accuracy:  0.39097682096468594 0.9\n",
      "9471 번째 loss, accuracy:  0.3909340556468039 0.9\n",
      "9472 번째 loss, accuracy:  0.3908912816005344 0.9\n",
      "9473 번째 loss, accuracy:  0.3908484988316838 0.9\n",
      "9474 번째 loss, accuracy:  0.3908057073460642 0.9\n",
      "9475 번째 loss, accuracy:  0.3907629071494914 0.9\n",
      "9476 번째 loss, accuracy:  0.39072009824778864 0.9\n",
      "9477 번째 loss, accuracy:  0.3906772806467835 0.9\n",
      "9478 번째 loss, accuracy:  0.39063445435230953 0.9\n",
      "9479 번째 loss, accuracy:  0.3905916193702045 0.9\n",
      "9480 번째 loss, accuracy:  0.39054877570631263 0.9\n",
      "9481 번째 loss, accuracy:  0.390505923366484 0.9\n",
      "9482 번째 loss, accuracy:  0.3904630623565723 0.9\n",
      "9483 번째 loss, accuracy:  0.3904201926824381 0.9\n",
      "9484 번째 loss, accuracy:  0.390377314349947 0.9\n",
      "9485 번째 loss, accuracy:  0.3903344273649696 0.9\n",
      "9486 번째 loss, accuracy:  0.39029153173338205 0.9\n",
      "9487 번째 loss, accuracy:  0.39024862746106614 0.9\n",
      "9488 번째 loss, accuracy:  0.3902057145539085 0.9\n",
      "9489 번째 loss, accuracy:  0.3901627930178014 0.9\n",
      "9490 번째 loss, accuracy:  0.3901198628586427 0.9\n",
      "9491 번째 loss, accuracy:  0.39007692408233524 0.9\n",
      "9492 번째 loss, accuracy:  0.3900339766947873 0.9\n",
      "9493 번째 loss, accuracy:  0.38999102070191266 0.9\n",
      "9494 번째 loss, accuracy:  0.3899480561096302 0.9\n",
      "9495 번째 loss, accuracy:  0.38990508292386383 0.9\n",
      "9496 번째 loss, accuracy:  0.3898621011505435 0.9\n",
      "9497 번째 loss, accuracy:  0.38981911079560366 0.9\n",
      "9498 번째 loss, accuracy:  0.38977611186498534 0.9\n",
      "9499 번째 loss, accuracy:  0.38973310436463343 0.9\n",
      "9500 번째 loss, accuracy:  0.38969008830049884 0.9\n",
      "9501 번째 loss, accuracy:  0.3896470636785377 0.9\n",
      "9502 번째 loss, accuracy:  0.3896040305047117 0.9\n",
      "9503 번째 loss, accuracy:  0.38956098878498746 0.9\n",
      "9504 번째 loss, accuracy:  0.38951793852533656 0.9\n",
      "9505 번째 loss, accuracy:  0.3894748797317367 0.9\n",
      "9506 번째 loss, accuracy:  0.3894318124101703 0.9\n",
      "9507 번째 loss, accuracy:  0.3893887365666255 0.9\n",
      "9508 번째 loss, accuracy:  0.38934565220709494 0.9\n",
      "9509 번째 loss, accuracy:  0.38930255933757724 0.9\n",
      "9510 번째 loss, accuracy:  0.3892594579640758 0.9\n",
      "9511 번째 loss, accuracy:  0.3892163480925994 0.9\n",
      "9512 번째 loss, accuracy:  0.3891732297291623 0.9\n",
      "9513 번째 loss, accuracy:  0.3891301028797842 0.9\n",
      "9514 번째 loss, accuracy:  0.38908696755048927 0.9\n",
      "9515 번째 loss, accuracy:  0.3890438237473078 0.9\n",
      "9516 번째 loss, accuracy:  0.38900067147627393 0.9\n",
      "9517 번째 loss, accuracy:  0.3889575107434287 0.9\n",
      "9518 번째 loss, accuracy:  0.38891434155481713 0.9\n",
      "9519 번째 loss, accuracy:  0.3888711639164903 0.9\n",
      "9520 번째 loss, accuracy:  0.3888279778345038 0.9\n",
      "9521 번째 loss, accuracy:  0.38878478331491895 0.9\n",
      "9522 번째 loss, accuracy:  0.38874158036380246 0.9\n",
      "9523 번째 loss, accuracy:  0.3886983689872257 0.9\n",
      "9524 번째 loss, accuracy:  0.3886551491912654 0.9\n",
      "9525 번째 loss, accuracy:  0.38861192098200303 0.9\n",
      "9526 번째 loss, accuracy:  0.38856868436552616 0.9\n",
      "9527 번째 loss, accuracy:  0.3885254393479268 0.9\n",
      "9528 번째 loss, accuracy:  0.3884821859353026 0.9\n",
      "9529 번째 loss, accuracy:  0.3884389241337561 0.9\n",
      "9530 번째 loss, accuracy:  0.38839565394939524 0.9\n",
      "9531 번째 loss, accuracy:  0.3883523753883327 0.9\n",
      "9532 번째 loss, accuracy:  0.38830908845668677 0.9\n",
      "9533 번째 loss, accuracy:  0.3882657931605806 0.9\n",
      "9534 번째 loss, accuracy:  0.38822248950614313 0.9\n",
      "9535 번째 loss, accuracy:  0.38817917749950737 0.9\n",
      "9536 번째 loss, accuracy:  0.388135857146812 0.9\n",
      "9537 번째 loss, accuracy:  0.38809252845420134 0.9\n",
      "9538 번째 loss, accuracy:  0.3880491914278236 0.9\n",
      "9539 번째 loss, accuracy:  0.38800584607383365 0.9\n",
      "9540 번째 loss, accuracy:  0.3879624923983901 0.9\n",
      "9541 번째 loss, accuracy:  0.38791913040765763 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9542 번째 loss, accuracy:  0.3878757601078055 0.9\n",
      "9543 번째 loss, accuracy:  0.38783238150500843 0.9\n",
      "9544 번째 loss, accuracy:  0.3877889946054459 0.9\n",
      "9545 번째 loss, accuracy:  0.3877455994153026 0.9\n",
      "9546 번째 loss, accuracy:  0.38770219594076816 0.9\n",
      "9547 번째 loss, accuracy:  0.3876587841880378 0.9\n",
      "9548 번째 loss, accuracy:  0.38761536416331144 0.9\n",
      "9549 번째 loss, accuracy:  0.38757193587279415 0.9\n",
      "9550 번째 loss, accuracy:  0.38752849932269595 0.9\n",
      "9551 번째 loss, accuracy:  0.3874850545192322 0.9\n",
      "9552 번째 loss, accuracy:  0.38744160146862294 0.9\n",
      "9553 번째 loss, accuracy:  0.38739814017709345 0.9\n",
      "9554 번째 loss, accuracy:  0.3873546706508743 0.9\n",
      "9555 번째 loss, accuracy:  0.38731119289620075 0.9\n",
      "9556 번째 loss, accuracy:  0.3872677069193134 0.9\n",
      "9557 번째 loss, accuracy:  0.3872242127264578 0.9\n",
      "9558 번째 loss, accuracy:  0.3871807103238845 0.9\n",
      "9559 번째 loss, accuracy:  0.3871371997178486 0.9\n",
      "9560 번째 loss, accuracy:  0.387093680914611 0.9\n",
      "9561 번째 loss, accuracy:  0.38705015392043735 0.9\n",
      "9562 번째 loss, accuracy:  0.38700661874159803 0.9\n",
      "9563 번째 loss, accuracy:  0.3869630753843689 0.9\n",
      "9564 번째 loss, accuracy:  0.3869195238550304 0.9\n",
      "9565 번째 loss, accuracy:  0.38687596415986825 0.9\n",
      "9566 번째 loss, accuracy:  0.38683239630517313 0.9\n",
      "9567 번째 loss, accuracy:  0.3867888202972406 0.9\n",
      "9568 번째 loss, accuracy:  0.38674523614237066 0.9\n",
      "9569 번째 loss, accuracy:  0.3867016438468698 0.9\n",
      "9570 번째 loss, accuracy:  0.3866580434170481 0.9\n",
      "9571 번째 loss, accuracy:  0.38661443485922103 0.9\n",
      "9572 번째 loss, accuracy:  0.3865708181797091 0.9\n",
      "9573 번째 loss, accuracy:  0.38652719338483776 0.9\n",
      "9574 번째 loss, accuracy:  0.3864835604809372 0.9\n",
      "9575 번째 loss, accuracy:  0.38643991947434286 0.9\n",
      "9576 번째 loss, accuracy:  0.3863962703713954 0.9\n",
      "9577 번째 loss, accuracy:  0.3863526131784392 0.9\n",
      "9578 번째 loss, accuracy:  0.3863089479018254 0.9\n",
      "9579 번째 loss, accuracy:  0.3862652745479083 0.9\n",
      "9580 번째 loss, accuracy:  0.3862215931230483 0.9\n",
      "9581 번째 loss, accuracy:  0.3861779036336101 0.9\n",
      "9582 번째 loss, accuracy:  0.38613420608596377 0.9\n",
      "9583 번째 loss, accuracy:  0.38609050048648363 0.9\n",
      "9584 번째 loss, accuracy:  0.38604678684154964 0.9\n",
      "9585 번째 loss, accuracy:  0.38600306515754634 0.9\n",
      "9586 번째 loss, accuracy:  0.3859593354408631 0.9\n",
      "9587 번째 loss, accuracy:  0.38591559769789424 0.9\n",
      "9588 번째 loss, accuracy:  0.3858718519350386 0.9\n",
      "9589 번째 loss, accuracy:  0.38582809815870056 0.9\n",
      "9590 번째 loss, accuracy:  0.385784336375289 0.9\n",
      "9591 번째 loss, accuracy:  0.38574056659121786 0.9\n",
      "9592 번째 loss, accuracy:  0.385696788812906 0.9\n",
      "9593 번째 loss, accuracy:  0.3856530030467765 0.9083333333333333\n",
      "9594 번째 loss, accuracy:  0.38560920929925824 0.9083333333333333\n",
      "9595 번째 loss, accuracy:  0.3855654075767841 0.9083333333333333\n",
      "9596 번째 loss, accuracy:  0.38552159788579216 0.9083333333333333\n",
      "9597 번째 loss, accuracy:  0.38547778023272555 0.9083333333333333\n",
      "9598 번째 loss, accuracy:  0.38543395462403207 0.9083333333333333\n",
      "9599 번째 loss, accuracy:  0.3853901210661641 0.9083333333333333\n",
      "9600 번째 loss, accuracy:  0.38534627956557915 0.9083333333333333\n",
      "9601 번째 loss, accuracy:  0.3853024301287392 0.9083333333333333\n",
      "9602 번째 loss, accuracy:  0.3852585727621113 0.9083333333333333\n",
      "9603 번째 loss, accuracy:  0.38521470747216746 0.9083333333333333\n",
      "9604 번째 loss, accuracy:  0.38517083426538457 0.9083333333333333\n",
      "9605 번째 loss, accuracy:  0.3851269531482437 0.9083333333333333\n",
      "9606 번째 loss, accuracy:  0.385083064127231 0.9083333333333333\n",
      "9607 번째 loss, accuracy:  0.3850391672088375 0.9083333333333333\n",
      "9608 번째 loss, accuracy:  0.384995262399559 0.9083333333333333\n",
      "9609 번째 loss, accuracy:  0.38495134970589634 0.9083333333333333\n",
      "9610 번째 loss, accuracy:  0.3849074291343547 0.9083333333333333\n",
      "9611 번째 loss, accuracy:  0.384863500691444 0.9083333333333333\n",
      "9612 번째 loss, accuracy:  0.3848195643836791 0.9083333333333333\n",
      "9613 번째 loss, accuracy:  0.3847756202175795 0.9083333333333333\n",
      "9614 번째 loss, accuracy:  0.3847316681996699 0.9083333333333333\n",
      "9615 번째 loss, accuracy:  0.3846877083364789 0.9083333333333333\n",
      "9616 번째 loss, accuracy:  0.38464374063454104 0.9083333333333333\n",
      "9617 번째 loss, accuracy:  0.38459976510039495 0.9083333333333333\n",
      "9618 번째 loss, accuracy:  0.3845557817405833 0.9083333333333333\n",
      "9619 번째 loss, accuracy:  0.38451179056165424 0.9083333333333333\n",
      "9620 번째 loss, accuracy:  0.3844677915701606 0.9083333333333333\n",
      "9621 번째 loss, accuracy:  0.38442378477265954 0.9083333333333333\n",
      "9622 번째 loss, accuracy:  0.3843797701757133 0.9083333333333333\n",
      "9623 번째 loss, accuracy:  0.38433574778588914 0.9083333333333333\n",
      "9624 번째 loss, accuracy:  0.3842917176097584 0.9083333333333333\n",
      "9625 번째 loss, accuracy:  0.384247679653897 0.9083333333333333\n",
      "9626 번째 loss, accuracy:  0.3842036339248865 0.9083333333333333\n",
      "9627 번째 loss, accuracy:  0.3841595804293121 0.9083333333333333\n",
      "9628 번째 loss, accuracy:  0.38411551917376396 0.9083333333333333\n",
      "9629 번째 loss, accuracy:  0.3840714501648366 0.9083333333333333\n",
      "9630 번째 loss, accuracy:  0.3840273734091305 0.9083333333333333\n",
      "9631 번째 loss, accuracy:  0.3839832889132498 0.9083333333333333\n",
      "9632 번째 loss, accuracy:  0.38393919668380333 0.9083333333333333\n",
      "9633 번째 loss, accuracy:  0.38389509672740446 0.9083333333333333\n",
      "9634 번째 loss, accuracy:  0.3838509890506713 0.9083333333333333\n",
      "9635 번째 loss, accuracy:  0.38380687366022664 0.9083333333333333\n",
      "9636 번째 loss, accuracy:  0.38376275056269843 0.9083333333333333\n",
      "9637 번째 loss, accuracy:  0.38371861976471827 0.9083333333333333\n",
      "9638 번째 loss, accuracy:  0.3836744812729228 0.9083333333333333\n",
      "9639 번째 loss, accuracy:  0.38363033509395433 0.9083333333333333\n",
      "9640 번째 loss, accuracy:  0.38358618123445776 0.9083333333333333\n",
      "9641 번째 loss, accuracy:  0.3835420197010842 0.9083333333333333\n",
      "9642 번째 loss, accuracy:  0.3834978505004881 0.9083333333333333\n",
      "9643 번째 loss, accuracy:  0.3834536736393301 0.9083333333333333\n",
      "9644 번째 loss, accuracy:  0.38340948912427386 0.9083333333333333\n",
      "9645 번째 loss, accuracy:  0.38336529696198896 0.9083333333333333\n",
      "9646 번째 loss, accuracy:  0.383321097159148 0.9083333333333333\n",
      "9647 번째 loss, accuracy:  0.38327688972242957 0.9083333333333333\n",
      "9648 번째 loss, accuracy:  0.3832326746585167 0.9083333333333333\n",
      "9649 번째 loss, accuracy:  0.3831884519740955 0.9083333333333333\n",
      "9650 번째 loss, accuracy:  0.38314422167585865 0.9083333333333333\n",
      "9651 번째 loss, accuracy:  0.38309998377050175 0.9083333333333333\n",
      "9652 번째 loss, accuracy:  0.3830557382647259 0.9083333333333333\n",
      "9653 번째 loss, accuracy:  0.3830114851652365 0.9083333333333333\n",
      "9654 번째 loss, accuracy:  0.3829672244787428 0.9083333333333333\n",
      "9655 번째 loss, accuracy:  0.38292295621196026 0.9083333333333333\n",
      "9656 번째 loss, accuracy:  0.3828786803716072 0.9083333333333333\n",
      "9657 번째 loss, accuracy:  0.38283439696440735 0.9083333333333333\n",
      "9658 번째 loss, accuracy:  0.3827901059970885 0.9083333333333333\n",
      "9659 번째 loss, accuracy:  0.3827458074763831 0.9083333333333333\n",
      "9660 번째 loss, accuracy:  0.3827015014090283 0.9083333333333333\n",
      "9661 번째 loss, accuracy:  0.38265718780176566 0.9083333333333333\n",
      "9662 번째 loss, accuracy:  0.38261286666134087 0.9083333333333333\n",
      "9663 번째 loss, accuracy:  0.38256853799450435 0.9083333333333333\n",
      "9664 번째 loss, accuracy:  0.382524201808011 0.9083333333333333\n",
      "9665 번째 loss, accuracy:  0.3824798581086203 0.9083333333333333\n",
      "9666 번째 loss, accuracy:  0.38243550690309597 0.9083333333333333\n",
      "9667 번째 loss, accuracy:  0.3823911481982065 0.9083333333333333\n",
      "9668 번째 loss, accuracy:  0.38234678200072464 0.9083333333333333\n",
      "9669 번째 loss, accuracy:  0.38230240831742773 0.9083333333333333\n",
      "9670 번째 loss, accuracy:  0.38225802715509666 0.9083333333333333\n",
      "9671 번째 loss, accuracy:  0.382213638520518 0.9083333333333333\n",
      "9672 번째 loss, accuracy:  0.3821692424204825 0.9083333333333333\n",
      "9673 번째 loss, accuracy:  0.38212483886178517 0.9083333333333333\n",
      "9674 번째 loss, accuracy:  0.38208042785122476 0.9083333333333333\n",
      "9675 번째 loss, accuracy:  0.3820360093956052 0.9083333333333333\n",
      "9676 번째 loss, accuracy:  0.3819915835017351 0.9083333333333333\n",
      "9677 번째 loss, accuracy:  0.3819471501764268 0.9083333333333333\n",
      "9678 번째 loss, accuracy:  0.38190270942649757 0.9083333333333333\n",
      "9679 번째 loss, accuracy:  0.3818582612587684 0.9083333333333333\n",
      "9680 번째 loss, accuracy:  0.38181380568006507 0.9083333333333333\n",
      "9681 번째 loss, accuracy:  0.38176934269721774 0.9083333333333333\n",
      "9682 번째 loss, accuracy:  0.3817248723170613 0.9083333333333333\n",
      "9683 번째 loss, accuracy:  0.3816803945464342 0.9083333333333333\n",
      "9684 번째 loss, accuracy:  0.38163590939217984 0.9083333333333333\n",
      "9685 번째 loss, accuracy:  0.3815914168611459 0.9083333333333333\n",
      "9686 번째 loss, accuracy:  0.3815469169601844 0.9083333333333333\n",
      "9687 번째 loss, accuracy:  0.3815024096961512 0.9083333333333333\n",
      "9688 번째 loss, accuracy:  0.381457895075907 0.9083333333333333\n",
      "9689 번째 loss, accuracy:  0.38141337310631707 0.9083333333333333\n",
      "9690 번째 loss, accuracy:  0.3813688437942511 0.9083333333333333\n",
      "9691 번째 loss, accuracy:  0.38132430714658216 0.9083333333333333\n",
      "9692 번째 loss, accuracy:  0.38127976317018825 0.9083333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9693 번째 loss, accuracy:  0.38123521187195153 0.9083333333333333\n",
      "9694 번째 loss, accuracy:  0.3811906532587589 0.9083333333333333\n",
      "9695 번째 loss, accuracy:  0.38114608733750077 0.9083333333333333\n",
      "9696 번째 loss, accuracy:  0.3811015141150727 0.9083333333333333\n",
      "9697 번째 loss, accuracy:  0.38105693359837395 0.9083333333333333\n",
      "9698 번째 loss, accuracy:  0.38101234579430837 0.9083333333333333\n",
      "9699 번째 loss, accuracy:  0.3809677507097838 0.9083333333333333\n",
      "9700 번째 loss, accuracy:  0.3809231483517127 0.9083333333333333\n",
      "9701 번째 loss, accuracy:  0.38087853872701155 0.9083333333333333\n",
      "9702 번째 loss, accuracy:  0.38083392184260123 0.9083333333333333\n",
      "9703 번째 loss, accuracy:  0.3807892977054069 0.9083333333333333\n",
      "9704 번째 loss, accuracy:  0.38074466632235776 0.9083333333333333\n",
      "9705 번째 loss, accuracy:  0.3807000277003868 0.9083333333333333\n",
      "9706 번째 loss, accuracy:  0.38065538184643255 0.9083333333333333\n",
      "9707 번째 loss, accuracy:  0.38061072876743657 0.9083333333333333\n",
      "9708 번째 loss, accuracy:  0.380566068470345 0.9083333333333333\n",
      "9709 번째 loss, accuracy:  0.38052140096210874 0.9083333333333333\n",
      "9710 번째 loss, accuracy:  0.3804767262496822 0.9083333333333333\n",
      "9711 번째 loss, accuracy:  0.3804320443400245 0.9083333333333333\n",
      "9712 번째 loss, accuracy:  0.380387355240098 0.9083333333333333\n",
      "9713 번째 loss, accuracy:  0.38034265895687086 0.9083333333333333\n",
      "9714 번째 loss, accuracy:  0.38029795549731354 0.9083333333333333\n",
      "9715 번째 loss, accuracy:  0.3802532448684025 0.9083333333333333\n",
      "9716 번째 loss, accuracy:  0.3802085270771174 0.9083333333333333\n",
      "9717 번째 loss, accuracy:  0.3801638021304419 0.9083333333333333\n",
      "9718 번째 loss, accuracy:  0.3801190700353645 0.9083333333333333\n",
      "9719 번째 loss, accuracy:  0.380074330798877 0.9083333333333333\n",
      "9720 번째 loss, accuracy:  0.3800295844279767 0.9083333333333333\n",
      "9721 번째 loss, accuracy:  0.3799848309296634 0.9083333333333333\n",
      "9722 번째 loss, accuracy:  0.3799400703109426 0.9083333333333333\n",
      "9723 번째 loss, accuracy:  0.3798953025788226 0.9083333333333333\n",
      "9724 번째 loss, accuracy:  0.3798505277403164 0.9083333333333333\n",
      "9725 번째 loss, accuracy:  0.3798057458024413 0.9083333333333333\n",
      "9726 번째 loss, accuracy:  0.3797609567722182 0.9083333333333333\n",
      "9727 번째 loss, accuracy:  0.3797161606566732 0.9083333333333333\n",
      "9728 번째 loss, accuracy:  0.37967135746283504 0.9083333333333333\n",
      "9729 번째 loss, accuracy:  0.3796265471977378 0.9083333333333333\n",
      "9730 번째 loss, accuracy:  0.37958172986841876 0.9083333333333333\n",
      "9731 번째 loss, accuracy:  0.3795369054819196 0.9083333333333333\n",
      "9732 번째 loss, accuracy:  0.3794920740452865 0.9083333333333333\n",
      "9733 번째 loss, accuracy:  0.3794472355655692 0.9083333333333333\n",
      "9734 번째 loss, accuracy:  0.3794023900498214 0.9083333333333333\n",
      "9735 번째 loss, accuracy:  0.3793575375051014 0.9083333333333333\n",
      "9736 번째 loss, accuracy:  0.3793126779384716 0.9083333333333333\n",
      "9737 번째 loss, accuracy:  0.37926781135699783 0.9083333333333333\n",
      "9738 번째 loss, accuracy:  0.37922293776775007 0.9083333333333333\n",
      "9739 번째 loss, accuracy:  0.3791780571778027 0.9083333333333333\n",
      "9740 번째 loss, accuracy:  0.3791331695942344 0.9083333333333333\n",
      "9741 번째 loss, accuracy:  0.3790882750241271 0.9083333333333333\n",
      "9742 번째 loss, accuracy:  0.3790433734745668 0.9083333333333333\n",
      "9743 번째 loss, accuracy:  0.37899846495264433 0.9083333333333333\n",
      "9744 번째 loss, accuracy:  0.3789535494654535 0.9083333333333333\n",
      "9745 번째 loss, accuracy:  0.3789086270200927 0.9083333333333333\n",
      "9746 번째 loss, accuracy:  0.3788636976236648 0.9083333333333333\n",
      "9747 번째 loss, accuracy:  0.37881876128327546 0.9083333333333333\n",
      "9748 번째 loss, accuracy:  0.37877381800603566 0.9083333333333333\n",
      "9749 번째 loss, accuracy:  0.3787288677990594 0.9083333333333333\n",
      "9750 번째 loss, accuracy:  0.37868391066946483 0.9083333333333333\n",
      "9751 번째 loss, accuracy:  0.37863894662437425 0.9083333333333333\n",
      "9752 번째 loss, accuracy:  0.37859397567091385 0.9083333333333333\n",
      "9753 번째 loss, accuracy:  0.3785489978162136 0.9083333333333333\n",
      "9754 번째 loss, accuracy:  0.3785040130674074 0.9083333333333333\n",
      "9755 번째 loss, accuracy:  0.3784590214316337 0.9083333333333333\n",
      "9756 번째 loss, accuracy:  0.3784140229160343 0.9083333333333333\n",
      "9757 번째 loss, accuracy:  0.3783690175277549 0.9083333333333333\n",
      "9758 번째 loss, accuracy:  0.3783240052739457 0.9083333333333333\n",
      "9759 번째 loss, accuracy:  0.37827898616176003 0.9083333333333333\n",
      "9760 번째 loss, accuracy:  0.37823396019835587 0.9083333333333333\n",
      "9761 번째 loss, accuracy:  0.3781889273908945 0.9083333333333333\n",
      "9762 번째 loss, accuracy:  0.37814388774654156 0.9083333333333333\n",
      "9763 번째 loss, accuracy:  0.37809884127246607 0.9083333333333333\n",
      "9764 번째 loss, accuracy:  0.3780537879758412 0.9083333333333333\n",
      "9765 번째 loss, accuracy:  0.3780087278638445 0.9083333333333333\n",
      "9766 번째 loss, accuracy:  0.37796366094365663 0.9083333333333333\n",
      "9767 번째 loss, accuracy:  0.37791858722246263 0.9083333333333333\n",
      "9768 번째 loss, accuracy:  0.37787350670745085 0.9083333333333333\n",
      "9769 번째 loss, accuracy:  0.3778284194058138 0.9083333333333333\n",
      "9770 번째 loss, accuracy:  0.3777833253247483 0.9083333333333333\n",
      "9771 번째 loss, accuracy:  0.377738224471454 0.9083333333333333\n",
      "9772 번째 loss, accuracy:  0.3776931168531361 0.9083333333333333\n",
      "9773 번째 loss, accuracy:  0.37764800247700153 0.9083333333333333\n",
      "9774 번째 loss, accuracy:  0.3776028813502622 0.9083333333333333\n",
      "9775 번째 loss, accuracy:  0.3775577534801337 0.9083333333333333\n",
      "9776 번째 loss, accuracy:  0.37751261887383514 0.9083333333333333\n",
      "9777 번째 loss, accuracy:  0.37746747753859017 0.9083333333333333\n",
      "9778 번째 loss, accuracy:  0.3774223294816256 0.9083333333333333\n",
      "9779 번째 loss, accuracy:  0.3773771747101721 0.9083333333333333\n",
      "9780 번째 loss, accuracy:  0.37733201323146404 0.9083333333333333\n",
      "9781 번째 loss, accuracy:  0.37728684505273985 0.9083333333333333\n",
      "9782 번째 loss, accuracy:  0.3772416701812417 0.9083333333333333\n",
      "9783 번째 loss, accuracy:  0.3771964886242155 0.9083333333333333\n",
      "9784 번째 loss, accuracy:  0.3771513003889106 0.9083333333333333\n",
      "9785 번째 loss, accuracy:  0.3771061054825807 0.9083333333333333\n",
      "9786 번째 loss, accuracy:  0.3770609039124827 0.9083333333333333\n",
      "9787 번째 loss, accuracy:  0.37701569568587795 0.9083333333333333\n",
      "9788 번째 loss, accuracy:  0.37697048081003004 0.9083333333333333\n",
      "9789 번째 loss, accuracy:  0.37692525929220805 0.9083333333333333\n",
      "9790 번째 loss, accuracy:  0.3768800311396837 0.9083333333333333\n",
      "9791 번째 loss, accuracy:  0.3768347963597332 0.9083333333333333\n",
      "9792 번째 loss, accuracy:  0.3767895549596361 0.9083333333333333\n",
      "9793 번째 loss, accuracy:  0.37674430694667493 0.9083333333333333\n",
      "9794 번째 loss, accuracy:  0.37669905232813666 0.9083333333333333\n",
      "9795 번째 loss, accuracy:  0.3766537911113123 0.9083333333333333\n",
      "9796 번째 loss, accuracy:  0.37660852330349626 0.9083333333333333\n",
      "9797 번째 loss, accuracy:  0.3765632489119857 0.9083333333333333\n",
      "9798 번째 loss, accuracy:  0.3765179679440827 0.9083333333333333\n",
      "9799 번째 loss, accuracy:  0.37647268040709264 0.9083333333333333\n",
      "9800 번째 loss, accuracy:  0.37642738630832434 0.9083333333333333\n",
      "9801 번째 loss, accuracy:  0.3763820856550904 0.9083333333333333\n",
      "9802 번째 loss, accuracy:  0.37633677845470714 0.9083333333333333\n",
      "9803 번째 loss, accuracy:  0.37629146471449404 0.9083333333333333\n",
      "9804 번째 loss, accuracy:  0.376246144441775 0.9083333333333333\n",
      "9805 번째 loss, accuracy:  0.3762008176438767 0.9083333333333333\n",
      "9806 번째 loss, accuracy:  0.3761554843281304 0.9083333333333333\n",
      "9807 번째 loss, accuracy:  0.37611014450187014 0.9083333333333333\n",
      "9808 번째 loss, accuracy:  0.37606479817243454 0.9083333333333333\n",
      "9809 번째 loss, accuracy:  0.3760194453471646 0.9083333333333333\n",
      "9810 번째 loss, accuracy:  0.37597408603340554 0.9083333333333333\n",
      "9811 번째 loss, accuracy:  0.37592872023850604 0.9083333333333333\n",
      "9812 번째 loss, accuracy:  0.3758833479698189 0.9083333333333333\n",
      "9813 번째 loss, accuracy:  0.37583796923469914 0.9083333333333333\n",
      "9814 번째 loss, accuracy:  0.3757925840405071 0.9083333333333333\n",
      "9815 번째 loss, accuracy:  0.37574719239460536 0.9083333333333333\n",
      "9816 번째 loss, accuracy:  0.3757017943043612 0.9083333333333333\n",
      "9817 번째 loss, accuracy:  0.3756563897771444 0.9083333333333333\n",
      "9818 번째 loss, accuracy:  0.3756109788203286 0.9083333333333333\n",
      "9819 번째 loss, accuracy:  0.3755655614412911 0.9083333333333333\n",
      "9820 번째 loss, accuracy:  0.3755201376474126 0.9083333333333333\n",
      "9821 번째 loss, accuracy:  0.37547470744607736 0.9083333333333333\n",
      "9822 번째 loss, accuracy:  0.37542927084467326 0.9083333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9823 번째 loss, accuracy:  0.3753838278505918 0.9083333333333333\n",
      "9824 번째 loss, accuracy:  0.3753383784712276 0.9083333333333333\n",
      "9825 번째 loss, accuracy:  0.37529292271397924 0.9083333333333333\n",
      "9826 번째 loss, accuracy:  0.3752474605862483 0.9083333333333333\n",
      "9827 번째 loss, accuracy:  0.3752019920954404 0.9083333333333333\n",
      "9828 번째 loss, accuracy:  0.37515651724896415 0.9083333333333333\n",
      "9829 번째 loss, accuracy:  0.3751110360542319 0.9083333333333333\n",
      "9830 번째 loss, accuracy:  0.3750655485186592 0.9083333333333333\n",
      "9831 번째 loss, accuracy:  0.3750200546496655 0.9083333333333333\n",
      "9832 번째 loss, accuracy:  0.3749745544546729 0.9083333333333333\n",
      "9833 번째 loss, accuracy:  0.3749290479411083 0.9083333333333333\n",
      "9834 번째 loss, accuracy:  0.37488353511640043 0.9083333333333333\n",
      "9835 번째 loss, accuracy:  0.3748380159879828 0.9083333333333333\n",
      "9836 번째 loss, accuracy:  0.37479249056329145 0.9083333333333333\n",
      "9837 번째 loss, accuracy:  0.37474695884976666 0.9083333333333333\n",
      "9838 번째 loss, accuracy:  0.3747014208548515 0.9083333333333333\n",
      "9839 번째 loss, accuracy:  0.37465587658599253 0.9083333333333333\n",
      "9840 번째 loss, accuracy:  0.3746103260506395 0.9083333333333333\n",
      "9841 번째 loss, accuracy:  0.3745647692562463 0.9083333333333333\n",
      "9842 번째 loss, accuracy:  0.3745192062102697 0.9083333333333333\n",
      "9843 번째 loss, accuracy:  0.3744736369201698 0.9083333333333333\n",
      "9844 번째 loss, accuracy:  0.37442806139340995 0.9083333333333333\n",
      "9845 번째 loss, accuracy:  0.374382479637457 0.9083333333333333\n",
      "9846 번째 loss, accuracy:  0.3743368916597817 0.9083333333333333\n",
      "9847 번째 loss, accuracy:  0.3742912974678576 0.9083333333333333\n",
      "9848 번째 loss, accuracy:  0.37424569706916155 0.9083333333333333\n",
      "9849 번째 loss, accuracy:  0.374200090471174 0.9083333333333333\n",
      "9850 번째 loss, accuracy:  0.3741544776813786 0.9083333333333333\n",
      "9851 번째 loss, accuracy:  0.3741088587072627 0.9083333333333333\n",
      "9852 번째 loss, accuracy:  0.37406323355631627 0.9083333333333333\n",
      "9853 번째 loss, accuracy:  0.37401760223603275 0.9083333333333333\n",
      "9854 번째 loss, accuracy:  0.3739719647539096 0.9083333333333333\n",
      "9855 번째 loss, accuracy:  0.3739263211174471 0.9166666666666666\n",
      "9856 번째 loss, accuracy:  0.3738806713341482 0.9166666666666666\n",
      "9857 번째 loss, accuracy:  0.37383501541151987 0.9166666666666666\n",
      "9858 번째 loss, accuracy:  0.3737893533570726 0.9166666666666666\n",
      "9859 번째 loss, accuracy:  0.37374368517831996 0.9166666666666666\n",
      "9860 번째 loss, accuracy:  0.37369801088277826 0.9166666666666666\n",
      "9861 번째 loss, accuracy:  0.37365233047796736 0.9166666666666666\n",
      "9862 번째 loss, accuracy:  0.373606643971411 0.9166666666666666\n",
      "9863 번째 loss, accuracy:  0.37356095137063494 0.9166666666666666\n",
      "9864 번째 loss, accuracy:  0.37351525268316926 0.9166666666666666\n",
      "9865 번째 loss, accuracy:  0.3734695479165466 0.9166666666666666\n",
      "9866 번째 loss, accuracy:  0.37342383707830323 0.9166666666666666\n",
      "9867 번째 loss, accuracy:  0.37337812017597877 0.9166666666666666\n",
      "9868 번째 loss, accuracy:  0.3733323972171153 0.9166666666666666\n",
      "9869 번째 loss, accuracy:  0.37328666820925893 0.9166666666666666\n",
      "9870 번째 loss, accuracy:  0.373240933159959 0.9166666666666666\n",
      "9871 번째 loss, accuracy:  0.37319519207676694 0.9166666666666666\n",
      "9872 번째 loss, accuracy:  0.37314944496723823 0.9166666666666666\n",
      "9873 번째 loss, accuracy:  0.37310369183893216 0.9166666666666666\n",
      "9874 번째 loss, accuracy:  0.37305793269940957 0.9166666666666666\n",
      "9875 번째 loss, accuracy:  0.37301216755623606 0.9166666666666666\n",
      "9876 번째 loss, accuracy:  0.37296639641697976 0.9166666666666666\n",
      "9877 번째 loss, accuracy:  0.3729206192892114 0.9166666666666666\n",
      "9878 번째 loss, accuracy:  0.37287483618050554 0.9166666666666666\n",
      "9879 번째 loss, accuracy:  0.37282904709843956 0.9166666666666666\n",
      "9880 번째 loss, accuracy:  0.37278325205059404 0.9166666666666666\n",
      "9881 번째 loss, accuracy:  0.372737451044553 0.9166666666666666\n",
      "9882 번째 loss, accuracy:  0.37269164408790373 0.9166666666666666\n",
      "9883 번째 loss, accuracy:  0.37264583118823524 0.9166666666666666\n",
      "9884 번째 loss, accuracy:  0.3726000123531415 0.9166666666666666\n",
      "9885 번째 loss, accuracy:  0.3725541875902182 0.9166666666666666\n",
      "9886 번째 loss, accuracy:  0.372508356907065 0.9166666666666666\n",
      "9887 번째 loss, accuracy:  0.3724625203112842 0.9166666666666666\n",
      "9888 번째 loss, accuracy:  0.37241667781048104 0.9166666666666666\n",
      "9889 번째 loss, accuracy:  0.37237082941226446 0.9166666666666666\n",
      "9890 번째 loss, accuracy:  0.37232497512424634 0.9166666666666666\n",
      "9891 번째 loss, accuracy:  0.37227911495404087 0.9166666666666666\n",
      "9892 번째 loss, accuracy:  0.37223324890926573 0.9166666666666666\n",
      "9893 번째 loss, accuracy:  0.37218737699754184 0.9166666666666666\n",
      "9894 번째 loss, accuracy:  0.3721414992264932 0.9166666666666666\n",
      "9895 번째 loss, accuracy:  0.37209561560374654 0.9166666666666666\n",
      "9896 번째 loss, accuracy:  0.3720497261369315 0.9166666666666666\n",
      "9897 번째 loss, accuracy:  0.372003830833681 0.9166666666666666\n",
      "9898 번째 loss, accuracy:  0.3719579297016315 0.9166666666666666\n",
      "9899 번째 loss, accuracy:  0.37191202274842183 0.9166666666666666\n",
      "9900 번째 loss, accuracy:  0.37186610998169356 0.9166666666666666\n",
      "9901 번째 loss, accuracy:  0.371820191409092 0.9166666666666666\n",
      "9902 번째 loss, accuracy:  0.3717742670382648 0.9166666666666666\n",
      "9903 번째 loss, accuracy:  0.3717283368768634 0.9166666666666666\n",
      "9904 번째 loss, accuracy:  0.37168240093254057 0.9166666666666666\n",
      "9905 번째 loss, accuracy:  0.3716364592129538 0.9166666666666666\n",
      "9906 번째 loss, accuracy:  0.3715905117257632 0.9166666666666666\n",
      "9907 번째 loss, accuracy:  0.37154455847863077 0.9166666666666666\n",
      "9908 번째 loss, accuracy:  0.3714985994792228 0.9166666666666666\n",
      "9909 번째 loss, accuracy:  0.3714526347352078 0.9166666666666666\n",
      "9910 번째 loss, accuracy:  0.3714066642542574 0.9166666666666666\n",
      "9911 번째 loss, accuracy:  0.37136068804404565 0.9166666666666666\n",
      "9912 번째 loss, accuracy:  0.3713147061122501 0.9166666666666666\n",
      "9913 번째 loss, accuracy:  0.3712687184665514 0.9166666666666666\n",
      "9914 번째 loss, accuracy:  0.37122272511463256 0.9166666666666666\n",
      "9915 번째 loss, accuracy:  0.3711767260641798 0.9166666666666666\n",
      "9916 번째 loss, accuracy:  0.3711307213228821 0.9166666666666666\n",
      "9917 번째 loss, accuracy:  0.3710847108984313 0.9166666666666666\n",
      "9918 번째 loss, accuracy:  0.3710386947985216 0.9166666666666666\n",
      "9919 번째 loss, accuracy:  0.3709926730308515 0.9166666666666666\n",
      "9920 번째 loss, accuracy:  0.3709466456031213 0.9166666666666666\n",
      "9921 번째 loss, accuracy:  0.37090061252303397 0.9166666666666666\n",
      "9922 번째 loss, accuracy:  0.3708545737982962 0.9166666666666666\n",
      "9923 번째 loss, accuracy:  0.37080852943661674 0.9166666666666666\n",
      "9924 번째 loss, accuracy:  0.370762479445708 0.9166666666666666\n",
      "9925 번째 loss, accuracy:  0.3707164238332838 0.9166666666666666\n",
      "9926 번째 loss, accuracy:  0.37067036260706204 0.9166666666666666\n",
      "9927 번째 loss, accuracy:  0.37062429577476336 0.9166666666666666\n",
      "9928 번째 loss, accuracy:  0.3705782233441108 0.9166666666666666\n",
      "9929 번째 loss, accuracy:  0.3705321453228302 0.9166666666666666\n",
      "9930 번째 loss, accuracy:  0.37048606171865034 0.9166666666666666\n",
      "9931 번째 loss, accuracy:  0.37043997253930266 0.9166666666666666\n",
      "9932 번째 loss, accuracy:  0.37039387779252164 0.9166666666666666\n",
      "9933 번째 loss, accuracy:  0.3703477774860448 0.9166666666666666\n",
      "9934 번째 loss, accuracy:  0.37030167162761113 0.9166666666666666\n",
      "9935 번째 loss, accuracy:  0.37025556022496375 0.9166666666666666\n",
      "9936 번째 loss, accuracy:  0.3702094432858477 0.9166666666666666\n",
      "9937 번째 loss, accuracy:  0.370163320818012 0.9166666666666666\n",
      "9938 번째 loss, accuracy:  0.3701171928292068 0.9166666666666666\n",
      "9939 번째 loss, accuracy:  0.37007105932718587 0.9166666666666666\n",
      "9940 번째 loss, accuracy:  0.3700249203197051 0.9166666666666666\n",
      "9941 번째 loss, accuracy:  0.36997877581452415 0.9166666666666666\n",
      "9942 번째 loss, accuracy:  0.3699326258194041 0.9166666666666666\n",
      "9943 번째 loss, accuracy:  0.36988647034211003 0.9166666666666666\n",
      "9944 번째 loss, accuracy:  0.36984030939040885 0.9166666666666666\n",
      "9945 번째 loss, accuracy:  0.3697941429720707 0.9166666666666666\n",
      "9946 번째 loss, accuracy:  0.36974797109486784 0.9166666666666666\n",
      "9947 번째 loss, accuracy:  0.3697017937665753 0.9166666666666666\n",
      "9948 번째 loss, accuracy:  0.3696556109949713 0.9166666666666666\n",
      "9949 번째 loss, accuracy:  0.3696094227878362 0.9166666666666666\n",
      "9950 번째 loss, accuracy:  0.3695632291529532 0.9166666666666666\n",
      "9951 번째 loss, accuracy:  0.36951703009810816 0.9166666666666666\n",
      "9952 번째 loss, accuracy:  0.3694708256310894 0.9166666666666666\n",
      "9953 번째 loss, accuracy:  0.36942461575968816 0.9166666666666666\n",
      "9954 번째 loss, accuracy:  0.3693784004916985 0.9166666666666666\n",
      "9955 번째 loss, accuracy:  0.3693321798349165 0.9166666666666666\n",
      "9956 번째 loss, accuracy:  0.369285953797141 0.9166666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9957 번째 loss, accuracy:  0.3692397223861741 0.9166666666666666\n",
      "9958 번째 loss, accuracy:  0.3691934856098197 0.9166666666666666\n",
      "9959 번째 loss, accuracy:  0.3691472434758844 0.9166666666666666\n",
      "9960 번째 loss, accuracy:  0.36910099599217766 0.9166666666666666\n",
      "9961 번째 loss, accuracy:  0.36905474316651127 0.9166666666666666\n",
      "9962 번째 loss, accuracy:  0.3690084850067001 0.9166666666666666\n",
      "9963 번째 loss, accuracy:  0.368962221520561 0.9166666666666666\n",
      "9964 번째 loss, accuracy:  0.3689159527159141 0.9166666666666666\n",
      "9965 번째 loss, accuracy:  0.36886967860058123 0.9166666666666666\n",
      "9966 번째 loss, accuracy:  0.36882339918238716 0.9166666666666666\n",
      "9967 번째 loss, accuracy:  0.3687771144691593 0.9166666666666666\n",
      "9968 번째 loss, accuracy:  0.3687308244687272 0.9166666666666666\n",
      "9969 번째 loss, accuracy:  0.3686845291889231 0.9166666666666666\n",
      "9970 번째 loss, accuracy:  0.3686382286375817 0.9166666666666666\n",
      "9971 번째 loss, accuracy:  0.3685919228225412 0.9166666666666666\n",
      "9972 번째 loss, accuracy:  0.36854561175164097 0.9166666666666666\n",
      "9973 번째 loss, accuracy:  0.3684992954327234 0.9166666666666666\n",
      "9974 번째 loss, accuracy:  0.36845297387363324 0.9166666666666666\n",
      "9975 번째 loss, accuracy:  0.3684066470822179 0.9166666666666666\n",
      "9976 번째 loss, accuracy:  0.3683603150663272 0.9166666666666666\n",
      "9977 번째 loss, accuracy:  0.36831397783381337 0.9166666666666666\n",
      "9978 번째 loss, accuracy:  0.3682676353925309 0.9166666666666666\n",
      "9979 번째 loss, accuracy:  0.36822128775033736 0.9166666666666666\n",
      "9980 번째 loss, accuracy:  0.3681749349150924 0.9166666666666666\n",
      "9981 번째 loss, accuracy:  0.3681285768946576 0.9166666666666666\n",
      "9982 번째 loss, accuracy:  0.36808221369689814 0.9166666666666666\n",
      "9983 번째 loss, accuracy:  0.3680358453296805 0.9166666666666666\n",
      "9984 번째 loss, accuracy:  0.36798947180087394 0.9166666666666666\n",
      "9985 번째 loss, accuracy:  0.3679430931183505 0.9166666666666666\n",
      "9986 번째 loss, accuracy:  0.3678967092899842 0.9166666666666666\n",
      "9987 번째 loss, accuracy:  0.3678503203236516 0.9166666666666666\n",
      "9988 번째 loss, accuracy:  0.3678039262272318 0.9166666666666666\n",
      "9989 번째 loss, accuracy:  0.3677575270086058 0.9166666666666666\n",
      "9990 번째 loss, accuracy:  0.3677111226756573 0.9166666666666666\n",
      "9991 번째 loss, accuracy:  0.36766471323627287 0.9166666666666666\n",
      "9992 번째 loss, accuracy:  0.3676182986983406 0.9166666666666666\n",
      "9993 번째 loss, accuracy:  0.3675718790697515 0.9166666666666666\n",
      "9994 번째 loss, accuracy:  0.36752545435839806 0.9166666666666666\n",
      "9995 번째 loss, accuracy:  0.36747902457217674 0.9166666666666666\n",
      "9996 번째 loss, accuracy:  0.36743258971898457 0.9166666666666666\n",
      "9997 번째 loss, accuracy:  0.3673861498067218 0.9166666666666666\n",
      "9998 번째 loss, accuracy:  0.36733970484329126 0.9166666666666666\n",
      "9999 번째 loss, accuracy:  0.36729325483659714 0.9166666666666666\n",
      "hidden layer의 Unit 수:  5\n",
      "learningRate:  0.01 , epoch:  10000 , batch_size:  120\n",
      "loss:  0.3672469492339276\n",
      "Train_Data accuracy:  0.9166666666666666\n",
      "Test_Data accuracy:  0.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from tlnn2 import TwoLayerNeuralNetwork2\n",
    "\n",
    "\"\"\" iris Data \"\"\"\n",
    "iris = load_iris()\n",
    "X = iris.data # iris data input\n",
    "y = iris.target # iris target (label)\n",
    "\n",
    "# 데이터 Split Use training : testing = 8 : 2 => 120 : 30\n",
    "suffle = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "for_train = suffle[:120]\n",
    "for_test = suffle[120:]\n",
    "\n",
    "# for training data (X, y)\n",
    "X_train = X[for_train]\n",
    "y_train = y[for_train]\n",
    "# for testing data (X, y)\n",
    "X_test = X[for_test]\n",
    "y_test = y[for_test]\n",
    "\n",
    "\"\"\" hidden layer의 Unit 수 = 5 \"\"\"\n",
    "input_size = 4\n",
    "hidden_size = 5\n",
    "output_size = 3\n",
    "tn2 = TwoLayerNeuralNetwork2(input_size, hidden_size, output_size)\n",
    "tn2.init_data(X_train, y_train)\n",
    "\n",
    "\"\"\" hyperParameter 값 \"\"\"\n",
    "lr = 0.01\n",
    "epoch = 10000\n",
    "batch_size = 120\n",
    "batch = False # 배치 이용\n",
    "check = True # loss와 accuracy의 추이와 Plt 확인\n",
    "\n",
    "lossPlt = []\n",
    "accPlt = []\n",
    "lossPlt, accPlt = tn2.learn(lr, epoch, batch_size, batch, check) # epoch번 반복한 loss와 accuracy의 List를 return \n",
    "    \n",
    "print(\"hidden layer의 Unit 수: \", hidden_size)\n",
    "print(\"learningRate: \", lr, \", epoch: \", epoch, \", batch_size: \", batch_size)\n",
    "# loss, Train_Data accuracy와 Test_Data accuracy 출력\n",
    "print(\"loss: \", tn2.loss(X_train, y_train))\n",
    "print(\"Train_Data accuracy: \", tn2.accuracy(X_train, y_train))\n",
    "print(\"Test_Data accuracy: \", tn2.accuracy(X_test, y_test))\n",
    "\n",
    "# loss와 training accuracy를 Plot\n",
    "x = np.arange(epoch)\n",
    "plt.plot(x, lossPlt, x, accPlt)\n",
    "plt.legend([\"loss\", \"training accuracy\"]) # 각주\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer의 Unit 수:  3\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.9246528107865217 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.540068976343346 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  1.097763721903511 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "평균 loss:  0.8541618363444595\n",
      "평균 Train_Data accuracy:  0.5777777777777778\n",
      "평균 Test_Data accuracy:  0.4666666666666666 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.47436328866599636 , Train_Data accuracy:  0.9416666666666667 , Test_Data accuracy:  0.8333333333333334\n",
      "2 번째 loss:  0.5172706208161766 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.6613289631958658 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.5509876242260129\n",
      "평균 Train_Data accuracy:  0.775\n",
      "평균 Test_Data accuracy:  0.6555555555555556 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.49867571968697 , Train_Data accuracy:  0.925 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.48492761936712225 , Train_Data accuracy:  0.7083333333333334 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.4762846332668041 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.48662932410696547\n",
      "평균 Train_Data accuracy:  0.861111111111111\n",
      "평균 Test_Data accuracy:  0.8444444444444444 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  1.0996668193527237 , Train_Data accuracy:  0.041666666666666664 , Test_Data accuracy:  0.03333333333333333\n",
      "2 번째 loss:  0.5794788515808406 , Train_Data accuracy:  0.9083333333333333 , Test_Data accuracy:  0.8666666666666667\n",
      "3 번째 loss:  0.6012290423748735 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.7601249044361459\n",
      "평균 Train_Data accuracy:  0.5472222222222222\n",
      "평균 Test_Data accuracy:  0.48888888888888893 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  1.0972329135478787 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "2 번째 loss:  0.6585224931377613 , Train_Data accuracy:  0.8666666666666667 , Test_Data accuracy:  0.8666666666666667\n",
      "3 번째 loss:  0.6019684695385759 , Train_Data accuracy:  0.7666666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.7859079587414053\n",
      "평균 Train_Data accuracy:  0.6611111111111111\n",
      "평균 Test_Data accuracy:  0.5666666666666667 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.6154221974380554 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.6211912451134386 , Train_Data accuracy:  0.9166666666666666 , Test_Data accuracy:  0.9\n",
      "3 번째 loss:  0.7859248949341338 , Train_Data accuracy:  0.65 , Test_Data accuracy:  0.7333333333333333\n",
      "평균 loss:  0.6741794458285426\n",
      "평균 Train_Data accuracy:  0.7527777777777778\n",
      "평균 Test_Data accuracy:  0.7333333333333334 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.6009260816882205 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9333333333333333\n",
      "2 번째 loss:  1.079617007698087 , Train_Data accuracy:  0.5583333333333333 , Test_Data accuracy:  0.43333333333333335\n",
      "3 번째 loss:  0.6193265703880668 , Train_Data accuracy:  0.9166666666666666 , Test_Data accuracy:  0.9\n",
      "평균 loss:  0.7666232199247914\n",
      "평균 Train_Data accuracy:  0.811111111111111\n",
      "평균 Test_Data accuracy:  0.7555555555555555 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  1.0529513553911076 , Train_Data accuracy:  0.4666666666666667 , Test_Data accuracy:  0.5\n",
      "2 번째 loss:  1.0739132505313265 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "3 번째 loss:  1.0983178789350736 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "평균 loss:  1.075060828285836\n",
      "평균 Train_Data accuracy:  0.38888888888888884\n",
      "평균 Test_Data accuracy:  0.3444444444444444 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  1.0347529404143527 , Train_Data accuracy:  0.5583333333333333 , Test_Data accuracy:  0.5333333333333333\n",
      "2 번째 loss:  0.8346612732072352 , Train_Data accuracy:  0.8416666666666667 , Test_Data accuracy:  0.8666666666666667\n",
      "3 번째 loss:  1.094458552323529 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "평균 loss:  0.9879575886483724\n",
      "평균 Train_Data accuracy:  0.5833333333333334\n",
      "평균 Test_Data accuracy:  0.5555555555555555 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  0.6713733388701644 , Train_Data accuracy:  0.8833333333333333 , Test_Data accuracy:  0.8666666666666667\n",
      "2 번째 loss:  0.8780812321048196 , Train_Data accuracy:  0.8583333333333333 , Test_Data accuracy:  0.8666666666666667\n",
      "3 번째 loss:  0.7716510534037866 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.7737018747929235\n",
      "평균 Train_Data accuracy:  0.8111111111111112\n",
      "평균 Test_Data accuracy:  0.7666666666666666 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  1.0986238746203703 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "2 번째 loss:  0.7460832955764379 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.8564033897730401 , Train_Data accuracy:  0.825 , Test_Data accuracy:  0.8333333333333334\n",
      "평균 loss:  0.9003701866566161\n",
      "평균 Train_Data accuracy:  0.6222222222222221\n",
      "평균 Test_Data accuracy:  0.5555555555555555 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.8160479930508778 , Train_Data accuracy:  0.825 , Test_Data accuracy:  0.7333333333333333\n",
      "2 번째 loss:  1.0780216738817374 , Train_Data accuracy:  0.6416666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.8031632064988597 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.7333333333333333\n",
      "평균 loss:  0.8990776244771584\n",
      "평균 Train_Data accuracy:  0.7194444444444444\n",
      "평균 Test_Data accuracy:  0.6777777777777777 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.2670974708749797 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.32687580428487 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.15399615541598252 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9\n",
      "평균 loss:  0.2493231435252774\n",
      "평균 Train_Data accuracy:  0.9611111111111111\n",
      "평균 Test_Data accuracy:  0.9666666666666667 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.2893190448201767 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.08768164258907576 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.09906016250942475 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.15868694997289237\n",
      "평균 Train_Data accuracy:  0.9722222222222222\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.2738312656681344 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.2937337709200498 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.9030571034992511 , Train_Data accuracy:  0.6583333333333333 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.4902073800291451\n",
      "평균 Train_Data accuracy:  0.8555555555555555\n",
      "평균 Test_Data accuracy:  0.8555555555555555 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  0.37354166457063503 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.396213035708706 , Train_Data accuracy:  0.9333333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.5036056922819409 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.424453464187094\n",
      "평균 Train_Data accuracy:  0.8583333333333334\n",
      "평균 Test_Data accuracy:  0.8555555555555555 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.49100584769063266 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.27677951362044634 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 번째 loss:  0.488997980782318 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.41892778069779896\n",
      "평균 Train_Data accuracy:  0.8694444444444445\n",
      "평균 Test_Data accuracy:  0.8444444444444444 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.4889394753375291 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.49190859701392636 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.13653490642755323 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "평균 loss:  0.3724609929263362\n",
      "평균 Train_Data accuracy:  0.7861111111111111\n",
      "평균 Test_Data accuracy:  0.6888888888888888 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.5628581007088073 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  1.0971340861311902 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "3 번째 loss:  0.3944901487985921 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9\n",
      "평균 loss:  0.6848274452128633\n",
      "평균 Train_Data accuracy:  0.6666666666666666\n",
      "평균 Test_Data accuracy:  0.5777777777777778 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  1.09778807471224 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "2 번째 loss:  0.5433580214314367 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.6422196497192142 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.7611219152876303\n",
      "평균 Train_Data accuracy:  0.5777777777777777\n",
      "평균 Test_Data accuracy:  0.4666666666666666 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  0.9995854962654283 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.48606094109728715 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.5969016829903263 , Train_Data accuracy:  0.8833333333333333 , Test_Data accuracy:  0.8666666666666667\n",
      "평균 loss:  0.6941827067843472\n",
      "평균 Train_Data accuracy:  0.8416666666666667\n",
      "평균 Test_Data accuracy:  0.8111111111111112 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  1.0967548676388106 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "2 번째 loss:  1.096482015387117 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "3 번째 loss:  0.49818124689796 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.897139376641296\n",
      "평균 Train_Data accuracy:  0.5499999999999999\n",
      "평균 Test_Data accuracy:  0.5111111111111111 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  0.729773007029313 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.5823110708938224 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  1.0992482523281657 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "평균 loss:  0.8037774434171004\n",
      "평균 Train_Data accuracy:  0.5777777777777778\n",
      "평균 Test_Data accuracy:  0.4666666666666666 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.537862849716107 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.47228249429912383 , Train_Data accuracy:  0.9083333333333333 , Test_Data accuracy:  0.7333333333333333\n",
      "3 번째 loss:  0.5269687616508439 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.5123713685553583\n",
      "평균 Train_Data accuracy:  0.9416666666666668\n",
      "평균 Test_Data accuracy:  0.9111111111111111 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.21029240253488174 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.06914004905153516 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.07455215817161198 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.11799486991934295\n",
      "평균 Train_Data accuracy:  0.9722222222222222\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.3938352206002909 , Train_Data accuracy:  0.9083333333333333 , Test_Data accuracy:  0.9\n",
      "2 번째 loss:  0.19196021306892533 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.18883317512206682 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.25820953626376103\n",
      "평균 Train_Data accuracy:  0.9416666666666668\n",
      "평균 Test_Data accuracy:  0.9666666666666667 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.23144362747781205 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.06359044141606006 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.07125345877848548 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.12209584255745254\n",
      "평균 Train_Data accuracy:  0.9722222222222222\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  0.34708594764416223 , Train_Data accuracy:  0.9333333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.16982122979868797 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.36394581625718214 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.8333333333333334\n",
      "평균 loss:  0.2936176645666774\n",
      "평균 Train_Data accuracy:  0.9527777777777778\n",
      "평균 Test_Data accuracy:  0.9444444444444445 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.28068096373435897 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "2 번째 loss:  0.09671659459597877 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.09463028157622635 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.15734261330218802\n",
      "평균 Train_Data accuracy:  0.9777777777777777\n",
      "평균 Test_Data accuracy:  0.9777777777777779 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.11159283403106904 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.18357842130789953 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.320241640683298 , Train_Data accuracy:  0.9416666666666667 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.20513763200742222\n",
      "평균 Train_Data accuracy:  0.9638888888888889\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.488087480275994 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.4430752213951828 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.1286397280393539 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.3532674765701769\n",
      "평균 Train_Data accuracy:  0.875\n",
      "평균 Test_Data accuracy:  0.8555555555555555 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  0.4057184216259357 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.48880749213585545 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.46966821079374405 , Train_Data accuracy:  0.8916666666666667 , Test_Data accuracy:  0.8\n",
      "평균 loss:  0.45473137485184506\n",
      "평균 Train_Data accuracy:  0.8444444444444444\n",
      "평균 Test_Data accuracy:  0.7888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  0.23170478495195793 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.5999444253785825 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.21492084694740357 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.34885668575931467\n",
      "평균 Train_Data accuracy:  0.8777777777777778\n",
      "평균 Test_Data accuracy:  0.8555555555555555 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  0.5029467983571045 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.5220542585612088 , Train_Data accuracy:  0.8416666666666667 , Test_Data accuracy:  0.7333333333333333\n",
      "3 번째 loss:  0.5603407427966093 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.5284472665716408\n",
      "평균 Train_Data accuracy:  0.8277777777777778\n",
      "평균 Test_Data accuracy:  0.7555555555555555 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 loss:  0.3493350819674064 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9\n",
      "2 번째 loss:  0.5555568003304988 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.3638141581040491 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9\n",
      "평균 loss:  0.4229020134673181\n",
      "평균 Train_Data accuracy:  0.875\n",
      "평균 Test_Data accuracy:  0.7888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.5220285184712382 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.530690956100546 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.5552720980865937 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.535997190886126\n",
      "평균 Train_Data accuracy:  0.6916666666666668\n",
      "평균 Test_Data accuracy:  0.5666666666666667 \n",
      "\n",
      "hidden layer의 Unit 수:  5\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.3379291125755365 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.4012256842789657 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.8333333333333334\n",
      "3 번째 loss:  0.3561418961770701 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.3650988976771908\n",
      "평균 Train_Data accuracy:  0.9638888888888889\n",
      "평균 Test_Data accuracy:  0.9333333333333335 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.2125290557645485 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.2916936844332557 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.3412913693158923 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.2818380365045655\n",
      "평균 Train_Data accuracy:  0.9638888888888889\n",
      "평균 Test_Data accuracy:  0.9555555555555556 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.22846600164606048 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9333333333333333\n",
      "2 번째 loss:  0.31936488971629906 , Train_Data accuracy:  0.9916666666666667 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.26641343177091864 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.27141477437775935\n",
      "평균 Train_Data accuracy:  0.9777777777777779\n",
      "평균 Test_Data accuracy:  0.9555555555555556 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  0.48500205953862835 , Train_Data accuracy:  0.9166666666666666 , Test_Data accuracy:  0.9\n",
      "2 번째 loss:  0.34469976382285866 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.6172085704679919 , Train_Data accuracy:  0.9 , Test_Data accuracy:  0.8666666666666667\n",
      "평균 loss:  0.4823034646098263\n",
      "평균 Train_Data accuracy:  0.9277777777777777\n",
      "평균 Test_Data accuracy:  0.9111111111111111 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.5596253360590067 , Train_Data accuracy:  0.8916666666666667 , Test_Data accuracy:  0.8\n",
      "2 번째 loss:  0.45104222561463236 , Train_Data accuracy:  0.925 , Test_Data accuracy:  0.8666666666666667\n",
      "3 번째 loss:  0.578827577723586 , Train_Data accuracy:  0.75 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.5298317131324083\n",
      "평균 Train_Data accuracy:  0.8555555555555556\n",
      "평균 Test_Data accuracy:  0.7444444444444445 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.6478854851680649 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.5996041530789857 , Train_Data accuracy:  0.6833333333333333 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.44703102030994785 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9333333333333333\n",
      "평균 loss:  0.5648402195189995\n",
      "평균 Train_Data accuracy:  0.7777777777777778\n",
      "평균 Test_Data accuracy:  0.6888888888888888 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.7451854871036481 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.7392239418496558 , Train_Data accuracy:  0.6833333333333333 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.4729595345281697 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.6524563211604911\n",
      "평균 Train_Data accuracy:  0.7833333333333333\n",
      "평균 Test_Data accuracy:  0.7111111111111111 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  0.5339080739720091 , Train_Data accuracy:  0.8833333333333333 , Test_Data accuracy:  0.7333333333333333\n",
      "2 번째 loss:  1.0965017564708768 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "3 번째 loss:  0.6702788190759708 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.7668962165062855\n",
      "평균 Train_Data accuracy:  0.6416666666666667\n",
      "평균 Test_Data accuracy:  0.5222222222222223 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  0.6283704375904091 , Train_Data accuracy:  0.9166666666666666 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  1.0958075249059296 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "3 번째 loss:  1.0845808990021661 , Train_Data accuracy:  0.5916666666666667 , Test_Data accuracy:  0.5333333333333333\n",
      "평균 loss:  0.9362529538328349\n",
      "평균 Train_Data accuracy:  0.6194444444444445\n",
      "평균 Test_Data accuracy:  0.5888888888888889 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  1.0423707636024235 , Train_Data accuracy:  0.48333333333333334 , Test_Data accuracy:  0.43333333333333335\n",
      "2 번째 loss:  0.7870369925692561 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  1.0002743704505976 , Train_Data accuracy:  0.6833333333333333 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.9432273755407591\n",
      "평균 Train_Data accuracy:  0.6194444444444445\n",
      "평균 Test_Data accuracy:  0.5222222222222223 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  0.733870897265877 , Train_Data accuracy:  0.9166666666666666 , Test_Data accuracy:  0.8\n",
      "2 번째 loss:  0.7702013626922853 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.9755830465692612 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.8265517688424745\n",
      "평균 Train_Data accuracy:  0.7666666666666666\n",
      "평균 Test_Data accuracy:  0.6444444444444445 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.8356157847810404 , Train_Data accuracy:  0.8666666666666667 , Test_Data accuracy:  0.8666666666666667\n",
      "2 번째 loss:  0.8192102484530907 , Train_Data accuracy:  0.9 , Test_Data accuracy:  0.8666666666666667\n",
      "3 번째 loss:  1.095739031980805 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "평균 loss:  0.9168550217383119\n",
      "평균 Train_Data accuracy:  0.7055555555555556\n",
      "평균 Test_Data accuracy:  0.6666666666666666 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.10924629204572266 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.10322456204663516 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9\n",
      "3 번째 loss:  0.277073709813474 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.16318152130194394\n",
      "평균 Train_Data accuracy:  0.9694444444444444\n",
      "평균 Test_Data accuracy:  0.9666666666666667 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.3005548949699809 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.0846172989566622 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.09594424831206753 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.16037214741290354\n",
      "평균 Train_Data accuracy:  0.9694444444444444\n",
      "평균 Test_Data accuracy:  0.9555555555555556 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.08362188596567703 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.08257096757312325 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 번째 loss:  0.28750077067403373 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.15123120807094467\n",
      "평균 Train_Data accuracy:  0.975\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  0.46024197048986437 , Train_Data accuracy:  0.9083333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.1513947209284381 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.1268731653812151 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.24616995226650584\n",
      "평균 Train_Data accuracy:  0.9583333333333334\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.14677631020057164 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.14918129231578778 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.18921473551329468 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.16172411267655137\n",
      "평균 Train_Data accuracy:  0.9694444444444444\n",
      "평균 Test_Data accuracy:  0.9555555555555556 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.39307685468760506 , Train_Data accuracy:  0.9333333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.23149572197125046 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.12131017533068553 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.24862758399651366\n",
      "평균 Train_Data accuracy:  0.9611111111111111\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.5364429783238231 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.5238167271625638 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.41645682230100195 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.49223884259579626\n",
      "평균 Train_Data accuracy:  0.7777777777777777\n",
      "평균 Test_Data accuracy:  0.7000000000000001 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  0.4856600915561295 , Train_Data accuracy:  0.7083333333333334 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.5449846169505181 , Train_Data accuracy:  0.9083333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.20608291434997922 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.41224254095220897\n",
      "평균 Train_Data accuracy:  0.8555555555555555\n",
      "평균 Test_Data accuracy:  0.8333333333333334 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  0.19619589679176025 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.25144990254475663 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.47279897391300746 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.3068149244165081\n",
      "평균 Train_Data accuracy:  0.9666666666666667\n",
      "평균 Test_Data accuracy:  0.9777777777777779 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  0.5739725881436264 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.4586123251050965 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.8275502714766177 , Train_Data accuracy:  0.85 , Test_Data accuracy:  0.8333333333333334\n",
      "평균 loss:  0.6200450615751135\n",
      "평균 Train_Data accuracy:  0.8305555555555556\n",
      "평균 Test_Data accuracy:  0.7777777777777778 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  0.9850443513608588 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.33267239398917176 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.27874353981684385 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.5321534283889581\n",
      "평균 Train_Data accuracy:  0.8777777777777778\n",
      "평균 Test_Data accuracy:  0.8555555555555555 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.6629244745222562 , Train_Data accuracy:  0.8333333333333334 , Test_Data accuracy:  0.8\n",
      "2 번째 loss:  0.5734930921207483 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.4676885773222331 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.5680353813217458\n",
      "평균 Train_Data accuracy:  0.8277777777777778\n",
      "평균 Test_Data accuracy:  0.7888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.07026129716799226 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.06228518934522064 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.22198648039011423 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.11817765563444238\n",
      "평균 Train_Data accuracy:  0.9694444444444444\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.06539072163563123 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9\n",
      "2 번째 loss:  0.06981526738416985 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.06907816611754984 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.06809471837911697\n",
      "평균 Train_Data accuracy:  0.9777777777777777\n",
      "평균 Test_Data accuracy:  0.9444444444444445 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.23823847287257033 , Train_Data accuracy:  0.95 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.06602763199727678 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.06523975771754008 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.1231686208624624\n",
      "평균 Train_Data accuracy:  0.9666666666666667\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  0.08645325524633908 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.10497919620042453 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.09127951168454737 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.09423732104377032\n",
      "평균 Train_Data accuracy:  0.975\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.12448066647121232 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.08953066613325496 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.22247714313765377 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.145496158580707\n",
      "평균 Train_Data accuracy:  0.9666666666666667\n",
      "평균 Test_Data accuracy:  0.9777777777777779 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.08371855892483844 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.0799142926303325 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.46582755668509696 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.20982013608008931\n",
      "평균 Train_Data accuracy:  0.9777777777777777\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.48292410275950215 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.47863652278366176 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.4295181342958695 , Train_Data accuracy:  0.925 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.46369291994634443\n",
      "평균 Train_Data accuracy:  0.7694444444444445\n",
      "평균 Test_Data accuracy:  0.7111111111111111 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  0.17326213569158164 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.13253007977929138 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.16630652111533434 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.15736624552873577\n",
      "평균 Train_Data accuracy:  0.9722222222222222\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 loss:  0.11860951079563109 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.11825621975244953 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.13336445504385122 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.1234100618639773\n",
      "평균 Train_Data accuracy:  0.9805555555555555\n",
      "평균 Test_Data accuracy:  0.9777777777777779 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  0.18922467475126953 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  1.0964231994552616 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "3 번째 loss:  0.5109632204776912 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.5988703648947408\n",
      "평균 Train_Data accuracy:  0.7638888888888888\n",
      "평균 Test_Data accuracy:  0.7444444444444445 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  0.4950319750982674 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.5179214008378323 , Train_Data accuracy:  0.9333333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.31873296384384225 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.44389544659331404\n",
      "평균 Train_Data accuracy:  0.8611111111111112\n",
      "평균 Test_Data accuracy:  0.8222222222222223 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.3594600189976939 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.26875987531016066 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.23944985232279034 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.2892232488768816\n",
      "평균 Train_Data accuracy:  0.9694444444444444\n",
      "평균 Test_Data accuracy:  0.9777777777777779 \n",
      "\n",
      "hidden layer의 Unit 수:  7\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.43050405161934757 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.2741555888670736 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.21666248511337297 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.30710737519993137\n",
      "평균 Train_Data accuracy:  0.9666666666666667\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.22577049324791784 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.2639388715048692 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.30417015322341284 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9333333333333333\n",
      "평균 loss:  0.26462650599206666\n",
      "평균 Train_Data accuracy:  0.9611111111111111\n",
      "평균 Test_Data accuracy:  0.9666666666666668 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.4284122251367541 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.8333333333333334\n",
      "2 번째 loss:  0.5089765290104513 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.26596862681137223 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.4011191269861925\n",
      "평균 Train_Data accuracy:  0.8694444444444445\n",
      "평균 Test_Data accuracy:  0.7999999999999999 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  1.0800813002209917 , Train_Data accuracy:  0.5166666666666667 , Test_Data accuracy:  0.5\n",
      "2 번째 loss:  0.5810736864945667 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.5027180385311648 , Train_Data accuracy:  0.9416666666666667 , Test_Data accuracy:  0.9\n",
      "평균 loss:  0.7212910084155744\n",
      "평균 Train_Data accuracy:  0.7166666666666668\n",
      "평균 Test_Data accuracy:  0.6555555555555556 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.5835420293256172 , Train_Data accuracy:  0.9166666666666666 , Test_Data accuracy:  0.7333333333333333\n",
      "2 번째 loss:  0.6109067438901702 , Train_Data accuracy:  0.8833333333333333 , Test_Data accuracy:  0.7666666666666667\n",
      "3 번째 loss:  0.46503557482579677 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9\n",
      "평균 loss:  0.5531614493471947\n",
      "평균 Train_Data accuracy:  0.9194444444444444\n",
      "평균 Test_Data accuracy:  0.7999999999999999 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.6105433412432265 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.6481098542714595 , Train_Data accuracy:  0.9333333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.5344340444319825 , Train_Data accuracy:  0.7 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.5976957466488896\n",
      "평균 Train_Data accuracy:  0.775\n",
      "평균 Test_Data accuracy:  0.6888888888888888 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.47595072139215466 , Train_Data accuracy:  0.925 , Test_Data accuracy:  0.8666666666666667\n",
      "2 번째 loss:  0.5884558782777984 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  1.0991444399052301 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "평균 loss:  0.7211836798583944\n",
      "평균 Train_Data accuracy:  0.6555555555555556\n",
      "평균 Test_Data accuracy:  0.5666666666666667 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  0.683142184860245 , Train_Data accuracy:  0.8 , Test_Data accuracy:  0.7\n",
      "2 번째 loss:  1.0999248721024941 , Train_Data accuracy:  0.36666666666666664 , Test_Data accuracy:  0.26666666666666666\n",
      "3 번째 loss:  0.5160645519195289 , Train_Data accuracy:  0.9333333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "평균 loss:  0.7663772029607561\n",
      "평균 Train_Data accuracy:  0.7000000000000001\n",
      "평균 Test_Data accuracy:  0.6333333333333333 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  0.6495068356920874 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  1.0750244287020767 , Train_Data accuracy:  0.6416666666666667 , Test_Data accuracy:  0.5333333333333333\n",
      "3 번째 loss:  0.6379087077532694 , Train_Data accuracy:  0.7916666666666666 , Test_Data accuracy:  0.6333333333333333\n",
      "평균 loss:  0.7874799907158111\n",
      "평균 Train_Data accuracy:  0.7083333333333334\n",
      "평균 Test_Data accuracy:  0.5777777777777778 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  0.7899835396430746 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.8005489137490802 , Train_Data accuracy:  0.8666666666666667 , Test_Data accuracy:  0.8666666666666667\n",
      "3 번째 loss:  0.8314452444153341 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.8073258992691629\n",
      "평균 Train_Data accuracy:  0.75\n",
      "평균 Test_Data accuracy:  0.6666666666666666 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  0.8020599880538558 , Train_Data accuracy:  0.8416666666666667 , Test_Data accuracy:  0.9\n",
      "2 번째 loss:  0.8879540910000735 , Train_Data accuracy:  0.6833333333333333 , Test_Data accuracy:  0.5666666666666667\n",
      "3 번째 loss:  0.6739528861944364 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.7879889884161219\n",
      "평균 Train_Data accuracy:  0.7388888888888889\n",
      "평균 Test_Data accuracy:  0.6777777777777777 \n",
      "\n",
      "epoch:  1000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  1.0282170210916861 , Train_Data accuracy:  0.4666666666666667 , Test_Data accuracy:  0.43333333333333335\n",
      "2 번째 loss:  0.6550676378212558 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.6333333333333333\n",
      "3 번째 loss:  1.108027260833437 , Train_Data accuracy:  0.35 , Test_Data accuracy:  0.26666666666666666\n",
      "평균 loss:  0.9304373065821263\n",
      "평균 Train_Data accuracy:  0.5027777777777778\n",
      "평균 Test_Data accuracy:  0.4444444444444444 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.09301220360707177 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.08693015909002914 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.07049135425966986 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.08347790565225692\n",
      "평균 Train_Data accuracy:  0.9777777777777777\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 loss:  0.07377780967235595 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.07947494182413672 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.08941828946827775 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.08089034698825681\n",
      "평균 Train_Data accuracy:  0.9777777777777777\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.06882300228656475 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.06541563937647141 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.07569064090499099 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.06997642752267573\n",
      "평균 Train_Data accuracy:  0.9833333333333333\n",
      "평균 Test_Data accuracy:  0.9777777777777779 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  0.15890107378639737 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.144006615122188 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.16467127963602218 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.15585965618153583\n",
      "평균 Train_Data accuracy:  0.975\n",
      "평균 Test_Data accuracy:  0.9666666666666667 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.22874336010039945 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.13187218860305405 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.1747943882620559 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.17846997898850314\n",
      "평균 Train_Data accuracy:  0.9805555555555555\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.4820299785819838 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.13434039504590628 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.46084769678063264 , Train_Data accuracy:  0.8333333333333334 , Test_Data accuracy:  0.7\n",
      "평균 loss:  0.35907269013617427\n",
      "평균 Train_Data accuracy:  0.8305555555555556\n",
      "평균 Test_Data accuracy:  0.7444444444444445 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.3636926924408222 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.4473373992805019 , Train_Data accuracy:  0.9166666666666666 , Test_Data accuracy:  0.9\n",
      "3 번째 loss:  0.5114762056866988 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.4408354324693409\n",
      "평균 Train_Data accuracy:  0.861111111111111\n",
      "평균 Test_Data accuracy:  0.8111111111111112 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  0.230201376829608 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.17626836237801372 , Train_Data accuracy:  0.9916666666666667 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.4694801048827454 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9333333333333333\n",
      "평균 loss:  0.2919832813634557\n",
      "평균 Train_Data accuracy:  0.9777777777777779\n",
      "평균 Test_Data accuracy:  0.9777777777777779 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  0.17633511670268393 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.42983633192315124 , Train_Data accuracy:  0.95 , Test_Data accuracy:  0.9\n",
      "3 번째 loss:  0.24341812644526564 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.28319652502370024\n",
      "평균 Train_Data accuracy:  0.9638888888888889\n",
      "평균 Test_Data accuracy:  0.9555555555555556 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  0.5560262633615821 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.502853320405975 , Train_Data accuracy:  0.7916666666666666 , Test_Data accuracy:  0.6666666666666666\n",
      "3 번째 loss:  0.5146002130599072 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "평균 loss:  0.5244932656091548\n",
      "평균 Train_Data accuracy:  0.725\n",
      "평균 Test_Data accuracy:  0.6 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  0.3543341254534363 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.3123298893468656 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.2619892191326477 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.30955107797764986\n",
      "평균 Train_Data accuracy:  0.9722222222222222\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  5000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.5831285098716051 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.42574510123014514 , Train_Data accuracy:  0.9333333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.4573492429414806 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.48874095134774365\n",
      "평균 Train_Data accuracy:  0.8611111111111112\n",
      "평균 Test_Data accuracy:  0.8222222222222223 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  40\n",
      "1 번째 loss:  0.06895080278172987 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.06769934403301861 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.06294531614003065 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.06653182098492637\n",
      "평균 Train_Data accuracy:  0.9805555555555555\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  80\n",
      "1 번째 loss:  0.06610998183961456 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.06503605516295374 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.06305498228493875 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.06473367309583568\n",
      "평균 Train_Data accuracy:  0.9805555555555555\n",
      "평균 Test_Data accuracy:  0.9666666666666667 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.05 , batch_size:  120\n",
      "1 번째 loss:  0.062172271614967335 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.05957148774844678 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.07193288994891453 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.06455888310410955\n",
      "평균 Train_Data accuracy:  0.9805555555555555\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  40\n",
      "1 번째 loss:  0.0798450874506711 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.08961825705351249 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.10534192519996424 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.0916017565680493\n",
      "평균 Train_Data accuracy:  0.975\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  80\n",
      "1 번째 loss:  0.08596240269022297 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.15004905774593388 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.08851384949657269 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.10817510331090985\n",
      "평균 Train_Data accuracy:  0.9722222222222222\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.02 , batch_size:  120\n",
      "1 번째 loss:  0.09751620510149618 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.14351333967190877 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.09008020394783912 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.11036991624041469\n",
      "평균 Train_Data accuracy:  0.9805555555555555\n",
      "평균 Test_Data accuracy:  1.0 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  40\n",
      "1 번째 loss:  0.15317367648329974 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 번째 loss:  0.18586318941914728 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "3 번째 loss:  0.12748957200990477 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.15550881263745062\n",
      "평균 Train_Data accuracy:  0.9722222222222222\n",
      "평균 Test_Data accuracy:  0.9444444444444445 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  80\n",
      "1 번째 loss:  0.1174204891716839 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "2 번째 loss:  0.20835140436644423 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.11813337205662731 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "평균 loss:  0.1479684218649185\n",
      "평균 Train_Data accuracy:  0.975\n",
      "평균 Test_Data accuracy:  0.9888888888888889 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.01 , batch_size:  120\n",
      "1 번째 loss:  0.10703367774457062 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "2 번째 loss:  0.1197468839965899 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.14371990001533583 , Train_Data accuracy:  0.975 , Test_Data accuracy:  0.9333333333333333\n",
      "평균 loss:  0.12350015391883211\n",
      "평균 Train_Data accuracy:  0.9777777777777777\n",
      "평균 Test_Data accuracy:  0.9555555555555556 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  40\n",
      "1 번째 loss:  0.5241726190668125 , Train_Data accuracy:  0.6916666666666667 , Test_Data accuracy:  0.5666666666666667\n",
      "2 번째 loss:  0.27759854562152964 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  1.0\n",
      "3 번째 loss:  0.4144797948220411 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.4054169865034611\n",
      "평균 Train_Data accuracy:  0.8722222222222222\n",
      "평균 Test_Data accuracy:  0.8555555555555555 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  80\n",
      "1 번째 loss:  0.49862994554579126 , Train_Data accuracy:  0.9083333333333333 , Test_Data accuracy:  0.8\n",
      "2 번째 loss:  0.2768963864444904 , Train_Data accuracy:  0.9583333333333334 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.2696401918887915 , Train_Data accuracy:  0.975 , Test_Data accuracy:  1.0\n",
      "평균 loss:  0.34838884129302433\n",
      "평균 Train_Data accuracy:  0.9472222222222223\n",
      "평균 Test_Data accuracy:  0.9222222222222222 \n",
      "\n",
      "epoch:  10000 , learningRate:  0.005 , batch_size:  120\n",
      "1 번째 loss:  0.24247716444005724 , Train_Data accuracy:  0.9833333333333333 , Test_Data accuracy:  0.9666666666666667\n",
      "2 번째 loss:  0.3457783767142555 , Train_Data accuracy:  0.9416666666666667 , Test_Data accuracy:  0.9666666666666667\n",
      "3 번째 loss:  0.37837615016986786 , Train_Data accuracy:  0.9666666666666667 , Test_Data accuracy:  0.9333333333333333\n",
      "평균 loss:  0.32221056377472684\n",
      "평균 Train_Data accuracy:  0.9638888888888889\n",
      "평균 Test_Data accuracy:  0.9555555555555556 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import load_iris\n",
    "from tlnn2 import TwoLayerNeuralNetwork2\n",
    "\n",
    "\"\"\" iris Data \"\"\"\n",
    "iris = load_iris()\n",
    "X = iris.data # iris data input\n",
    "y = iris.target # iris target (label)\n",
    "\n",
    "# 데이터 Split Use training : testing = 8 : 2 => 120 : 30\n",
    "suffle = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "for_train = suffle[:120]\n",
    "for_test = suffle[120:]\n",
    "\n",
    "# for training data (X, y)\n",
    "X_train = X[for_train]\n",
    "y_train = y[for_train]\n",
    "# for testing data (X, y)\n",
    "X_test = X[for_test]\n",
    "y_test = y[for_test]\n",
    "\n",
    "\"\"\" hidden layer의 Unit 수 = 3, 5, 7, 9 \"\"\"\n",
    "hidden_size = [3, 5, 7]\n",
    "input_size = 4\n",
    "output_size = 3\n",
    "for hid in hidden_size:\n",
    "    print(\"hidden layer의 Unit 수: \", hid)\n",
    "    tn2 = TwoLayerNeuralNetwork2(input_size, hid, output_size)\n",
    "    tn2.init_data(X_train, y_train) # Set Training Data\n",
    "\n",
    "    \"\"\" hyperParameter 값 변화하며 Test \"\"\"\n",
    "    lr = [0.05, 0.02, 0.01, 0.005] # learningRate 0.05, 0.02, 0.01, 0.005\n",
    "    epoch = [1000, 5000, 10000] # epoch 1000, 5000, 10000\n",
    "    batch_size = [40, 80, 120] # batchSize 40, 80, 120\n",
    "    batch = True # 배치 이용\n",
    "    check = False # loss와 accuracy의 추이와 Plt 확인 안함\n",
    "\n",
    "    for e in epoch:\n",
    "        for l in lr:\n",
    "            for b in batch_size:\n",
    "                # 각 lr, epoch, batchsize에서의 loss, Train_Data accuracy, Test_Data accuracy 출력\n",
    "                print(\"epoch: \", e, \", learningRate: \", l, \", batch_size: \", b)\n",
    "                lo, Tr, Te = 0.0, 0.0, 0.0\n",
    "                for i in range(3):\n",
    "                    tn2.learn(l, e, b, batch, check)\n",
    "                    lo1 = tn2.loss(X_train, y_train)\n",
    "                    Tr1, Te1 = tn2.accuracy(X_train, y_train), tn2.accuracy(X_test, y_test)\n",
    "                    tn2.reset() # parameter값들 Reset 해주어야 한다.\n",
    "                    print(i+1, \"번째 loss: \", lo1, \", Train_Data accuracy: \", Tr1,\", Test_Data accuracy: \", Te1)\n",
    "                    lo += lo1\n",
    "                    Tr += Tr1\n",
    "                    Te += Te1\n",
    "                print(\"평균 loss: \", lo / 3.0)\n",
    "                print(\"평균 Train_Data accuracy: \", Tr / 3.0)\n",
    "                print(\"평균 Test_Data accuracy: \", Te / 3.0, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
